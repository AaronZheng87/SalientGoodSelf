## Experiment 1c
In this study, we further control the valence of words using in our experiment. Instead of using label with moral valence, we used valence-neutral names in China. Participant first learn behaviors of the different person, then, they associate the names and shapes. And then they perform a name-shape matching task.

### Method

#### Participants
`r df1c.T.basic$N` college students (`r df1c.T.basic$Nf` female, age = `r df1c.T.basic$Age_mean` $\pm$ `r df1c.T.basic$Age_sd` years) participated. All of them were recruited from Tsinghua University community in 2014. Informed consent was obtained from all participants prior to the experiment according to procedures approved by the local ethics committees. No participant was excluded because they overall accuracy were above 0.6.

#### Stimuli and Tasks
Three geometric shapes (triangle, square, and circle, with 3.7º × 3.7º of visual angle) were presented above a white fixation cross subtending 0.8º × 0.8º of visual angle at the center of the screen. The three most common names were chosen, which are neutral in moral valence before the manipulation.
Three names (Zhang, Wang, Li) were first paired with three paragraphs of behavioral description. Each description includes one sentence of biographic information and four sentences that describing the moral behavioral under that name. To assess the that these three descriptions represented good, neutral, and bad valence, we collected the ratings of three person on six dimensions: morality, likability, trustworthiness, dominance, competence, and aggressiveness, from an independent sample (n = 34, 18 female, age = 19.6 ± 2.05). The rating results showed that the person with morally good behavioral description has higher score on morality (M = 3.59, SD = 0.66) than neutral (M = 0.88, SD = 1.1), *t*(33) = 12.94, *p* < .001, and bad conditions (M = -3.4, SD = 1.1), *t*(33) = 30.78, *p* < .001. Neutral condition was also significant higher than bad conditions $t(33) = 13.9$, $p < .001$ (See supplementary materials).

#### Procedure
After arriving the lab, participants were informed to complete two experimental tasks, first a social memory task to remember three person and their behaviors, after tested for their memory, they will finish a perceptual matching task. 
In the social memory task, the descriptions of three person were presented without time limitation. Participant self-paced to memorized the behaviors of each person. After they memorizing, a recognition task was used to test their memory effect. Each participant was required to have over 95% accuracy before preceding to matching task.
The perceptual learning task was followed, three names were randomly paired with geometric shapes. Participants were required to learn the association and perform a practicing task before they start the formal experimental blocks. They kept practicing until they reached 70% accuracy. Then, they would start the perceptual matching task as in experiment 1a. They finished 6 blocks of perceptual matching trials, each have 120 trials. 

### Data Analysis
Data was analyzed as in experiment 1a. 

### Results

```{r 'ex1c-dprime-rt', fig.cap="RT and *d* prime of Experiment 1c.", fig.height=6, fig.width=10, warning=FALSE}
Val_plot_NHST(df.rt = df1c.v.rt_m, df.d = df1c.v.dprime_l)
```

```{r 1c_rt_dprime, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
# anova for d prime
df1c_dprime_anova <- afex::aov_ez('Subject','dprime',df1c.v.dprime_l,  # using afex's function 
                                  within = c('Valence'))

df1c_dprime_anova_apa <- df1c_dprime_anova %>% papaja::apa_print.afex_aov()

posthoc_1c_d <- emmeans::emmeans(df1c_dprime_anova, "Valence") # compare each valence for both self and other condition
#pairs(posthoc_1c_d)

df1c_RT_anova <- afex::aov_ez('Subject','RT_m',df1c.v.rt_m,     # using afex's function 
                                  within = c('Matchness','Valence'))
df1c_RT_anova_apa <- df1c_RT_anova %>% papaja::apa_print.afex_aov()

```

Figure \@ref(fig:ex1c-dprime-rt) shows *d* prime and reaction times of experiment 1c. We conducted same analysis as in Experiment 1a. Our analysis didn't should effect of valence on *d* prime, `r df1c_dprime_anova_apa$full$Valence`. Neither the effect of valence on RT (`r df1c_RT_anova_apa$full$Valence`) or interaction between valence and matchness on RT (`r df1c_RT_anova_apa$full$Matchness_Valence`).

#### Signal detection theory analysis of accuracy
We fitted a Bayesian hierarchical GLM for SDT. The results showed that when the shapes were tagged with labels with different moral valence, the sensitivity ($d'$) and criteria ($c$) were both influenced. For the $d'$, we found that the shapes tagged with morally good person (2.30, 95% CI[1.93 2.70]) is greater than shapes tagged with moral bad (2.11, 95% CI[1.83 2.42]), $P_{PosteriorComparison} = 0.8$. Shape tagged with morally good person is also greater than shapes tagged with neutral person (2.16, 95% CI[1.88 2.45]), $P_{PosteriorComparison} = 0.75$. 

Interesting, we also found the criteria for three conditions also differ, the shapes tagged with good person has the highest criteria (-0.97, [-1.12 -0.82]), followed by shapes tagged with neutral person(-0.96, [-1.09 -0.83]), and then the shapes tagged with bad person(-1.03, [-1.22 -0.84]). However, pair-wise comparison showed that only showed strong evidence for the difference between good and bad conditions.

```{r 1c_BGLMM_sdt, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
exp1c_sdt_m1 <- fun_sdt_val('1c')
summary(exp1c_sdt_m1)    # check summary
#pp_check(exp1c_sdt_m1)   # posterior predictive check

hypothesis(exp1c_sdt_m1, "ValenceGood:ismatch > ValenceNeutral:ismatch")  # 0.75
hypothesis(exp1c_sdt_m1, "ValenceGood:ismatch > ValenceBad:ismatch")      # .8
hypothesis(exp1c_sdt_m1, "ValenceNeutral:ismatch < ValenceBad:ismatch")   # 0.39
hypothesis(exp1c_sdt_m1, "ValenceGood > ValenceNeutral")  # 0.45
hypothesis(exp1c_sdt_m1, "ValenceGood > ValenceBad")      # 0.71
hypothesis(exp1c_sdt_m1, "ValenceNeutral > ValenceBad")   # 0.77

# extract the population level parameters
# criteria
exp1c_sdt_p <- fun_plot_sdt_val(exp1c_sdt_m1)
```

#### Reaction time
We fitted a Bayesian hierarchical GLM for RTs, with a log-normal distribution as the link function. We used the posterior distribution of the regression coefficient to make statistical inferences. As in previous studies, the matched conditions are much faster than the mismatched trials ($P_{PosteriorComparison} = .75$). We focused on matched trials only, and compared different conditions: Good () is not faster than the neutral (), $P_{PosteriorComparison} = .5$, it was faster than the Bad condition (), $P_{PosteriorComparison} = .88$. And the neutral condition is faster than the bad condition, $P_{PosteriorComparison} = .95$. However, the mismatched trials are largely overlapped. 

```{r 1c_BGLMM_rt, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
exp1c_rt_m1 <- fun_rt_val('1c')

#plot(exp1b_rt_m1, "b_")
summary(exp1c_rt_m1)  # n
#pp_check(exp1c_rt_m1)

hypothesis(exp1c_rt_m1, "ismatch < 0")  # Effect of matchness: Match < mis-match, p = 1
hypothesis(exp1c_rt_m1, "ValenceGood:ismatch < 0")  # Match good < Match Neutral, p = 0.5
hypothesis(exp1c_rt_m1, "ValenceBad:ismatch > 0")   # Match Bad > Match Neutral, p = 0.95
hypothesis(exp1c_rt_m1, "(ValenceGood:ismatch - ValenceBad:ismatch) < 0")   # Match Good < Match Bad, p = 0.86

exp1c_rt_p <- fun_plot_rt_val(exp1c_rt_m1)
```


```{r plot-exp1c-BGLM, fig.cap="Exp1c: Results of Bayesian GLM analysis.",  fig.height=4.5, fig.width=9, warning=FALSE}
library(patchwork)
exp1c_sdt_p[[1]] + exp1c_sdt_p[[2]] + exp1c_sdt_p[[3]] + exp1c_sdt_p[[4]] + exp1c_rt_p[[1]] + exp1c_rt_p[[2]] + exp1c_rt_p[[3]] + exp1c_rt_p[[4]] + plot_annotation(tag_levels = 'A')  + plot_layout(nrow = 4, byrow = FALSE)
```


### HDDM
We fitted our data with HDDM, using the response-coding [also see @Hu_2020_GoodSelf]. We estimated separate drift rate ($v$), non-decision time ($T_{0}$), and boundary separation ($a$) for each condition. We found that the shapes tagged with good person has higher drift rate and higher boundary separation than shapes tagged with both neutral and bad person. Also, the shapes tagged with neutral person has a higher drift rate than shapes tagged with bad person, but not for the boundary separation. Finally, we found that shapes tagged with bad person had longer non-decision time (see figure \@ref(fig:plot-exp1c-HDDM))).


```{r plot-exp1c-HDDM, fig.cap="Exp1c: Results of HDDM.",  fig.height=4.5, fig.width=9, warning=FALSE}
df1c.hddm.group.trace <- readr::read_csv(here::here('HDDM','df1c_group_traces.csv')) # this will keep the '(' and ')' in the column name

params_p <- df1c.hddm.group.trace %>%
  dplyr::mutate(sample = 1:nrow(.)) %>%
  dplyr::select(chain, sample, contains('Match') | contains('Mismatch')) %>%
  tidyr::pivot_longer(.,`a(Match.Bad)`:`t(Mismatch.Neutral)`, names_to = 'conditions', values_to = 'value') %>%
  tidyr::separate(., conditions, into = c('v1', 'valence'), sep= '[.]') %>%       # split into two part
  tidyr::separate(., v1, into = c('param', 'matchness'), sep = '[(]') %>%         # further split the first half into two part
  dplyr::mutate(valence = stringr::str_sub(.$valence, start = 1, end = -2)) %>%   # remove the last two elements ') ' from the strings
  dplyr::arrange(., param) %>%
  tidyr::pivot_wider(., id_cols = c('chain', 'sample', 'matchness', 'valence'), names_from = 'param', values_from = 'value')

params_p %>% 
  dplyr::mutate(valence = factor(valence, levels = c("Good", "Neutral", "Bad")),
                matchness = ifelse(matchness == 'Mismatch', 'Nonmatch', matchness)) %>%
  ggplot2::ggplot(., aes(x = v, y = a, group = valence, color = valence)) +
  geom_point() + 
  scale_colour_brewer(palette = "Dark2") +
  scale_fill_brewer(palette = "Dark2") +
  facet_grid(~ matchness) +
  ylab(expression(paste("Boundary separation ",italic("a"), sep = ' '))) +
  xlab(expression(paste("Drift rate ",italic("v"), sep = ' '))) +
  theme_bw()+
    theme(panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          panel.background = element_blank(),
          panel.border = element_blank(),
          text=element_text(family='Times'),
          legend.title=element_blank(),
          legend.text = element_text(size =16),
          plot.title = element_text(lineheight=.8, face="bold", size = 18, margin=margin(0,0,20,0)),
          axis.text = element_text (size = 16, color = 'black'),
          axis.title = element_text (size = 16),
          #axis.title.x = element_blank(),
          #axis.title.y = element_blank(),
          axis.line.x = element_line(color='black', size = 1),    # increase the size of font
          axis.line.y = element_line(color='black', size = 1),    # increase the size of font
          strip.text = element_text (size = 16, color = 'black'), # size of text in strips, face = "bold"
          panel.spacing = unit(3, "lines")
    ) 
```