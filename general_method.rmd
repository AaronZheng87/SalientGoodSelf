# General methods
## Design and Procedure
This series of experiments studied the perceptual process of moral character, using the social associative learning paradigm (or tagging paradigm)[@Sui_2012_JEPHPP], in which participants first learned the associations between geometric shapes and labels of person with different moral character (e.g., in first three studies, the triangle, square, and circle and good person, neutral person, and bad person, respectively). The associations of the shapes and label were counterbalanced across participants. After remembered the associations, participants finished a practice phase to familiar with the task, in which they viewed one of the shapes upon the fixation while one of the labels below the fixation and judged whether the shape and the label matched the association they learned. When participants reached 60% or higher accuracy at the end of the practicing session, they started the experimental task which was the same as in the practice phase. 

The experiment 1a, 1b, 1c, 2, and 6a shared a 2 (matching: match vs. nonmatch) by 3 (moral character: good person vs. neutral person vs. bad person) within-subject design. Experiment 1a was the first one of the whole series studies and found the prioritization of stimuli associated with good-person. To confirm that it is the moral character that caused the effect, we further conducted experiment 1b, 1c, and 2. More specifically, experiment 1b used different Chinese words as label to test whether the effect only occurred with certain familiar words. Experiment 1c manipulated the moral valence indirectly: participants first learned to associate different moral behaviors with different neutral names, after remembered the association, they then performed the perceptual matching task by associating names with different shapes. Experiment 2 further tested whether the way we presented the stimuli influence the effect of valence, by sequentially presenting labels and shapes. Note that part of participants of experiment 2 were from experiment 1a because we originally planned a cross task comparison. Experiment 6a, which shared the same design as experiment 2, was an EEG experiment which aimed at exploring the neural correlates of the effect. But we will focus on the behavioral results of experiment 6a in the current manuscript.

For experiment 3a, 3b, 4a, 4b, 6b, 7a, and 7b, we included self-reference as another within-subject variable in the experimental design. For example, the experiment 3a directly extend the design of experiment 1a into a 2 (matchness: match vs. nonmatch) by 2 (reference: self vs. other) by 3 (moral valence: good vs. neutral vs. bad) within-subject design. Thus in experiment 3a, there were six conditions (good-self, neutral-self, bad-self, good-other, neutral-other, and bad-other) and six shapes (triangle, square, circle, diamond, pentagon, and trapezoids). The experiment 6b was an EEG experiment extended from experiment 3a but presented the label and shape sequentially. Because of the relatively high working memory load (six label-shape pairs), experiment 6b were conducted in two days: the first day participants finished perceptual matching task as a practice, and the second day, they finished the task again while the EEG signals were recorded. Experiment 3b was designed to separate the self-referential trials and other-referential trials. That is, participants finished two different types of block: in the self-referential blocks, they only responded to good-self, neutral-self, and bad-self, with half match trials and half non-match trials; in the other-reference blocks, they only responded to good-other, neutral-other, and bad-other. Experiment 7a and 7b were designed to test the cross task robustness of the effect we observed in the aforementioned experiments [see, @Hu_2020_GoodSelf]. The matching task in these two experiments shared the same design with experiment 3a, but only with two moral character, i.e., good vs. bad. We didn't include the neutral condition in experiment 7a and 7b because we found that the neutral and bad conditions constantly showed non-significant results in experiment 1 ~ 6.

Experiment 4a and 4b were design to explore the mechanism behind the prioritization of good-self. In 4a, we used only two labels (self vs. other) and two shapes (circle, square). To manipulate the moral valence, we added the moral-related words within the shape and instructed participants to ignore the words in the shape during the task. In 4b, we reversed the role of self-reference and valence in the task: participant learnt three labels (good-person, neutral-person, and bad-person) and three shapes (circle, square, and triangle), and the words related to identity, "self" or "other", were presented in the shapes. As in 4a, participants were told to ignore the words inside the shape during the task. 

Finally, experiment 5 was design to test the specificity of the moral valence. We extended experiment 1a with an additional independent variable: domains of the valence words. More specifically, besides the moral valence, we also added valence from other domains: appearance of person (beautiful, neutral, ugly), appearance of a scene (beautiful, neutral, ugly), and emotion (happy, neutral, and sad). Label-shape pairs from different domains were separated into different blocks. 

E-prime 2.0 was used for presenting stimuli and collecting behavioral responses, except that experiment 7a and 7b used Matlab Psychtoolbox [@Brainard_1997;@Pelli_1997]. For participants recruited in Tsinghua University, they finished the experiment individually in a dim-lighted chamber, stimuli were presented on 22-inch CRT monitors and their head were fixed by a chin-rest brace. The distance between participants' eyes and the screen was about 60 cm. The visual angle of geometric shapes was about $3.7^\circ × 3.7^\circ$, the fixation cross is of ($0.8^\circ × 0.8^\circ$ of visual angle) at the center of the screen. The words were of $3.6^\circ$ × $1.6^\circ$ visual angle. The distance between the center of the shape or the word and the fixation cross was $3.5^\circ$ of visual angle. For participants recruited in Wenzhou University, they finished the experiment in a group consisted of 3 ~ 12 participants in a dim-lighted testing room. Participants were required to finished the whole experiment independently. Also, they were instructed to start the experiment at the same time, so that the distraction between participants were minimized. The stimuli were presented on 19-inch CRT monitor. The visual angles are could not be exactly controlled because participants’s chin were not fixed.

In most of these experiments, participant were also asked to fill a battery of questionnaire after they finish the behavioral tasks. All the questionnaire data are open [see, dataset 4 in @Liu_2020_JOPD]. See Table S1 for a summary information about all the experiments. 

## Data analysis

### Analysis of individual study
We used the `tidyverse` of r (see script `Load_save_data.r`) to exclude the practicing trials, invalid trials of each participants, and invalid participants, if there were any, in the raw data. Results of each experiment were then analyzed in two Bayesian approaches. 

#### Bayesian hierarchical generalized linear model (GLM)
We first tested the effect of experimental manipulation using Bayesian hierarchical generalized linear model (BGLM), because it provided three advantages over the classic NHST approach (repeated measure ANOVA or t-tests): first, Bayesian models use posterior distribution of parameter for statistical inference, therefore provided uncertainty in estimation [@Rouder_2005_BHM_SDT],second, BGLM can use distribution that fit the real distribution, which is the case for reaction time data [@Rousselet_2019], third, BGLM also integrated different levels of analysis, fully account the variability from each participants. We used the r package `BRMs` [@Bürkner_2017] to build the model, which used Stan [@Carpenter_2017_stan] to sample from the posterior. 

#### Signal detection theory
As in [@Hu_2020_GoodSelf; @Sui_2012_JEPHPP], we also used signal detection approach to analyze the accuracy data. More specifically, we assume the match trials are sigal and the non-match trials are noise. To estimate the sensitivity and criterion of SDT, we adopted the Bayesian hierarchical GLM approach from [@Rouder_2005_BHM_SDT]. When modelling the accuracy data for one participant, we assume that the accuracy of each trial is Bernoulli distributed (binomial with 1 trial), with probability $p_{i}$ that $y_{i} = 1$. 

$$ y_{i} \sim Bernoulli(p_{i})$$
In the perceptual matching task, the probability $p_{i}$ can then be modeled as a function of the trial type:

$$ \Phi(p_{i}) =  \beta_{0} + \beta_{1}IsMatch_{i}  * Valence_{i} $$
The outcomes $y_{i}$ are 0 if the participant responded "nonmatch" on trial $i$, 1 if they responded "match". The probability of the "match" response for trial $i$ for a participant is $p_{i}$. We then write the generalized linear model on the probits (z-scores; $\Phi$, "Phi") of $p$s. $\Phi$ is the cumulative normal density function and maps $z$ scores to probabilities. Given this parameterization, the intercept of the model ($\beta_0$) is the standardized false alarm rate (probability of saying 1 when predictor is 0), which we take as our criterion $c$. The slope of the model ($\beta_1$) is the increase of saying 1 when predictor is 1, in $z$-scores,  which is another expression of $d'$. Therefore, $c$ = -$z$HR = $-\beta_0$, and $d' = \beta_1$.

In each experiment, we had multiple participants, to estimate the group-level parameters, we need to estimate parameters on individual level and the group level parameter simultaneously. In this case, as above, we first assume that the outcome of each trial is Bernoulli distributed, with probability $p_{ij}$ that $y_{ij} = 1$. 

$$ y_{ij} \sim Bernoulli(p_{ij})$$
And the the generalized linear model was re-written to include two levels:
$$ \Phi(p_{ij}) =  \beta_{0j} + \beta_{1j}IsMatch_{ij} * Valence_{ij}$$
The outcomes $y_{ij}$ are 0 if participant $j$ responded "nonmatch" on trial $i$, 1 if they responded "match". The probability of the "match" response for trial $i$ for subject $j$ is $p_{ij}$. We again can write the generalized linear model on the probits (z-scores; $\Phi$, "Phi") of $p$s. 

The subjective-specific intercepts ($\beta_{0} = -zFAR$) and slopes ($\beta_{1} = d'$) are describe by multivariate normal with means and a covariance matrix for the parameters.
$$ \begin{bmatrix}\beta_{0j}\\
\beta_{1j}\\
\end{bmatrix} \sim N(\begin{bmatrix}\theta_{0}\\
\theta_{1}\\
\end{bmatrix}, \sum) $$

For experiments that had 2 (matching: match vs. non-match) by 3 (moral character: good vs. neutral vs. bad), i.e., experiment 1a, 1b, 1c, 2, 5, and 6a, the formula for BGLM is as follow:

`saymatch ~ 0 + Valence + Valence:ismatch + (0 + Valence + Valence:ismatch | Subject), family = bernoulli(link="probit")`

For the reaction time, we used the log normal distribution (https://lindeloev.github.io/shiny-rt/#34_(shifted)_log-normal) to model the data. This means that we need to estimate the posterior of two parameters: $\mu$, $\sigma$. $\mu$ is the mean of the logNormal distribution, and $\sigma$ is the disperse of the distribution. The log normal distribution can be extended to shifted log normal distribution, with one more parameter: shift, which is the earliest possible response. The reaction time is a linear function of trial type:

$$y_{ij} = \beta_{0j} + \beta_{1j}*IsMatch_{ij} * Valence_{ij}$$

while the log of the reaction time is log-normal distributed:
$$ log(y_{ij}) \sim N(\mu_{j}, \sigma_{j})$$ 
$y_{ij}$ is the RT of the $i$th trial of the $j$th participants.

$$\mu_{j} \sim N(\mu, \sigma)$$

$$\sigma_{j} \sim Cauchy()$$


#### Hierarchical drift diffusion model (HDDM)
To further explore the psychological mechanism under perceptual decision-making, we used a generative mode drift diffusion model to model our RTs and accuracy data. As the hypothesis testing part, we also used hierarchical Bayesian model to fit the DDM. The package we used was the HDDM [@wiecki_hddm_2013], a python package for fitting hierarchical DDM. We used the prior implemented in HDDM, that is, weakly informative priors that constrains parameter estimates to be in the range of plausible values based on past literature [@matzke_psychological_2009]. As reported in @Hu_2020_GoodSelf, we used the stimulus code approach, match response were coded as 1 and nonmatch responses were coded as 0. To fully explore all parameters, we allow all four parameters of DDM free to vary. We then extracted the estimation of all the four parameters for each participants for the correlation analyses. However, because the starting point is only related to response (match vs. non-match) but not the valence of the stimuli, we didn't included it in correlation analysis.

### Synthesized results
We also reported the synthesized results from the experiments, because many of them shared the similar experimental design. We reported the results in five parts: valence effect, explicit interaction between valence and self-relevance, implicit interaction between valence and self-relevance, specificity of valence effect, and behavior-questionnaire correlation. 

We estimated the synthesized effect size using Bayesian hierarchical model, which extended the two-level hierarchical model in each experiment into three-level model, which experiment as an additional level. For SDT, we can use a nested hierarchical model to model all the experiment with similar design:
$$y_{ijk} \sim Bernoulli(p_{ijk})$$
where 
$$ \Phi(p_{ijk}) =  \beta_{0jk} + \beta_{1jk}IsMatch_{ijk}$$
The outcomes $y_{ijk}$ are 0 if participant $j$ in experiment k responded "nonmatch" on trial $i$, 1 if they responded "match". 

$$\begin{bmatrix}\beta_{0jk}\\
\beta_{1jk}\\
\end{bmatrix} \sim N(\begin{bmatrix}\theta_{0k}\\
\theta_{1k}\\
\end{bmatrix}, \sum)$$

and the experiment level parameter $mu_{0k}$ and $mu_{1k}$ is from a higher order distribution:

$$\begin{bmatrix}\theta_{0k}\\
\theta_{1k}\\
\end{bmatrix} \sim N(\begin{bmatrix}\mu_{0}\\
\mu_{1}\\
\end{bmatrix}, \sum)$$
in which $\mu_{0}$ and $\mu_{1}$ means the population level parameter.

This model can be easily expand to three-level model in which participants and experiments are two group level variable and participants were nested in the experiments.

$$ log(y_{ijk}) \sim N(\mu_{jk}, \sigma_{jk})$$ 

$y_{ijk}$ is the RT of the $i$th trial of the $j$th participants in the $k$th experiment.

$$\mu_{jk} \sim N(\mu_{k}, \sigma_{k})$$
$$\sigma_{jk} \sim Cauchy()$$
$$\mu_{k} \sim N(\mu, \sigma)$$
$$\theta_{k} \sim Cauchy()$$




Using the Bayesian hierarchical model, we can directly estimate the over-all effect of valence on $d'$ across all experiments with similar experimental design, instead of using a two-step approach where we first estimate the $d'$ for each participant and then use a random effect model meta-analysis [@Goh_2016_mini]. 


#### Valence effect
We synthesized effect size of $d'$ and RT from experiment 1a, 1b, 1c, 2, 5 and 6a for the valence effect. We reported the synthesized the effect across all experiments that tested the valence effect, using the mini meta-analysis approach [@Goh_2016_mini]. 

#### Explicit interaction between Valence and self-relevance
The results from experiment 3a, 3b, 6b, 7a, and 7b. These experiments explicitly included both moral valence and self-reference. 

#### Implicit interaction between valence and self-relevance
In the third part, we focused on experiment 4a and 4b, which were designed to examine the implicit effect of the interaction between moral valence and self-referential processing. We are interested in one particular question: will self-referential and morally positive valence had a mutual facilitation effect. That is, when moral valence (experiment 4a) or self-referential (experiment 4a) was presented as task-irrelevant stimuli, whether they would facilitate self-referential or valence effect on perceptual decision-making. For experiment 4a, we reported the comparisons between different valence conditions under the self-referential task and other-referential task. For experiment 4b, we first calculated the effect of valence for both self- and other-referential conditions and then compared the effect size of these three contrast from self-referential condition and from other-referential condition. Note that the results were also analyzed in a standard repeated measure ANOVA (see supplementary materials).

#### Specificity of the valence effect
In this part, we reported the data from experiment 5, which included positive, neutral, and negative valence from four different domains: morality, aesthetic of person, aesthetic of scene, and emotion. This experiment was design to test whether the positive bias is specific to morality.

#### Behavior-Questionnaire correlation

Finally, we explored correlation between results from behavioral results and self-reported measures. 

For the questionnaire part, we are most interested in the self-rated distance between different person and self-evaluation related questionnaires: self-esteem, moral-self identity, and moral self-image. Other questionnaires (e.g., personality) were not planned to correlated with behavioral data were not included. Note that all data were reported in [@Liu_2020_JOPD].

For the behavioral task part, we used three parameters from drift diffusion model: drift rate (*v*), boundary separation (*a*), and non decision-making time (*t*), because these parameters has relative clear psychological meaning. We used the mean of parameter posterior distribution as the estimate of each parameter for each participants in the correlation analysis.

Based on results form the experiment, we reason that the correlation between behavioral result in self-referential will appear in the data without mentioning the self/other (exp 3a, 3b, 6a, 7a, 7b). To this end, we first calculated the correlation between behavioral indicators and questionnaires for self-referential and other-referential separately. Given the small sample size of the data (N = ), we used a relative liberal threshold for these exploration (alpha = 0.1). 

Then we confirmed the significant results from the data without self- and other-referential (exp1a, 1b, 1c, 2, 5, 6a). In this confirmatory analysis, we used alpha = 0.05 and used bootstrap by `BootES` package [@kirby_bootes_2013] to estimate the correlation. To avoid false positive, we further determined the threshold for significant by permutation. More specifically, for each pairs that initially with  $p < .05$, we randomly shuffle the participants data of each score and calculated the correlation between the shuffled vectors. After repeating this procedure for 5000 times, we choose arrange these 5000 correlation coefficients and use the 95% percentile number as our threshold.