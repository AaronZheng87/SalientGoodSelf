## Experiment 3a
To examine the modulation effect of positive valence was an intrinsic, self-referential process, we designed study 3. In this study, moral valence was assigned to both self and a stranger. We hypothesized that the modulation effect of moral valence will be stronger for the self than for a stranger.

### Method

#### Participants
`r df3a.T.basic$N` college students (`r df3a.T.basic$Nf` female, age = `r df3a.T.basic$Age_mean` $\pm$ `r df3a.T.basic$Age_sd`) participated in experiment 3a. All of them were right-handed, and all had normal or corrected-to-normal vision. Informed consent was obtained from all participants prior to the experiment according to procedures approved by a local ethics committee. One female and one male student did not finish the experiment, and `r nrow(df3a.excld.sub)` participants' data were excluded from analysis because less than 60% overall accuracy, remains `r df3a.v.basic$N` participants (`r df3a.v.basic$Nf` female, age = `r df3a.v.basic$Age_mean` $\pm$ `r df3a.v.basic$Age_sd`).

#### Design
Study 3a combined moral valence with self-relevance, hence the experiment has a   2 × 3 × 2 within-subject design. The first variable was self-relevance, include two levels: self-relevance vs. stranger-relevance; the second variable was moral valence, include good, neutral and bad; the third variable was the matching between shape and label: match vs. nonmatch.

#### Stimuli
The stimuli used in study 3a share the same parameters with experiment 1 & 2. The differences was that we used six shapes: triangle, square, circle, trapezoid, diamond, regular pentagon, and six labels: good self, neutral self, bad self, good person, bad person, and neutral person. To match the concreteness of the label, we asked participant to chosen an unfamiliar name of their own gender to be the stranger.

#### Procedure
After being fully explained and signed the informed consent, participants were instructed to chose a name that can represent a stranger with same gender as the participant themselves, from a common Chinese name pool. Before experiment, the experimenter explained the meaning of each label to participants. For example, the “good self” mean the morally good side of themselves, them could imagine the moment when they do something’s morally applauded, “bad self” means the morally bad side of themselves, they could also imagine the moment when they doing something morally wrong, and “neutral self” means the aspect of self that does not related to morality, they could imagine the moment when they doing something irrelevant to morality. In the same sense, the “good other”, “bad other”, and “neutral other” means the three different aspects of the stranger, whose name was chosen before the experiment. Then, the experiment proceeded as study 1a. Each participant finished 6 blocks, each have 120 trials. The sequence of trials was pseudo-randomized so that there are 10 matched trials for each condition and 10 non-matched trials for each condition (good self, neutral self, bad self, good other, neutral other, bad other) for each block.

#### Data Analysis
Data analysis followed strategies described in the general method section. Reaction times and *d* prime data were analyzed as in study 1 and study 2, except that one more within-subject variable (i.e., self-relevance) was included in the analysis. 

### Results

#### NHST
```{r 'ex3a-dprime-rt', fig.cap="RT and *d* prime of Experiment 3a.", fig.height=6, fig.width=10, warning=FALSE}
#rtdata <- df3a.v.rt_m %>% dplyr::filter(Matchness == "Match") %>% dplyr::rename(RT = RT_m)
#Mplots(expName = 'exp3a', df3a.v.dprime_l,rtdata)

Val_id_plot_NHST(df.rt = df3a.v.rt_m, df.d = df3a.v.dprime_l)

```

Figure \@ref(fig:ex3a-dprime-rt) shows *d* prime and reaction times of experiment 3a. Less than 5% correct trials with less than 200ms reaction times were excluded.

##### d prime

```{r 3a_dprime, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
# anova for d prime
df3a_dprime_anova <- afex::aov_ez('Subject','dprime',df3a.v.dprime_l, within = c('Identity','Valence'))
df3a_dprime_anova_apa <- df3a_dprime_anova %>% papaja::apa_print.afex_aov()

posthoc_3a_d <- emmeans::emmeans(df3a_dprime_anova, "Valence") # compare each valence for both self and other condition
#pairs(posthoc_3a_d)

df3a_dprime_s_anova <- df3a.v.dprime_l %>%
  dplyr::filter(Identity == 'Self') %>%
  afex::aov_ez('Subject','dprime', ., within = c('Valence'))
df3a_dprime_s_anova_apa <- df3a_dprime_s_anova %>% papaja::apa_print.afex_aov()
posthoc_3a_d_s <- emmeans::emmeans(df3a_dprime_s_anova, "Valence")
pairs(posthoc_3a_d_s)

df3a_dprime_o_anova <- df3a.v.dprime_l %>%
  dplyr::filter(Identity == 'Other') %>%
  afex::aov_ez('Subject','dprime', ., within = c('Valence'))
df3a_dprime_o_anova_apa <- df3a_dprime_o_anova %>% papaja::apa_print.afex_aov()
posthoc_3a_d_o <- emmeans::emmeans(df3a_dprime_o_anova, "Valence")
pairs(posthoc_3a_d_o)

```
There was evidence for the main effect of valence, `r df3a_dprime_anova_apa$full$Valence`, and main effect of self-relevance, `r df3a_dprime_anova_apa$full$Identity`, as well as the interaction, `r df3a_dprime_anova_apa$full$Identity_Valence`. 

We then conducted separated ANOVA for self-referential and other-referential trials. The valence effect was shown for the self-referential conditions, `r df3a_dprime_s_anova_apa$full$Valence`. Post-hoc test revealed that the Good-Self condition (1.97 $\pm$ 0.14) was with greater *d* prime than Netural condition (1.41 $\pm$ 0.12, *t*(34) = 4.505, *p* = 0.0002), and Bad-self condition (1.43 $\pm$ 0.102),  *t*(34) = 3.856, *p* = 0.0014. There was difference between neutral and bad condition, *t*(34) = -0.238, *p* = 0.9694. However, no effect of valence was found for the other-referential condition `r df3a_dprime_o_anova_apa$full$Valence`.

##### Reaction time

```{r 3a_RT, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
df3a_RT_anova <- afex::aov_ez('Subject','RT_m',df3a.v.rt_m,     # using afex's function 
                                  within = c('Matchness','Identity','Valence'))
df3a_RT_anova_apa <- df3a_RT_anova %>% papaja::apa_print.afex_aov()
```

We found interaction between Matchness and Valence (`r df3a_RT_anova_apa$full$Matchness_Valence`) and then analyzed the matched trials and nonmatch trials separately, as in previous experiments.

```{r 3a_RT_match, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
# match trials
df3a_RT_anova_m <- df3a.v.rt_m %>%
  dplyr::filter(Matchness == "Match") %>%
  afex::aov_ez('Subject','RT_m',., within = c('Identity','Valence'))

df3a_RT_anova_m_apa <- df3a_RT_anova_m %>% papaja::apa_print.afex_aov()

#posthoc_3a_rt <- emmeans::emmeans(df3a_RT_anova_m, c('Identity',"Valence")) # compare each valence for both self and other condition
# pairs(posthoc_3a_rt)

df3a_RT_anova_m_s <- df3a.v.rt_m %>%
  dplyr::filter(Matchness == "Match" & Identity == "Self") %>%
  afex::aov_ez('Subject','RT_m',., within = c('Valence'))

df3a_RT_anova_m_s_apa <- df3a_RT_anova_m_s %>% papaja::apa_print.afex_aov()

posthoc_3a_rt_m_s <- emmeans::emmeans(df3a_RT_anova_m_s, 'Valence')
pairs(posthoc_3a_rt_m_s)

df3a_RT_anova_m_o <- df3a.v.rt_m %>%
  dplyr::filter(Matchness == "Match" & Identity == "Other") %>%
  afex::aov_ez('Subject','RT_m',., within = c('Valence'))

df3a_RT_anova_m_o_apa <- df3a_RT_anova_m_o %>% papaja::apa_print.afex_aov()

# nonmatch trials
df3a_RT_anova_nm <- df3a.v.rt_m %>%
  dplyr::filter(Matchness == "Mismatch") %>%
  afex::aov_ez('Subject','RT_m', ., within = c('Identity','Valence'))

df3a_RT_anova_nm_apa <- df3a_RT_anova_nm %>% papaja::apa_print.afex_aov()
```
For the match trials, we found that the interaction between identity and valence, `r df3a_RT_anova_m_apa$full$Identity_Valence`, as well as the main effect of valence `r df3a_RT_anova_m_apa$full$Valence`, but not the effect of identity `r df3a_RT_anova_m_apa$full$Identity`. As for the *d* prime, we separated analyzed the self-referential and other-referential trials. For the Self-referential trials, we found the main effect of valence, `r df3a_RT_anova_m_s_apa$full$Valence`; for the other-referential trials, the effect of valence is weaker, `r df3a_RT_anova_m_o_apa$full$Valence`. We then focused on the self conditions: the good-self condition (713 $\pm$ 12) is faster than neutral- (776 $\pm$ 11.8), *t*(34) = -7.396, *p* < .0001 , and bad-self (772 $\pm$ 10.1) conditions,  *t*(34) = -5.66, *p* < .0001. But there is not difference between neutral- and bad-self conditions, *t*(34) = 0.481, *p* = 0.881.

For the nonmatch trials, we didn't found any strong effect: identity, `r df3a_RT_anova_nm_apa$full$Identity`, valence `r df3a_RT_anova_nm_apa$full$Valence`, or interaction between the two `r df3a_RT_anova_nm_apa$full$Identity_Valence`.


#### BGLM
##### Signal detection theory analysis of accuracy

```{r 3a_BGLMM_sdt, echo=FALSE, results='hide', warning=FALSE, message=FALSE}

exp3a_sdt_m1 <- fun_sdt_val_id('3a')

summary(exp3a_sdt_m1)    # check summary

# check fixed and varying effect using bayestestR
bayestestR::describe_posterior(
  exp3a_sdt_m1,
  effects = "all",
  component = "all",
  test = c("p_direction", "p_significance"),
  centrality = "all"
)
#pp_check(exp3a_sdt_m1)   # posterior predictive check

# d-prime
hypothesis(exp3a_sdt_m1, "IdentitySelf:ValenceGood:ismatch> IdentitySelf:ValenceNeutral:ismatch")  # 1
hypothesis(exp3a_sdt_m1, "IdentitySelf:ValenceGood:ismatch> IdentitySelf:ValenceBad:ismatch")  # 1
hypothesis(exp3a_sdt_m1, "IdentitySelf:ValenceNeutral:ismatch> IdentitySelf:ValenceBad:ismatch")  # .55
hypothesis(exp3a_sdt_m1, "IdentityOther:ValenceGood:ismatch> IdentityOther:ValenceNeutral:ismatch")  # .85
hypothesis(exp3a_sdt_m1, "IdentityOther:ValenceGood:ismatch> IdentityOther:ValenceBad:ismatch ")  # .71
hypothesis(exp3a_sdt_m1, "IdentityOther:ValenceNeutral:ismatch> IdentityOther:ValenceBad:ismatch")  # .27

hypothesis(exp3a_sdt_m1, "IdentitySelf:ValenceGood:ismatch> IdentityOther:ValenceGood:ismatch")  # .73
hypothesis(exp3a_sdt_m1, "IdentitySelf:ValenceNeutral:ismatch> IdentityOther:ValenceNeutral:ismatch")  # .05
hypothesis(exp3a_sdt_m1, "IdentitySelf:ValenceBad:ismatch> IdentityOther:ValenceBad:ismatch")  # .0

hypothesis(exp3a_sdt_m1, "IdentitySelf:ValenceGood > IdentitySelf:ValenceNeutral")  # .73
hypothesis(exp3a_sdt_m1, "IdentitySelf:ValenceGood > IdentitySelf:ValenceBad")  # .9
hypothesis(exp3a_sdt_m1, "IdentitySelf:ValenceNeutral > IdentitySelf:ValenceBad")  # .49
hypothesis(exp3a_sdt_m1, "IdentityOther:ValenceGood > IdentityOther:ValenceNeutral")  # .68
hypothesis(exp3a_sdt_m1, "IdentityOther:ValenceGood > IdentityOther:ValenceBad")  # .92
hypothesis(exp3a_sdt_m1, "IdentityOther:ValenceNeutral> IdentityOther:ValenceBad")  # .8

hypothesis(exp3a_sdt_m1, "IdentitySelf:ValenceGood > IdentityOther:ValenceGood")  # .92
hypothesis(exp3a_sdt_m1, "IdentitySelf:ValenceNeutral > IdentityOther:ValenceNeutral")  # .76
hypothesis(exp3a_sdt_m1, "IdentitySelf:ValenceBad > IdentityOther:ValenceBad")  # .96

# extract the population level parameters
# criteria
exp3a_sdt_p <- exp3a_sdt_m1 %>%
  emmeans::emmeans( ~ ismatch | Identity| Valence) %>%
  tidybayes::gather_emmeans_draws() %>%
  dplyr::mutate(ismatch = ifelse(ismatch == 0, 'criterion', 'd prime'),
                ismatch = factor(ismatch, levels = c('d prime', 'criterion')),
                Valence = factor(Valence, levels = c('Bad', 'Neutral',  'Good')),
                Identity = factor(Identity, levels = c('Self', 'Other'))) %>%
  ggplot2::ggplot(aes(x = Valence, y = .value, group = Identity, color = Identity)) +
  #ggplot2::ggplot(aes(x = Valence, y = .value, group = .draw)) +
  #geom_line(alpha = .01) +
  tidybayes::stat_halfeye() + # position=position_dodge(width = 0.1)
  stat_summary(aes(group = Identity, color = Identity), fun.y = mean, geom = "line"
               #,position=position_dodge(width = 0.1)
               ) +
  #scale_fill_brewer() +
  facet_grid(~ ismatch) +
  theme_classic()
```
We found that the *d* prime is greater when shapes were associated with good self condition than with neutral self or bad self, but shapes associated with bad self and neutral self didn't show differences. comparing the self vs other under three condition revealed that shapes associated with good self is greater than with good other, but with a weak evidence. In contrast, for both neutral and bad valence condition, shapes associated with other had greater *d* prime than with self.

##### Reaction time

```{r 3a_BGLMM_rt, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
exp_name <- '3a'
exp3a_rt_m1 <- fun_rt_val_id(exp_name)

summary(exp3a_rt_m1)  # n

bayestestR::describe_posterior(
  exp3a_rt_m1,
  effects = "all",
  component = "all",
  test = c("p_direction", "p_significance"),
  centrality = "all"
)

#pp_check(exp3a_rt_m1)
rg <- emmeans::ref_grid(exp3a_rt_m1)
em <- emmeans::emmeans(rg, 'ismatch')
summary(em, point.est = median)
emmeans::joint_tests(exp3a_rt_m1)

exp3a_rt_p <- exp3a_rt_m1 %>%
  emmeans::emmeans( ~ ismatch | Identity| Valence) %>%
  tidybayes::gather_emmeans_draws() %>%
  dplyr::mutate(ismatch = ifelse(ismatch == 0, 'nonmatch', 'match'),
              Valence = factor(Valence, levels = c('Bad', 'Neutral',  'Good')),
              Identity = factor(Identity, levels = c('Self', 'Other'))) %>%
  dplyr::rename(log_RT = .value) %>%
  ggplot2::ggplot(aes(x = Valence, y = log_RT, group = Identity, color = Identity)) +
  #ggplot2::ggplot(aes(x = Valence, y = .value, group = .draw)) +
  #geom_line(alpha = .01) +
  tidybayes::stat_halfeye() +
  ggplot2::stat_summary(aes(group = Identity, color = Identity), fun.y = mean, geom = "line") +
  #scale_fill_brewer() +
  facet_grid(~ ismatch) +
  theme_classic()

emm1 <- emmeans::emmeans(exp3a_rt_m1, specs = pairwise ~ Identity | Valence | ismatch)
emm1$contrasts %>% summary(infer = TRUE, point.est = mean)

emm2 <- emmeans::emmeans(exp3a_rt_m1, specs = pairwise ~ Valence | Identity | ismatch)
emm2$contrasts %>% summary(infer = TRUE, point.est = mean)

```

```{r plot-exp3a-BGLM, fig.cap="Exp3a: Results of Bayesian GLM analysis.",  fig.height=4.5, fig.width=9, warning=FALSE}
library(patchwork)
exp3a_sdt_p + exp3a_rt_p + plot_annotation(tag_levels = 'A')  + plot_layout(nrow = 1, byrow = FALSE)
```

In reaction times, we found that same trends in the match trials as in the RT: while the shapes associated with good self was greater than with good other (log mean diff = -0.02858, 95%HPD[-0.070898, 0.0154]), the direction is reversed for neutral and negative condition. see Figure \@ref(fig:plot-exp3a-BGLM) 

### HDDM

```{r plot-exp3a-HDDM, fig.cap="Exp3a: Results of HDDM.",  fig.height=8, fig.width=9, warning=FALSE}
df3a.hddm.group.trace <- readr::read_csv(here::here('HDDM','df3a_group_traces.csv')) # this will keep the '(' and ')' in the column name

params_p <- df3a.hddm.group.trace %>%
  dplyr::mutate(sample = 1:nrow(.)) %>%
  dplyr::select(chain, sample, contains('Match') | contains('Mismatch')) %>%
  tidyr::pivot_longer(.,`a(Other.Match.Bad)`:`t(Self.Mismatch.Neutral)`, names_to = 'conditions', values_to = 'value') %>%
  tidyr::separate(., conditions, into = c('v1', 'matchness','valence'), sep= '[.]') %>%       # split into two part
  tidyr::separate(., v1, into = c('param', 'identity'), sep = '[(]') %>%         # further split the first half into two part
  dplyr::mutate(valence = stringr::str_sub(.$valence, start = 1, end = -2)) %>%   # remove the last two elements ') ' from the strings
  dplyr::arrange(., param) %>%
  tidyr::pivot_wider(., id_cols = c('chain', 'sample', 'matchness', 'identity', 'valence'), names_from = 'param', values_from = 'value')

params_p %>% 
  dplyr::mutate(valence = factor(valence, levels = c("Good", "Neutral", "Bad")),
                matchness = ifelse(matchness == 'Mismatch', 'Nonmatch', matchness)) %>%
  ggplot2::ggplot(., aes(x = v, y = a, group = valence, color = valence)) +
  geom_point() + 
  scale_colour_brewer(palette = "Dark2") +
  scale_fill_brewer(palette = "Dark2") +
  facet_grid(identity ~ matchness) +
  #facet_grid(~ matchness) +
  ylab(expression(paste("Boundary separation ",italic("a"), sep = ' '))) +
  xlab(expression(paste("Drift rate ",italic("v"), sep = ' '))) +
  theme_bw()+
    theme(panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          panel.background = element_blank(),
          panel.border = element_blank(),
          text=element_text(family='Times'),
          legend.title=element_blank(),
          legend.text = element_text(size =16),
          plot.title = element_text(lineheight=.8, face="bold", size = 18, margin=margin(0,0,20,0)),
          axis.text = element_text (size = 16, color = 'black'),
          axis.title = element_text (size = 16),
          #axis.title.x = element_blank(),
          #axis.title.y = element_blank(),
          axis.line.x = element_line(color='black', size = 1),    # increase the size of font
          axis.line.y = element_line(color='black', size = 1),    # increase the size of font
          strip.text = element_text (size = 16, color = 'black'), # size of text in strips, face = "bold"
          panel.spacing = unit(3, "lines")
    ) 
```

We fitted our data with HDDM, using the response-coding [also see @Hu_2020_GoodSelf]. We estimated separate drift rate ($v$), non-decision time ($T_{0}$), and boundary separation ($a$) for each condition. We found that the shapes tagged with good person has higher drift rate and higher boundary separation than shapes tagged with both neutral and bad person. Also, the shapes tagged with neutral person has a higher drift rate than shapes tagged with bad person, but not for the boundary separation. Finally, we found that shapes tagged with bad person had longer non-decision time (see figure \@ref(fig:plot-exp3a-HDDM))).