---
title: "Analyizing the Behavioral Data of Experimental 2"
author: "Chuan-Peng Hu"
date: "2016.09.05"
output: word_document
---
<style type="text/css">

body{ /* Normal  */
   font-family: Times     
   font-size: 12px;
}
td {  /* Table  */
   font-size: 8px;
}
h1 { /* Header 1 */
 font-size: 28px;
}
h2 { /* Header 2 */
 font-size: 22px;
}
h3 { /* Header 3 */
 font-size: 18px;
 color: DarkBlue;
}
code.r{ /* Code block */
  font-size: 10px;
}
pre { /* Code block */
  font-size: 10px
}
</style>


This script is 

```{r Initializing, include=FALSE}
Sys.setlocale("LC_ALL", "English")  # set local encoding to English
Sys.setenv(LANG = "en") # set the feedback language to English
options(scipen = 999)   # force R to output in decimal instead of scientifc notion
options(digits=5)       # limit the number of reporting
rm(list = setdiff(ls(), lsf.str()))  # remove all data but keep functions

pkgTest <- function(x)
 {
   if (!require(x,character.only = TRUE))
  {
    install.packages(x,dep = TRUE)
   if(!require(x,character.only = TRUE)) stop("Package not found")
  }
}

pkgNeeded <- (c("ez","plyr","ggplot2", "reshape2", "MBESS", "bootES"))

lapply(pkgNeeded,pkgTest)
rm('pkgNeeded') # remove the variable 'pkgNeeded';

## using APA style plot ####
# Save some time and stor APA format-related code in an object so you can easily
# use it in multiple plots
windowsFonts(Times=windowsFont("TT Times New Roman")) # explicit mapping to "times"
apatheme=theme_bw()+
        theme(panel.grid.major = element_blank(),
              panel.grid.minor = element_blank(),
              panel.background = element_blank(),
              panel.border = element_blank(),
              text=element_text(family='Times'),
              legend.title=element_blank(),
              legend.position='top',
              axis.line.x = element_line(color='black'),
              axis.line.y = element_line(color='black'))

# define the d prime function
dprime <- function(hit,fa) {
        qnorm(hit) - qnorm(fa)
}

## code for calculate the summary with sE, adopted from cook book for R
summarySE <- function(data=NULL, measurevar, groupvars=NULL, na.rm=FALSE,
                      conf.interval=.95, .drop=TRUE) {
        library(plyr)
        
        # New version of length which can handle NA's : if na.rm == T, don't count the
        length2 <- function(x, na.rm=FALSE){
                if(na.rm) sum(!is.na(x))
                else      length(x)
        }
        
        # this does the summary. For each group's data frame, return a vector with
        # N, mean, and sd
        datac <- ddply(data,groupvars, .drop=.drop,
                       .fun = function(xx,col){
                        c(N    = length2(xx[[col]],na.rm=na.rm),
                          mean = mean(xx[[col]],na.rm=na.rm),
                          sd   = sd  (xx[[col]],na.rm=na.rm)
                           )
                       },
                       measurevar
                       )
        # Rename the "mean" column
        
        datac <- rename(datac,c("mean" = measurevar))
        
        datac$se <- datac$sd /sqrt(datac$N)   # calculate standard error of the mean
        
        # Confidence interval mltiplier for standard error
        # calculate t-statistic for confidence interval:
        # e.g., if conf.interval is .95, use .975 (above/below), and use df = N-1
        ciMult <- qt(conf.interval/2 + .5, datac$N-1)
        datac$ci <- datac$se * ciMult
        
        return (datac)
}

## code for calculate the summary with sE for within subject data, adopted from cook book for R
summarySEwithin <- function(data=NULL, measurevar, betweenvars=NULL, withinvars=NULL,idvar=NULL, na.rm=FALSE, conf.interval=.95, .drop=TRUE) {
        
        # Ensure that the betweenvars and withinvars are factors
        factorvars <- vapply(data[, c(betweenvars, withinvars), drop=FALSE],
                             FUN=is.factor, FUN.VALUE=logical(1))
        
        if (!all(factorvars)) {
                nonfactorvars <- names(factorvars)[!factorvars]
                message("Automatically converting the following non-factors to factors: ",
                        paste(nonfactorvars, collapse = ", "))
                data[nonfactorvars] <- lapply(data[nonfactorvars], factor)
        }
        
        # Get the means from the un-normed data
        datac <- summarySE(data, measurevar, groupvars=c(betweenvars, withinvars),
                           na.rm=na.rm, conf.interval=conf.interval, .drop=.drop)
        
        # Drop all the unused columns (these will be calculated with normed data)
        datac$sd <- NULL
        datac$se <- NULL
        datac$ci <- NULL
        
        # Norm each subject's data
        ndata <- normDataWithin(data, idvar, measurevar, betweenvars, na.rm, .drop=.drop)
        
        # This is the name of the new column
        measurevar_n <- paste(measurevar, "_norm", sep="")
        
        # Collapse the normed data - now we can treat between and within vars the same
        ndatac <- summarySE(ndata, measurevar_n, groupvars=c(betweenvars, withinvars),
                            na.rm=na.rm, conf.interval=conf.interval, .drop=.drop)
        
        # Apply correction from Morey (2008) to the standard error and confidence interval
        #  Get the product of the number of conditions of within-S variables
        nWithinGroups    <- prod(vapply(ndatac[,withinvars, drop=FALSE], FUN=nlevels,
                                        FUN.VALUE=numeric(1)))
        correctionFactor <- sqrt( nWithinGroups / (nWithinGroups-1) )
        
        # Apply the correction factor
        ndatac$sd <- ndatac$sd * correctionFactor
        ndatac$se <- ndatac$se * correctionFactor
        ndatac$ci <- ndatac$ci * correctionFactor
        
        # Combine the un-normed means with the normed results
        merge(datac, ndatac)
}

### code for normalizing the SE
normDataWithin <- function(data=NULL, idvar, measurevar, betweenvars=NULL,
                           na.rm=FALSE, .drop=TRUE) {
        library(plyr)
        
        # Measure var on left, idvar + between vars on right of formula.
        data.subjMean <- ddply(data, c(idvar, betweenvars), .drop=.drop,
                               .fun = function(xx, col, na.rm) {
                                       c(subjMean = mean(xx[,col], na.rm=na.rm))
                               },
                               measurevar,
                               na.rm
        )
        
        # Put the subject means with original data
        data <- merge(data, data.subjMean)
        
        # Get the normalized data in a new column
        measureNormedVar <- paste(measurevar, "_norm", sep="")
        data[,measureNormedVar] <- data[,measurevar] - data[,"subjMean"] +
                mean(data[,measurevar], na.rm=na.rm)
        
        # Remove this subject mean column
        data$subjMean <- NULL
        
        return(data)
}

#
multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
        library(grid)
        
        # Make a list from the ... arguments and plotlist
        plots <- c(list(...), plotlist)
        
        numPlots = length(plots)
        
        # If layout is NULL, then use 'cols' to determine layout
        if (is.null(layout)) {
                # Make the panel
                # ncol: Number of columns of plots
                # nrow: Number of rows needed, calculated from # of cols
                layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
                                 ncol = cols, nrow = ceiling(numPlots/cols))
        }
        
        if (numPlots==1) {
                print(plots[[1]])
                
        } else {
                # Set up the page
                grid.newpage()
                pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))
                
                # Make each plot, in the correct location
                for (i in 1:numPlots) {
                        # Get the i,j matrix positions of the regions that contain this subplot
                        matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))
                        
                        print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
                                                        layout.pos.col = matchidx$col))
                }
        }
}


```

# Experiment 2 

```{r loadingData_e2,echo=FALSE,results='hide'}
df2 <- read.csv("rawdata_exp_behav_moral_asso_2.csv",header = TRUE, sep = ",",stringsAsFactors=FALSE,na.strings=c("","NA"))

# rename colnames
colnames(df2)[colnames(df2)=="Target.ACC"] <- "ACC"
colnames(df2)[colnames(df2)=="Target.RT"] <- "RT"
colnames(df2)[colnames(df2)=="YesNoResp"] <- "matchness"
colnames(df2)[colnames(df2)=="Shape"] <- "morality"

# renames independent variables
df2$morality[df2$morality == "Good"] <- "Moral"
df2$morality[df2$morality == "Normal"] <- "Average"
df2$morality[df2$morality == "Bad"] <- "Immoral"
df2$morality <- factor(df2$morality, levels=c("Moral", "Average","Immoral")) # make the variables in a specified order
# df2$Identity <- factor(df2$Identity, levels=c("Self", "Other"))
df2$matchness[df2$matchness == "Yes"] <- "Match"
df2$matchness[df2$matchness == "No"] <- "Mismatch"
df2$matchness <- factor(df2$matchness, levels=c("Match", "Mismatch"))

```

```{r clean_the_data_e2,echo=FALSE,results='hide',warning=FALSE, message=FALSE}
## Basic information of the data ####
df2.T.basic <- df2[!duplicated(df2$Subject), 1:4]
e2.num.subj <- nrow(df2.T.basic)
e2.numT.female <- sum(df2.T.basic$Sex == 'female');
e2.numT.male <- sum(df2.T.basic$Sex == 'male');
e2.ageT.mean <- round(mean(df2.T.basic$Age),2);
e2.ageT.std <- round(sd(df2.T.basic$Age),2);

injureFingerID <- c(45) # this subjects has an injured right middel finger
ninjure<- length(injureFingerID)
df2 <- df2[!(df2$Subject %in% injureFingerID),]

df2.P <- df2[is.na(df2$BlockList.Sample),]            # data from practice
df2.T <- df2[complete.cases(df2$BlockList.Sample),]   # data from test
# trials that should be excluded from analysis because of less than 200 ms
# note that this should be reconsidered when doinng DDM analysis
# and also the trials without response
e2.excld.trials <- df2.T[df2.T$RT <= 200,]
e2.ratio.excld.trials <- nrow(e2.excld.trials)/nrow(df2.T) # ratio of excluded trials in all triasl.
# caculate the overall accuracy for each subject
df2.acc.g <-  ddply(df2.T,.(Subject), summarise,
                      N = length(ACC),
                      countN = sum(ACC),
                      ACC = sum(ACC)/length(ACC))
e2.excld.sub <- df2.acc.g$Subject[df2.acc.g$ACC < 0.6]
df2.valid <- df2.T[!(df2.T$Subject %in% e2.excld.sub),] # exclude the invalid subjects
length(unique(df2.valid$Subject)) + length(e2.excld.sub) == length(unique(df2$Subject))
# excld.trials3 <- excld.trials[!(excld.trials$Subject %in% e2.excld.sub),]
e2.excld.trials2 <- df2.valid[df2.valid$RT <= 200,]
df2.V <- df2.valid[!(df2.valid$RT <= 200),]  

## Basic information of the data ####
e2.num.excld.sub <- length(unique(e2.excld.sub))
df2.V.basic <- df2.V[!duplicated(df2.V$Subject), 1:4]
e2.numV.female <- sum(df2.V.basic$Sex == 'female');
e2.numV.male <- sum(df2.V.basic$Sex == 'male');
e2.ageV.mean <- round(mean(df2.V.basic$Age),2);
e2.ageV.std <- round(sd(df2.V.basic$Age),2);
e2.ratio.excld.trials2 <- nrow(e2.excld.trials2)/nrow(df2.valid)
```

## Participants
`r e2.num.subj` participants were recruited from local university (`r e2.numT.female` female, age: `r e2.ageT.mean` $\pm$ `r e2.ageT.std`), all participants had normal vision or corrected-to-normal vision and right handed. Data from `r ninjure` participants were excluded from analysis because she has a slightly injured right middle finger, which is used for response.Data from `r e2.num.excld.sub` participants were excluded from analysis due to less than 60% overall accuracy, leaving `r nrow(df2.V.basic)` participants (`r e2.numV.female` female, age: `r e2.ageV.mean` $\pm$ `r e2.ageV.std` years).

##Results
Correct responses shorter than 200 ms were excluded from the analysis, eliminated `r  paste0(formatC(100 * round(e2.ratio.excld.trials2,3)), "%")` of the trials overall. Table 1 shows the accuracy and Reaction times(RTs) of paired trials in Experiment 1. 

###Analaysis of d prime
```{r analyzing d prime e2, echo=FALSE, results='hide',warning=FALSE, message=FALSE}

df2.V$sdt <- NA
for (i in 1:nrow(df2.V)){
        if (df2.V$Target.RESP[i] == df2.V$Target.CRESP[i] & df2.V$matchness[i] == "Match"){
                df2.V$sdt[i] <- "hit"
        } else if (df2.V$Target.RESP[i] == df2.V$Target.CRESP[i] & df2.V$matchness[i] == "Mismatch"){
                df2.V$sdt[i] <- "CR"
        } else if (df2.V$Target.RESP[i] != df2.V$Target.CRESP[i] & df2.V$matchness[i] == "Match"){
                df2.V$sdt[i] <- "miss"
        } else if (df2.V$Target.RESP[i] != df2.V$Target.CRESP[i] & df2.V$matchness[i] == "Mismatch"){
                df2.V$sdt[i] <- "FA"
        }
}

# calculate the number of each for each condition
df2.V.SDT <-  ddply(df2.V,.(Subject,morality,sdt), summarise,
                   N = length(sdt))


# long format to wide
df2.V.SDT_w <- dcast(df2.V.SDT, Subject + morality  ~ sdt,value.var = "N")
df2.V.SDT_w$miss[is.na(df2.V.SDT_w$miss)] <- 0
df2.V.SDT_w$FA[is.na(df2.V.SDT_w$FA)] <- 0
df2.V.SDT_w$hitR <- df2.V.SDT_w$hit/(df2.V.SDT_w$hit + df2.V.SDT_w$miss)
df2.V.SDT_w$faR <- df2.V.SDT_w$FA/(df2.V.SDT_w$FA + df2.V.SDT_w$CR)

# standardized way to deal with the extreme values
for (i in 1:nrow(df2.V.SDT_w)){
        if (df2.V.SDT_w$hitR[i] == 1){
                df2.V.SDT_w$hitR[i] <- 1 - 1/(2*(df2.V.SDT_w$hit[i] + df2.V.SDT_w$miss[i]))
        }
}

for (i in 1:nrow(df2.V.SDT_w)){
        if (df2.V.SDT_w$faR[i] == 0){
                df2.V.SDT_w$faR[i] <- 1/(2*(df2.V.SDT_w$FA[i] + df2.V.SDT_w$CR[i]))
        }
}

# calculate the d prime for each condition
df2.V.SDT_w$dprime <- mapply(dprime,df2.V.SDT_w$hitR,df2.V.SDT_w$faR)

# anova for d prime with 2*2 design
e2.d_anova1 <- ezANOVA(df2.V.SDT_w,dv = dprime, wid = Subject, within=.(morality), type=3)
print(e2.d_anova1)

df2.V.SDT_ww <- dcast(df2.V.SDT_w, Subject ~ morality ,value.var = "dprime")

# t-test
# moral vs immoral
e2.d.t.mrl_imm <- t.test(df2.V.SDT_ww$Moral,df2.V.SDT_ww$Immoral,paired = TRUE)
df2.V.SDT_ww$mrl_imm <- df2.V.SDT_ww$Moral - df2.V.SDT_ww$Immoral
e2.d.mrl_imm.CI <- bootES(df2.V.SDT_ww$mrl_imm,R = 20000, effect.type = "cohens.d")

e2.d.tvalue.mrl_imm <- round(as.numeric(e2.d.t.mrl_imm[[1]]),3)
e2.d.df2.d.mrl_imm <- as.numeric(e2.d.t.mrl_imm[[2]])
e2.d.pvalue.mrl_imm.adj <- p.adjust(as.numeric(e2.d.t.mrl_imm[[3]],"bonferroni",3))
e2.d.cohens.mrl_imm <- round(e2.d.mrl_imm.CI[[1]],4) 
e2.d.CI.L.mrl_imm <- round(e2.d.mrl_imm.CI[[12]][1],4)
e2.d.CI.H.mrl_imm <- round(e2.d.mrl_imm.CI[[12]][2],4)

# moral vs Average
e2.d.t.mrl_ave <- t.test(df2.V.SDT_ww$Moral,df2.V.SDT_ww$Average,paired = TRUE)
df2.V.SDT_ww$mrl_ave <- df2.V.SDT_ww$Moral - df2.V.SDT_ww$Average
e2.d.mrl_ave.CI <- bootES(df2.V.SDT_ww$mrl_ave,R = 20000, effect.type = "cohens.d")

e2.d.tvalue.mrl_ave  <- round(as.numeric(e2.d.t.mrl_ave[[1]]),3)
e2.d.df2.mrl_ave  <- as.numeric(e2.d.t.mrl_ave[[2]])
e2.d.pvalue.mrl_ave.adj <- p.adjust(as.numeric(e2.d.t.mrl_ave[[3]],"bonferroni",3))
e2.d.cohens.mrl_ave <- round(e2.d.mrl_ave.CI[[1]],4) 
e2.d.CI.L.mrl_ave <- round(e2.d.mrl_ave.CI[[12]][1],4)
e2.d.CI.H.mrl_ave <- round(e2.d.mrl_ave.CI[[12]][2],4)

# Immoral vs. Average
e2.d.t.imm_ave <- t.test(df2.V.SDT_ww$Immoral,df2.V.SDT_ww$Average,paired = TRUE)
df2.V.SDT_ww$imm_ave <- df2.V.SDT_ww$Immoral - df2.V.SDT_ww$Average
e2.d.imm_ave.CI <- bootES(df2.V.SDT_ww$imm_ave,R = 20000, effect.type = "cohens.d")

e2.d.tvalue.imm_ave <- round(as.numeric(e2.d.t.imm_ave[[1]]),3)
e2.d.df2.imm_ave <- as.numeric(e2.d.t.imm_ave[[2]])
e2.d.pvalue.imm_ave.adj <- p.adjust(as.numeric(e2.d.t.imm_ave[[3]],"bonferroni",3))
e2.d.cohens.imm_ave <- round(e2.d.imm_ave.CI[[1]],4) 
e2.d.CI.L.imm_ave <- round(e2.d.imm_ave.CI[[12]][1],4)
e2.d.CI.H.imm_ave <- round(e2.d.imm_ave.CI[[12]][2],4)


## plot and save the results of d'
# df2.V.SDT.sum <- summarySEwithin(df2.V.SDT_w,measurevar = 'dprime',withinvars = c('morality'), idvar = 'Subject')
df2.V.SDT.sum <- summarySE(df2.V.SDT_w,measurevar = 'dprime',groupvars = c('morality'))
e2.d.mean.ml <- round(df2.V.SDT.sum$dprime[df2.V.SDT.sum$morality == 'Moral'],2)
e2.d.sd.ml <- round(df2.V.SDT.sum$sd[df2.V.SDT.sum$morality == 'Moral'],2)
e2.d.mean.im <- round(df2.V.SDT.sum$dprime[df2.V.SDT.sum$morality == 'Immoral'],2)
e2.d.sd.im <- round(df2.V.SDT.sum$sd[df2.V.SDT.sum$morality == 'Immoral'],2)
e2.d.mean.av <- round(df2.V.SDT.sum$dprime[df2.V.SDT.sum$morality == 'Average'],2)
e2.d.sd.av <-round(df2.V.SDT.sum$sd[df2.V.SDT.sum$morality == 'Average'],2)

e2.p_dprime <- ggplot(data = df2.V.SDT.sum,aes(y = dprime, x = morality, group = morality,shape = morality, fill = morality)) +
        geom_bar(position = position_dodge(),stat = "identity",colour = "black", size=.3, width = .6) +         # Thinner lines
        geom_errorbar(aes(ymin = dprime - se, ymax = dprime + se),
        #geom_errorbar(aes(ymin = 1, ymax = 4),
                      size = .3,
                      width = .2,
                      position=position_dodge(.6)) +
        labs(x = 'Moral valence',y = 'd prime') +
        #ylab(" Reaction times") + 
        #ylim(1, 4) +
        ggtitle("d prime for each condition") +
        coord_cartesian(ylim=c(1,3.5))+
        scale_y_continuous(breaks = seq(1,3.5,0.5),expand = c(0, 0)) +
        scale_fill_grey (start=0.2, end=0.8) +   # using grey scale, start from darker, end to lighter. 
        #theme_classic()
        apatheme  +
        theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank())

# ggsave('e1_dprime_mean_plot.png', width=4, height=6, unit='in', dpi=300)  # save the plot
```

The effect of `r e2.d_anova1[[1]][1,1]`: *F*(`r e2.d_anova1[[1]][1,2]`, `r e2.d_anova1[[1]][1,3]`) = `r round(e2.d_anova1[[1]][1,4],3)`, *p* = `r round(e2.d_anova1[[1]][1,5],4)`, $\eta_g^2$ = `r round(e2.d_anova1[[1]][1,7],4)`

Then we conducted sample effect analysis for (see figure 1).

Moral (*d'* = `r e2.d.mean.ml` $\pm$  `r e2.d.sd.ml`) vs immoral  (*d'* = `r e2.d.mean.im` $\pm$  `r e2.d.sd.im`) association: *t*(`r e2.d.df2.d.mrl_imm`) = `r e2.d.tvalue.mrl_imm`, *p* = 
`r e2.d.pvalue.mrl_imm.adj`, *Cohen's* $d_z$ = `r e2.d.cohens.mrl_imm`, 95% CI [`r e2.d.CI.L.mrl_imm` `r e2.d.CI.H.mrl_imm`]

Moral (*d'* = `r e2.d.mean.ml` $\pm$  `r e2.d.sd.ml`) vs. Average (*d'* = `r e2.d.mean.av` $\pm$  `r e2.d.sd.av`) Association: *t*(`r e2.d.df2.mrl_ave`) = `r e2.d.tvalue.mrl_ave`, *p* = 
`r e2.d.pvalue.mrl_ave.adj`, *Cohen's* $d_z$ = `r e2.d.cohens.mrl_ave`, 95% CI [`r e2.d.CI.L.mrl_ave` `r e2.d.CI.H.mrl_ave`]

Immoral (*d'* = `r e2.d.mean.im` $\pm$  `r e2.d.sd.im`) vs. Average (*d'* = `r e2.d.mean.av` $\pm$  `r e2.d.sd.av`) association: *t*(`r e2.d.df2.imm_ave`) = `r e2.d.tvalue.imm_ave`, *p* = 
`r e2.d.pvalue.imm_ave.adj`, *Cohen's* $d_z$ = `r e2.d.cohens.imm_ave`, 95% CI [`r e2.d.CI.L.imm_ave` `r e2.d.CI.H.imm_ave`]


```{r plot the d prime e2, fig.width=4, fig.height=6,echo=FALSE,warning=FALSE,message=FALSE }
ggplot(data = df2.V.SDT.sum,aes(y = dprime, x = morality, group = morality,shape = morality, fill = morality)) +
        geom_bar(position = position_dodge(),stat = "identity",colour = "black", size=.3, width = .6) +         # Thinner lines
        geom_errorbar(aes(ymin = dprime - se, ymax = dprime + se),
        #geom_errorbar(aes(ymin = 1, ymax = 4),
                      size = .3,
                      width = .2,
                      position=position_dodge(.6)) +
        labs(x = 'Moral valence',y = 'd prime') +
        #ylab(" Reaction times") + 
        #ylim(1, 4) +
        ggtitle("d prime for each condition") +
        coord_cartesian(ylim=c(1,3.5))+
        scale_y_continuous(breaks = seq(1,3.5,0.5),expand = c(0, 0)) +
        scale_fill_grey (start=0.2, end=0.8) +   # using grey scale, start from darker, end to lighter. 
        #theme_classic()
        apatheme +
        theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank())
```

###Analaysis of reaction time
```{r analyzing RT e2,echo=FALSE,results='hide',warning=FALSE, message=FALSE}
## plot density of each subject's RT and save them individually
subNo <- unique(df2.V$Subject)
## doing the analysis for RT ####
df2.V.RT <- df2.V[df2.V$ACC ==1,]  # exclued rt data less than 200 ms, and inaccurate data
df2.V.RT.subj <- summarySEwithin(df2.V.RT,measurevar = 'RT', withinvars = c('Subject','matchness','morality'), idvar = 'Subject',na.rm = TRUE)

#df2.V.RT.grand <- summarySEwithin(df2.V.RT.subj,measurevar = 'RT', withinvar = c('matchness','morality'),idvar = 'Subject',na.rm = TRUE)
df2.V.RT.grand <- summarySE(df2.V.RT.subj,measurevar = 'RT', groupvars = c('matchness','morality'),na.rm = TRUE)
df2.V.RT_match <- df2.V.RT[df2.V.RT$matchness == "Match",]
df2.V.RT_mismatch <- df2.V.RT[df2.V.RT$matchness == "Mismatch",]

e2.rt_anova.match <- ezANOVA(df2.V.RT_match,dv = RT, wid = Subject, within=.(morality),within_full=.(morality), type=3)
e2.rt_anova.mismatch <- ezANOVA(df2.V.RT_mismatch,dv = RT, wid = Subject, within=.(morality),within_full=.(morality), type=3)

## t-test for matched trials
df2.V.RT.subj_w <- dcast(df2.V.RT.subj, Subject ~ matchness + morality ,value.var = "RT") 

# moral vs. immoral
e2.rt.t.m.mrl_imm <- t.test(df2.V.RT.subj_w$Match_Moral,df2.V.RT.subj_w$Match_Immoral,paired = TRUE)
df2.V.RT.subj_w$m.mrl_imm <- df2.V.RT.subj_w$Match_Moral - df2.V.RT.subj_w$Match_Immoral
e2.rt.t.m.mrl_imm.CI <- bootES(df2.V.RT.subj_w$m.mrl_imm, R = 20000,effect.type = "cohens.d")

e2.rt.tvalue.mrl_imm  <- round(as.numeric(e2.rt.t.m.mrl_imm [[1]]),3)
e2.rt.df2.mrl_imm  <- as.numeric(e2.rt.t.m.mrl_imm [[2]])
e2.rt.pvalue.mrl_imm.adj <- p.adjust(as.numeric(e2.rt.t.m.mrl_imm [[3]],"bonferroni",3))
e2.rt.cohens.mrl_imm <- round(e2.rt.t.m.mrl_imm.CI[[1]],4) 
e2.rt.CI.L.mrl_imm <- round(e2.rt.t.m.mrl_imm.CI[[12]][1],4)
e2.rt.CI.H.mrl_imm <- round(e2.rt.t.m.mrl_imm.CI[[12]][2],4)

# moral vs. average
e2.rt.t.m.mrl_ave <- t.test(df2.V.RT.subj_w$Match_Moral,df2.V.RT.subj_w$Match_Average,paired = TRUE)
df2.V.RT.subj_w$m.mrl_ave <- df2.V.RT.subj_w$Match_Moral - df2.V.RT.subj_w$Match_Average
e2.rt.t.m.mrl_ave.CI <- bootES(df2.V.RT.subj_w$m.mrl_ave, R = 20000,effect.type = "cohens.d")

e2.rt.tvalue.mrl_ave <- round(as.numeric(e2.rt.t.m.mrl_ave [[1]]),3)
e2.rt.df2.mrl_ave <- as.numeric(e2.rt.t.m.mrl_ave[[2]])
e2.rt.pvalue.mrl_ave.adj <- p.adjust(as.numeric(e2.rt.t.m.mrl_ave[[3]],"bonferroni",3))
e2.rt.cohens.mrl_ave <- round(e2.rt.t.m.mrl_ave.CI[[1]],4) 
e2.rt.CI.L.mrl_ave <- round(e2.rt.t.m.mrl_ave.CI[[12]][1],4)
e2.rt.CI.H.mrl_ave <- round(e2.rt.t.m.mrl_ave.CI[[12]][2],4)

# immoral vs. average
e2.rt.t.m.imm_ave <- t.test(df2.V.RT.subj_w$Match_Immoral,df2.V.RT.subj_w$Match_Average,paired = TRUE)
df2.V.RT.subj_w$m.imm_ave <- df2.V.RT.subj_w$Match_Immoral - df2.V.RT.subj_w$Match_Average
e2.rt.t.m.imm_ave.CI <- bootES(df2.V.RT.subj_w$m.imm_ave, R = 20000,effect.type = "cohens.d")

e2.rt.tvalue.imm_ave <- round(as.numeric(e2.rt.t.m.imm_ave[[1]]),3)
e2.rt.df2.imm_ave  <- as.numeric(e2.rt.t.m.imm_ave[[2]])
e2.rt.pvalue.imm_ave.adj <- p.adjust(as.numeric(e2.rt.t.m.imm_ave[[3]],"bonferroni",3))
e2.rt.cohens.imm_ave <- round(e2.rt.t.m.imm_ave.CI [[1]],4) 
e2.rt.CI.L.imm_ave <- round(e2.rt.t.m.imm_ave.CI[[12]][1],4)
e2.rt.CI.H.imm_ave <- round(e2.rt.t.m.imm_ave.CI[[12]][2],4)

df2.V.RT.grand.match <- df2.V.RT.grand[df2.V.RT.grand$matchness == "Match",]
e2.rt.mean.ml <- round(df2.V.RT.grand.match$RT[df2.V.RT.grand.match$morality == 'Moral'],0)
e2.rt.sd.ml <- round(df2.V.RT.grand.match$sd[df2.V.RT.grand.match$morality == 'Moral'],0)
e2.rt.mean.im <- round(df2.V.RT.grand.match$RT[df2.V.RT.grand.match$morality == 'Immoral'],0)
e2.rt.sd.im <- round(df2.V.RT.grand.match$sd[df2.V.RT.grand.match$morality == 'Immoral'],0)
e2.rt.mean.av <- round(df2.V.RT.grand.match$RT[df2.V.RT.grand.match$morality == 'Average'],0)
e2.rt.sd.av <- round(df2.V.RT.grand.match$sd[df2.V.RT.grand.match$morality == 'Average'],0)

e2.p_rt <- ggplot(data = df2.V.RT.grand.match, aes(x=morality,y=RT,group=morality,shape = morality,fill = morality)) +
        geom_bar(position = position_dodge(),stat = "identity",colour = "black", size=.3, width = .6) +         # Thinner lines
        geom_errorbar(aes(ymin = RT-se, ymax = RT + se),
                      size = .3,
                      width = .2,
                      position=position_dodge(.6)) +
        labs(y = 'Reaction times (ms)') +
        coord_cartesian(ylim=c(500,800))+
        scale_y_continuous(breaks = seq(500,800,50),expand = c(0, 0)) +
        scale_fill_grey (start=0.2, end=0.8) +   # using grey scale, start from darker, end to lighter.
        #ylim(0.3, 0.8) +
        ggtitle("RT for each condition") +
        #scale_y_continuous("Reation Times  (ms)",expand = c(0, 0)) + 
        apatheme +
        theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank())
# ggsave('e1_RT_mean_plot.png', width=4, height=6, unit='in', dpi=300)  # save the plot

tiff(filename = "Figure 2. d prime and RTs of Experiment 2.tiff", width = 8, height = 6, units = 'in', res = 300)
multiplot(e2.p_dprime,e2.p_rt,cols = 2)
dev.off()

```

We conducted two repeated measure ANOVA for RT of matched trials and mismatched trials separately
For the matched trials, 
The effect of `r e2.rt_anova.match[[1]][1,1]`: *F*(`r e2.rt_anova.match[[1]][1,2]`, `r e2.rt_anova.match[[1]][1,3]`) = `r round(e2.rt_anova.match[[1]][1,4],3)`, *p* = `r round(e2.rt_anova.match[[1]][1,5],4)`, $\eta_g^2$ = `r round(e2.rt_anova.match[[1]][1,7],4)`

For the nonmatched trials, 
The effect of `r e2.rt_anova.mismatch[[1]][1,1]`: *F*(`r e2.rt_anova.mismatch[[1]][1,2]`, `r e2.rt_anova.mismatch[[1]][1,3]`) = `r round(e2.rt_anova.mismatch[[1]][1,4],3)`, *p* = `r round(e2.rt_anova.mismatch[[1]][1,5],4)`, $\eta_g^2$ = `r round(e2.rt_anova.mismatch[[1]][1,7],4)`

Then we conducted sample effect analysis for the matched trials.

Moral (RT = `r e2.rt.mean.ml` $\pm$ `r e2.rt.sd.ml`) vs immoral (RT = `r e2.rt.mean.im` $\pm$ `r e2.rt.sd.im`) association : *t*(`r e2.rt.df2.mrl_imm`) = `r e2.rt.tvalue.mrl_imm`, *p* = `r e2.rt.pvalue.mrl_imm.adj`, *Cohen's* $d_z$ = `r e2.rt.cohens.mrl_imm`, 95% CI [`r e2.rt.CI.L.mrl_imm` `r e2.rt.CI.H.mrl_imm`]

Moral (RT = `r e2.rt.mean.ml` $\pm$ `r e2.rt.sd.ml`) vs. average  (RT = `r e2.rt.mean.av` $\pm$ `r e2.rt.sd.av`) association: *t*(`r e2.rt.df2.mrl_ave`) = `r e2.rt.tvalue.mrl_ave`, *p* = `r e2.rt.pvalue.mrl_ave.adj`, *Cohen's* $d_z$ = `r e2.rt.cohens.mrl_ave`, 95% CI [`r e2.rt.CI.L.mrl_ave` `r e2.rt.CI.H.mrl_ave`]

Immoral (RT = `r e2.rt.mean.im` $\pm$ `r e2.rt.sd.im`) vs. average (RT = `r e2.rt.mean.av` $\pm$ `r e2.rt.sd.av`) association: *t*(`r e2.rt.df2.imm_ave`) = `r e2.rt.tvalue.imm_ave`, *p* = `r e2.rt.pvalue.imm_ave.adj`, *Cohen's* $d_z$ = `r e2.rt.cohens.imm_ave`, 95% CI [`r e2.rt.CI.L.imm_ave` `r e2.rt.CI.H.imm_ave`]


```{r plot the RT1 e2, fig.width=4, fig.height=6,echo=FALSE,warning=FALSE,message=FALSE }
# df2.V.RT.grand.match <- df2.V.RT.grand[df2.V.RT.grand$matchness == "match",]
ggplot(data = df2.V.RT.grand.match, aes(x=morality,y=RT,group=morality,shape = morality,fill = morality)) +
        geom_bar(position = position_dodge(),stat = "identity",colour = "black", size=.3, width = .6) +         # Thinner lines
        geom_errorbar(aes(ymin = RT-se, ymax = RT + se),
                      size = .3,
                      width = .2,
                      position=position_dodge(.6)) +
        labs(x = 'Moral valence',y = 'Reaction times (ms)') +
        coord_cartesian(ylim=c(500,800))+
        scale_y_continuous(breaks = seq(500,800,50),expand = c(0, 0)) +
        scale_fill_grey (start=0.2, end=0.8) +   # using grey scale, start from darker, end to lighter.
        #ylim(0.3, 0.8) +
        ggtitle("RT for each condition") +
        #scale_y_continuous("Reation Times  (ms)",expand = c(0, 0)) + 
        apatheme +
        theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank())

```

The above is the reaction time for each condition
