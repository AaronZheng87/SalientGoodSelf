---
title             : "Positivity bias in perceptual matching may reflect a spontaneous self-referential processing"
shorttitle        : "Positivity as spontaneous self-referential processing"

author: 
  - name          : "Hu Chuan-Peng"
    affiliation   : "1,2"
    corresponding : yes    # Define only one corresponding author
    address       : "Langenbeckstr. 1, Neuroimaging Center, University Medical Center Mainz, 55131 Mainz, Germany"
    email         : "hcp4715@gmail.com"
  - name          : "Kaiping Peng"
    affiliation   : "3"
  - name          : "Jie Sui"
    affiliation   : "3,4"

affiliation:
  - id            : "1"
    institution   : "TBA"
  - id            : "2"
    institution   : "Leibniz Institute for Resilience Research, 55131 Mainz, Germany"
  - id            : "3"
    institution   : "Tsinghua University, 100084 Beijing, China"
  - id            : "4"
    institution   : "University of Aberdeen, Aberdeen, Scotland"

authornote: |
  Hu Chuan-Peng, Leibniz Institute for Resilience Research (LIR).
  Kaiping Peng, Department of Psychology, Tsinghua University, 100084 Beijing, China.
  Jie Sui, School of Psychology, University of Aberdeen, Aberdeen, Scotland.

  Authors contriubtion: HCP, JS, & KP design the study, HCP collected the data, HCP analyzed the data and drafted the manuscript. KP & JS supported this project.

abstract: |
  To navigate in a complex social world, individual has learnt to prioritize valuable information. Previous studies suggested the moral related stimuli was prioritized [@gantman_moral_2014;@anderson_visual_2011]. Using social associative learning paradigm (self-tagging paradigm), we found that when geometric shapes, without soical meaning, were associated with different moral valence (morally good, neutral, or bad), the shapes that associated with positive moral valence were prioritized in a perceptual matching task. This patterns of results were robust across different procedures. Further, we tested whether this positivity effect was modulated by self-relevance by manipulating the self-relevance explicitly and found that this moral positivity effect was strong when the moral valence is describing onself, but only weak evidence that such effect occured when the moral valence was describing others. We further found that this effect exist even when the self-relevance or the moral valence were presented as a task-irrelevant information, though the effect size become smaller. We also tested whether the positivity effect only exist in moral domain and found that this effect was not limited to moral domain. Exploratory analyses on task-questionnaire relationship found that moral self-image score (how closely one feel they are to the ideal moral image of themselves) is positively correlated to the *d'* of morally positive condition in singal detection and the drift rate using DDM, while the self-esteem is negatively correlated with *d'* of neutral and morally negative conditions. These results suggest that the positive self prioritzation in perceptual decision-making may reflect ...
  
  <!-- https://tinyurl.com/ybremelq -->
  
keywords          : "Perceptual decision-making, Self, positive bias, morality"
wordcount         : "X"

bibliography      : 
  - r-references.bib
  - endnote.bib

floatsintext      : no
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : yes
mask              : no
draft             : no
figsintext        : no

documentclass     : "apa6"
classoption       : "man"
output            : 
  papaja::apa6_pdf:
    latex_engine  : xelatex

---
 <!-- This documents -->
 
```{r setup, include = FALSE}
#rm(list = ls())
source('Initial.r')

curDir = here::here() # dirname(rstudioapi::getActiveDocumentContext()$path)
figDir = here::here('figures')

# Seed for random number generation
set.seed(42)
options(tinytex.verbose = T) # debug the tex
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed)
```
 <!-- What is the theoretic meaning of the series study? -->

# Introduction

[sentences in bracket are key ideas]

[Morality is the central of human social life]. Its importance is manifested in many ways in human cognition. For example, morality is a basic dimension of person perception [@goodwin_moral_2014; @goodwin_moral_2015; @abele_navigating_2020; @willis_first_2006], moral judgment is common in daily life [].

[Given the importance of morality in social life, moral character, i.e., the ...., is crucial for individual.] More specially, a person needs to both accurately evaluate whether the moral character of others and behave in a way that she is perceived as a moral person, or at least not a morally bad person. The former was usually investigated as person perception in social psychology while the latter was studied separately as moral self-concept, moral self-image, or moral self-enhancement. There are abundant of evidence that people weigh morality heavily in evaluating others [@goodwin_moral_2015] and evaluating the change of identity of others []. These findings suggest that, given the importance of morality in social life, morality has been internalized in socialized individuals, and this internalized moral concept influence how they perceiving, remembering, and making decisions. 

When it comes to self perception, there is accumulating evidence that people actively maintain a good moral-self image. For example,  recent research found that self-enhancement effect is stronger than that in other domains, such as competence or social competence [@tappin_illusion_2017]. Also, participants maintain their moral self-image even after their own unethical behaviors (e.g., cheating)[]. Similarly, when asked how likely they will act ethically or unethically, most participants showed the tendency of less likely to do unethical things []. In other words, existing evidence supported the notion that morality is important in person perception and self-concept, people are motivated to maintain a good moral-self image.

[whether moral character information influence perception?, link to exp1a, b, c, and exp2] Yet, as @freeman_dynamic_2011 put it, the focus of the previous studies is not to explain the perceptual process, rather, they are explaining the higher-order social cognitive processes that come after, e.g., impression, evaluation. That is, current studies on person perception is studies without perceptual process. In other words, the perceptual decision-making process of moral character related information is unknown. Without knowledge of these processes work, we can not have a full picture of how moral information is processed in our cognition. As increasing attention paid to perceptual process of social perception, it's clear that perceptual decision-making is strongly influenced by social factors, such as group-categorization, stereotype [@xiao_perceiving_2016]. Given the importance of moral character and that moral character related information has strong influence on learning and memory [@stanley_moral_2019; @carlson_motivated_2020], one might expect that moral character related information could also play a role in perceptual decision-making.

[using associative learning task to study the moral character's influence on perception] Though theoretically possible, no empirical studies had directly addressed this issue. There were only a few studies about the temporal dynamics of judging the trustworthiness of face [e.g., @dzhelyova_temporal_2012], but trustworthy is not equal to morality. One difficulty of studying moral character's influence on perceptual decision-making is that moral character is a high-level and hidden state instead of observable feature, one also needs moral information, e.g., behavior history, to infer moral character of a person. For example, @anderson_visual_2011 asked participant to first study the behavioral description of faces and then asked participant to perform a perceptual detection task. They found that faces linked with "bad" social behavior are detected faster (but see). 

An alternative is to use abstract semantic concepts to study how these concepts influence perception. After all, abstract concepts of moral character is part of our daily life and it can be used to identify useful constructs in social life. For example, .... Also, different levels of information may form a dynamic network in human brain and visual cues can activate more abstract, non-observable personal traits (e.g., aggressiveness) [@freeman_dynamic_2011; @amodio_social_2019]. If a concept of moral character (e.g., good person) is activated, it should also be able to have influence on perceptual process of the visual cues through the dynamic network, especially when the perceptual decision-making is about the concept-cue association. In this case, abstract concepts of moral character may serve as signal of moral reputation (for others) or moral self-concept. Indeed, previous studies used the moral words and found that moral related information can be perceived faster [@gantman_moral_2014]. If moral character is an important social category, then, as those other social categories (races, education, etc, see @xiao_perceiving_2016), moral character related information might change the perceptual processes.

Here, we used an associative learning paradigm to study how moral character concept change perceptual decision-making. In this paradigm, simple geometric shapes were paired with different words whose dominant use is to describe the moral character of person. Participants first learn the association between shapes and words, i.e. good-person and triangle, building direct association between high-level, hidden moral character and visual cue. After remembered the associations, they perform a matching task to judge whether the shape-word pair presented on the screen match the association they learned. This paradigm has been used in studying the perceptual process of self-concept, but had also proven useful in studying other concepts like social group [@enock_self_2018]. 

Our first question is, whether the words used the in the associative paradigm is really related to the moral character? As we reviewed above, previous theories, especially the interactive dynamic theory, would support this assumption. To validate that moral character concepts activated moral character as a social cue, we used four experiments to explore and validate the paradigm. The first experiment direct adopted associative paradigm and change the words from "self", "other" to "good-person", "neutral-person", and "bad-person". Then, we change the words to the ones that have more explicit moral meaning ("kind-person", "neutral-person", and "evil-person"). Then, as in @anderson_visual_2011, we asked participant to learn the behavioral history of three different names, and then use the names as moral character words. Finally, we also tested that simultaneously present shape-word pair and sequentially present word and shape didn't change the pattern. All of these four experiments showed a robust effect of moral content. 

[possible explanations: person-based self-categorization vs. stimuli-based valence] Then, we explored the underlying mechanism. Two theoretical frameworks are relevant here. The first one is valence theory, which emphasize the importance of valence in perceptual decision-making. Under this framework, the valence of the stimuli drives the perceptual decision-making. There exists three different sub-theories under this framework: Negativity effect, positivity effect, and valence effect. The first one might be the threaten detection theory, which predicted that threatening stimuli are preferentially processed because of the evolutionary advantage. Though appealing in the first glance, this threat-detection theory itself has been questioned for the evidence on which this theory was initially proposed. That is negative prioritized because of the low-level physical features of the stimuli []. given that the physical stimuli associated with moral character are manipulated in our study, we expect the low level feature will not play a role, and therefore we have a low a priori on the negative first prediction. The second prediction is positivity hypothesis, which predict that positive moral character will be prioritized. There are also evidence consistent with this idea. For example, XXX found that trustworthy faces attracted attention more than untrustworthy faces, probably because trustworthy faces are more likely to be the collaborative partners subsequent tasks, which will bring reward. A third possibility is that both negative and positive is faster than neutral because of the valence. The underlying of the valence assumption is that the stimuli presented in the associative task (word-shape pair) can elicit approaching-avoiding motivation. This probability of this assumption is true is low, because the all these stimuli do not have visual cue that really threatening or rewarding. Therefore, the difference in perceptual decision-making make reflect the value of the words to participants, which can be the interaction of the meaning of the words and the participants' idiosyncratic characteristics. 

Previous research converged that, if an object to be of value to an individual, then that object must be judged as relevant to that individual, i.e., self-relevance [@juechems_where_2019; @reicher_perception_2016]. There are two possible way an external stimuli be valuable (relevant) for an individual. First, we might evaluate its rewarding-threatening value, as many previous perceptual research had done. In this explanation, we will view the moral character and the person behind the moral character, as objects and only judge whether they are rewarding or potentially rewarding to us. A different view is that we will still perceive those moral character as human and apply social categorization, i.e., we categorize whether the person behind the moral character is in the same group as we do. However, the above four experiments can not distinguish between these two possibilities, because there are evidence for both reward [@Sui_2012_JEPHPP] and in-group [@enock_self_2018] prioritization.  

[Distinguish two explanations by make self salient, and found relative adv of self: exp3a, 3b, 6b] Though these two framework has similar prediction for the studies with moral character such as "good-person", "neutral person", and "bad person", they have different prediction when if the experiment design include both identity and moral valence. With an orthogonal design, we have good, bad, and neutral conditions for both self and other. In this case the identity become salient and participants are less likely to spontaneously identify good-person as self, but the value of good-person still exists. This means that the social categorization theory predicts participants prioritize good-self but not good-other, while reward-based attention theory predicts participants are both prioritized. Also, as in @Hu_2020_GoodSelf, people may also only identify with good-self instead of neutral or bad self. That is, people will show a unique pattern of self-identification: only good-self is identified as "self" while all the others categories were excluded.

In exp 3a, 3b, and 6b, we found that (1) good-self is always faster than neutral-self and bad-self, but good-other only have weak to null advantage to neutral-other and bad-other. which mean the social categorization is self-centered. (2) good-self's advantage over good other only occur when self- and other- were in the same task. i.e. the relative advantage is competition based instead of absolute. These three experiments suggest that people more like to view the moral character stimuli as person and categorize good-self as an unique category against all others. A meta-analysis showed that there was no effect of valence when the identity is other.

[what we care? valence of the self exp4a or identity of the good exp4b?] Next, we go further to disentangle the self-good complex: people care more about whether the self is good, or whether the good is self, or both? If people care more about whether the self is good, then, subtle cue of the valence may have an impact on perceptual process of the self. In contrast, if people care more about whether the good's identity, i.e., whether the good is self, then subtle cue of identity (self v. other) may have a impact on percpetual process of the good. We tested the good-self complex with two more experiments. In exp 4a (id is task-relevant, valence is task-irrelevant), if people care about the valence of the self, then, the task-irrelevant information may influence the processing of the self. While in exp 4b (valence is task-relevant, id is task-irrelevant), if people care about the id of the good, then, the task-irrelevant id information will has a influence on the process of the good.

[whether categorize self as positive is not limited to morality? no, but limited to traits, yet not state] Self-categorization is not limited to morality, even morality is central to social life. we used aesthetic aspect as another instance. 

[Self-bad as an index of self-reported self-categorization in moral term]

Below are just my thoughts
Still need to thinking about the relationship between several key concepts: self-categorization, morality (moral character), perceptual decision-making, interactive dynamic theory.

As previous studies in social psychology and cognitive psychology found the perceiving self and perceiving others has huge difference, therefore, a question immediately followed is, how the self- and other-related moral character information are processed in perceptual decision-making. To investigate this phenomenon, we included both self- and other-related moral character information in the self-tagging paradigm. abstract moral concepts are prioritized in perceptual decision-making? There are several possible predictions. 

*Self-categories* are cognitive groupings of self and some class of stimuli as identical or different from some other class. [Turner et al.]
*Personal identity* refers to self-categories that define the individual as a unique person in terms of his or her individual differences from other (in-group) persons.
*Social identity* refers to the shared social categorical self ("us" vs. "them").

*variable self*: Who we are, how we see ourselves, how we define our relations to others (indeed whether they are construed as ‘other’ or as part of the extended 'we' self) is different in different settings. 

variable self and morality in perception. self is variable, morality is basic, the point is: how moral other is perceive as extension of self, not reverse.

categorization based on morality and variable self/identity

What is the prediction of the model/theory?

Identification: the degree to which an individual feels connected to an ingroup or includes the ingroup in his or her self-concept. (self is not bad; )

People are more likely to identify themselves with trustworthy faces [@verosky_differential_2010] (trustworthy faces has longer RTs).

In 1950s, @bruner_perceptual_1957 had proposed the "New Look" approach of perception, which was resurrected by accumulating evidence [@stolier_functional_2016; @xiao_perceiving_2016]. These studies supported the view that there is a bidirectional interplay between perception and higher-level cognition, such as stereotype [@stolier_functional_2016; @xiao_perceiving_2016], and self-relevance [@Sui_2012_JEPHPP]. Few studies also tested whether moral-laden information was prioritized in the perception [@anderson_visual_2011; @gantman_moral_2014]. Still, the moral self-image information has rarely been studied (except @Hu_2020_GoodSelf).


Potential theoretical discussion points:
Close distance of the semantic representation of self and moral character (attractor network) (Freeman & Ambady, 2011).
The core/true/authentic self concept.
social meter theory of self-esteem.
evolutionary perspective of morality and moral self-conception, moral identity.

In our experimental setting, we have the following limitations:
The perceptual decision-making will show certain pattern under certain task demand. In our case, it's the forced, speed, two-option choice task.

Additional assumption about the self-moral id:
People will automatically enhance their moral concept, therefore prefer the positive moral self-concept.



# Disclosures
We reported all the measurements, analyses, and results in all the experiments in the current study. Participants whose overall accuracy lower than 60% were excluded from analysis. Also, the accurate responses with less than 200ms reaction times were excluded from the analysis.  

All the experiments reported were not pre-registered. Most experiments (1a ~ 6b, except experiment 3b) reported in the current study were first finished between 2014 to 2016 in Tsinghua University, Beijing, China. Participants in these experiments were recruited in the local community. To increase the sample size of experiments to 50 or more [@Simmons_2013_life], we recruited additional participants in Wenzhou University, Wenzhou, China in 2017 for experiment 1a, 1b, 4a, and 4b. Experiment 3b was finished in Wenzhou University in 2017. To have a better estimation of the effect size, we included the data from two experiments (experiment 7a, 7b) that were reported in @Hu_2020_GoodSelf (See Table S1 for overview of these experiments). 

All participant received informed consent and compensated for their time. These experiments were approved by the ethic board in the Department of Tsinghua University. 

 <!-- 21-word solution (Simmons, Nelson & Simonsohn, 2012; retrieved from http://ssrn.com/abstract=2160588) -->


```{r loadingData,echo=FALSE,results='hide'}
load("AllData.RData")
```

```{r define_funs,echo=FALSE,results='hide'}
# define a function to run the sdt GLMM for all exp with Matchness * Valence design
# for 1a, 1b, 1c, 2, 6a
fun_sdt_val <- function(exp_name) {
  df_name <- paste('df', exp_name, '.v', sep = '')
  m_name <- paste("glmmModels/exp", exp_name, "_sdt_m1_DummyCode", sep = '')
  df <- get(df_name)  # get the data by string
  
  m <- df %>%
  dplyr::filter(!is.na(RESP)) %>% # filter trials without response
  dplyr::mutate(ismatch = ifelse(Matchness == 'Match', 1, 0),
                saymatch = ifelse((Matchness == 'Match' & ACC == 1) | 
                                    (Matchness == 'Mismatch' & ACC == 0), 1, 0),
                Valence = factor(Valence, levels = c('Neutral', 'Bad', 'Good'))) %>%
  brms::brm(saymatch ~ 0 + Valence + ismatch:Valence + 
              (0 + Valence + ismatch:Valence | Subject),
            family = bernoulli(link="probit"),
            data = .,
            control = list(adapt_delta = .99),
            iter = 4000,
            thin = 2,
            cores = parallel::detectCores(),
            file = here::here(m_name))
  return(m)
}

fun_plot_sdt_val <- function(m_sdt) {
    # extract c
    tmp_c <- m_sdt %>% 
      tidybayes::gather_draws(b_ValenceBad, b_ValenceNeutral, b_ValenceGood) %>%
      dplyr::rename(Valence = .variable, sdt_c = .value) %>% dplyr::ungroup() %>%
      dplyr::mutate(Valence = gsub("b_", "", Valence)) %>%
      dplyr::mutate(Valence = ifelse(stringr::str_detect(Valence, 'Bad'), 'Bad',
                                     ifelse(stringr::str_detect(Valence, 'Good'), 'Good', 'Neutral')))
    
    # dprime
    tmp_d <- m_sdt %>% 
      tidybayes::gather_draws(`b_ValenceBad:ismatch`, `b_ValenceNeutral:ismatch`, 
                              `b_ValenceGood:ismatch`) %>%
      dplyr::rename(Valence = .variable, sdt_d = .value) %>% dplyr::ungroup() %>%
      dplyr::mutate(Valence = gsub("b_", "", Valence)) %>%
      dplyr::mutate(Valence = ifelse(stringr::str_detect(Valence, 'Bad'), 'Bad',
                                     ifelse(stringr::str_detect(Valence, 'Good'), 'Good', 'Neutral')))
    
    # plot summaries with densities
    p_sdt_d_sum <- tmp_d %>%
      dplyr::mutate(Valence = factor(Valence, levels = c('Bad', 'Neutral', 'Good'))) %>%
      ggplot2::ggplot(aes(x = sdt_d, y = Valence)) +
      tidybayes::stat_halfeyeh() + 
      labs(x = "sensitivity (d')", y = 'Posterior') +
      theme_classic()
    
    p_sdt_c_sum <- tmp_c %>%
      dplyr::mutate(Valence = factor(Valence, levels = c('Bad', 'Neutral', 'Good'))) %>%
      ggplot2::ggplot(aes(x = sdt_c, y = Valence)) +
      tidybayes::stat_halfeyeh() + 
      labs(x = "criteria (c)", y = 'Posterior') +
      theme_classic()
    
    # plot comparison
    p_sdt_d <- tmp_d %>%
      dplyr::mutate(Valence = factor(Valence, levels = c('Neutral', 'Bad', 'Good'))) %>%
      tidybayes::compare_levels(sdt_d, by = Valence) %>%
      ggplot2::ggplot(aes(x = sdt_d, y = Valence, fill = stat(x > 0))) +
      tidybayes::stat_halfeyeh() + 
      geom_vline(xintercept =0, linetype = "dashed") +
      scale_fill_manual(values = c("gray80", "skyblue")) +
      labs(x = "sensitivity (d')", y = 'Comparison') +
      theme_classic()
    
    p_sdt_c <- tmp_c %>%
      dplyr::mutate(Valence = factor(Valence, levels = c('Neutral', 'Bad', 'Good'))) %>%
      tidybayes::compare_levels(sdt_c, by = Valence) %>%
      ggplot2::ggplot(aes(x = sdt_c, y = Valence, fill = stat(x > 0))) +
      tidybayes::stat_halfeyeh() + 
      geom_vline(xintercept =0, linetype = "dashed") +
      scale_fill_manual(values = c("gray80", "skyblue")) +
      labs(x = "criteria (c)", y = 'Comparison') +
      theme_classic()
    
    return(list(p_sdt_d_sum, p_sdt_c_sum, p_sdt_d, p_sdt_c))
}

# define a function to run the RT GLMM for all exp with Matchness * Valence design
fun_rt_val <- function(exp_name) {
  df_name <- paste('df', exp_name, '.v', sep = '')
  m_name <- paste("glmmModels/exp", exp_name, "_rt_m1_DummyCode", sep = '')
  df <- get(df_name)  # get the data by string
  m <- df %>%
    dplyr::mutate(RT_sec = RT/1000) %>% # log RT in seconds
    dplyr::filter(ACC == 1) %>%
    dplyr::mutate(ismatch = ifelse(Matchness == 'Match', 1, 0),
                  Valence = factor(Valence, levels = c('Neutral', 'Bad', 'Good'))) %>%
    brms::brm(RT_sec ~ ismatch*Valence + (ismatch*Valence | Subject),
              family = shifted_lognormal(),
              data = ., control = list(adapt_delta = .99),
              iter = 4000,
              thin = 2,
              cores = parallel::detectCores(),
              file = here::here(m_name))
  return(m)
}

fun_plot_rt_val <- function(m_rt) {
    tmp_rt <- m_rt %>% 
      tidybayes::spread_draws(b_Intercept, b_ValenceBad, b_ValenceGood, 
                              b_ismatch,   `b_ValenceBad:ismatch`, `b_ValenceGood:ismatch`) %>%
      dplyr::mutate(Neut_MM = b_Intercept,
                    Bad_MM = Neut_MM + b_ValenceBad,
                    Good_MM = Neut_MM + b_ValenceGood,
                    Neut_M = Neut_MM + b_ismatch,
                    Bad_M = Neut_MM + b_ismatch + `b_ValenceBad:ismatch`,
                    Good_M = Neut_MM + b_ismatch + `b_ValenceGood:ismatch`) %>%
      dplyr::select(-contains('b_')) %>%
      tidyr::pivot_longer(cols = Neut_MM:Good_M,
                          names_to = 'cond',
                          values_to = 'logRT') %>%
      dplyr::mutate(RT = exp(logRT)*1000,
                    Matchness = dplyr::case_when(cond == 'Neut_MM' | cond == 'Bad_MM' | cond == 'Good_MM' ~ 'Mismatch',
                                                 cond == 'Neut_M'  | cond == 'Bad_M'  | cond == 'Good_M' ~ 'Match'),
                    Valence = dplyr::case_when(cond == 'Neut_MM' | cond == 'Neut_M' ~ 'Neutral',
                                               cond == 'Bad_MM'  | cond == 'Bad_M'  ~ 'Bad', 
                                               cond == 'Good_MM' | cond == 'Good_M' ~ 'Good'))
    p_exp1b_rt_m_sum <- tmp_rt %>% dplyr::mutate(Valence = factor(Valence, levels = c('Bad', 'Neutral', 'Good'))) %>%
      dplyr::filter(Matchness == 'Match') %>%
      ggplot2::ggplot(aes(x = RT, y = Valence)) +
      tidybayes::stat_halfeyeh() + 
      labs(x = "RTs (Matching, ms)", y = 'Posterior') +
      theme_classic()
    p_exp1b_rt_mm_sum <- tmp_rt %>% dplyr::mutate(Valence = factor(Valence, levels = c('Bad', 'Neutral', 'Good'))) %>%
      dplyr::filter(Matchness == 'Mismatch') %>%
      ggplot2::ggplot(aes(x = RT, y = Valence)) +
      tidybayes::stat_halfeyeh() + 
      labs(tag = 'D', x = "RTs (Mismatching, ms)", y = 'Posterior') +
      theme_classic()
    
    # plot comparison
    p_exp1b_rt_m <- tmp_rt %>% dplyr::mutate(Valence = factor(Valence, levels = c('Neutral', 'Bad', 'Good'))) %>%
      dplyr::filter(Matchness == 'Match') %>%
      tidybayes::compare_levels(RT, by = Valence) %>%
      ggplot2::ggplot(aes(x = RT, y = Valence, fill = stat(x < 0))) +
      tidybayes::stat_halfeyeh() + 
      geom_vline(xintercept =0, linetype = "dashed") +
      scale_fill_manual(values = c("gray80", "skyblue")) +
      labs(tag = 'C', x = "RTs (Matching, ms)", y = 'Comparison') +
      theme_classic()
    p_exp1b_rt_mm <- tmp_rt %>% dplyr::mutate(Valence = factor(Valence, levels = c('Neutral', 'Bad', 'Good'))) %>%
      dplyr::filter(Matchness == 'Mismatch') %>%
      tidybayes::compare_levels(RT, by = Valence) %>%
      ggplot2::ggplot(aes(x = RT, y = Valence, fill = stat(x < 0))) +
      tidybayes::stat_halfeyeh() + 
      geom_vline(xintercept =0, linetype = "dashed") +
      scale_fill_manual(values = c("gray80", "skyblue")) +
      labs(tag = 'D', x = "RTs (Mismatching, ms)", y = 'Comparison') +
      theme_classic()
    return(list(p_exp1b_rt_m_sum, p_exp1b_rt_mm_sum, p_exp1b_rt_m, p_exp1b_rt_mm))
}

fun_sdt_val_id <- function(exp_name) {
  df_name <- paste('df', exp_name, '.v', sep = '')
  m_name <- paste("glmmModels/exp", exp_name, "_sdt_m1_DummyCode", sep = '')
  df <- get(df_name)  # get the data by string
  
  m <- df %>%
  dplyr::filter(!is.na(RESP)) %>% # filter trials without response
  dplyr::mutate(ismatch = ifelse(Matchness == 'Match', 1, 0),
                saymatch = ifelse((Matchness == 'Match' & ACC == 1) | 
                                    (Matchness == 'Mismatch' & ACC == 0), 1, 0),
                Valence = factor(Valence, levels = c('Neutral', 'Bad', 'Good')),
                Identity = factor(Identity, levels = c('Self', 'Other'))) %>%
  brms::brm(saymatch ~ 0 + Identity:Valence + ismatch:Identity:Valence + 
              (0 + Identity:Valence + ismatch:Identity:Valence | Subject),
            family = bernoulli(link="probit"),
            data = .,
            control = list(adapt_delta = .99),
            iter = 4000,
            thin = 2,
            cores = parallel::detectCores(),
            file = here::here(m_name))
  return(m)
}

# define a function to run the RT GLMM for all exp with Matchness * Valence design
fun_rt_val_id <- function(exp_name) {
  df_name <- paste('df', exp_name, '.v', sep = '')
  m_name <- paste("glmmModels/exp", exp_name, "_rt_m1_DummyCode", sep = '')
  df <- get(df_name)  # get the data by string
  m <- df %>%
    dplyr::mutate(RT_sec = RT/1000) %>% # log RT in seconds
    dplyr::filter(ACC == 1) %>%
    dplyr::mutate(ismatch = ifelse(Matchness == 'Match', 1, 0),
                  Valence = factor(Valence, levels = c('Neutral', 'Bad', 'Good')),
                  Identity = factor(Identity, levels=c('Self', 'Other'))) %>%
    brms::brm(RT_sec ~ ismatch*Identity*Valence + (ismatch*Identity*Valence | Subject),
              family = shifted_lognormal(),
              data = ., control = list(adapt_delta = .99),
              iter = 4000,
              thin = 2,
              cores = parallel::detectCores(),
              file = here::here(m_name))
  return(m)
}

```

  <!-- A general method part describing experimental design and data analysis -->
```{r child = "general_method.rmd"}
```

# Part 1: Moral valence effect
In this part, we report five experiments that aimed at testing whether the instantly acquired association between shapes and good person would be prioritized in perceptual decision-making.

```{r child = "exp1a.rmd"}
```

```{r child = "exp1b.rmd"}
```

```{r child = "exp1c.rmd"}
```

```{r child = "exp2.rmd"}
```

```{r child = "exp6a.rmd"}
```

# Part 2: interaction between valence and identity

In this part, we report two experiments that aimed at testing whether the moral valence effect found in the previous experiment can be modulated by the self-referential processing.

```{r child = "exp3a.rmd"}
```

```{r child = "exp3b.rmd"}
```

```{r child = "exp6b.rmd"}
```

# Part 3: Implicit binding between valence and identity

In this part, we reported two studies in which the moral valence or the self-referential processing is not task-relevant. We are interested in testing whether the task-relevance will eliminate the effect observed in previous experiment. 

```{r child = "exp4a.rmd"}
```

```{r child = "exp4b.rmd"}
```

```{r remove repeated subj Data,echo=FALSE,results='hide'}
## exclude the repeating subjects
df1c.meta.d <- df1c.meta.d %>% dplyr::filter(!Subject %in% c(1206, 1207, 1208, 1210))
df1c.meta.rt <- df1c.meta.rt %>% dplyr::filter(!Subject %in% c(1206, 1207, 1208, 1210)) # exclude participants who participated exp1a or 1b

df2.meta.d <- df2.meta.d %>% dplyr::filter(Subject > 2000)    # exclude participant from exp 1a
df2.meta.rt <- df2.meta.rt %>% dplyr::filter(Subject > 2000)

df3a.meta.d <- df3a.meta.d %>% dplyr::filter(!Subject %in% c(3013, 3012, 3043, 3046)) # exclude participants from ex1b, 1c, and 2
df3a.meta.rt <- df3a.meta.rt %>% dplyr::filter(!Subject %in% c(3013, 3012, 3043, 3046)) # exclude participants from ex1b, 1c, and 2

df4b.meta.d <- df4b.meta.d %>% dplyr::filter(!Subject %in% c(4210, 4202, 4201))   # exclude participants from ex1b, 1c, and 2
df4b.meta.rt <- df4b.meta.rt %>% dplyr::filter(!Subject %in% c(4210, 4202, 4201)) # exclude participants from ex1b, 1c, and 2

df5.meta.d <- df5.meta.d %>% dplyr::filter(!Subject %in% c(5201))   # exclude participants from ex1b, 1c, and 2
df5.meta.rt <- df5.meta.rt %>% dplyr::filter(!Subject %in% c(5201)) # exclude participants from ex1b, 1c, and 2

df6a.meta.d <- df6a.meta.d %>% dplyr::filter(!Subject %in% c(6118,6119,6122,6123,6131))   # exclude participants from ex1b, 1c, and 2
df6a.meta.rt <- df6a.meta.rt %>% dplyr::filter(!Subject %in% c(6118,6119,6122,6123,6131)) # exclude participants from ex1b, 1c, and 2

df6b.meta.d <- df6b.meta.d %>% dplyr::filter(!Subject %in% c(6217))   # exclude participants from ex1b, 1c, and 2
df6b.meta.rt <- df6b.meta.rt %>% dplyr::filter(!Subject %in% c(6217)) # exclude participants from ex1b, 1c, and 2

df7a_m.meta.d <- df7a_m.meta.d %>% dplyr::filter(!Subject %in% c(7020))   # exclude participants from ex1b, 1c, and 2
df7a_m.meta.rt <- df7a_m.meta.rt %>% dplyr::filter(!Subject %in% c(7020)) # exclude participants from ex1b, 1c, and 2

```

# Results
```{r first meta,echo=FALSE,results='hide'}
# Combine the data -----
df.meta_d_1 <- rbind(df1a.meta.d, df1b.meta.d, df1c.meta.d, df2.meta.d, df4b.meta.d , df5.meta.d, df6a.meta.d) 
df.meta_rt_1 <- rbind(df1a.meta.rt, df1b.meta.rt, df1c.meta.rt, df2.meta.rt, df4b.meta.rt,df5.meta.rt, df6a.meta.rt)

# Prepare the data for meta ----
# calculate the mean, sd, n, and r for estimating the effect size and SE of effect size.
effectList_1 <- c('Good_Bad','Good_Neut','Bad_Neut')

df.ES_1 <- data.frame(matrix(nrow=length(unique(df.meta_d_1$ExpID))*length(effectList_1)*2, ncol=0)) %>%
  dplyr::mutate(DVtype = rep(c('RT', 'dprime'), each = length(unique(df.meta_d_1$ExpID))*length(effectList_1)),
                ExpID  = rep(rep(unique(df.meta_d_1$ExpID), each = length(effectList_1)), 2),
                Effect = rep(effectList_1, length(unique(df.meta_d_1$ExpID))*2),
                #Group  = rep(groupList, length(unique(df.meta_d$ExpID))*2),
                M1 = NA, SD1 = NA, M2 = NA, SD2 = NA, N = NA, r = NA, ES = NA, ES.var = NA)

for (DVName in c('RT','dprime')){
  if (DVName == 'RT'){
    metaData <- df.meta_rt_1 %>% dplyr::filter(Matchness == "Match") %>% dplyr::rename(Value = RT)
  } else{
    metaData <- df.meta_d_1 %>% dplyr::rename(Value = dprime)
  }
  
  for (expName in unique(metaData$ExpID)){
    for (effectName in effectList_1){
      tmpdata <- metaData %>% dplyr::filter(ExpID == expName & Domain == 'Morality')
      
      if (effectName == 'Good_Bad'){
        #print(paste('processing Good_Bad of ', expName, sep = ''))
        dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good")
        dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Bad")
        }
      else if (effectName == 'Good_Neut'){
        #print(paste('processing Good_Neut of ', expName, sep = ''))
        #if ('Neutral' %in% tmpdata$Valence){
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good")
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Neutral")
        #  }
        #else{
          #print(paste('There is no Neutral condition in', expName, sepe=''))
        #  next
        #  }
        }
      else if (effectName == 'Bad_Neut'){
        #if ('Neutral' %in% tmpdata$Valence)
        #  {
            dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Bad")
            dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Neutral")  
        #  }
        #else{
            #print(paste('There is no Neutral condition in', expName, sepe=''))
        #    next
        #  }
        }
      #}
      M1  <- mean(dataCond1$Value) -> df.ES_1$M1[df.ES_1$DVtype == DVName & df.ES_1$ExpID == expName & df.ES_1$Effect == effectName]
      SD1 <- sd(dataCond1$Value)   -> df.ES_1$SD1[df.ES_1$DVtype == DVName & df.ES_1$ExpID == expName & df.ES_1$Effect == effectName] 
      M2  <- mean(dataCond2$Value) -> df.ES_1$M2[df.ES_1$DVtype == DVName & df.ES_1$ExpID == expName & df.ES_1$Effect == effectName]
      SD2 <- sd(dataCond2$Value)   -> df.ES_1$SD2[df.ES_1$DVtype == DVName & df.ES_1$ExpID == expName & df.ES_1$Effect == effectName]
      N   <- length(unique(dataCond2$Subject)) -> df.ES_1$N[df.ES_1$DVtype == DVName & df.ES_1$ExpID == expName & df.ES_1$Effect == effectName]
      r   <- cor(dataCond1$Value,dataCond2$Value) -> df.ES_1$r[df.ES_1$DVtype == DVName & df.ES_1$ExpID == expName & df.ES_1$Effect == effectName] 
      tmp2 <- d.sgpp(m.1 = M1, m.2 = M2, sd.1 = SD1, sd.2 = SD2,n = N, r = r)
      df.ES_1$ES[df.ES_1$DVtype == DVName & df.ES_1$ExpID == expName & df.ES_1$Effect == effectName] <- tmp2[1,1]
      df.ES_1$ES.var[df.ES_1$DVtype == DVName & df.ES_1$ExpID == expName & df.ES_1$Effect == effectName] <- tmp2[1,2]
    }
  }
}

# Do the meta-analysis in a for loop ----
df.ES_1_sum <- df.ES_1 %>% 
  dplyr::group_by(DVtype, Effect) %>% 
  tidyr::drop_na() %>% 
  dplyr::summarise(Nexp = length(unique(ExpID)), Nsubj = sum(N, na.rm = T))

df.res.meta_1 <- data.frame(matrix(nrow= 3*2, ncol=0)) %>%
  dplyr::mutate(DVtype = rep(c('RT', 'dprime'), each = 3),
                #Group  = rep(groupList_1, 2),
                Effect = rep(effectList_1, 2),
                #Group  = rep(groupList, length(unique(df.meta_d$ExpID))*2),
                N_exp = NA, Cohen_d = NA, se = NA, CI_low = NA, CI_upp = NA, pval = NA)

for (DVName in c('RT','dprime')){
  for (effectName in effectList_1){
    df.res.meta <- df.ES_1 %>%
      dplyr::filter(DVtype == DVName & Effect == effectName) %>%
      tidyr::drop_na()
    
    tmp.meta.res <- metafor::rma(yi = df.res.meta$ES,
                           vi = df.res.meta$ES.var,
                           slab = df.res.meta$ExpID)
    df.res.meta_1$N_exp[df.res.meta_1$DVtype == DVName & df.res.meta_1$Effect == effectName] <- tmp.meta.res$k
    df.res.meta_1$Cohen_d[df.res.meta_1$DVtype == DVName & df.res.meta_1$Effect == effectName] <- tmp.meta.res$beta
    df.res.meta_1$se[df.res.meta_1$DVtype == DVName & df.res.meta_1$Effect == effectName] <- tmp.meta.res$se
    df.res.meta_1$CI_low[df.res.meta_1$DVtype == DVName & df.res.meta_1$Effect == effectName] <- tmp.meta.res$ci.lb
    df.res.meta_1$CI_upp[df.res.meta_1$DVtype == DVName & df.res.meta_1$Effect == effectName] <- tmp.meta.res$ci.ub
    df.res.meta_1$pval[df.res.meta_1$DVtype == DVName & df.res.meta_1$Effect == effectName] <- tmp.meta.res$pval
  }
}

# Prepare data for plotting the effect size ----
df.res.meta_1 <- df.res.meta_1 %>%
  dplyr::mutate(Identity = "No-Ref.",
                EffectType = Effect) 
```

```{r second meta,echo=FALSE,results='hide'}
# Results part 2: with self-referential, included experiments: 3a, 3b, 6b, 7a, 7b

# Combine the data  ----
df.meta_d_2 <- rbind(df3a.meta.d, df3b.meta.d, df6b.meta.d, df7a_m.meta.d, df7b_m.meta.d) 
df.meta_rt_2 <- rbind(df3a.meta.rt, df3b.meta.rt, df6b.meta.rt, df7a_m.meta.rt, df7b_m.meta.rt)

# Calculate the mean, sd, n, and r ----
# for estimating the effect size and SE of effect size.
effectList_2 <- c('Good_Bad_S','Good_Neut_S','Bad_Neut_S',
                'Good_Bad_O','Good_Neut_O','Bad_Neut_O')

df.ES_2 <- data.frame(matrix(nrow=length(unique(df.meta_d_2$ExpID))*length(effectList_2)*2, ncol=0)) %>%
  dplyr::mutate(DVtype = rep(c('RT', 'dprime'), each = length(unique(df.meta_d_2$ExpID))*length(effectList_2)),
                ExpID  = rep(rep(unique(df.meta_d_2$ExpID), each = length(effectList_2)), 2),
                Effect = rep(effectList_2, length(unique(df.meta_d_2$ExpID))*2),
                M1 = NA, SD1 = NA, M2 = NA, SD2 = NA, N = NA, r = NA, ES = NA, ES.var = NA)

for (DVName in c('RT','dprime')){
  if (DVName == 'RT'){
    metaData <- df.meta_rt_2 %>% dplyr::filter(Matchness == "Match") %>% dplyr::rename(Value = RT)
  } else{
    metaData <- df.meta_d_2 %>% dplyr::rename(Value = dprime)
  }
  
  for (expName in unique(metaData$ExpID)){
    for (effectName in effectList_2){
      tmpdata <- metaData %>% dplyr::filter(ExpID == expName & Domain == 'Morality')
      
      if (effectName == 'Good_Bad_S'){
        
        if (!all(is.na(tmpdata$Identity))){
          #print(paste('processing Good_Bad_S of ', expName, sep = ''))
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good" & Identity == 'Self')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Bad" & Identity == 'Self')  
          }
        else{
            #print(paste('Skip Good_Bad_S of ', expName, sep = ''))
          next
          }
        }
      else if (effectName == 'Good_Neut_S'){
        if (!all(is.na(tmpdata$Identity)) & 'Neutral' %in% tmpdata$Valence ){
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good" & Identity == 'Self')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Neutral" & Identity == 'Self')  
          }
        else{
          next
          }
        }  
      else if (effectName == 'Bad_Neut_S'){
        if (!all(is.na(tmpdata$Identity)) & 'Neutral' %in% tmpdata$Valence ){
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Bad" & Identity == 'Self')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Neutral" & Identity == 'Self')  
          }
        else{
          next
          }
        }
      else if (effectName == 'Good_Bad_O'){
        if (!all(is.na(tmpdata$Identity))){
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good" & Identity == 'Other')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Bad" & Identity == 'Other')  
          }
        else{
          next
          }
        }
      else if (effectName == 'Good_Neut_O'){
        if (!all(is.na(tmpdata$Identity)) & 'Neutral' %in% tmpdata$Valence )
          {
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good" & Identity == 'Other')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Neutral" & Identity == 'Other')  
          }
        else{
          next
          }
        }
      else if (effectName == 'Bad_Neut_O'){
        if (!all(is.na(tmpdata$Identity)) & 'Neutral' %in% tmpdata$Valence){
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Bad" & Identity == 'Other')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Neutral" & Identity == 'Other')  
          }
        else{
          next
          }
      }
      
      M1  <- mean(dataCond1$Value) -> df.ES_2$M1[df.ES_2$DVtype == DVName & df.ES_2$ExpID == expName & df.ES_2$Effect == effectName]
      SD1 <- sd(dataCond1$Value)   -> df.ES_2$SD1[df.ES_2$DVtype == DVName & df.ES_2$ExpID == expName & df.ES_2$Effect == effectName] 
      M2  <- mean(dataCond2$Value) -> df.ES_2$M2[df.ES_2$DVtype == DVName & df.ES_2$ExpID == expName & df.ES_2$Effect == effectName]
      SD2 <- sd(dataCond2$Value)   -> df.ES_2$SD2[df.ES_2$DVtype == DVName & df.ES_2$ExpID == expName & df.ES_2$Effect == effectName]
      N   <- length(unique(dataCond2$Subject)) -> df.ES_2$N[df.ES_2$DVtype == DVName & df.ES_2$ExpID == expName & df.ES_2$Effect == effectName]
      r   <- cor(dataCond1$Value,dataCond2$Value) -> df.ES_2$r[df.ES_2$DVtype == DVName & df.ES_2$ExpID == expName & df.ES_2$Effect == effectName] 
      tmp2 <- d.sgpp(m.1 = M1, m.2 = M2, sd.1 = SD1, sd.2 = SD2,n = N, r = r)
      df.ES_2$ES[df.ES_2$DVtype == DVName & df.ES_2$ExpID == expName & df.ES_2$Effect == effectName] <- tmp2[1,1]
      df.ES_2$ES.var[df.ES_2$DVtype == DVName & df.ES_2$ExpID == expName & df.ES_2$Effect == effectName] <- tmp2[1,2]
    }
  }
}

# Do the meta ----
# info about participants
df.ES_2_sum <- df.ES_2 %>% 
  dplyr::group_by(DVtype, Effect) %>% 
  tidyr::drop_na() %>% 
  dplyr::summarise(Nexp = length(unique(ExpID)), Nsubj = sum(N, na.rm = T))

df.res.meta_2 <- data.frame(matrix(nrow= (2*3)*2, ncol=0)) %>%
  dplyr::mutate(DVtype = rep(c('RT', 'dprime'), each = (2*3)),
                Effect = rep(effectList_2, 2),
                N_exp = NA, Cohen_d = NA, se = NA, CI_low = NA, CI_upp = NA, pval = NA)

# meta -analysis
for (DVName in c('RT','dprime')){
  for (effectName in effectList_2){
    df.res.meta <- df.ES_2 %>%
      dplyr::filter(DVtype == DVName & Effect == effectName) %>%
      tidyr::drop_na()
  
    tmp.meta.res <- metafor::rma(yi = df.res.meta$ES,
                           vi = df.res.meta$ES.var,
                           slab = df.res.meta$ExpID)
    df.res.meta_2$N_exp[df.res.meta_2$DVtype == DVName & df.res.meta_2$Effect == effectName] <- tmp.meta.res$k
    df.res.meta_2$Cohen_d[df.res.meta_2$DVtype == DVName & df.res.meta_2$Effect == effectName] <- tmp.meta.res$beta
    df.res.meta_2$se[df.res.meta_2$DVtype == DVName & df.res.meta_2$Effect == effectName] <- tmp.meta.res$se
    df.res.meta_2$CI_low[df.res.meta_2$DVtype == DVName & df.res.meta_2$Effect == effectName] <- tmp.meta.res$ci.lb
    df.res.meta_2$CI_upp[df.res.meta_2$DVtype == DVName & df.res.meta_2$Effect == effectName] <- tmp.meta.res$ci.ub
    df.res.meta_2$pval[df.res.meta_2$DVtype == DVName & df.res.meta_2$Effect == effectName] <- tmp.meta.res$pval
  }
}

# plot the effect size  ----
df.res.meta_2 <- df.res.meta_2 %>%
  dplyr::mutate(Identity = ifelse(Effect == "Good_Bad_S" | Effect == "Good_Neut_S" | Effect == "Bad_Neut_S",
                                  "Self-Ref.", "Other-Ref."),
                EffectType = ifelse(Effect == "Good_Bad_S" | Effect == "Good_Bad_O", "Good_Bad",
                                    ifelse(Effect == "Good_Neut_S" | Effect == "Good_Neut_O", "Good_Neut", "Bad_Neut")))

df.res_meta_pdata <- rbind(df.res.meta_1, df.res.meta_2) %>%
  dplyr::mutate(Identity = factor(Identity, levels = c("No-Ref.", "Self-Ref.", "Other-Ref.")),
                EffectType = factor(EffectType, levels = c("Good_Bad", "Good_Neut", "Bad_Neut" )))

```

## Effect of moral valence

```{r plot-all-effect, fig.cap="Effect size (Cohen's *d*) of Valence.", warning=FALSE}
# fig.width=8, 
df.res_meta_pdata %>%
  dplyr::filter(EffectType != 'Good_Bad') %>%
  ggplot2::ggplot(., aes(x = EffectType, y=Cohen_d, color=EffectType, fill=EffectType )) + # 
  geom_pointrange(aes(ymin=Cohen_d - 1.96*se, ymax = Cohen_d + 1.96*se), 
                  position = position_dodge(width = 0.5),
                  shape=18, size=0.8) +
  geom_hline(yintercept=0, size=1, color='grey', linetype = 'dashed') +
  coord_cartesian(ylim=c(-1.5, 1.5))+
  scale_color_brewer(palette = "Dark2")+
  scale_fill_brewer(palette = "Dark2")+
  ylab(expression(paste("Effect size: Cohen's ",italic("d"), sep = ' '))) +
  xlab('Contrasts between different valence') +
  apatheme_x +
  facet_grid(  DVtype ~ Identity)
```

In this part, we synthesized results from experiment 1a, 1b, 1c, 2, 5 and 6a. Data from 192 participants were included in these analyses. We found differences between positive and negative conditions on RT was Cohen's *d* = `r df.res.meta_1$Cohen_d[df.res.meta_1$DVtype == 'RT' & df.res.meta_1$Effect =='Good_Bad']` $\pm$ `r df.res.meta_1$se[df.res.meta_1$DVtype == 'RT' & df.res.meta_1$Effect =='Good_Bad']`, 95% CI [`r df.res.meta_1$CI_low[df.res.meta_1$DVtype == 'RT' & df.res.meta_1$Effect =='Good_Bad']` `r df.res.meta_1$CI_upp[df.res.meta_1$DVtype == 'RT' & df.res.meta_1$Effect =='Good_Bad']`]; on *d'* was Cohen's *d* = `r df.res.meta_1$Cohen_d[df.res.meta_1$DVtype == 'dprime' & df.res.meta_1$Effect =='Good_Bad']` $\pm$ `r df.res.meta_1$se[df.res.meta_1$DVtype == 'dprime' & df.res.meta_1$Effect =='Good_Bad']`, 95% CI [`r df.res.meta_1$CI_low[df.res.meta_1$DVtype == 'dprime' & df.res.meta_1$Effect =='Good_Bad']` `r df.res.meta_1$CI_upp[df.res.meta_1$DVtype == 'dprime' & df.res.meta_1$Effect =='Good_Bad']`]. The effect was also observed between positive and neutral condition, RT: Cohen's *d* = `r df.res.meta_1$Cohen_d[df.res.meta_1$DVtype == 'RT' & df.res.meta_1$Effect =='Good_Neut']` $\pm$ `r df.res.meta_1$se[df.res.meta_1$DVtype == 'RT' & df.res.meta_1$Effect =='Good_Neut']`, 95% CI [`r df.res.meta_1$CI_low[df.res.meta_1$DVtype == 'RT' & df.res.meta_1$Effect =='Good_Neut']` `r df.res.meta_1$CI_upp[df.res.meta_1$DVtype == 'RT' & df.res.meta_1$Effect =='Good_Neut']`]; *d'*: Cohen's *d* = `r df.res.meta_1$Cohen_d[df.res.meta_1$DVtype == 'dprime' & df.res.meta_1$Effect =='Good_Neut']` $\pm$ `r df.res.meta_1$se[df.res.meta_1$DVtype == 'dprime' & df.res.meta_1$Effect =='Good_Neut']`, 95% CI [`r df.res.meta_1$CI_low[df.res.meta_1$DVtype == 'dprime' & df.res.meta_1$Effect =='Good_Neut']` `r df.res.meta_1$CI_upp[df.res.meta_1$DVtype == 'dprime' & df.res.meta_1$Effect =='Good_Neut']`]. And the difference between neutral and bad conditions are not significant, RT: Cohen's *d* = `r df.res.meta_1$Cohen_d[df.res.meta_1$DVtype == 'RT' & df.res.meta_1$Effect =='Bad_Neut']` $\pm$ `r df.res.meta_1$se[df.res.meta_1$DVtype == 'RT' & df.res.meta_1$Effect =='Bad_Neut']`, 95% CI [`r df.res.meta_1$CI_low[df.res.meta_1$DVtype == 'RT' & df.res.meta_1$Effect =='Bad_Neut']` `r df.res.meta_1$CI_upp[df.res.meta_1$DVtype == 'RT' & df.res.meta_1$Effect =='Bad_Neut']`]; *d'*: Cohen's *d* = `r df.res.meta_1$Cohen_d[df.res.meta_1$DVtype == 'dprime' & df.res.meta_1$Effect =='Bad_Neut']` $\pm$ `r df.res.meta_1$se[df.res.meta_1$DVtype == 'dprime' & df.res.meta_1$Effect =='Bad_Neut']`, 95% CI [`r df.res.meta_1$CI_low[df.res.meta_1$DVtype == 'dprime' & df.res.meta_1$Effect =='Bad_Neut']` `r df.res.meta_1$CI_upp[df.res.meta_1$DVtype == 'dprime' & df.res.meta_1$Effect =='Bad_Neut']`]. See Figure \@ref(fig:plot-all-effect) left panel.

## Interaction between valence and self-reference
In this part, we combined the experiments that explicitly manipulated the self-reference and valence, which includes 3a, 3b, 6b, 7a, and 7b. For the positive versus negative contrast, data were from five experiments with 178 participants; for positive versus neutral and neutral versus negative contrasts, data were from three experiments ( 3a, 3b, and 6b) with 108 participants.

In most of these experiments, the interaction between self-reference and valence was significant (see results of each experiment in supplementary materials). In the mini-meta-analysis, we analyzed the valence effect for self-referential condition and other-referential condition separately.

For the self-referential condition, we found the same pattern as in the first part of results. That is we found significant differences between positive and neutral as well as positive and negative, but not neutral and negative. The effect size of RT between positive and negative is Cohen's *d* = `r df.res.meta_2$Cohen_d[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Good_Bad_S']` $\pm$ `r df.res.meta_2$se[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Good_Bad_S']`, 95% CI [`r df.res.meta_2$CI_low[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Good_Bad_S']` `r df.res.meta_2$CI_upp[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Good_Bad_S']`]; on *d'* was Cohen's *d* = `r df.res.meta_2$Cohen_d[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Good_Bad_S']` $\pm$ `r df.res.meta_2$se[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Good_Bad_S']`, 95% CI [`r df.res.meta_2$CI_low[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Good_Bad_S']` `r df.res.meta_2$CI_upp[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Good_Bad_S']`]. The effect was also observed between positive and neutral condition, RT: Cohen's *d* = `r df.res.meta_2$Cohen_d[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Good_Neut_S']` $\pm$ `r df.res.meta_2$se[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Good_Neut_S']`, 95% CI [`r df.res.meta_2$CI_low[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Good_Neut_S']` `r df.res.meta_2$CI_upp[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Good_Neut_S']`]; *d'*: Cohen's *d* = `r df.res.meta_2$Cohen_d[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Good_Neut_S']` $\pm$ `r df.res.meta_2$se[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Good_Neut_S']`, 95% CI [`r df.res.meta_2$CI_low[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Good_Neut_S']` `r df.res.meta_2$CI_upp[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Good_Neut_S']`]. And the difference between neutral and bad conditions are not significant, RT: Cohen's *d* = `r df.res.meta_2$Cohen_d[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Bad_Neut_S']` $\pm$ `r df.res.meta_2$se[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Bad_Neut_S']`, 95% CI [`r df.res.meta_2$CI_low[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Bad_Neut_S']` `r df.res.meta_2$CI_upp[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Bad_Neut_S']`]; *d'*: Cohen's *d* = `r df.res.meta_2$Cohen_d[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Bad_Neut_S']` $\pm$ `r df.res.meta_2$se[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Bad_Neut_S']`, 95% CI [`r df.res.meta_2$CI_low[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Bad_Neut_S']` `r df.res.meta_2$CI_upp[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Bad_Neut_S']`]. See Figure \@ref(fig:plot-all-effect) the middle panel.

For the other-referential condition, we found that only the difference between positive and negative on RT was significant, all the other conditions were not. The effect size of RT between positive and negative is Cohen's *d* = `r df.res.meta_2$Cohen_d[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Good_Bad_O']` $\pm$ `r df.res.meta_2$se[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Good_Bad_O']`, 95% CI [`r df.res.meta_2$CI_low[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Good_Bad_O']` `r df.res.meta_2$CI_upp[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Good_Bad_O']`]; on *d'* was Cohen's *d* = `r df.res.meta_2$Cohen_d[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Good_Bad_O']` $\pm$ `r df.res.meta_2$se[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Good_Bad_O']`, 95% CI [`r df.res.meta_2$CI_low[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Good_Bad_O']` `r df.res.meta_2$CI_upp[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Good_Bad_O']`]. The effect was not observed between positive and neutral condition, RT: Cohen's *d* = `r df.res.meta_2$Cohen_d[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Good_Neut_O']` $\pm$ `r df.res.meta_2$se[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Good_Neut_O']`, 95% CI [`r df.res.meta_2$CI_low[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Good_Neut_O']` `r df.res.meta_2$CI_upp[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Good_Neut_O']`]; *d'*: Cohen's *d* = `r df.res.meta_2$Cohen_d[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Good_Neut_O']` $\pm$ `r df.res.meta_2$se[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Good_Neut_O']`, 95% CI [`r df.res.meta_2$CI_low[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Good_Neut_O']` `r df.res.meta_2$CI_upp[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Good_Neut_O']`]. And the difference between neutral and bad conditions are not significant, RT: Cohen's *d* = `r df.res.meta_2$Cohen_d[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Bad_Neut_O']` $\pm$ `r df.res.meta_2$se[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Bad_Neut_O']`, 95% CI [`r df.res.meta_2$CI_low[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Bad_Neut_O']` `r df.res.meta_2$CI_upp[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Bad_Neut_O']`]; *d'*: Cohen's *d* = `r df.res.meta_2$Cohen_d[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Bad_Neut_O']` $\pm$ `r df.res.meta_2$se[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Bad_Neut_O']`, 95% CI [`r df.res.meta_2$CI_low[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Bad_Neut_O']` `r df.res.meta_2$CI_upp[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Bad_Neut_O']`]. See Figure \@ref(fig:plot-all-effect) right panel.

## Generalizibility of the valence effect
In this part, we reported the results from experiment 4 in which either moral valence or self-reference were manipulated as task-irrelevant stimuli. 

```{r analyzing exp4a, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
df.ES_4a <- data.frame(matrix(nrow=length(unique(df4a.meta.d$ExpID))*length(effectList_2)*2, ncol=0)) %>%
  dplyr::mutate(DVtype = rep(c('RT', 'dprime'), each = length(unique(df4a.meta.d$ExpID))*length(effectList_2)),
                ExpID  = rep(rep(unique(df4a.meta.d$ExpID), each = length(effectList_2)), 2),
                Effect = rep(effectList_2, length(unique(df4a.meta.d$ExpID))*2),
                M1 = NA, SD1 = NA, M2 = NA, SD2 = NA, N = NA, r = NA, ES = NA, ES.var = NA)

for (DVName in c('RT','dprime')){
  if (DVName == 'RT'){
    metaData <- df4a.meta.rt %>% dplyr::filter(Matchness == "Match") %>% dplyr::rename(Value = RT)
  } else{
    metaData <- df4a.meta.d %>% dplyr::rename(Value = dprime)
  }
  
  for (expName in unique(metaData$ExpID)){
    for (effectName in effectList_2){
      tmpdata <- metaData %>% dplyr::filter(ExpID == expName & Domain == 'Morality')
      
      if (effectName == 'Good_Bad_S'){
        
        if (!all(is.na(tmpdata$Identity))){
          #print(paste('processing Good_Bad_S of ', expName, sep = ''))
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good" & Identity == 'Self')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Bad" & Identity == 'Self')  
          }
        else{
            #print(paste('Skip Good_Bad_S of ', expName, sep = ''))
          next
          }
        }
      else if (effectName == 'Good_Neut_S'){
        if (!all(is.na(tmpdata$Identity)) & 'Neutral' %in% tmpdata$Valence ){
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good" & Identity == 'Self')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Neutral" & Identity == 'Self')  
          }
        else{
          next
          }
        }  
      else if (effectName == 'Bad_Neut_S'){
        if (!all(is.na(tmpdata$Identity)) & 'Neutral' %in% tmpdata$Valence ){
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Bad" & Identity == 'Self')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Neutral" & Identity == 'Self')  
          }
        else{
          next
          }
        }
      else if (effectName == 'Good_Bad_O'){
        if (!all(is.na(tmpdata$Identity))){
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good" & Identity == 'Other')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Bad" & Identity == 'Other')  
          }
        else{
          next
          }
        }
      else if (effectName == 'Good_Neut_O'){
        if (!all(is.na(tmpdata$Identity)) & 'Neutral' %in% tmpdata$Valence )
          {
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good" & Identity == 'Other')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Neutral" & Identity == 'Other')  
          }
        else{
          next
          }
        }
      else if (effectName == 'Bad_Neut_O'){
        if (!all(is.na(tmpdata$Identity)) & 'Neutral' %in% tmpdata$Valence){
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Bad" & Identity == 'Other')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Neutral" & Identity == 'Other')  
          }
        else{
          next
          }
      }
      
      M1  <- mean(dataCond1$Value) -> df.ES_4a$M1[df.ES_4a$DVtype == DVName & df.ES_4a$ExpID == expName & df.ES_4a$Effect == effectName]
      SD1 <- sd(dataCond1$Value)   -> df.ES_4a$SD1[df.ES_4a$DVtype == DVName & df.ES_4a$ExpID == expName & df.ES_4a$Effect == effectName] 
      M2  <- mean(dataCond2$Value) -> df.ES_4a$M2[df.ES_4a$DVtype == DVName & df.ES_4a$ExpID == expName & df.ES_4a$Effect == effectName]
      SD2 <- sd(dataCond2$Value)   -> df.ES_4a$SD2[df.ES_4a$DVtype == DVName & df.ES_4a$ExpID == expName & df.ES_4a$Effect == effectName]
      N   <- length(unique(dataCond2$Subject)) -> df.ES_4a$N[df.ES_4a$DVtype == DVName & df.ES_4a$ExpID == expName & df.ES_4a$Effect == effectName]
      r   <- cor(dataCond1$Value,dataCond2$Value) -> df.ES_4a$r[df.ES_4a$DVtype == DVName & df.ES_4a$ExpID == expName & df.ES_4a$Effect == effectName] 
      tmp2 <- d.sgpp(m.1 = M1, m.2 = M2, sd.1 = SD1, sd.2 = SD2,n = N, r = r)
      df.ES_4a$ES[df.ES_4a$DVtype == DVName & df.ES_4a$ExpID == expName & df.ES_4a$Effect == effectName] <- tmp2[1,1]
      df.ES_4a$ES.var[df.ES_4a$DVtype == DVName & df.ES_4a$ExpID == expName & df.ES_4a$Effect == effectName] <- tmp2[1,2]
    }
  }
}

df.ES_4a <- df.ES_4a %>%
  dplyr::mutate(Identity = ifelse(Effect == "Good_Bad_S" | Effect == "Good_Neut_S" | Effect == "Bad_Neut_S",
                                  "Self-ref.", "Other-ref."),
                EffectType = ifelse(Effect == "Good_Bad_S" | Effect == "Good_Bad_O", "Good_Bad",
                                    ifelse(Effect == "Good_Neut_S" | Effect == "Good_Neut_O", "Good_Neut", "Bad_Neut")),
                Identity = factor(Identity, levels = c("Self-ref.", "Other-ref.")),
                EffectType = factor(EffectType, levels = c("Good_Bad", "Good_Neut", "Bad_Neut")))
```

```{r 'plot-exp4a-effect', fig.cap="Effect size (Cohen's *d*) of Valence in Exp4a.", warning=FALSE}
df.ES_4a %>%
  dplyr::filter(EffectType != "Good_Bad") %>%
  ggplot(., aes(x=EffectType, y=ES, color=EffectType, fill=EffectType)) + 
  geom_pointrange(aes(ymin=ES - 1.96*sqrt(ES.var), ymax = ES + 1.96*sqrt(ES.var)), 
                  position = position_dodge(width = 0.5),
                  shape=18, size=0.8) +
  geom_hline(yintercept=0, size=1, color='grey', linetype = 'dashed') +
  # ggtitle('A: Valence effect') +
  coord_cartesian(ylim=c(-1.1, 1.1))+
  scale_color_brewer(palette = "Dark2")+
  scale_fill_brewer(palette = "Dark2")+
  ylab(expression(paste("Effect size: Cohen's ",italic("d"), sep = ' ')))+
  xlab('Contrasts between different valence')+
  apatheme_x +
  facet_grid(DVtype ~ Identity)
```

For experiment 4a, when self-reference was the target and moral valence was task-irrelevant, we found that only under the implicit self-referential condition, i.e., when the moral words were presented as task irrelevant stimuli, there was the main effect of valence and interaction between valence and reference for both *d* prime and RT (See supplementary results for the detailed statistics). For *d* prime, we found good-self condition (`r df.ES_4a$M1[df.ES_4a$DVtype == 'dprime' & df.ES_4a$Effect == 'Good_Bad_S']` $\pm$ `r df.ES_4a$SD1[df.ES_4a$DVtype == 'dprime' & df.ES_4a$Effect == 'Good_Bad_S']`) had higher *d* prime than bad-self condition (`r df.ES_4a$M2[df.ES_4a$DVtype == 'dprime' & df.ES_4a$Effect == 'Good_Bad_S']` $\pm$ `r df.ES_4a$SD2[df.ES_4a$DVtype == 'dprime' & df.ES_4a$Effect == 'Good_Bad_S']`); good self condition was also higher than neutral self (`r df.ES_4a$M2[df.ES_4a$DVtype == 'dprime' & df.ES_4a$Effect == 'Good_Neut_S']` $\pm$ `r df.ES_4a$SD2[df.ES_4a$DVtype == 'dprime' & df.ES_4a$Effect == 'Good_Neut_S']`) but there was not statistically significant, while the neutral-self condition was higher than bad self condition and not significant neither. For reaction times, good-self condition (`r df.ES_4a$M1[df.ES_4a$DVtype == 'RT' & df.ES_4a$Effect == 'Good_Bad_S']` $\pm$ `r df.ES_4a$SD1[df.ES_4a$DVtype == 'RT' & df.ES_4a$Effect == 'Good_Bad_S']`) were faster relative to bad-self condition (`r df.ES_4a$M2[df.ES_4a$DVtype == 'RT' & df.ES_4a$Effect == 'Good_Bad_S']` $\pm$ `r df.ES_4a$SD2[df.ES_4a$DVtype == 'RT' & df.ES_4a$Effect == 'Good_Bad_S']`), and over neutral-self condition (`r df.ES_4a$M2[df.ES_4a$DVtype == 'RT' & df.ES_4a$Effect == 'Good_Neut_S']` $\pm$ `r df.ES_4a$SD2[df.ES_4a$DVtype == 'RT' & df.ES_4a$Effect == 'Good_Neut_S']`). The difference between neutral-self and bad-self conditions were not significant. However, for the other-referential condition, there was no significant differences between different valence conditions. See Figure \@ref(fig:plot-exp4a-effect).

```{r analyzing exp4b, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
#### Approach 1: compared between self and other
effectList_3 <- c('Self_Other_G','Self_Other_N', 'Self_Other_B')

df.ES_4b <- data.frame(matrix(nrow=length(unique(df4b.meta.d$ExpID))*length(effectList_3)*2, ncol=0)) %>%
  dplyr::mutate(DVtype = rep(c('RT', 'dprime'), each = length(unique(df4b.meta.d$ExpID))*length(effectList_3)),
                ExpID  = rep(rep(unique(df4b.meta.d$ExpID), each = length(effectList_3)), 2),
                Effect = rep(effectList_3, length(unique(df4b.meta.d$ExpID))*2),
                M1 = NA, SD1 = NA, M2 = NA, SD2 = NA, N = NA, r = NA, ES = NA, ES.var = NA)

for (DVName in c('RT','dprime')){
  if (DVName == 'RT'){
    metaData <- df4b.meta.rt %>% dplyr::filter(Matchness == "Match") %>% dplyr::rename(Value = RT)
  } else{
    metaData <- df4b.meta.d %>% dplyr::rename(Value = dprime)
  }
  for (expName in unique(metaData$ExpID)){
    for (effectName in effectList_3){
      tmpdata <- metaData %>% dplyr::filter(ExpID == expName & Domain == 'Morality')

      if (effectName == 'Self_Other_G'){

        if (!all(is.na(tmpdata$Identity))){
          #print(paste('processing Good_Bad_S of ', expName, sep = ''))
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good" & Identity == 'Self')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Good" & Identity == 'Other')
          }
        else{
            #print(paste('Skip Good_Bad_S of ', expName, sep = ''))
          next
          }
        }
      else if (effectName == 'Self_Other_N'){
        if (!all(is.na(tmpdata$Identity)) & 'Neutral' %in% tmpdata$Valence ){
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Neutral" & Identity == 'Self')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Neutral" & Identity == 'Other')
          }
        else{
          next
          }
        }
      else if (effectName == 'Self_Other_B'){
        if (!all(is.na(tmpdata$Identity)) & 'Bad' %in% tmpdata$Valence ){
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Bad" & Identity == 'Self')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Bad" & Identity == 'Other')
          }
        else{
          next
          }
        }

      M1  <- mean(dataCond1$Value) -> df.ES_4b$M1[df.ES_4b$DVtype == DVName & df.ES_4b$ExpID == expName & df.ES_4b$Effect == effectName]
      SD1 <- sd(dataCond1$Value)   -> df.ES_4b$SD1[df.ES_4b$DVtype == DVName & df.ES_4b$ExpID == expName & df.ES_4b$Effect == effectName]
      M2  <- mean(dataCond2$Value) -> df.ES_4b$M2[df.ES_4b$DVtype == DVName & df.ES_4b$ExpID == expName & df.ES_4b$Effect == effectName]
      SD2 <- sd(dataCond2$Value)   -> df.ES_4b$SD2[df.ES_4b$DVtype == DVName & df.ES_4b$ExpID == expName & df.ES_4b$Effect == effectName]
      N   <- length(unique(dataCond2$Subject)) -> df.ES_4b$N[df.ES_4b$DVtype == DVName & df.ES_4b$ExpID == expName & df.ES_4b$Effect == effectName]
      r   <- cor(dataCond1$Value,dataCond2$Value) -> df.ES_4b$r[df.ES_4b$DVtype == DVName & df.ES_4b$ExpID == expName & df.ES_4b$Effect == effectName]
      tmp2 <- d.sgpp(m.1 = M1, m.2 = M2, sd.1 = SD1, sd.2 = SD2,n = N, r = r)
      df.ES_4b$ES[df.ES_4b$DVtype == DVName & df.ES_4b$ExpID == expName & df.ES_4b$Effect == effectName] <- tmp2[1,1]
      df.ES_4b$ES.var[df.ES_4b$DVtype == DVName & df.ES_4b$ExpID == expName & df.ES_4b$Effect == effectName] <- tmp2[1,2]
    }
  }
}

df.ES_4b <- df.ES_4b %>%
  dplyr::mutate(Val = ifelse(Effect == "Self_Other_G", "Good",
                                  ifelse(Effect == "Self_Other_N", 'Neutral', 'Bad')),
                EffectType = 'Self_Other',
                Val = factor(Val, levels = c("Good", "Neutral", "Bad")))

#### Approach 2: compared between self and other
# Added the interaction in the effect size calculation directly
df.ES_4b_2 <- data.frame(matrix(nrow= (length(unique(df4b.meta.d$ExpID))*length(effectList_2) +3)*2 , ncol=0)) %>%
  dplyr::mutate(DVtype = rep(c('RT', 'dprime'), each = length(unique(df4b.meta.d$ExpID))*length(effectList_2) + 3),
                ExpID  = rep(rep(unique(df4b.meta.d$ExpID), each = length(effectList_2) + 3), 2),
                Effect = rep(c(effectList_2, c('Good_Bad_SO', 'Good_Neut_SO', 'Bad_Neut_SO')), length(unique(df4b.meta.d$ExpID))*2),
                M1 = NA, SD1 = NA, M2 = NA, SD2 = NA, N = NA, r = NA, ES = NA, ES.var = NA)

for (DVName in c('RT','dprime')){
  if (DVName == 'RT'){
    metaData <- df4b.meta.rt %>% dplyr::filter(Matchness == "Match") %>% dplyr::rename(Value = RT)
  } else{
    metaData <- df4b.meta.d %>% dplyr::rename(Value = dprime)
  }

  for (expName in unique(metaData$ExpID)){
    for (effectName in c(effectList_2, c('Good_Bad_SO', 'Good_Neut_SO', 'Bad_Neut_SO'))){
      tmpdata <- metaData %>% dplyr::filter(ExpID == expName & Domain == 'Morality')

      if (effectName == 'Good_Bad_S'){

        if (!all(is.na(tmpdata$Identity))){
          #print(paste('processing Good_Bad_S of ', expName, sep = ''))
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good" & Identity == 'Self')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Bad" & Identity == 'Self')
          }
        else{
            #print(paste('Skip Good_Bad_S of ', expName, sep = ''))
          next
          }
        }
      else if (effectName == 'Good_Neut_S'){
        if (!all(is.na(tmpdata$Identity)) & 'Neutral' %in% tmpdata$Valence ){
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good" & Identity == 'Self')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Neutral" & Identity == 'Self')
          }
        else{
          next
          }
        }
      else if (effectName == 'Bad_Neut_S'){
        if (!all(is.na(tmpdata$Identity)) & 'Neutral' %in% tmpdata$Valence ){
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Bad" & Identity == 'Self')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Neutral" & Identity == 'Self')
          }
        else{
          next
          }
        }
      else if (effectName == 'Good_Bad_O'){
        if (!all(is.na(tmpdata$Identity))){
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good" & Identity == 'Other')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Bad" & Identity == 'Other')
          }
        else{
          next
          }
        }
      else if (effectName == 'Good_Neut_O'){
        if (!all(is.na(tmpdata$Identity)) & 'Neutral' %in% tmpdata$Valence )
          {
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good" & Identity == 'Other')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Neutral" & Identity == 'Other')
          }
        else{
          next
          }
        }
      else if (effectName == 'Bad_Neut_O'){
        if (!all(is.na(tmpdata$Identity)) & 'Neutral' %in% tmpdata$Valence){
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Bad" & Identity == 'Other')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Neutral" & Identity == 'Other')
          }
        else{
          next
          }
      }
      else if (effectName == 'Good_Bad_SO'){
        if (!all(is.na(tmpdata$Identity))){
          dataCond01 <- tmpdata %>% dplyr::filter(Valence == "Good" & Identity == 'Self')
          dataCond02 <- tmpdata %>% dplyr::filter(Valence == "Bad" & Identity == 'Self')
          dataCond03 <- tmpdata %>% dplyr::filter(Valence == "Good" & Identity == 'Other')
          dataCond04 <- tmpdata %>% dplyr::filter(Valence == "Bad" & Identity == 'Other') 
          
          dataCond1 <- dataCond01 %>% dplyr::mutate(Value = Value - dataCond02$Value)  # good-self - bad-self 
          dataCond2 <- dataCond03 %>% dplyr::mutate(Value = Value - dataCond04$Value)   # good-other - bad-other
          }
        else{
          next
          }
        }
      else if (effectName == 'Good_Neut_SO'){
        if (!all(is.na(tmpdata$Identity)) & 'Neutral' %in% tmpdata$Valence )
          {
          dataCond01 <- tmpdata %>% dplyr::filter(Valence == "Good" & Identity == 'Self') 
          dataCond02 <- tmpdata %>% dplyr::filter(Valence == "Neutral" & Identity == 'Self')
          dataCond03 <- tmpdata %>% dplyr::filter(Valence == "Good" & Identity == 'Other')
          dataCond04 <- tmpdata %>% dplyr::filter(Valence == "Neutral" & Identity == 'Other')
          
          dataCond1 <- dataCond01 %>% dplyr::mutate(Value = Value - dataCond02$Value)   # good-self - neutral-self 
          dataCond2 <- dataCond03 %>% dplyr::mutate(Value = Value - dataCond04$Value)   # good-other - neutral-other
          }
        else{
          next
          }
        }
      else if (effectName == 'Bad_Neut_SO'){
        if (!all(is.na(tmpdata$Identity)) & 'Neutral' %in% tmpdata$Valence){
          dataCond01 <- tmpdata %>% dplyr::filter(Valence == "Bad" & Identity == 'Self')
          dataCond02 <- tmpdata %>% dplyr::filter(Valence == "Neutral" & Identity == 'Self')
          dataCond03 <- tmpdata %>% dplyr::filter(Valence == "Bad" & Identity == 'Other')
          dataCond04 <- tmpdata %>% dplyr::filter(Valence == "Neutral" & Identity == 'Other')
          
          dataCond1 <- dataCond01 %>% dplyr::mutate(Value = Value - dataCond02$Value) # bad-self - neutral-self
          dataCond2 <- dataCond03 %>% dplyr::mutate(Value = Value - dataCond04$Value) # bad-other - neutral-other
          }
        else{
          next
          }
      }
      M1  <- mean(dataCond1$Value) -> df.ES_4b_2$M1[df.ES_4b_2$DVtype == DVName & df.ES_4b_2$ExpID == expName & df.ES_4b_2$Effect == effectName]
      SD1 <- sd(dataCond1$Value)   -> df.ES_4b_2$SD1[df.ES_4b_2$DVtype == DVName & df.ES_4b_2$ExpID == expName & df.ES_4b_2$Effect == effectName]
      M2  <- mean(dataCond2$Value) -> df.ES_4b_2$M2[df.ES_4b_2$DVtype == DVName & df.ES_4b_2$ExpID == expName & df.ES_4b_2$Effect == effectName]
      SD2 <- sd(dataCond2$Value)   -> df.ES_4b_2$SD2[df.ES_4b_2$DVtype == DVName & df.ES_4b_2$ExpID == expName & df.ES_4b_2$Effect == effectName]
      N   <- length(unique(dataCond2$Subject)) -> df.ES_4b_2$N[df.ES_4b_2$DVtype == DVName & df.ES_4b_2$ExpID == expName & df.ES_4b_2$Effect == effectName]
      r   <- cor(dataCond1$Value,dataCond2$Value) -> df.ES_4b_2$r[df.ES_4b_2$DVtype == DVName & df.ES_4b_2$ExpID == expName & df.ES_4b_2$Effect == effectName]
      tmp2 <- d.sgpp(m.1 = M1, m.2 = M2, sd.1 = SD1, sd.2 = SD2,n = N, r = r)
      df.ES_4b_2$ES[df.ES_4b_2$DVtype == DVName & df.ES_4b_2$ExpID == expName & df.ES_4b_2$Effect == effectName] <- tmp2[1,1]
      df.ES_4b_2$ES.var[df.ES_4b_2$DVtype == DVName & df.ES_4b_2$ExpID == expName & df.ES_4b_2$Effect == effectName] <- tmp2[1,2]
    }
  }
}

df.ES_4b_2 <- df.ES_4b_2 %>%
  dplyr::mutate(Identity = ifelse(Effect == "Good_Bad_S" | Effect == "Good_Neut_S" | Effect == "Bad_Neut_S",
                                  "Self-ref.", 
                                  ifelse(Effect == "Good_Bad_O" | Effect == "Good_Neut_O" | Effect == "Bad_Neut_O", 
                                         "Other-ref.", 'Interaction')),
                EffectType = ifelse(Effect == "Good_Bad_S" | Effect == "Good_Bad_O"  | Effect == "Good_Bad_SO", "Good_Bad",
                                    ifelse(Effect == "Good_Neut_S" | Effect == "Good_Neut_O"  | Effect == "Good_Neut_SO", "Good_Neut", "Bad_Neut")),
                Identity = factor(Identity, levels = c("Self-ref.", "Other-ref.", 'Interaction')),
                EffectType = factor(EffectType, levels = c("Good_Bad", "Good_Neut", "Bad_Neut")))
```

```{r 'plot-exp4b-effect-1', fig.cap="Effect size (Cohen's *d*) of Valence in Exp4b.", warning=FALSE}
df.ES_4b %>%
  #dplyr::filter(Identity == "Self") %>%
  ggplot(., aes(x=EffectType, y=ES, color=Val, fill=Val)) + # , color=Val, fill=Val
  geom_pointrange(aes(ymin=ES - 1.96*sqrt(ES.var), ymax = ES + 1.96*sqrt(ES.var)),
                  position = position_dodge(width = 0.5),
                  shape=18, size=0.8) +
  geom_hline(yintercept=0, size=0.5, color='grey', linetype = 'dashed') +
  # ggtitle('Self-reference effect') +
  coord_cartesian(ylim=c(-1.1, 1.1))+
  scale_color_brewer(palette = "Dark2")+
  scale_fill_brewer(palette = "Dark2")+
  ylab(expression(paste("Cohen's ",italic("d"), sep = ' '))) +
  xlab('Self-reference effect') + 
  apatheme_x +
  facet_grid(DVtype ~ .)
```

```{r 'plot-exp4b-effect-2', fig.cap="Effect size (Cohen's *d*) of Valence in Exp4b.", warning=FALSE}
df.ES_4b_2 %>%
  dplyr::filter(Effect %in% effectList_2) %>%
  dplyr::filter(EffectType != "Good_Bad") %>%
  ggplot(., aes(x=EffectType, y=ES, color=EffectType, fill=EffectType)) +
  geom_pointrange(aes(ymin=ES - 1.96*sqrt(ES.var), ymax = ES + 1.96*sqrt(ES.var)),
                  position = position_dodge(width = 0.5),
                  shape=18, size=1) +
  geom_hline(yintercept=0, size=1, color='grey', linetype = 'dashed') +
  # ggtitle('A: Valence effect') +
  coord_cartesian(ylim=c(-1.1, 1.1))+
  scale_color_brewer(palette = "Dark2")+
  scale_fill_brewer(palette = "Dark2")+
  ylab(expression(paste("Effect size: Cohen's ",italic("d"), sep = ' ')))+
  xlab('Valence effect')+
  apatheme_x +
  facet_grid(DVtype ~ Identity)
```

```{r 'plot-exp4b-diff-diff', fig.cap="Effect size (Cohen's *d*) of Valence in Exp4b.", warning=FALSE}
df.ES_4b_2 %>%
  #dplyr::filter(Effect %in% c('Good_Bad_SO', 'Good_Neut_SO', 'Bad_Neut_SO')) %>%
  dplyr::filter(Effect %in% c('Good_Neut_SO', 'Bad_Neut_SO')) %>%
  ggplot(., aes(x=EffectType, y=ES, color=EffectType, fill=EffectType)) + 
  geom_pointrange(aes(ymin=ES - 1.96*sqrt(ES.var), ymax = ES + 1.96*sqrt(ES.var)), 
                  position = position_dodge(width = 0.5),
                  shape=18, size=0.8) +
  geom_hline(yintercept=0, size=0.5, color='grey', linetype = 'dashed') +
  # ggtitle('Differences in valence effect (self-other)') +
  coord_cartesian(ylim=c(-1.1, 1.1))+
  scale_color_brewer(palette = "Dark2")+
  scale_fill_brewer(palette = "Dark2")+
  ylab(expression(paste("Effect size: Cohen's ",italic("d"), sep = ' ')))+
  xlab('Diff of valence effect between self vs. other condition')+
  apatheme_x +
  facet_grid(DVtype ~ .)
  # facet_wrap(~ DVtype, strip.position="right")
```

For experiment 4b, when valence was the target and the identity was task-irrelevant, we found a strong valence effect (see supplementary results and Figure \@ref(fig:plot-exp4b-effect-1), Figure \@ref(fig:plot-exp4b-effect-2)). 

In this experiment, the advantage of good-self condition can only be disentangled by comparing the self-referential and other-referential conditions. Therefore, we calculated the differences between the valence effect under self-referential and other referential conditions and used the weighted variance as the variance of this differences. We found this modulation effect on RT. The valence effect of RT was stronger in self-referential than other-referential for the Good vs. Neutral condition (`r df.ES_4b_2$ES[df.ES_4b_2$DVtype == 'RT' & df.ES_4b_2$Effect == 'Good_Neut_SO']` $\pm$ `r df.ES_4b_2$ES.var[df.ES_4b_2$DVtype == 'RT' & df.ES_4b_2$Effect == 'Good_Neut_SO']`), and to a less extent the Good vs. Bad condition (`r df.ES_4b_2$ES[df.ES_4b_2$DVtype == 'RT' & df.ES_4b_2$Effect == 'Good_Bad_SO']` $\pm$ `r df.ES_4b_2$ES.var[df.ES_4b_2$DVtype == 'RT' & df.ES_4b_2$Effect == 'Good_Bad_SO']`). While the size of the other effect's CI included zero, suggestion those effects didn't differ from zero. See Figure \@ref(fig:plot-exp4b-diff-diff).

## Specificity of valence effect

```{r analyzing exp5, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
effectList_exp5 <- c('Good_Bad_Mrl','Good_Neut_Mrl','Bad_Neut_Mrl',
                     'Good_Bad_BP','Good_Neut_BP','Bad_Neut_BP',
                     'Good_Bad_BS','Good_Neut_BS','Bad_Neut_BS',
                     'Good_Bad_Emo','Good_Neut_Emo','Bad_Neut_Emo')

df.ES_5 <- data.frame(matrix(nrow=length(unique(df5.meta.d$ExpID))*length(effectList_exp5)*2, ncol=0)) %>%
  dplyr::mutate(DVtype = rep(c('RT', 'dprime'), each = length(unique(df5.meta.d$ExpID))*length(effectList_exp5)),
                ExpID  = rep(rep(unique(df5.meta.d$ExpID), each = length(effectList_exp5)), 2),
                Effect = rep(effectList_exp5, length(unique(df5.meta.d$ExpID))*2),
                M1 = NA, SD1 = NA, M2 = NA, SD2 = NA, N = NA, r = NA, ES = NA, ES.var = NA)

for (DVName in c('RT','dprime')){
  if (DVName == 'RT'){
    metaData <- df5.meta.rt %>% dplyr::filter(Matchness == "Match") %>% dplyr::rename(Value = RT)
  } else{
    metaData <- df5.meta.d %>% dplyr::rename(Value = dprime)
  }
  
  for (expName in unique(metaData$ExpID)){
    for (effectName in effectList_exp5){
      if (effectName == 'Good_Bad_Mrl'){
        tmpdata <- metaData %>% dplyr::filter(ExpID == expName & Domain == 'Morality')
        dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good")
        dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Bad")  
        }
      else if (effectName == 'Good_Neut_Mrl'){
        tmpdata <- metaData %>% dplyr::filter(ExpID == expName & Domain == 'Morality')
        dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good")
        dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Neutral")  
        }  
      else if (effectName == 'Bad_Neut_Mrl'){
        tmpdata <- metaData %>% dplyr::filter(ExpID == expName & Domain == 'Morality')
        dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Bad")
        dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Neutral")
      }
      
      else if (effectName == 'Good_Bad_BP'){
        tmpdata <- metaData %>% dplyr::filter(ExpID == expName & Domain == 'Person')
        dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good")
        dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Bad")  
        }
      else if (effectName == 'Good_Neut_BP'){
        tmpdata <- metaData %>% dplyr::filter(ExpID == expName & Domain == 'Person')
        dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good")
        dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Neutral")  
        }  
      else if (effectName == 'Bad_Neut_BP'){
        tmpdata <- metaData %>% dplyr::filter(ExpID == expName & Domain == 'Person')
        dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Bad")
        dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Neutral")
      }
      
      else if (effectName == 'Good_Bad_BS'){
        tmpdata <- metaData %>% dplyr::filter(ExpID == expName & Domain == 'Scene')
        dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good")
        dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Bad")  
        }
      else if (effectName == 'Good_Neut_BS'){
        tmpdata <- metaData %>% dplyr::filter(ExpID == expName & Domain == 'Scene')
        dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good")
        dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Neutral")  
        }  
      else if (effectName == 'Bad_Neut_BS'){
        tmpdata <- metaData %>% dplyr::filter(ExpID == expName & Domain == 'Scene')
        dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Bad")
        dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Neutral")
      }
      
      else if (effectName == 'Good_Bad_Emo'){
        tmpdata <- metaData %>% dplyr::filter(ExpID == expName & Domain == 'Emotion')
        dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good")
        dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Bad")  
        }
      else if (effectName == 'Good_Neut_Emo'){
        tmpdata <- metaData %>% dplyr::filter(ExpID == expName & Domain == 'Emotion')
        dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good")
        dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Neutral")  
        }  
      else if (effectName == 'Bad_Neut_Emo'){
        tmpdata <- metaData %>% dplyr::filter(ExpID == expName & Domain == 'Emotion')
        dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Bad")
        dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Neutral")
        }
      
      M1  <- mean(dataCond1$Value) -> df.ES_5$M1[df.ES_5$DVtype == DVName & df.ES_5$ExpID == expName & df.ES_5$Effect == effectName]
      SD1 <- sd(dataCond1$Value)   -> df.ES_5$SD1[df.ES_5$DVtype == DVName & df.ES_5$ExpID == expName & df.ES_5$Effect == effectName] 
      M2  <- mean(dataCond2$Value) -> df.ES_5$M2[df.ES_5$DVtype == DVName & df.ES_5$ExpID == expName & df.ES_5$Effect == effectName]
      SD2 <- sd(dataCond2$Value)   -> df.ES_5$SD2[df.ES_5$DVtype == DVName & df.ES_5$ExpID == expName & df.ES_5$Effect == effectName]
      N   <- length(unique(dataCond2$Subject)) -> df.ES_5$N[df.ES_5$DVtype == DVName & df.ES_5$ExpID == expName & df.ES_5$Effect == effectName]
      r   <- cor(dataCond1$Value,dataCond2$Value) -> df.ES_5$r[df.ES_5$DVtype == DVName & df.ES_5$ExpID == expName & df.ES_5$Effect == effectName] 
      tmp2 <- d.sgpp(m.1 = M1, m.2 = M2, sd.1 = SD1, sd.2 = SD2,n = N, r = r)
      df.ES_5$ES[df.ES_5$DVtype == DVName & df.ES_5$ExpID == expName & df.ES_5$Effect == effectName] <- tmp2[1,1]
      df.ES_5$ES.var[df.ES_5$DVtype == DVName & df.ES_5$ExpID == expName & df.ES_5$Effect == effectName] <- tmp2[1,2]
    }
  }
}

df.ES_5 <- df.ES_5 %>%
  dplyr::mutate(Domain = ifelse(Effect == "Good_Bad_Mrl" | Effect == "Good_Neut_Mrl" | Effect == "Bad_Neut_Mrl",
                                  "Mrl",
                                ifelse(Effect == "Good_Bad_BP" | Effect == "Good_Neut_BP" | Effect == "Bad_Neut_BP",
                                  "AP",
                                  ifelse(Effect == "Good_Bad_BS" | Effect == "Good_Neut_BS" | Effect == "Bad_Neut_BS",
                                  "AS", 'Emo'))),
                Domain = factor(Domain, levels = c("Mrl", "AP", "AS", "Emo")),
                EffectType = ifelse(Effect == "Good_Bad_Mrl" | Effect == "Good_Bad_BP"  | Effect == "Good_Bad_BS"  | Effect == "Good_Bad_Emo", "Pos_Neg",
                                    ifelse(Effect == "Good_Neut_Mrl" | Effect == "Good_Neut_BP" | Effect == "Good_Neut_BS" | Effect == "Good_Neut_Emo", "Pos_Neut", "Neg_Neut")),
                EffectType = factor(EffectType, levels = c("Pos_Neg", "Pos_Neut", "Neg_Neut")))
```

```{r 'plot-exp5-effect', fig.cap="Effect size (Cohen's *d*) of Valence in Exp5.", warning=FALSE}
df.ES_5 %>%
  dplyr::filter(EffectType != "Pos_Neg") %>%
  ggplot(., aes(x=EffectType, y=ES, color=EffectType, fill=EffectType)) + 
  geom_pointrange(aes(ymin=ES - 1.96*sqrt(ES.var), ymax = ES + 1.96*sqrt(ES.var)), 
                  position = position_dodge(width = 0.4),
                  shape=18, size=1) +
  geom_hline(yintercept=0, size=1, color='black') +
  # ggtitle('Valence effect across different domains') +
  coord_cartesian(ylim=c(-1.5, 1.5))+
  scale_color_brewer(palette = "Dark2")+
  scale_fill_brewer(palette = "Dark2")+
  ylab(expression(paste("Effect size: Cohen's ",italic("d"), sep = ' '))) +
  xlab('Contrast between different valences') +
  facet_grid(DVtype ~ Domain) +
  apatheme_x
```

In this part, we analyzed the results from experiment 5, which included positive, neutral, and negative valence from four different domains: morality, emotion, aesthetics of human, and aesthetics of scene. We found interaction between valence and domain for both *d* prime and RT (match trials). A common pattern appeared in all four domains: each domain showed a binary results instead of gradient on both *d* prime and RT. For morality, aesthetics of human, and aesthetics of scene, there was a positivity effect where the positive conditions had advantages over both neutral (greater *d* prime and faster RT), while neutral and negative conditions didn't differ from each other. But for the emotional stimuli, there was a reversed negativity effect: positive and neutral conditions were not significantly different from each other but both had advantage over negative conditions. See supplementary materials for detailed statistics. Also note that the effect size in moral domain is smaller than the aesthetic domains (beauty of people and beauty of scene). See Figure \@ref(fig:plot-exp5-effect).

## Self-reported personal distance

```{r personal distance, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
# prepare questionnaire data
df.scales <- read.csv(here::here("Scale_data", "FADGS_dataset4ID_clean.csv"), header = TRUE, sep = ",",
                 stringsAsFactors=FALSE,na.strings=c("","NA")) %>%
  dplyr::mutate(expID = derivedFactor("Exp1a" = (expID == "exp1.0"), 
                                      "Exp1b" = (expID == "exp1.1"),
                                      "Exp3a" = (expID == "exp3"),
                                      "Exp3b" = (expID == "exp3.1"),
                                      "Exp4a" = (expID == "exp4.1"),
                                      "Exp4b" = (expID == "exp4.2"),
                                      "Exp5" = (expID == "exp5.2"),
                                      "Exp6b" = (expID == "exp6.2"),
                                      "Exp7a" = (expID == "exp7.1"),
                                      "Exp7b" = (expID == "exp7r"),
                                      "Exp_dpr" = (expID == "exp6"),
                                      .method ="first", .default = NA),
                expID = as.character(expID))

## get the questionnaire names
# Self-esteem
SlfEstNames <- c("SES1","SES2","SES3","SES4","SES5","SES6","SES7","SES8","SES9","SES10")
SlfEstNames_r <- c("SES1","SES2","SES3_r","SES4","SES5_r","SES6","SES7","SES8","SES9_r","SES10_r")

# moral identity
mrlIdNames <- c("morId_1","morId_2","morId_3","morId_4", "morId_5","morId_6",
                "morId_7","morId_8","morId_9","morId_10","morId_11","morId_12",
                "morId_13","morId_14","morId_15","morId_16")

mrlIdIntNames <- c("morId_1","morId_2","morId_5","morId_8", "morId_10","morId_11",
                   "morId_12","morId_13","morId_14")
mrlIdIntNames_r <- c("morId_1","morId_2","morId_5_r","morId_8", "morId_10","morId_11",
                   "morId_12","morId_13","morId_14")
mrlIdExtNames <- c("morId_3","morId_4", "morId_6", "morId_7", "morId_9",
                   "morId_15", "morId_16")

# moral self images
mrlslfImgNames <- c("morSlfImg_1","morSlfImg_2","morSlfImg_3","morSlfImg_4",
                    "morSlfImg_5","morSlfImg_6","morSlfImg_7","morSlfImg_8","morSlfImg_9")

# personal distance
perDistNames <- c("SelfSelf", 
                  "SelfGood_1", "SelfGood_2", "SelfGood_3", "SelfGood_4",
                  "SelfNeut_1", "SelfNeut_2", "SelfNeut_3", "SelfNeut_4",
                  "SelfBad_1",  "SelfBad_2",  "SelfBad_3",  "SelfBad_4",
                  "SelfStra_1", "SelfStra_2", "SelfStra_3", "SelfStra_4",
                  "GoodNeut_1", "GoodNeut_2", "GoodNeut_3", "GoodNeut_4", 
                  "GoodBad_1",  "GoodBad_2",  "GoodBad_3",  "GoodBad_4",
                  "NeutBad_1",  "NeutBad_2",  "NeutBad_3",  "NeutBad_4")

perDistNames2 <- c("SelfGood_1", "SelfGood_2", "SelfGood_3", "SelfGood_4",
                  "SelfNeut_1", "SelfNeut_2", "SelfNeut_3", "SelfNeut_4",
                  "SelfBad_1",  "SelfBad_2",  "SelfBad_3",  "SelfBad_4",
                  "GoodNeut_1", "GoodNeut_2", "GoodNeut_3", "GoodNeut_4", 
                  "GoodBad_1",  "GoodBad_2",  "GoodBad_3",  "GoodBad_4",
                  "NeutBad_1",  "NeutBad_2",  "NeutBad_3",  "NeutBad_4")

# Normalize the person distance by dividing the maximum value for each data point
df.perdist <- df.scales %>%
  dplyr::select(c(expID, subjID),perDistNames) %>%
  dplyr::mutate(sd_raw = matrixStats::rowSds(as.matrix(.[perDistNames]))) %>%
  dplyr::filter(sd_raw >=10) %>%                                # remove data with small variance
  dplyr::mutate(maxDist = pmax(!!!rlang::syms(perDistNames)))   # find the maximum value of the row

df.perdist[,3:31] <- df.perdist[,3:31]/df.perdist$maxDist       # dividing the maximum

# Get the mean value of each distance
df.perdist <- df.perdist %>%        
    dplyr::mutate(# sumRaw = rowMeans(.[3:31], na.rm = T),
                SelfGood = rowMeans(.[grep("SelfGood", names(.))], na.rm = T),
                SelfNeut = rowMeans(.[grep("SelfNeut", names(.))], na.rm = T),
                SelfBad  = rowMeans(.[grep("SelfBad", names(.))], na.rm = T),
                GoodNeut = rowMeans(.[grep("GoodNeut", names(.))], na.rm = T),
                GoodBad  = rowMeans(.[grep("GoodBad", names(.))], na.rm = T),
                NeutBad  = rowMeans(.[grep("NeutBad", names(.))], na.rm = T)) %>%
    dplyr::select(expID, subjID,
                SelfGood, SelfNeut, SelfBad, GoodNeut, GoodBad, NeutBad) %>%
  tidyr::drop_na()

# calculate the factor score for moral identity, moral self image, self-esteem, and personal distance.

df.scales <- df.scales %>%
  dplyr::mutate(morId_5_r = 0 - morId_5, # reverse the items that need to be reversed.
                SES3_r = 5 - SES3,
                SES5_r = 5 - SES5,
                SES9_r = 5 - SES9,
                SES10_r = 5 - SES10) %>%
  dplyr::mutate(SlfEst_sum = rowSums(.[SlfEstNames_r]),
                mrlIdInt_sum = rowSums(.[mrlIdIntNames_r]),
                mrlIdExt_sum = rowSums(.[mrlIdExtNames]),
                mrlSlfImg_sum = rowSums(.[mrlslfImgNames]))

df.scale.fs <- df.scales %>% dplyr::select(expID, subjID, SlfEst_sum, mrlIdInt_sum, mrlIdExt_sum, mrlSlfImg_sum)

FS.m.id1 <- 'mrlIdInt =~ morId_1 + morId_2 + morId_5_r + morId_8 + morId_10 + morId_11 + morId_12 + morId_13 + morId_14
             
             mrlIdExt =~ morId_3 + morId_4 + morId_6 + morId_7 + morId_9 + morId_15 + morId_16 '

FS.m.id1.fit <- lavaan::cfa(FS.m.id1, data = df.scales, estimator = "MLR")

idx <- lavInspect(FS.m.id1.fit, "case.idx")
fscores <- lavPredict(FS.m.id1.fit)
for (fs in colnames(fscores)) {
  df.scale.fs[idx, fs] <- fscores[ , fs]
}

FS.m.id2 <- ' morSlfImg =~ morSlfImg_1 + morSlfImg_2 + morSlfImg_3 + morSlfImg_4 + morSlfImg_5 + morSlfImg_6 + morSlfImg_7 + 
                          morSlfImg_8 + morSlfImg_9 '

FS.m.id2.fit <- lavaan::cfa(FS.m.id2, data = df.scales, estimator = "MLR")

idx <- lavInspect(FS.m.id2.fit, "case.idx")
fscores <- lavPredict(FS.m.id2.fit)
for (fs in colnames(fscores)) {
  df.scale.fs[idx, fs] <- fscores[ , fs]
}

FS.m.id3 <- ' SlfEst =~ SES1 + SES2 + SES3_r + SES4 + SES5_r + SES6 + SES7 + SES8 + SES9_r + SES10_r '

FS.m.id3.fit <- lavaan::cfa(FS.m.id3, data = df.scales, estimator = "MLR")

# summary(FS.m.id3.fit, standardize = TRUE, fit.measures=TRUE)
# semPlot::semPaths(FS.m.id3.fit, "std", edge.label.cex = 0.5, curvePivot = TRUE, intercepts = FALSE)

idx <- lavInspect(FS.m.id3.fit, "case.idx")
fscores <- lavPredict(FS.m.id3.fit)
for (fs in colnames(fscores)) {
  df.scale.fs[idx, fs] <- fscores[ , fs]
}

df.scale.fs <- df.scale.fs %>%
  dplyr::left_join(., df.perdist)

```


```{r plot-person-dist, fig.cap="Self-rated personal distance", fig.width=8, warning=FALSE}
# Boxplot
p_dist_1 <- df.perdist %>% 
  tidyr::pivot_longer(., cols = SelfGood:NeutBad,
                      names_to = 'PerDist',
                      values_to = 'value') %>%
  dplyr::mutate(PerDist=factor(PerDist, levels = c('SelfNeut', 'SelfGood', 'GoodNeut', 'NeutBad', 'GoodBad', 'SelfBad'))) %>%
  ggplot2::ggplot(.,aes(x=PerDist, y=value)) +
  ggplot2::geom_boxplot() +
  ggplot2::geom_point(position = position_jitter(),size = 1, shape = 20, alpha = 0.15) + 
  scale_fill_brewer(palette = "Dark2") +
    theme_bw() +
    theme(panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          panel.background = element_blank(),
          panel.border = element_blank(),
          text=element_text(family='Times'),
          legend.title=element_blank(),
          legend.text = element_text(size =12),
          plot.title = element_text(lineheight=.8, face="bold", size = 16, margin=margin(0,0,20,0)),
          axis.text = element_text (size = 12, color = 'black'),
          axis.title = element_text (size = 12),
          axis.title.x = element_blank(),
          axis.title.y = element_blank(),
          axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1),
          axis.line.x = element_line(color='black', size = 1),    # increase the size of font
          axis.line.y = element_line(color='black', size = 1),    # increase the size of font
          strip.text = element_text (size = 12, color = 'black'), # size of text in strips, face = "bold"
          panel.spacing = unit(3, "lines")) 

dist.cor <- df.perdist %>%
  dplyr::select(-c(subjID, expID)) %>%
  as.matrix() %>%
  Hmisc::rcorr(., type = 'spearman')

p_dist_2 <- ggcorrplot::ggcorrplot(dist.cor$r, hc.order = TRUE, type = "lower",
     outline.col = "white", colors = c('red', 'white', 'blue'),
     lab = TRUE, p.mat = dist.cor$P) +
  #theme_bw() +
  scale_y_discrete(position='right') +
  theme(panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          panel.background = element_blank(),
          panel.border = element_blank(),
          text=element_text(family='Times'),
          legend.title=element_blank(),
          legend.text = element_text(size =12),
          plot.title = element_text(lineheight=.8, face="bold", size = 16, margin=margin(0,0,20,0)),
          axis.text = element_text (size = 12, color = 'black'),
          axis.title = element_text (size = 12),
          axis.title.x = element_blank(),
          axis.title.y = element_blank(),
          axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1),
          #axis.line.x = element_line(color='black', size = 1),    # increase the size of font
          #axis.line.y = element_line(color='black', size = 1),    # increase the size of font
          strip.text = element_text (size = 12, color = 'black'), # size of text in strips, face = "bold"
          panel.spacing = unit(0, "lines")) 

# correlation bewteen self-reported measures
dist.cor2 <- df.scale.fs %>%
  dplyr::select(mrlIdInt:NeutBad) %>%
  as.matrix() %>%
  Hmisc::rcorr(., type = 'spearman')

p_dist_3 <- ggcorrplot::ggcorrplot(dist.cor2$r, hc.order = TRUE, type = "lower",
     outline.col = "white", colors = c('red', 'white', 'blue'),  insig = "blank",
     lab = TRUE, p.mat = dist.cor2$P) +
  #theme_bw() +
  scale_y_discrete(position='right') +
  theme(panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          panel.background = element_blank(),
          panel.border = element_blank(),
          text=element_text(family='Times'),
          legend.title=element_blank(),
          legend.text = element_text(size =12),
          plot.title = element_text(lineheight=.8, face="bold", size = 16, margin=margin(0,0,20,0)),
          axis.text = element_text (size = 12, color = 'black'),
          axis.title = element_text (size = 12),
          axis.title.x = element_blank(),
          axis.title.y = element_blank(),
          axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1),
          #axis.line.x = element_line(color='black', size = 1),    # increase the size of font
          #axis.line.y = element_line(color='black', size = 1),    # increase the size of font
          strip.text = element_text (size = 12, color = 'black'), # size of text in strips, face = "bold"
          panel.spacing = unit(0, "lines")) 
# 
# corrplot(dist.cor$r, type = "upper", order = "hclust", 
#          tl.col = "black", tl.srt = 45,
#          p.mat = dist.cor$P, sig.level = 0.01, insig = "blank")

# col <- colorRampPalette(c( "red", "white", "blue"))(20)
# p_dist_2 <- heatmap(x = dist.cor$r, col = col, symm = TRUE)
# 
# corrplot(dist.cor$r, type="upper", order="hclust", col=col)
# legend(x="bottomright", legend=c("min", "ave", "max"), 
#      fill=colorRampPalette(c( "red", "white", "blue"))(20))
  
library(patchwork)
p_dist_1 + p_dist_2 + plot_annotation(tag_levels = 'A')  + plot_layout(nrow = 1, byrow = FALSE)

```

See Figure \@ref(fig:plot-person-dist).

## Correlation analyses
The reliability of questionnaires can be found in [@Liu_2020_JOPD]. We calculated the correlation between the data from behavioral task and the questionnaire data. First, we calculated the score for each scale based on their structure and factor loading, instead of sum score [@mcneish_thinking_2020]. Then, we used SEM to estimate the correlation because it can include measurement model and statistical model in a unified framework. 

To make sure that what we found were not false positive, we used two method to ensure the robustness of our analysis. first, we split the data into two half: the data with self and without, then, we used the conditional random forest to find the robust correlation in the exploratory data (with self reference) that can be replicated in the confirmatory data (without the self reference). The robust correlation were then analyzed using SEM


```{r correlation analysis, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
### failed attempt:
# We tried to first correlate the DDM parameters and the questionnaire separately for self-referential and other-referential, and then validation the correlation using data of experiment without self/other-referential. But the sample size for the correlation between questionnaires and behavioral results from experiment without identity are too small n = 16. Therefore, we give up this exploration-validation approach.

# Step 1: Get the parameter values
params.list <- list.files(here::here('HDDM'), pattern = '*_hddm_params.csv')

df_hddm_ls_1 <- params.list[c(1:4, 9:10)]
df_hddm_ls_2 <- params.list[c(5, 6, 11:13)]

for (indx in 1:6){
  if ((indx ==1) && exists('df_hddm_param_1')){   # if the variable already exist before the for loop start
    rm(df_hddm_param_1)
  }
  if (indx == 5 ){
    hddm_params_tmp <- read.csv(here::here("HDDM", df_hddm_ls_1[indx]), header = TRUE, sep = ",",
                   stringsAsFactors=FALSE,na.strings=c("","NA")) %>%
      dplyr::filter(domain == "Morality") %>%
      dplyr::rename(Subject = subj_idx, Matchness = match, Valence = val) %>%
      dplyr::select(Subject, Matchness, Valence, knode_name, mean) %>%
      tidyr::drop_na() %>%
      tidyr::separate(knode_name, into = paste('v', 1:2, sep= '')) %>%
      dplyr::rename(param = v1)  %>% dplyr::filter(Matchness=='Match') %>% dplyr::select(- c(v2, Matchness)) %>%
      tidyr::pivot_wider(., names_from = c('Valence', 'param'), values_from = 'mean')  
    
  } else {
    hddm_params_tmp <- read.csv(here::here("HDDM", df_hddm_ls_1[indx]), header = TRUE, sep = ",",
                   stringsAsFactors=FALSE,na.strings=c("","NA")) %>%
      dplyr::rename(Subject = subj_idx, Matchness = match, Valence = val) %>%
      dplyr::select(Subject, Matchness, Valence, knode_name, mean) %>%
      tidyr::drop_na() %>%
      tidyr::separate(knode_name, into = paste('v', 1:2, sep= '')) %>%
      dplyr::rename(param = v1)  %>% dplyr::filter(Matchness=='Match') %>% dplyr::select(- c(v2, Matchness)) %>%
      tidyr::pivot_wider(., names_from = c('Valence', 'param'), values_from = 'mean')   # %>%
      #dplyr::mutate(ExpID = 'Exp1a')
  }
  if (exists('df_hddm_param_1')) {
    df_hddm_param_1 <- rbind(df_hddm_param_1, hddm_params_tmp) 
  } else {
    df_hddm_param_1 <- hddm_params_tmp
  }
}

for (indx in 1:5){
  if ((indx ==1) && exists('df_hddm_param_2')){   # in case the variable exist in the env.
    rm(df_hddm_param_2)
  }
  hddm_params_tmp <- read.csv(paste(here::here("HDDM", df_hddm_ls_2[indx])), header = TRUE, sep = ",",
                 stringsAsFactors=FALSE,na.strings=c("","NA")) %>%
    dplyr::rename(Subject = subj_idx, Matchness = match, Valence = val, Identity = id) %>%
    dplyr::select(Subject, Matchness, Identity, Valence, knode_name, mean) %>%
    tidyr::drop_na() %>%
    tidyr::separate(knode_name, into = paste('v', 1:2, sep= '')) %>%
    dplyr::rename(param = v1)  %>% 
    dplyr::filter(Matchness=='Match') %>% 
    dplyr::select(- c(v2, Matchness)) %>%
    tidyr::unite(conds, c(Valence, param)) %>%
    #tidyr::unite(conds, c(Identity, Valence, param)) %>%
    tidyr::pivot_wider(., names_from = c('conds'), values_from = 'mean')   # %>%
    #dplyr::mutate(ExpID = 'Exp1a')
  if (indx == 4 | indx == 5){
    hddm_params_tmp <- hddm_params_tmp %>%
      dplyr::mutate(Neutral_v = NA,
                    Neutral_a = NA,
                    #Other_Neutral_v = NA,
                    #Other_Neutral_a = NA,
                    #Other_Neutral_t = NA,
                    Neutral_t = NA) # %>%
      #dplyr::select(Subject, Identity, Bad_a, Good_a, Neutral_a, Bad_v, Good_v, Neutral_v, Bad_t, Good_t,
      #              Neutral_t)
  }
  
  if (exists('df_hddm_param_2')) {
    df_hddm_param_2 <- rbind(df_hddm_param_2, hddm_params_tmp) 
  } else {
    df_hddm_param_2 <- hddm_params_tmp
  }
}

df_hddm_param_1 <- df_hddm_param_1 %>%
  dplyr::mutate(Identity = NA) %>%
  dplyr::select(colnames(df_hddm_param_2))

df_hddm_param_all <- df_hddm_param_2 %>%
  dplyr::filter(Identity == "Self") %>%
  rbind(df_hddm_param_1, .)

# intersection between participant from behavioral task and scales and get the data
subj.common <- intersect(df.scale.fs$subjID, unique(df_hddm_param_all$Subject))  # 260

df.q_scores.v <- df.scale.fs %>% dplyr::filter(subjID %in% subj.common) %>%
  dplyr::select_if(~sum(!is.na(.)) > 0) # remove columns that only have NA.

# temp data for SEM
# tmp <- merge(df.scales.v, df_hddm_param_all, by.x = 'subjID', by.y = 'Subject')

## calculate correlation ----
df.corr <- merge(df.q_scores.v, df_hddm_param_all, by.x = 'subjID', by.y = 'Subject') %>%
  dplyr::select(-c(expID, Identity)) %>%
  dplyr::select(-contains('_sum')) # %>%
  
# library(corrr)
res.cor_all <-df.corr %>%
  dplyr::select(-c(subjID)) %>%
  as.matrix() %>%
  Hmisc::rcorr(., type = 'spearman')

#heatmap(x = res.cor_all$r, col = col, symm = TRUE)

p.mat <- res.cor_all$P %>%
  tidyr::replace_na(1)

# plat the corr matrix
#ggcorrplot::ggcorrplot(res.cor_all$r, hc.order = TRUE, p.mat = p.mat, insig = "blank", # type = "lower",
#                       outline.col = "black", colors = c('red', 'white', 'blue'), lab = T)

#res.cor_all <-df.corr %>%
#  dplyr::select(-c(subjID)) %>%
#  correlation::correlation(., method="spearman", p_adjust = "holm")

param1_names <- colnames(df.scale.fs)[7:length(df.scale.fs)]
param2_names <- colnames(df_hddm_param_all[3:11])

cor_pairs_all <- data.frame(matrix(ncol = 4, nrow = 0))
x <- c("Parameter1", "Parameter2", "r", 'p')
colnames(cor_pairs_all) <- x
i = 0
for (param1 in param1_names) {
  # print(param1)
  for (param2 in param2_names) {
    tmp_r <- res.cor_all$r[param1, param2]
    tmp_p <- res.cor_all$P[param1, param2]
    if (tmp_p <= 0.05) {
      i = i + 1
      cor_pairs_all[i, "Parameter1"] <- param1
      cor_pairs_all[i, "Parameter2"] <- param2
      cor_pairs_all[i, "r"] <- tmp_r
      cor_pairs_all[i, "p"] <- tmp_p
    }
  }
}

```

Instead of use the exploratory correlation analysis, we used a more principled way to explore the correlation between parameter of HDDM (*v*, *t*, and *a*) and scale scores and person distance. 

```{r get plots of correlation, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
# Permutation
set.seed(12345)
permutation <- function(df) {
  v1 <- df[, 1] %>% base::sample(.)
  v2 <- df[, 2] %>% base::sample(.)
  tmp_cor <- cor(v1, v2, method = "pearson")
  tmp_cor
}

# plot for all
boot_plot_list <- list()
corr_plot_list <- list()
for (row_id in 1:nrow(cor_pairs_all)){
  
  # select variables
  var1 <- df.corr %>% dplyr::select(cor_pairs_all$Parameter1[row_id])
  var2 <- df.corr %>% dplyr::select(cor_pairs_all$Parameter2[row_id])
  var_tmp <- data.frame(var1, var2) %>%
    tidyr::drop_na()
  
  # boot
  boot_var <- var_tmp %>%
    bootES::bootES(., R = 5000, effect.type = 'r')
  
  cor_pairs_all$BootES_cor[row_id] <- boot_var$t0[1]
  cor_pairs_all$BootES_lb[row_id] <- boot_var$bounds[[1]]
  cor_pairs_all$BootES_ub[row_id] <- boot_var$bounds[[2]]
  
  # permutation
  per_cor <- rep(NA, 5000)
  for (i in 1:length(per_cor)){
    per_cor[i] <- permutation(var_tmp)
  }
  
  # plot scatter plot
  corr_plot_list[[row_id]] <- data.frame(var1, var2) %>%
    ggplot(., aes_string(x = cor_pairs_all$Parameter1[row_id], y = cor_pairs_all$Parameter2[row_id])) + 
    geom_point() + 
    geom_smooth(method=lm) +
    labs(title=paste(cor_pairs_all$Parameter1[row_id], '&', cor_pairs_all$Parameter2[row_id], sep = ' '), 
       x = cor_pairs_all$Parameter1[row_id], 
       y = cor_pairs_all$Parameter2[row_id]) +
    apatheme_s
  
  # plot permutation and boot 
  boot_cor <- boot_var$t %>%
    as.data.frame(.) %>%
    dplyr::arrange(V1) %>%
    dplyr::rename(corcoef = V1) %>%
    dplyr::mutate(Method = 'bootstrap')
    # dplyr::pull(V1)
  per_cor <- data.frame(per_cor) %>%
    dplyr::rename(corcoef = per_cor) %>%
    dplyr::mutate(Method = 'permutation')
  
  probs <- c(0.025, 0.975)
  quantiles <- quantile(per_cor$corcoef, prob=probs)
  
  # p_dist_df <- rbind(boot_cor, per_cor)
  
  xd <- data.frame(density(per_cor$corcoef)[c("x", "y")]) %>% dplyr::mutate(Method = 'permutation')
  yd <- data.frame(density(boot_cor$corcoef)[c("x", "y")]) %>% dplyr::mutate(Method = 'bootstrap')
  zd <- rbind(xd, yd)
  
  label_r <- paste("r = ", round(cor_pairs_all$r[row_id], 3), sep = '')
  
  boot_plot_list[[row_id]] <- ggplot(zd, aes(x, y, group=Method, colour = Method)) + 
      geom_area(data = subset(xd, x > quantiles[1] & x < quantiles[2]), fill = "grey") + # plot the 95 % area of zero
      geom_line() + 
      geom_vline(xintercept = cor_pairs_all$r[row_id], colour = 'blue') +
      geom_vline(xintercept = quantiles[1], colour = 'grey', linetype="dashed") + 
      geom_vline(xintercept = quantiles[2], colour = 'grey', linetype="dashed") + 
      geom_vline(xintercept = 0, colour = 'grey', linetype="dashed") + 
      # geom_text(aes(x = cor_pairs_all$r[row_id]*2, y = 6, label = label_r), colour = 'blue') +
      scale_color_grey() +
      apatheme_s
}

```
We didn't find the correlation between scale scores and the parameters of HDDM, but found weak correlation between personal distance and the parameter estimated from Good and neutral conditions. 

First, boundary separation (*a*) of moral good condition was correlated with both Self-Bad distance ($r = 0.198$, 95% CI [], $p = 0.0063$) and Neutral-Bad distance ($r = 0.1571$, 95% CI [], $p = 0.031$). At the same time, the non-decision time is negatively correlated with Self-Bad distance ($r = 0.169$, 95% CI [], $p = 0.0197$). See Figure \@ref(fig:plot-corr-1).

```{r plot-corr-1, fig.cap="Correlation between moral identity and boundary separation of good condition; moral self-image and drift rate of good condition", fig.width=8, warning=FALSE}
library(patchwork)
corr_plot_list[[3]] + corr_plot_list[[6]] + corr_plot_list[[5]]  + 
           boot_plot_list[[3]] + boot_plot_list[[6]] + boot_plot_list[[5]]+ plot_layout(ncol = 3)
```

Second, we found the boundary separation of neutral condition is positively correlated with the personal distance between self and good distance ($r = 0.189$, 95% CI [], $p = 0.036$), but negatively correlated with self-neutral distance($r = -0.183$, 95% CI [], $p = 0.042$). Also, the drift rate of the neutral condition is positively correlated with the Self-Bad distance ($r = 0.177$, 95% CI [], $p = 0.048$).a. See figure \@ref(fig:plot-corr-2)

```{r plot-corr-2, fig.cap="Correlation between personal distance and boundary separation of neutral condition", fig.width=8, warning=FALSE}
library(patchwork)
corr_plot_list[[1]] + corr_plot_list[[2]]  + corr_plot_list[[4]] + 
           boot_plot_list[[1]] + boot_plot_list[[2]] + boot_plot_list[[4]] + plot_layout(ncol = 3)
```

We also explored the correlation between behavioral data and questionnaire scores separately for experiments with and without self-referential, however, the sample size is very low for some conditions.

# Discussion

# References
```{r create_r-references, echo=FALSE,results='hide'}
#r_refs(file = "r-references.bib"))
```

\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

<div id = "refs"></div>
\endgroup
