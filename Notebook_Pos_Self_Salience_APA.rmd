---
title             : "Open notebook of perpecptual salience of positive self"
shorttitle        : "Salient Positive Self"

author: 
  - name          : "Chuan-Peng Hu"
    affiliation   : "1,2"
    corresponding : yes    # Define only one corresponding author
    address       : "55131"
    email         : "hcp4715@email.com"
  - name          : "Jie Sui"
    affiliation   : "3"
  - name          : "Kaiping Peng"
    affiliation   : "1"

affiliation:
  - id            : "1"
    institution   : "Tsinghua University, 100084 Beijing, China"
  - id            : "2"
    institution   : "German Resilience Center, 55131 Mainz, Germany"
  - id            : "3"
    institution   : "University of Bath, Bath, UK"

authornote: |
  Chuan-Peng Hu, Department of Psychology, Tsinghua University, 100084 Beijing, China; Germany Resilience Center, 55131 Mainz, Germany.
  Kaiping Peng, Department of Psychology, Tsinghua University, 100084 Beijing, China.
  Jie Sui, Department of Psychology, the University of Bath, Bath, UK.

  Authors contriubtion: CPH, JS, & KP design the study, CPH collected the data, CPH analyzed the data and drafted the manuscript. KP & JS supported this project.

abstract: |
  One or two sentences providing a **basic introduction** to the field,  comprehensible to a scientist in any discipline.
  
  Two to three sentences of **more detailed background**, comprehensible  to scientists in related disciplines.
  
  One sentence clearly stating the **general problem** being addressed by  this particular study.
  
  One sentence summarizing the main result (with the words "**here we show**" or their equivalent).
  
  Two or three sentences explaining what the **main result** reveals in direct comparison to what was thought to be the case previously, or how the  main result adds to previous knowledge.
  
  One or two sentences to put the results into a more **general context**.
  
  Two or three sentences to provide a **broader perspective**, readily comprehensible to a scientist in any discipline.
  
  <!-- https://tinyurl.com/ybremelq -->
  
keywords          : "Perceptual decision-making, Self"
wordcount         : "X"

bibliography      : ["r-references.bib"]

floatsintext      : no
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : yes
mask              : no
draft             : no

documentclass     : "apa6"
classoption       : "man"
output            : 
  papaja::apa6_pdf:
    latex_engine  : xelatex

---

```{r setup, include = FALSE}
#library("papaja")
source('Initial.r')

# using afex and emmeans to do the ANOVA and emmeans for post-hoc comparison
afex_options(emmeans_model = "multivariate")
options(tinytex.verbose = F) # debug the tex
```

```{r analysis-preferences}
# Seed for random number generation
set.seed(42)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed)
```

# General Methods
## Participants.
The experiments (except experiment 3b) reported in the current study were first conducted between 2014 to 2016 in Tsinghua University, Beijing, participants of these experiments were recruited in Tsinghua University community. To increase the power by adding collecting more data so that each experiment has 50 or more valid data (Simmons, Nelson, & Simonsohn, 2013) , we recruited additional participants in Wenzhou University, Wenzhou, China in 2017. However, duo to the limited time and resources, additional data were not collected for experiment 2, 3, and 4b. 

 <!-- 21-word solution (Simmons, Nelson & Simonsohn, 2012; retrieved from http://ssrn.com/abstract=2160588) -->

## Material and Procedure
In the current study, we used the social associative learning paradigm (Sui, He, & Humphreys, 2012), in which participants first learn the associations between geometric shapes and labels of person with different moral valence (e.g., in first three studies, the triangle, square, and circle and good person, neutral person, and bad person, respectively). The associations of the shapes and label were counterbalanced across participants. After learning phase, participants finish a practice phase to familiar with the task, in which they viewed one of the shapes upon the fixation while one of the labels below the fixation and judged whether the shape and the label were matched. When participants can get 60% or higher accuracy at the end of the practicing session, they can start the experimental task which is the same as in the practice phase.

If not noted, E-prime 2.0 was used in all experiments. For participants recruited in Tsinghua University, they finished the experiment individually in a dim-lighted chamber, stimuli were presented on 22-inch CRT monitors, with a chin-rest brace. The visual angle of geometric shapes was about 3.7º × 3.7º, the finxation cross is of (0.8º × 0.8º of visual angle) at the center of the screen. The words were of 3.6º × 1.6º visual angle. The distance between the center of the shape or the word and the fixation cross was 3.5º of visual angle. Participant fixed their head on a chin-fixation, about 60 cm from the screen. 

For participants recruited in Wenzhou University, they finished the experiment in a group consist of 3 ~ 12 participants in a dim-lighted testing room. Participants were required to finished the whole experiment independently. Also, they were instructed to start the experiment at the same time, so that the distraction between participants were minimized. The stimuli were presented on 19-inch CRT monitor. The visual angles are could not be exactly controlled because participants’s chin were not fixed.


## Data analysis
We reported all the measurements, analysis and results in all the experiments in the current study. All data were first pre-processed using R `r cite_r("r-references.bib")`. The clean data were analyzed using JASP (0.8.6.0, www.jasp-stats.org, (Love et al., 2019)). Participants whose overall accuracy lower than 60% were excluded from analysis. Also, the accurate responses with less than 200ms reaction times were excluded from the analysis.

We analyzed accuracy performance using a signal detection approach, as in Sui et al. (2012). The performance in each match condition was combined with that in the nonmatching condition with the same shape to form a measure of d’. Trials without response were coded either as “miss” (matched trials) or “false alarm” (mismatched trials). The d’ were then analyzed using repeated measures analyses of variance (repeated measures ANOVA). 

The reaction times of accurate trials were also analyzed using repeated measures ANOVA. To control the false positive when conducting the post-hoc comparisons, we used Bonferroni correction. Please note that in the first two experiment (experiment 1a and 1b), we included the variable matchness (matched vs. mismatched) in our ANOVA of reaction times and then examine matched trials and mismatched trials separately when the interaction between matchness and other variables are significant. In both experiments, we found significant interaction between matchness and valence. Then, as previous study, we focused on the matched trial for the rest of the experiment (Sui et al., 2012). 

We reported the effect size of repeated measures ANOVA (omega squared) (Bakeman, 2005; Lakens, 2013). Also, we reported Cohen’s d and its 95% confidence intervals for the post-hoc comparisons. To provide more information about the results, we also reported the Bayes Factor using JASP (Hu, Kong, Wagenmakers, Ly, & Peng, 2018; Wagenmakers et al., 2018). The Bayes factor is the ratio of the probability of the current data pattern under alternative hypothesis (H1) and the probability of the current data pattern under null hypothesis (H0), which index the relative evidence for these two hypotheses from the current data. The BF10 represents the evidence for alternative hypothesis (H1) vs. evidence for null hypothesis (H0); in contrast, BF01 represents that evidence for null hypothesis over the evidence for althernative hypothesis. We used the default prior in JASP for all the Bayes Factor analyses, and used Jeffreys (1961)’s convention for the strength of evidence: the BF10 > 3 means there are some evidence for H1 as compared with H0,  BF10 great or equal to 10 means strong evidence for H1.

To assess the individual difference, we explored correlation between self-reported psychological distance and more objective responses bias (i.e., reaction times and d prime). To do this, we first normalized the personal distance by taking the percentage of the mean distance between each two persons in the sum of all 6 distances (self-good, self-normal, self-bad, good-normal, good-bad, normal-bad), and then calculated the bias score (indexed by the differences between good-normal, good-bad). Also, as exploratory analysis, we analyzed the correlation between behavioral response and moral identity, self-esteem, if data are available. As recent study showed that small size leads to unstable correlation estimates (Schönbrodt & Perugini, 2013), we only reported the correlation based on data pooled from all experiments, while the results of each experiment were reported in supplementary results.


# Experiment 1a

```{r loadingData_1a,echo=FALSE,results='hide'}
#### record from the meta-data:
# One participant's ID changed from 26 to 261, because of duplication of subject id.
# participant No. 14 finished two sessions of the experiment, only the first session were included in the analysis
# # there are 4 foreign students, we didn't exclude them:
# foreignStdID <- c(24,29,30,33)

# data collected in Tsinghua U
df1a_1 <- read.csv(".\\exp1a\\rawdata_behav_exp1a_2014.csv", header = TRUE,
                   sep = ",", stringsAsFactors=FALSE, na.strings=c("","NA")) %>%
        dplyr::mutate(Site = "THU") 

# data collected in Wenzhou U
df1a_2 <- read.csv(".\\exp1a\\rawdata_behav_exp1a_2017.csv",header = TRUE,
                   sep = ",",stringsAsFactors=FALSE,na.strings=c("","NA")) %>%
        dplyr::mutate(Site = "WZU")

# combine data and clean
df1a   <- rbind(df1a_1,df1a_2) %>%
        dplyr::rename(ACC = Target.ACC,           # rename columns
                      RT  = Target.RT,
                      CRESP = Target.CRESP,
                      BlockNo = BlockList.Sample,
                      TrialNo = SubTrial,
                      RESP = Target.RESP,
                      Matchness = YesNoResp,
                      Valence = Shape) %>%
        dplyr::mutate(Valence = ifelse(Valence == "Normal", "Neutral", Valence),   # recode values
                      Matchness = ifelse(Matchness == "Yes", "Match", "Mismatch"),
                      Age = ifelse(Age == 0, NA, Age),
                      Subject = factor(Subject),
                      Site = factor(Site))  # if the min age is 0, that age is missing

rm(df1a_1,df1a_2)

df1a.T.basic     <- df1a %>%
  dplyr::select(Site, Subject, Age, Sex) %>%
  dplyr::distinct(Subject, .keep_all = TRUE) %>%
  dplyr::summarise(N = length(Subject),
                   N_thu = length(Site[Site == "THU"]),
                   N_wzu = length(Site[Site == "WZU"]),
                   Nf = length(Sex[Sex == "female"]),
                   Nm = length(Sex[Sex == "male"]),
                   Age_mean = round(mean(Age,na.rm=TRUE),2),
                   Age_sd = round(sd(Age,na.rm=TRUE),2))
  
# distinguish between practice and formal data
#df1a.subj_P <- df1a %>%
#  dplyr::filter(is.na(BlockNo)) %>%
#  dplyr::distinct(Subject)

#[is.na(df1a$BlockList.Sample),]            # data from practice
#df1a.subj_T <- df1a %>%
#  dplyr::filter(complete.cases(BlockNo)) %>%
#  dplyr::distinct(Subject)

#[complete.cases(df1a$BlockList.Sample),]   # data from test

# number of participant who didn't finished the experiment
nQuit <- length(unique(df1a$Subject[is.na(df1a$BlockNo)])) - length(unique(df1a$Subject[!is.na(df1a$BlockNo)]))

#.T[df1a.T$RT <= 200 & df1a.T$ACC == 1,]
#df1a.excld.trial.r <- nrow(df1a.excld.trial)/nrow(df1a.T) # ratio of excluded trials in all triasl.

df1a.excld.sub <-  df1a %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::group_by(Subject) %>%
  #dplyr::filter(RT > 200)  %>%                       # only use > 200 ms response (this standard will keep more participants)
  #dplyr::mutate(ACC = ifelse(RT <= 200, 0, ACC)) %>%  # set less than 200 ms response as wrong
  dplyr::summarise(N = length(ACC),                   # caculate the overall accuracy for each subject
                   N_crrct = sum(ACC),
                   ACC = sum(ACC)/length(ACC)) %>%
  dplyr::filter(ACC < 0.6) %>%                        # exlucde the participants with less than 60% overall accuracy
  dplyr::select(Subject)

# The rate of excluded trials in valid data
df1a.invalid_trial_rate   <- df1a %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::filter(!(Subject %in% df1a.excld.sub$Subject)) %>%   # exclude the invalid subjects
  dplyr::summarize(rate = length(RT[RT <= 200 & ACC == 1])/length(RT))

df1a.v   <- df1a %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::filter(!(Subject %in% df1a.excld.sub$Subject)) %>%   # exclude the invalid subjects
  dplyr::filter(!(RT <= 200 & ACC == 1))                      # exclude < 200 trials

df1a.v.basic     <- df1a.v %>%
  dplyr::select(Site, Subject, Age, Sex) %>%
  dplyr::distinct(Subject, .keep_all = TRUE) %>%
  dplyr::summarise(N = length(Subject),
                   N_thu = length(Site[Site == "THU"]),
                   N_wzu = length(Site[Site == "WZU"]),
                   Nf = length(Sex[Sex == "female"]),
                   Nm = length(Sex[Sex == "male"]),
                   Age_mean = round(mean(Age,na.rm=TRUE),2),
                   Age_sd = round(sd(Age,na.rm=TRUE),2))
```
## Methods
### Participants
`r df1a.T.basic$N` college students (`r df1a.T.basic$Nf` female, age = `r df1a.T.basic$Age_mean` $\pm$ `r df1a.T.basic$Age_sd` years) participated. `r df1a.T.basic$N_thu` of them were recruited from Tsinghua University community in 2014; `r df1a.T.basic$N_wzu` were recruited from Wenzhou University in 2017. All participants were right-handed except one, and all had normal or corrected-to-normal vision. Informed consent was obtained from all participants prior to the experiment according to procedures approved by the local ethics committees. `r nrow(df1a.excld.sub)` participant’s data were excluded from analysis because nearly random level of accuracy, leaving `r df1a.v.basic$N` participants (`r df1a.v.basic$Nf` female, age = `r df1a.v.basic$Age_mean` $\pm$ `r df1a.v.basic$Age_sd` years).

### Stimuli and Tasks
Three geometric shapes were used in this experiment: triangle, square, and circle. These shapes were paired with three labels (bad person, good person or neutral person). The pairs were counterbalanced across participants. 

### Procedure
As we describe in general method part, this experiment had two phases. First, there was a learning stage. Participants were asked to learn the relationship between geometric shapes (triangle, square, and circle) and different person (bad person, a good person, or a neutral person). For example, a participant was told, “bad person is a circle; good person is a triangle; and a neutral person is represented by a square.” After participant remember the associations (usually in a few minutes), participants started a practicing phase of matching task which has the exact task as in the experimental task. 
In the experimental task, participants judged whether shape–label pairs, which were subsequently presented, were correct. Each trial started with the presentation of a central fixation cross for 500 ms. Subsequently, a pairing of a shape and label (good person, bad person, and neutral person) was presented for 100 ms. The pair presented could confirm to the verbal instruction for each pairing given in the training stage, or it could be a recombination of a shape with a different label, with the shape–label pairings being generated at random. The next frame showed a blank for 1100ms. Participants were expected to judge whether the shape was correctly assigned to the person by pressing one of the two response buttons as quickly and accurately as possible within this timeframe (to encourage immediate responding). Feedback (correct or incorrect) was given on the screen for 500 ms at the end of each trial, if no response detected, “too slow” was presented to remind participants to accelerate. Participants were informed of their overall accuracy at the end of each block. The practice phase finished and the experimental task began after the overall performance of accuracy during practice phase achieved 60%. 
For pariticpants from the Tsinghua community, they completed 6 experimental blocks of 60 trials. Thus, there were 60 trials in each condition (bad-person matched, bad-person nonmatching, good-person matched, good-person nonmatching, neutral-person matched, and neutral-person nonmatching). For the participants from Wenzhou Univeristy, they finished 6 blocks of 120 trials, therefore, 120 trials for each condition.

### Questionnaires
After the experiment, part of the participants in Tsinghua University also finished psychological distance, trait social justice (Bai, 2013), cognitive reflection test (Frederick, 2005), and disgust senstivity (Tan, Cong, & Lu, 2007). The psychological distance measurement finished by indicating the the psychological distance between self, good person, bad person and neutral person, through two points on a horizontal line. This procedure is presented by Matlab. This method had been proven been an effective way to measure the psychological distance (Enock, Sui, Hewstone, & Humphreys, 2018). 
For all participants from Wenzhou University, they finished following questionnaires online immediately after the experiment: objective and subjective socioeconomic status (the objective SES measured by parents’ education and occupation (Shi & Shen, 2007), the subjective SES measured by ladder task (Ostrove, Adler, Kuppermann, & Washington, 2000)), psychological distance (Enock et al., 2018), sensitivity to justice (Wu et al., 2014), cognitive reflection test (Frederick, 2005), disgust senstivity scale (Tan et al., 2007), belief in just world (short) (Wu et al., 2011), a short version of big five personality (John & Srivastava, 1999), trait self-esteem (Rosenberg, 1965), locus of control (Levenson，1981), Free will and determinism plus (FAD+) (translated version) (Liu, Jian, Hu, & Peng, 2015; Paulhus & Carey, 2010), moral identity (Aquino & Reed II, 2002), and moral self image (translated version) (Jordan, Leliveld, & Tenbrunsel, 2015). Only the psychological distance data were analyized in the current study.  

### Data analysis
As we describe in the general method section.

## Results
### Analaysis of d prime.
We conducted a single factor (morlaity: good, neutral, bad) repeated measure ANOVA:
```{r 1a_dprime, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
# calculate d prime
df1a.v.dprime_l <- df1a.v %>%
  dplyr::mutate(sdt = mosaic::derivedFactor("hit" = (ACC ==1 & Matchness == "Match"),     # code as hit
                                    "CR" = (ACC ==1  & Matchness == "Mismatch"),  # code as correct reject
                                    "miss" = (ACC == 0 & Matchness == "Match"),   # code as miss
                                    "FA" = (ACC == 0 & Matchness == "Mismatch"),  # code as false alarm
                                    .method ="first",  .default = NA)) %>% 
  dplyr::group_by(Site, Subject, Age, Sex, Valence, sdt) %>%
  dplyr::summarise(N = length(sdt)) %>%                                      # calculate the counts for each 
  dplyr::ungroup() %>%
  tidyr::spread(key = sdt, value = N,fill = 0) %>%                           # long-to-wide format
  dplyr::mutate(hitR = hit/(hit + miss),                                     # hit rate
                FAR  = FA/(FA+CR)) %>%                                       # fa rate
  dplyr::mutate(hitR = ifelse(hitR == 1, 1 - 1/(2*(hit + miss)), hitR),      # if hit rate is 1, standardize it
                FAR  = ifelse(FAR == 0, 1/(2*(hit + miss)), FAR)) %>%        # if FA rate is 0, standardize it
  dplyr::mutate(dprime = qnorm(hitR) - qnorm(FAR)) %>%
  dplyr::select(Site, Subject, Age, Sex, Valence, dprime) %>%                # select relevant columns
  dplyr::mutate(Valence = factor(Valence, levels = c("Good","Neutral","Bad")))

### Long to wide
#df1a.v.dprime_w <- df1a.v.dprime_l %>%
  #tidyr::unite(col = "Cond",c("Valence"),sep = "_", remove = T) %>%  # combine two factors to condition
#  tidyr::spread(key = Valence, value = dprime) %>%                                   # long to wide
#  dplyr::rename_at(vars(-Site,-Subject,-Age,-Sex),function(x) paste0("d_",x))           # add prefix to certain conditions

# anova for d prime with 2*2 design
df1a_dprime_anova <- afex::aov_ez('Subject','dprime',df1a.v.dprime_l,  # using afex's function 
                                  within = c('Valence'))

# use LMM, random intercept for each participant
df1a_d_mixed <- afex::mixed(dprime ~ Valence +(1|Subject), 
                          df1a.v.dprime_l,
                          method = "S",
                          control = lmerControl(optCtrl = list(maxfun = 1e6)))

df1a_dprime_anova_apa <- df1a_dprime_anova$aov %>% papaja::apa_print()
#df4b_dprime_anova <- apa_print(df4b_dprime_anova)
```
We found the effect of Valence (`r df1a_dprime_anova_apa$full$Valence`).

```{r results='asis', echo = F}
#knitr::kable(nice(df4b_dprime_anova), caption = "ANOVA of d prime")
apa_table(df1a_dprime_anova_apa$table
  , caption = "A really beautiful ANOVA table."
  , note = "Note that the column names contain beautiful mathematical copy: This is because the table has variable labels."
)
```

We further examined the effect of valence. 

```{r results='asis', echo = F}
posthoc_1a_d <- emmeans::emmeans(df1a_dprime_anova, "Valence") # compare each valence for both self and other condition
#pairs(posthoc_1a_d)
```
The Good condition (2.23 $\pm$ 0.14) is great than Netural condition (2.05 $\pm$ 0.16, t(45) = 1.67, p = 0.226) and bad condition (1.87 $\pm$ 1.4, *t*(45) = 3.07, *p* = 0.01, Cohen'd = 0.36). This is no-significant difference between neutral and bad conidition, *t*(45) = 1.81, p = 1.77.

### Analaysis of reaction time.
We conducted 2 (Matchness: Match v. Mismatch) by 3 (Valence: good, neutral, bad) repeated measure ANOVA:
```{r 1a_RT, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
# anova for RT with 2*2 design
df1a.v.rt_m <- df1a.v %>%
  dplyr::filter(ACC == 1) %>%
  dplyr::group_by(Site,Subject,Matchness, Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup()

df1a_RT_anova <- afex::aov_ez('Subject','RT_m',df1a.v.rt_m, within = c('Matchness','Valence')) # using afex's function

df1a_RT_anova_apa <- df1a_RT_anova %>% papaja::apa_print()

# use LMM, random intercept for each participant
df1a_RT_mixed <- afex::mixed(RT_m ~ Matchness*Valence + (1|Subject), 
                          df1a.v.rt_m,
                          method = "S",
                          control = lmerControl(optCtrl = list(maxfun = 1e6)))

# LMM for RT with 2*2 design, using trials data
df1a.v.rt_lmm <- df1a.v %>%
  dplyr::filter(ACC == 1) %>%
  dplyr::group_by(Site,Subject,Matchness, Valence) %>%
  dplyr::ungroup()

# use LMM, random intercept for each participant
#df1a_RT_mixed <- afex::mixed(RT ~ Matchness*Valence + (1|Subject), 
#                          df1a.v.rt_lmm,
#                          method = "S",
#                          control = lmerControl(optCtrl = list(maxfun = 1e6)))

```
We found the main effect of Matchness (`r df1a_RT_anova_apa$full$Matchness`), main effect of valence (`r df1a_RT_anova_apa$full$Valence`), and intercation between Matchness and Valence (`r df1a_RT_anova_apa$full$Matchness_Valence`)

```{r 1a_RT_match, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
df1a.v.rt_m1 <- df1a.v %>%
  dplyr::filter(ACC == 1 & Matchness == "Match") %>%
  dplyr::group_by(Site,Subject,Matchness, Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup() %>%
  dplyr::mutate(Valence = factor(Valence, levels = c("Good","Neutral","Bad")))

df1a_RT_anova_m <- afex::aov_ez('Subject','RT_m',df1a.v.rt_m1,     # using afex's function 
                                  within = c('Valence'))

df1a.v.rt_m2 <- df1a.v %>%
  dplyr::filter(ACC == 1 & Matchness == "Mismatch") %>%
  dplyr::group_by(Site,Subject,Matchness, Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup()

df1a_RT_anova_nm <- afex::aov_ez('Subject','RT_m',df1a.v.rt_m2,     # using afex's function 
                                  within = c('Valence'))

posthoc_1a_rt <- emmeans::emmeans(df1a_RT_anova_m, "Valence") # compare each valence for both self and other condition
# pairs(posthoc_1a_rt)

```

We carried out two separate ANOVA for both Match and mismatched trials. For matched trials, we found the effect of valence `r df1a_RT_anova_m$full$Valence`. For non-matched trials, there was no significant effect of Valence (`r df1a_RT_anova_nm$full$Valence`).

We further examined the effect of valence for both self and other for mached trials. We found that shapes associated with Good Person responded faster than Neutral (t(45) = -2.662, p = 0.0284) and Bad Person (*t*(45) = -4.793, *p* = 0.0001). Neutral condition is slightly faster than bad condition (t(45) = -2.33, p = 0.0618)

# Experiment 1b
In this study, we aimed at excluding the potential confouding factor of the familarity of words we used in experiment 1a, by matching the familiarity of the words.

## Method

```{r loadingData_1b,echo=FALSE,results='hide'}
# data collected in Tsinghua U
df1b_1 <- read.csv(".\\exp1b\\rawdata_behav_exp1b_2014.csv", header = TRUE,
                   sep = ",", stringsAsFactors=FALSE, na.strings=c("","NA")) %>%
        dplyr::mutate(Site = "THU") 

# data collected in Wenzhou U
df1b_2 <- read.csv(".\\exp1b\\rawdata_behav_exp1b_201705.csv",header = TRUE,
                   sep = ",",stringsAsFactors=FALSE,na.strings=c("","NA")) %>%
        dplyr::mutate(Site = "WZU")

# combine data and clean
df1b   <- rbind(df1b_1,df1b_2) %>%
        dplyr::rename(ACC = Target.ACC,           # rename columns
                      RT  = Target.RT,
                      CRESP = Target.CRESP,
                      BlockNo = BlockList.Sample,
                      TrialNo = SubTrial,
                      RESP = Target.RESP,
                      Matchness = YesNoResp,
                      Valence = Shape) %>%
        dplyr::mutate(Valence = ifelse(Valence == "Normal", "Neutral", Valence),   # recode values
                      Matchness = ifelse(Matchness == "Yes", "Match", "Mismatch"),
                      Age = ifelse(Age == 0, NA, Age),
                      Subject = factor(Subject),
                      Site = factor(Site))  # if the min age is 0, that age is missing

rm(df1b_1,df1b_2)

df1b.T.basic     <- df1b %>%
  dplyr::select(Site, Subject, Age, Sex) %>%
  dplyr::distinct(Subject, .keep_all = TRUE) %>%
  dplyr::summarise(N = length(Subject),
                   N_thu = length(Site[Site == "THU"]),
                   N_wzu = length(Site[Site == "WZU"]),
                   Nf = length(Sex[Sex == "female"]),
                   Nm = length(Sex[Sex == "male"]),
                   Age_mean = round(mean(Age,na.rm=TRUE),2),
                   Age_sd = round(sd(Age,na.rm=TRUE),2))
  
# distinguish between practice and formal data
#df1b.subj_P <- df1b %>%                      # subjet for practice
#  dplyr::filter(is.na(BlockNo)) %>%
#  dplyr::distinct(Subject)

#df1b.subj_T <- df1b %>%                       # subjects in formal exp
#  dplyr::filter(complete.cases(BlockNo)) %>%
#  dplyr::distinct(Subject)

# number of participant who didn't finished the experiment
#nQuit <- length(df1b.subj_P) - length(df1b.subj_T)
nQuit <- length(unique(df1b$Subject[is.na(df1b$BlockNo)])) - length(unique(df1b$Subject[!is.na(df1b$BlockNo)]))

# participants should be excluded
df1b.excld.sub <-  df1b %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::group_by(Subject) %>%
#  dplyr::mutate(ACC = ifelse(RT <= 200, 0, ACC)) %>%  # set less than 200 ms response as wrong
  dplyr::summarise(N = length(ACC),                   # caculate the overall accuracy for each subject
                   N_crrct = sum(ACC),
                   ACC = sum(ACC)/length(ACC)) %>%
  dplyr::filter(ACC < 0.6) %>%                        # exlucde the participants with less than 60% overall accuracy
  dplyr::select(Subject)

# The rate of excluded trials in valid data
df1b.invalid_trial_rate   <- df1b %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::filter(!(Subject %in% df1b.excld.sub$Subject)) %>%   # exclude the invalid subjects
  dplyr::summarize(rate = length(RT[RT <= 200 & ACC == 1])/length(RT))

df1b.v   <- df1b %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::filter(!(Subject %in% df1b.excld.sub$Subject)) %>%   # exclude the invalid subjects
  dplyr::filter(!(RT <= 200 & ACC == 1))                      # exclude < 200 trials

df1b.v.basic     <- df1b.v %>%
  dplyr::select(Site, Subject, Age, Sex) %>%
  dplyr::distinct(Subject, .keep_all = TRUE) %>%
  dplyr::summarise(N = length(Subject),
                   N_thu = length(Site[Site == "THU"]),
                   N_wzu = length(Site[Site == "WZU"]),
                   Nf = length(Sex[Sex == "female"]),
                   Nm = length(Sex[Sex == "male"]),
                   Age_mean = round(mean(Age,na.rm=TRUE),2),
                   Age_sd = round(sd(Age,na.rm=TRUE),2))
```

### Participants
`r df1b.T.basic$N` college students (`r df1b.T.basic$Nf` female, age = `r df1b.T.basic$Age_mean` $\pm$ `r df1b.T.basic$Age_sd` years) participated. `r df1b.T.basic$N_thu` of them were recruited from Tsinghua University community in 2014; `r df1b.T.basic$N_wzu` were recruited from Wenzhou University in 2017. All participants were right-handed except one, and all had normal or corrected-to-normal vision. Informed consent was obtained from all participants prior to the experiment according to procedures approved by the local ethics committees. `r nrow(df1b.excld.sub)` participant’s data were excluded from analysis because nearly random level of accuracy, leaving `r df1b.v.basic$N` participants (`r df1b.v.basic$Nf` female, age = `r df1b.v.basic$Age_mean` $\pm$ `r df1b.v.basic$Age_sd` years).

### Stimuli and Tasks
Three geometric shapes (triangle, square, and circle, with 3.7º × 3.7º of visual angle) were presented above a white fixation cross subtending 0.8º × 0.8º of visual angle at the center of the screen. The three shapes were randomly assigned to three labels with different moral valence: a morally bad person (“恶人”, ERen), a morally good person (“善人”, ShanRen) or a morally neutral person (“常人”, ChangRen). The order of the associations between shapes and labels was counterbalanced across participants.
Three labels used in this experiment is selected based on the rating results from an independent survey, in which participants rated the familiarity, frequency, and concreteness of eight different words online. Of the eight words, three of them are morally positive (HaoRen, ShanRen, Junzi), two of them are morally neutral (ChangRen, FanRen), and three of them are morally negative (HuaiRen, ERen, LiuMang). An independent sample consist of 35 participants (22 females, age 20.6 ± 3.11) were recruited to rate these words. Based on the ratings (see supplementary materials Figure S1), we selected ShanRen, ChangRen, and ERen to represent morally positve, neutral, and negative person. 

### Procedure
For participants from both Tsinghua community and Wenzhou community, the procedure in the current study was exactly same as in experiment 1a. For participants in Tsinghua community, they finished a survey suite include personal distance, objective and subjective SES, belief in just world (Wu et al., 2011), disgust senstivity scale (谭永红 et al., 2007), trait justice (Wu et al., 2014), and cognitive reflection test (Frederick, 2005). For participants from Wenzhou community, they finished exactly the same questionnaires as the participants from Wenzhou University in experiment 1a.

## Data Analysis
Data was analyzed as in experiment 1a. 

## Results
We replicated the advantage of positive condition in experiment 1a. 

### Analaysis of d prime.

```{r 1b_dprime, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
# calculate d prime
df1b.v.dprime_l <- df1b.v %>%
  dplyr::mutate(sdt = mosaic::derivedFactor("hit" = (ACC ==1 & Matchness == "Match"),     # code as hit
                                    "CR" = (ACC ==1  & Matchness == "Mismatch"),  # code as correct reject
                                    "miss" = (ACC == 0 & Matchness == "Match"),   # code as miss
                                    "FA" = (ACC == 0 & Matchness == "Mismatch"),  # code as false alarm
                                    .method ="first",  .default = NA)) %>% 
  dplyr::group_by(Site, Subject, Age, Sex, Valence, sdt) %>%
  dplyr::summarise(N = length(sdt)) %>%                                      # calculate the counts for each 
  dplyr::ungroup() %>%
  tidyr::spread(key = sdt, value = N,fill = 0) %>%                           # long-to-wide format
  dplyr::mutate(hitR = hit/(hit + miss),                                     # hit rate
                FAR  = FA/(FA+CR)) %>%                                       # fa rate
  dplyr::mutate(hitR = ifelse(hitR == 1, 1 - 1/(2*(hit + miss)), hitR),      # if hit rate is 1, standardize it
                FAR  = ifelse(FAR == 0, 1/(2*(hit + miss)), FAR)) %>%        # if FA rate is 0, standardize it
  dplyr::mutate(dprime = qnorm(hitR) - qnorm(FAR)) %>%
  dplyr::select(Site, Subject, Age, Sex, Valence, dprime) %>%                # select relevant columns
  dplyr::mutate(Valence = factor(Valence, levels = c("Good","Neutral","Bad")))

### Long to wide
#df1b.v.dprime_w <- df1b.v.dprime_l %>%
#  tidyr::spread(key = Valence, value = dprime) %>%                                   # long to wide
#  dplyr::rename_at(vars(-Site,-Subject,-Age,-Sex),function(x) paste0("d_",x))           # add prefix to certain conditions

# anova for d prime
df1b_dprime_anova <- afex::aov_ez('Subject','dprime',df1b.v.dprime_l,  # using afex's function 
                                  within = c('Valence'))
# use LMM, random intercept for each participant
#df1b_d_mixed <- afex::mixed(dprime ~ Valence +(1|Subject), 
#                          df1b.v.dprime_l,
#                          method = "S",
#                          control = lmerControl(optCtrl = list(maxfun = 1e6)))

df1b_dprime_anova_apa <- df1b_dprime_anova$aov %>% papaja::apa_print()

posthoc_1b_d <- emmeans::emmeans(df1b_dprime_anova, "Valence") # compare each valence for both self and other condition
#pairs(posthoc_1b_d)

```
There was evidence for the main effect of valence, `r df1b_dprime_anova_apa$full$Valence`. Paired t test showed that the Good-Person condition (1.9 $\pm$ 0.104) was with greater *d* prime than Netural condition (1.49 $\pm$ 0.1, *t*(49) = 5.583, *p* < 0.001, Cohen's *d* = 0.415). We also found that the Bad-Person condition (1.71 $\pm$ 0.11) has also greater *d* prime than neutral condition , *t*(49) = -3.106, *p* = 0.008, Cohen's *d* = -0.229). There was no-significant difference between Good and bad conidition, *t*(49) = 2.05, *p* = 0.11.

```{r results='asis', echo = F}
#knitr::kable(nice(df4b_dprime_anova), caption = "ANOVA of d prime")
#apa_table(df1b_dprime_anova_apa$table
#  , caption = "A really beautiful ANOVA table."
#  , note = "Note that the column names contain beautiful mathematical copy: This is because the table has variable labels."
#)
```

### Analaysis of reaction time.
The results of reaction times of matchness trials showed similiar pattern as the *d* prime data.
```{r 1b_RT, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
# anova for d prime with 2*2 design
df1b.v.rt_m <- df1b.v %>%
  dplyr::filter(ACC == 1) %>%
  dplyr::group_by(Site,Subject,Matchness, Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup()

df1b_RT_anova <- afex::aov_ez('Subject','RT_m',df1b.v.rt_m,     # using afex's function 
                                  within = c('Matchness','Valence'))
df1b_RT_anova_apa <- df1b_RT_anova %>% papaja::apa_print()

# use LMM, random intercept for each participant
df1b_RT_mixed <- afex::mixed(RT_m ~ Matchness*Valence + (1|Subject), 
                          df1b.v.rt_m,
                          method = "S",
                          control = lmerControl(optCtrl = list(maxfun = 1e6)))
```
We found intercation between Matchness and Valence (`r df1b_RT_anova_apa$full$Matchness_Valence`) and then analyzed the matched trials and mismatched trials separately, as in experiment 1a.

```{r 1b_RT_match, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
df1b.v.rt_m1 <- df1b.v %>%
  dplyr::filter(ACC == 1 & Matchness == "Match") %>%
  dplyr::group_by(Site,Subject,Matchness, Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup() %>%
  dplyr::mutate(Valence = factor(Valence, levels = c("Good","Neutral","Bad")))

df1b_RT_anova_m <- afex::aov_ez('Subject','RT_m',df1b.v.rt_m1,     # using afex's function 
                                  within = c('Valence'))
df1b_RT_anova_m_apa <- df1b_RT_anova_m %>% papaja::apa_print()

df1b.v.rt_m2 <- df1b.v %>%
  dplyr::filter(ACC == 1 & Matchness == "Mismatch") %>%
  dplyr::group_by(Site,Subject,Matchness, Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup()

df1b_RT_anova_nm <- afex::aov_ez('Subject','RT_m',df1b.v.rt_m2,     # using afex's function 
                                  within = c('Valence'))
df1b_RT_anova_nm_apa <- df1b_RT_anova_nm %>% papaja::apa_print()
posthoc_1b_rt <- emmeans::emmeans(df1b_RT_anova_m, "Valence") # compare each valence for both self and other condition
# pairs(posthoc_1b_rt)

```
For matched trials, we found the effect of valence `r df1b_RT_anova_m_apa$full$Valence`. For non-matched trials, there was no significant effect of Valence (`r df1b_RT_anova_nm_apa$full$Valence`).

Post-hoc *t*-tests revealed that shapes associated with Good Person (686 $\pm$ 8.97) were responded faster than Neutral-Person (743 $\pm$ 9.66), (*t*(49) = -8.379, *p* < 0.001) and Bad Person (730 $\pm$ 9.11), *t*(49) = -5.632, *p* < 0.0001). While there was no significant differences between Neutral and Bad-Person condition (*t*(49) = 1.83, *p* = 0.171).

## Discussion
These results confirmed the facilitation effect of positive moral valence on the perceptual matching task. This pattern of results mimic prior results demonstrating self-bias effect on perceptual matching (Sui et al., 2012) and in line with previous studies that indirect learning of other’s moral reputation do have influence on our subsequence behavior (Fouragnan et al., 2013). 


# Experiment 1c
In this study, we further control the valence of words using in our experiment. Instead of using label with moral valence, we used valence-neutral names in China. Participant first learn behaviors of the different person, then, they associate the names and shapes. And then they perform a name-shape matching task.

## Method

```{r loadingData_1c,echo=FALSE,results='hide'}
# data collected in Tsinghua U
df1c <- read.csv(".\\exp1c\\rawdata_behav_exp1c_2014.csv", header = TRUE,
                   sep = ",", stringsAsFactors=FALSE, na.strings=c("","NA")) %>%
  dplyr::select(ï..Subject,Age,Sex,TrialList1.Sample,BlockList.Sample,
                 Shape,YesNoResp,CorrectAnswer,                         # select necessary columns
                 Target1.ACC,Target1.RESP, Target1.RT) %>%
  dplyr::rename(Subject = ï..Subject, 
                BlockNo = BlockList.Sample,
                TrialNo = TrialList1.Sample,
                ACC = Target1.ACC,                         # rename columns
                RT = Target1.RT, RESP =Target1.RESP,
                Matchness = YesNoResp, Valence = Shape) %>%
  dplyr::mutate(Valence = ifelse(Valence == "Normal", "Neutral", Valence),    # change value
                Valence = factor(Valence, levels=c("Good", "Neutral","Bad")),
                Matchness = ifelse(Matchness == "Yes", "Match", "Mismatch"),
                Matchness = factor(Matchness, levels=c("Match", "Mismatch"))) %>%
  dplyr::mutate(Site = "THU")
#length(unique(df1c$Subject))

# distinguish between practice and formal data
df1c.subj_P <- df1c %>%                      # subjet for practice
  dplyr::filter(is.na(BlockNo)) %>%
  dplyr::distinct(Subject)

df1c.subj_T <- df1c %>%                       # subjects in formal exp
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::distinct(Subject)

# number of participant who didn't finished the experiment
nQuit <- length(df1c.subj_P) - length(df1c.subj_T)

df1c.T.basic     <- df1c %>%
  dplyr::select(Site, Subject, Age, Sex) %>%
  dplyr::distinct(Subject, .keep_all = TRUE) %>%
  dplyr::summarise(N = length(Subject),
                   N_thu = length(Site[Site == "THU"]),
                   N_wzu = length(Site[Site == "WZU"]),
                   Nf = length(Sex[Sex == "female"]),
                   Nm = length(Sex[Sex == "male"]),
                   Age_mean = round(mean(Age,na.rm=TRUE),2),
                   Age_sd = round(sd(Age,na.rm=TRUE),2))

# participants should be excluded
df1c.excld.sub <-  df1c %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::group_by(Subject) %>%
  #dplyr::mutate(ACC = ifelse(RT <= 200, 0, ACC)) %>%  # set less than 200 ms response as wrong
  dplyr::summarise(N = length(ACC),                   # caculate the overall accuracy for each subject
                   N_crrct = sum(ACC),
                   ACC = sum(ACC)/length(ACC)) %>%
  dplyr::filter(ACC < 0.6) %>%                        # exlucde the participants with less than 60% overall accuracy
  dplyr::select(Subject)

# The rate of excluded trials in valid data
df1c.invalid_trial_rate   <- df1c %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::filter(!(Subject %in% df1c.excld.sub$Subject)) %>%   # exclude the invalid subjects
  dplyr::summarize(rate = length(RT[RT <= 200 & ACC == 1])/length(RT))

df1c.v   <- df1c %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::filter(!(Subject %in% df1c.excld.sub$Subject)) %>%   # exclude the invalid subjects
  dplyr::filter(!(RT <= 200 & ACC == 1))                      # exclude < 200 trials

df1c.v.basic     <- df1c.v %>%
  dplyr::select(Site, Subject, Age, Sex) %>%
  dplyr::distinct(Subject, .keep_all = TRUE) %>%
  dplyr::summarise(N = length(Subject),
                   N_thu = length(Site[Site == "THU"]),
                   N_wzu = length(Site[Site == "WZU"]),
                   Nf = length(Sex[Sex == "female"]),
                   Nm = length(Sex[Sex == "male"]),
                   Age_mean = round(mean(Age,na.rm=TRUE),2),
                   Age_sd = round(sd(Age,na.rm=TRUE),2))
```

### Participants
`r df1c.T.basic$N` college students (`r df1c.T.basic$Nf` female, age = `r df1c.T.basic$Age_mean` $\pm$ `r df1c.T.basic$Age_sd` years) participated. All of them were recruited from Tsinghua University community in 2014. Informed consent was obtained from all participants prior to the experiment according to procedures approved by the local ethics committees. No participant was excluded because they overall accuracy were above 0.6.

### Stimuli and Tasks
Three geometric shapes (triangle, square, and circle, with 3.7º × 3.7º of visual angle) were presented above a white fixation cross subtending 0.8º × 0.8º of visual angle at the center of the screen. The three most common names were chosen, which are neutral in moral valence before the manipulation.
Three names (Zhang, Wang, Li) were first paired with three paragraphs of behavioral description. Each description includes one sentence of biographic infomration and four sentences that describing the moral behavioral under that name. To assess the that these three descriptions represented good, neutral, and bad valence, we collected the ratings of three person on six dimensions: morality, likability, trustworthiness, dominance, competence, and aggressiviess, from an independent sample (n = 34, 18 female, age = 19.6 ± 2.05). The rating results showed that the person with morally good behavioral description has higher score on morality (M = 3.59, SD = 0.66) than neutral (M = 0.88, SD = 1.1), *t*(33) = 12.94, *p* < .001, and bad conditions (M = -3.4, SD = 1.1), *t*(33) = 30.78, *p* < .001. Neutral condition was also significant higher than bad conditions *t*(33) = 13.9, *p* < .001 (See supplementary materials).

### Procedure
After arriving the lab, participants were informed to complete two experimental tasks, first a social memory task to remember three person and their behaviors, after tested for their memory, they will finish a perceptual matching task. 
In the social memory task, the descriptions of three person were presented without time limitation. Participant self-paced to memorized the behaviors of each person. After they memorizing, a recognition task was used to test their memory effect. Each participant was required to have over 95% accuracy before preceding to matching task.
The perceptual learning task was followed, three names were randomly paired with geometric shapes. Participants were required to learn the association and perform a practicing task before they start the formal experimental blocks. They kept practicing util they reached 70% accuracy. Then, they would start the perceptual matching task as in experiment 1a. They finished 6 blocks of perceptual matching trials, each have 120 trials. 

## Data Analysis
Data was analyzed as in experiment 1a. 

## Results

```{r 1c_rt_dprime, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
# calculate d prime
df1c.v.dprime_l <- df1c.v %>%
  dplyr::mutate(sdt = mosaic::derivedFactor("hit" = (ACC ==1 & Matchness == "Match"),     # code as hit
                                    "CR" = (ACC ==1  & Matchness == "Mismatch"),  # code as correct reject
                                    "miss" = (ACC == 0 & Matchness == "Match"),   # code as miss
                                    "FA" = (ACC == 0 & Matchness == "Mismatch"),  # code as false alarm
                                    .method ="first",  .default = NA)) %>% 
  dplyr::group_by(Site, Subject, Age, Sex, Valence, sdt) %>%
  dplyr::summarise(N = length(sdt)) %>%                                      # calculate the counts for each 
  dplyr::ungroup() %>%
  tidyr::spread(key = sdt, value = N,fill = 0) %>%                           # long-to-wide format
  dplyr::mutate(hitR = hit/(hit + miss),                                     # hit rate
                FAR  = FA/(FA+CR)) %>%                                       # fa rate
  dplyr::mutate(hitR = ifelse(hitR == 1, 1 - 1/(2*(hit + miss)), hitR),      # if hit rate is 1, standardize it
                FAR  = ifelse(FAR == 0, 1/(2*(hit + miss)), FAR)) %>%        # if FA rate is 0, standardize it
  dplyr::mutate(dprime = qnorm(hitR) - qnorm(FAR)) %>%
  dplyr::select(Site, Subject, Age, Sex, Valence, dprime) %>%                # select relevant columns
  dplyr::mutate(Valence = factor(Valence, levels = c("Good","Neutral","Bad")))

### Long to wide
#df1b.v.dprime_w <- df1b.v.dprime_l %>%
#  tidyr::spread(key = Valence, value = dprime) %>%                                   # long to wide
#  dplyr::rename_at(vars(-Site,-Subject,-Age,-Sex),function(x) paste0("d_",x))           # add prefix to certain conditions

# anova for d prime
df1c_dprime_anova <- afex::aov_ez('Subject','dprime',df1c.v.dprime_l,  # using afex's function 
                                  within = c('Valence'))

df1c_dprime_anova_apa <- df1c_dprime_anova$aov %>% papaja::apa_print()

posthoc_1c_d <- emmeans::emmeans(df1c_dprime_anova, "Valence") # compare each valence for both self and other condition
#pairs(posthoc_1c_d)

# anova for RT
df1c.v.rt_m <- df1c.v %>%
  dplyr::filter(ACC == 1) %>%
  dplyr::group_by(Site,Subject,Matchness, Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup()

df1c_RT_anova <- afex::aov_ez('Subject','RT_m',df1c.v.rt_m,     # using afex's function 
                                  within = c('Matchness','Valence'))
df1c_RT_anova_apa <- df1c_RT_anova %>% papaja::apa_print()

```
We didn't found effect of valence on *d* prime, `r df1c_dprime_anova_apa$full$Valence`. Also no effect of valence on RT (`r df1c_RT_anova_apa$full$Valence`) or interaction between valence and matchness on RT (`r df1c_RT_anova_apa$full$Matchness_Valence`).

## Discussion
Experiment 1c was conducted in a old way, i.e., we peeked the data when we collected around 20 participants, and decided to stop because the non-signficant results. (move this experiment to supplementary?) 

# Experiment 2: Sequential presenting
Experiment 2 was conducted for two purpose: (1) to further confirm the facilitation effect of positive moral associations; (2) to test the effect of expectation of occurrence of each pair. In this experiment, after participant learned the assocation between labels and shapes, they were presented a label first and then a shape, they then asked to judge whether the shape matched the label or not (see  (Sui, Sun, Peng, & Humphreys, 2014). Previous studies showed that when the labels presented before the shapes, participants formed expectations about the shape, and therefore a top-down process were introduced into the perceptual matching processing. If the facilitation effect of postive moral valence we found in experiment 1 was mainly drive by top-down processes, this sequential presenting paradigm may eliminate or attenuate this effect; if, however, the facilitation effect ocured because of button-up processes, then, similar facilitation effect will appear even with sequential presenting paradigm.

## Method

```{r loadingData_2,echo=FALSE,results='hide'}
# data collected in Tsinghua U
df2 <- read.csv(".\\exp2\\rawdata_behav_exp2.csv", header = TRUE,
                   sep = ",", stringsAsFactors=FALSE, na.strings=c("","NA")) %>%
  dplyr::mutate(Site = "THU") %>%
  dplyr::rename(ACC = Target.ACC,           # rename columns
                RT  = Target.RT,
                CRESP = Target.CRESP,
                BlockNo = BlockList.Sample,
                TrialNo = SubTrial,
                RESP = Target.RESP,
                Matchness = YesNoResp,
                Valence = Shape) %>%
  dplyr::mutate(Valence = ifelse(Valence == "Normal", "Neutral", Valence),   # recode values
                Matchness = ifelse(Matchness == "Yes", "Match", "Mismatch"),
                Age = ifelse(Age == 0, NA, Age),                             # if the min age is 0, that age is missing
                Subject = factor(Subject))  

df2.T.basic     <- df2 %>%
  dplyr::select(Site, Subject, Age, Sex) %>%
  dplyr::distinct(Subject, .keep_all = TRUE) %>%
  dplyr::summarise(N = length(Subject),
                   N_thu = length(Site[Site == "THU"]),
                   N_wzu = length(Site[Site == "WZU"]),
                   Nf = length(Sex[Sex == "female"]),
                   Nm = length(Sex[Sex == "male"]),
                   Age_mean = round(mean(Age,na.rm=TRUE),2),
                   Age_sd = round(sd(Age,na.rm=TRUE),2))
  
# number of participant who practiced but not in the formal experiment
nQuit <- length(unique(df2$Subject[is.na(df2$BlockNo)])) - length(unique(df2$Subject[!is.na(df2$BlockNo)]))

# participants should be excluded
df2.excld.sub <-  df2 %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::group_by(Subject) %>%
  #dplyr::mutate(ACC = ifelse(RT <= 200, 0, ACC)) %>%  # set less than 200 ms response as wrong
  dplyr::summarise(N = length(ACC),                   # caculate the overall accuracy for each subject
                   N_crrct = sum(ACC),
                   ACC = sum(ACC)/length(ACC)) %>%
  dplyr::filter(ACC < 0.6) %>%                        # exlucde the participants with less than 60% overall accuracy
  dplyr::select(Subject)

# The rate of excluded trials in valid data
df2.invalid_trial_rate   <- df2 %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::filter(!(Subject %in% df2.excld.sub$Subject)) %>%   # exclude the invalid subjects
  dplyr::summarize(rate = length(RT[RT <= 200 & ACC == 1])/length(RT))

df2.v   <- df2 %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::filter(!(Subject %in% df2.excld.sub$Subject)) %>%   # exclude the invalid subjects
  dplyr::filter(!(RT <= 200 & ACC == 1))                      # exclude < 200 trials

df2.v.basic     <- df2.v %>%
  dplyr::select(Site, Subject, Age, Sex) %>%
  dplyr::distinct(Subject, .keep_all = TRUE) %>%
  dplyr::summarise(N = length(Subject),
                   N_thu = length(Site[Site == "THU"]),
                   N_wzu = length(Site[Site == "WZU"]),
                   Nf = length(Sex[Sex == "female"]),
                   Nm = length(Sex[Sex == "male"]),
                   Age_mean = round(mean(Age,na.rm=TRUE),2),
                   Age_sd = round(sd(Age,na.rm=TRUE),2))
```

### Participants

`r df2.T.basic$N` participants (`r df2.T.basic$Nf` female, age = `r df2.T.basic$Age_mean` $\pm$ `r df2.T.basic$Age_sd`) were recruited. 24 of them had participated in Experiment 1a (9 male, mean age = 21.9, s.d. = 2.9), and the time gap between these experiment 1a and experiment 2 is at least six weeks. The results of `r nrow(df2.excld.sub)` participants were excluded from analysis because of less than 60% overall accuracy, remains `r df2.v.basic$N` participants (`r df2.v.basic$Nf` female, age = `r df2.v.basic$Age_mean` $\pm$ `r df2.v.basic$Age_sd`).

### Procedure
In Experiment 2, the sequential presenting makes the matching task much easier than experiment 1. To avoid ceiling effect on behavioral data, we did a few pilot experiments to get optimal parameters, i.e., the conditions under which participant have similar accuracy as in Experiment 1 (around 70 ~ 80% accuracy). 
In the final procedure, the label (good person, bad person, or neutral person) was presented for 50 ms and then masked by a scrambled image for 200 ms. A geometric shape followed the scrambled mask for 50 ms in a noisy background (which was produced by first decomposing a square with ¾ gray area and ¼ white area to small squares with a size of 2 × 2 pixels and then re-combine these small pieces randomly), instead of pure gray background in Experiment 1. After that, a blank screen was presented 1100 ms, during which participants should press a button to indicate the label and the shape match the original association or not. Feedback was given, as in study 1. The next trial then started after 700 ~ 1100 ms blank. Other aspects of study 2 were identical to study 1.
### Analysis
Data was analyzed as in study 1a. 

## Results
Less than 0.2% correct trials with less than 200ms reaction times were exlucded.

### Analaysis of d prime.

```{r 2_dprime, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
# calculate d prime
df2.v.dprime_l <- df2.v %>%
  dplyr::mutate(sdt = mosaic::derivedFactor("hit" = (ACC ==1 & Matchness == "Match"),     # code as hit
                                    "CR" = (ACC ==1  & Matchness == "Mismatch"),  # code as correct reject
                                    "miss" = (ACC == 0 & Matchness == "Match"),   # code as miss
                                    "FA" = (ACC == 0 & Matchness == "Mismatch"),  # code as false alarm
                                    .method ="first",  .default = NA)) %>% 
  dplyr::group_by(Site, Subject, Age, Sex, Valence, sdt) %>%
  dplyr::summarise(N = length(sdt)) %>%                                      # calculate the counts for each 
  dplyr::ungroup() %>%
  tidyr::spread(key = sdt, value = N,fill = 0) %>%                           # long-to-wide format
  dplyr::mutate(hitR = hit/(hit + miss),                                     # hit rate
                FAR  = FA/(FA+CR)) %>%                                       # fa rate
  dplyr::mutate(hitR = ifelse(hitR == 1, 1 - 1/(2*(hit + miss)), hitR),      # if hit rate is 1, standardize it
                FAR  = ifelse(FAR == 0, 1/(2*(hit + miss)), FAR)) %>%        # if FA rate is 0, standardize it
  dplyr::mutate(dprime = qnorm(hitR) - qnorm(FAR)) %>%
  dplyr::select(Site, Subject, Age, Sex, Valence, dprime) %>%                # select relevant columns
  dplyr::mutate(Valence = factor(Valence, levels = c("Good","Neutral","Bad")))

### Long to wide
#df1b.v.dprime_w <- df1b.v.dprime_l %>%
#  tidyr::spread(key = Valence, value = dprime) %>%                                   # long to wide
#  dplyr::rename_at(vars(-Site,-Subject,-Age,-Sex),function(x) paste0("d_",x))           # add prefix to certain conditions

# anova for d prime
df2_dprime_anova <- afex::aov_ez('Subject','dprime',df2.v.dprime_l,  # using afex's function 
                                  within = c('Valence'))
# use LMM, random intercept for each participant
#df1b_d_mixed <- afex::mixed(dprime ~ Valence +(1|Subject), 
#                          df1b.v.dprime_l,
#                          method = "S",
#                          control = lmerControl(optCtrl = list(maxfun = 1e6)))

df2_dprime_anova_apa <- df2_dprime_anova$aov %>% papaja::apa_print()

posthoc_2_d <- emmeans::emmeans(df2_dprime_anova, "Valence") # compare each valence for both self and other condition
#pairs(posthoc_2_d)

```
There was evidence for the main effect of valence, `r df2_dprime_anova_apa$full$Valence`. Paired t test showed that the Good-Person condition (2.86 $\pm$ 0.16) was with greater *d* prime than Netural condition (2.28 $\pm$ 0.15, *t*(32) = 4.46, *p* = 0.002, Cohen's *d* = 0.587). We also found that the Bad-Person condition (2.47 $\pm$ 0.135) has also greater *d* prime than neutral condition , *t*(32) = 4.15, *p* = 0.007, Cohen's *d* = 0.396). There was no-significant difference between Good and bad conidition, *t*(32) = -1,667, *p* = 0.233, Cohen's *d* = -0.191.

### Analaysis of reaction time.
The results of reaction times of matchness trials showed similiar pattern as the *d* prime data.
```{r 2_RT, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
# anova for d prime with 2*2 design
df2.v.rt_m <- df2.v %>%
  dplyr::filter(ACC == 1) %>%
  dplyr::group_by(Site,Subject,Matchness, Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup()

df2_RT_anova <- afex::aov_ez('Subject','RT_m',df2.v.rt_m,     # using afex's function 
                                  within = c('Matchness','Valence'))
df2_RT_anova_apa <- df2_RT_anova %>% papaja::apa_print()

# use LMM, random intercept for each participant
#df1b_RT_mixed <- afex::mixed(RT_m ~ Matchness*Valence + (1|Subject), 
#                          df1b.v.rt_m,
#                          method = "S",
#                          control = lmerControl(optCtrl = list(maxfun = 1e6)))
```
We found intercation between Matchness and Valence (`r df2_RT_anova_apa$full$Matchness_Valence`) and then analyzed the matched trials and mismatched trials separately, as in experiment 1a.

```{r 2_RT_match, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
# match trials
df2.v.rt_m1 <- df2.v %>%
  dplyr::filter(ACC == 1 & Matchness == "Match") %>%
  dplyr::group_by(Site,Subject,Matchness, Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup() %>%
  dplyr::mutate(Valence = factor(Valence, levels = c("Good","Neutral","Bad")))

df2_RT_anova_m <- afex::aov_ez('Subject','RT_m',df2.v.rt_m1,     # using afex's function 
                                  within = c('Valence'))
df2_RT_anova_m_apa <- df2_RT_anova_m %>% papaja::apa_print()

posthoc_2_rt <- emmeans::emmeans(df2_RT_anova_m, "Valence") # compare each valence for both self and other condition
# pairs(posthoc_2_rt)

# Mismatch trials
df2.v.rt_m2 <- df2.v %>%
  dplyr::filter(ACC == 1 & Matchness == "Mismatch") %>%
  dplyr::group_by(Site,Subject,Matchness, Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup()

df2_RT_anova_nm <- afex::aov_ez('Subject','RT_m',df2.v.rt_m2,     # using afex's function 
                                  within = c('Valence'))
df2_RT_anova_nm_apa <- df2_RT_anova_nm %>% papaja::apa_print()
```
For matched trials, we found the effect of valence `r df2_RT_anova_m_apa$full$Valence`. For non-matched trials, there was no significant effect of Valence (`r df2_RT_anova_nm_apa$full$Valence`).

Post-hoc *t*-tests revealed that shapes associated with Good Person (550 $\pm$ 9.45) were responded faster than Neutral-Person (583 $\pm$ 11.1), (*t*(32) = -3.871, *p* = 0.0018) and Bad Person (584 $\pm$ 10.2), *t*(32) = -3.838, *p* = 0.0016). While there was no significant differences between Neutral and Bad-Person condition (*t*(32) = -0.122, *p* = 0.9918).

## Discussion
In this experiment, we repeated the results pattern that the positive moral valenced stimuli has an advantage over the neutral or the negative valenced association. Moreover, with a croass task analysis, we didn’t found evidence that the experiment task interacted with moral valence, suggesting that the effect might not be effect by experiment task. 
These findings suggested that the facilitation effect of positive moral valence is robust and not affected by task. This robust effect detected by the associative learning is unexpected. 

# Experiment 3a
To examine the modulation effect of positive valence was an intrinsic, self-referential process, we designed study 3. In this study, moral valence was assigned to both self and a stranger. We hypothesized that the modulation effect of moral valence will be stronger for the self than for a stranger.

## Method
```{r loadingData_3a,echo=FALSE,results='hide'}
# data collected in Tsinghua U
df3a <- read.csv(".\\exp3a\\rawdata_behav_exp3a_2014.csv", header = TRUE,
                   sep = ",", stringsAsFactors=FALSE, na.strings=c("","NA")) %>%
  dplyr::mutate(Site = "THU") %>%
  dplyr::rename(ACC = Target.ACC,           # rename columns
                RT  = Target.RT,
                CRESP = Target.CRESP,
                BlockNo = BlockList.Sample,
                TrialNo = SubTrial,
                RESP = Target.RESP,
                Matchness = YesNoResp,
                Valence = morality,
                Identity = self) %>%
  # in this experiment we need to get the value of valence and identity from shape
  dplyr::mutate(Valence = derivedFactor("Neutral" = (Shape == "Normalself" | Shape == 'Normalother'), 
                                        "Good" = (Shape == "Goodself" | Shape == 'Goodother'), 
                                        "Bad" = (Shape == "Badself" | Shape == 'Badother'), 
                                        .method ="first", .default = NA),
                Identity  = derivedFactor("Self" = (Shape == "Normalself" | Shape == 'Goodself' | Shape == 'Badself'), 
                                        "Other" = (Shape == "Normalother" | Shape == 'Goodother' | Shape == 'Badother'), 
                                        .method ="first", .default = NA),
                Matchness = ifelse(Matchness == "Yes", "Match", "Mismatch"),
                Age = ifelse(Age == 0, NA, Age),                             # if the min age is 0, that age is missing
                Subject = factor(Subject))

df3a.T.basic     <- df3a %>%
  dplyr::select(Site, Subject, Age, Sex) %>%
  dplyr::distinct(Subject, .keep_all = TRUE) %>%
  dplyr::summarise(N = length(Subject),
                   N_thu = length(Site[Site == "THU"]),
                   N_wzu = length(Site[Site == "WZU"]),
                   Nf = length(Sex[Sex == "female"]),
                   Nm = length(Sex[Sex == "male"]),
                   Age_mean = round(mean(Age,na.rm=TRUE),2),
                   Age_sd = round(sd(Age,na.rm=TRUE),2))
  
# number of participant who practiced but not in the formal experiment
nQuit <- length(unique(df3a$Subject[is.na(df3a$BlockNo)])) - length(unique(df3a$Subject[!is.na(df3a$BlockNo)]))

# participants should be excluded
df3a.excld.sub <-  df3a %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::group_by(Subject) %>%
  #dplyr::mutate(ACC = ifelse(RT <= 200, 0, ACC)) %>%  # set less than 200 ms response as wrong
  #dplyr::filter(!(ACC == 1 & RT <= 200)) %>%
  dplyr::summarise(N = length(ACC),                   # caculate the overall accuracy for each subject
                   N_crrct = sum(ACC),
                   ACC = sum(ACC)/length(ACC)) %>%
  dplyr::filter(ACC < 0.6) %>%                        # exlucde the participants with less than 60% overall accuracy
  dplyr::select(Subject)

# The rate of excluded trials in valid data
df3a.invalid_trial_rate   <- df3a %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::filter(!(Subject %in% df3a.excld.sub$Subject)) %>%   # exclude the invalid subjects
  dplyr::summarize(rate = length(RT[RT <= 200 & ACC == 1])/length(RT)) %>%
  dplyr::pull()

df3a.v   <- df3a %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::filter(!(Subject %in% df3a.excld.sub$Subject)) %>%   # exclude the invalid subjects
  dplyr::filter(!(RT <= 200 & ACC == 1))                      # exclude < 200 trials

df3a.v.basic     <- df3a.v %>%
  dplyr::select(Site, Subject, Age, Sex) %>%
  dplyr::distinct(Subject, .keep_all = TRUE) %>%
  dplyr::summarise(N = length(Subject),
                   N_thu = length(Site[Site == "THU"]),
                   N_wzu = length(Site[Site == "WZU"]),
                   Nf = length(Sex[Sex == "female"]),
                   Nm = length(Sex[Sex == "male"]),
                   Age_mean = round(mean(Age,na.rm=TRUE),2),
                   Age_sd = round(sd(Age,na.rm=TRUE),2))
```

### Participants
`r df3a.T.basic$N` college students (`r df3a.T.basic$Nf` female, age = `r df3a.T.basic$Age_mean` $\pm$ `r df3a.T.basic$Age_sd`) participated in experiment 3a. All of them were right-handed, and all had normal or correted-to-normal vision. Informed consent was obtained from all participants prior to the experiment according to procedures approved by a local ethics committee. One female and one male student did not finish the experiment, and `r nrow(df3a.excld.sub)` participants' data were excluded from analysis because less than 60% overall accuracy, remains `r df3a.v.basic$N` participants (`r df3a.v.basic$Nf` female, age = `r df3a.v.basic$Age_mean` $\pm$ `r df3a.v.basic$Age_sd`).

### Design
Study 3a combined moral valence with self-relevance, hence the experiment has a   2 × 3 × 2 within-subject design. The first variable was self-relevance, include two levels: self-relevance vs. stranger-relevance; the second variable was moral valence, include good, neutral and bad; the third variable was the matching between shape and label: match vs. mismatch.

### Stimuli
The stimuli used in study 3a share the same parameters with experiment 1 & 2. 6 shapes were included (triangle, square, circle, trapezoid, diamond, regular pentagon), as well as 6 labels (good self, neutral self, bad self, good person, bad person, neutral person). To match the concreteness of the label, we asked participant to chosen an unfamiliar name of their own gender to be the stranger.

### Procedure
After being fully explained and signed the informed consent, participants were instructed to chose a name that can represent a stranger with same gender as the participant themselves, from a common Chinese name pool. Before experiment, the experimenter explained the meaning of each label to participants. For example, the “good self” mean the morally good side of themselves, them could imagine the moment when they do something’s morally applauded, “bad self” means the morally bad side of themselves, they could also imagine the moment when they doing something morally wrong, and “neutral self” means the aspect of self that doesn’t related to morality, they could imagine the moment when they doing something irrelevant to morality. In the same sense, the “good other”, “bad other”, and “neutral other” means the three different aspects of the stranger, whose name was chosen before the experiment. Then, the experiment proceeded as study 1a. Each participant finished 6 blocks, each have 120 trials. The sequence of trials was pseudo-randomized so that there are 10 matched trials for each condition and 10 non-matched trials for each condition (good self, neutral sef, bad self, good other, neutral other, bad other) for each block.

### Data Analysis
Data analysis followed strategies described in the general method section. Reaction times and *d* prime data were analyzed as in study 1 and study 2, except that one more within-subject variable (i.e., self-relevance) was included in the repeated measures ANOVA. 


## Results
`r df3a.invalid_trial_rate` correct trials with less than 200ms reaction times were exlucded.

### Analaysis of d prime.

```{r 3a_dprime, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
# calculate d prime
df3a.v.dprime_l <- df3a.v %>%
  dplyr::mutate(sdt = mosaic::derivedFactor("hit" = (ACC ==1 & Matchness == "Match"), # code as hit
                                    "CR" = (ACC ==1  & Matchness == "Mismatch"),      # correct reject
                                    "miss" = (ACC == 0 & Matchness == "Match"),       # miss
                                    "FA" = (ACC == 0 & Matchness == "Mismatch"),      # false alarm
                                    .method ="first",  .default = NA)) %>% 
  dplyr::group_by(Site, Subject, Age, Sex, Valence,Identity, sdt) %>%
  dplyr::summarise(N = length(sdt)) %>%                                    # calculate the counts for each 
  dplyr::ungroup() %>%
  tidyr::spread(key = sdt, value = N,fill = 0) %>%                          # long-to-wide format
  dplyr::mutate(hitR = hit/(hit + miss),                                    # hit rate
                FAR  = FA/(FA+CR)) %>%                                      # fa rate
  dplyr::mutate(hitR = ifelse(hitR == 1, 1 - 1/(2*(hit + miss)), hitR),     # if hit rate is 1, standardize it
                FAR  = ifelse(FAR == 0, 1/(2*(hit + miss)), FAR)) %>%       # if FA rate is 0, standardize it
  dplyr::mutate(dprime = qnorm(hitR) - qnorm(FAR)) %>%
  dplyr::select(Site, Subject, Age, Sex, Valence, Identity, dprime) %>%   # select relevant columns
  dplyr::mutate(Valence = factor(Valence, levels = c("Good","Neutral","Bad")),
                Identity = factor(Identity, levels = c('Self', 'Other')))

### Long to wide
#df1b.v.dprime_w <- df1b.v.dprime_l %>%
#  tidyr::spread(key = Valence, value = dprime) %>%                                   # long to wide
#  dplyr::rename_at(vars(-Site,-Subject,-Age,-Sex),function(x) paste0("d_",x))           # add prefix to certain conditions

# anova for d prime
df3a_dprime_anova <- afex::aov_ez('Subject','dprime',df3a.v.dprime_l,  # using afex's function 
                                  within = c('Identity','Valence'))
# use LMM, random intercept for each participant
#df1b_d_mixed <- afex::mixed(dprime ~ Valence +(1|Subject), 
#                          df1b.v.dprime_l,
#                          method = "S",
#                          control = lmerControl(optCtrl = list(maxfun = 1e6)))

df3a_dprime_anova_apa <- df3a_dprime_anova$aov %>% papaja::apa_print()

#posthoc_3a_d <- emmeans::emmeans(df3a_dprime_anova, "Valence") # compare each valence for both self and other condition
#pairs(posthoc_3a_d)

```
There was evidence for the main effect of valence, `r df3a_dprime_anova_apa$full$Valence`, and main effect of self-relevance, `r df3a_dprime_anova_apa$full$Identity`. 

Paired t test showed that the Good-Person condition (2.86 $\pm$ 0.16) was with greater *d* prime than Netural condition (2.28 $\pm$ 0.15, *t*(32) = 4.46, *p* = 0.002, Cohen's *d* = 0.587). We also found that the Bad-Person condition (2.47 $\pm$ 0.135) has also greater *d* prime than neutral condition , *t*(32) = 4.15, *p* = 0.007, Cohen's *d* = 0.396). There was no-significant difference between Good and bad conidition, *t*(32) = -1,667, *p* = 0.233, Cohen's *d* = -0.191.

### Analaysis of reaction time.
The results of reaction times of matchness trials showed similiar pattern as the *d* prime data.
```{r 3a_RT, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
# anova for RT with 2*2*3 design
df3a.v.rt_m <- df3a.v %>%
  dplyr::filter(ACC == 1) %>%
  dplyr::group_by(Site,Subject,Matchness, Identity, Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup()

df3a_RT_anova <- afex::aov_ez('Subject','RT_m',df3a.v.rt_m,     # using afex's function 
                                  within = c('Matchness','Identity','Valence'))
df3a_RT_anova_apa <- df3a_RT_anova %>% papaja::apa_print()
```
We found intercation between Matchness and Valence (`r df3a_RT_anova_apa$full$Matchness_Valence`) and then analyzed the matched trials and mismatched trials separately, as in previous experiments.

```{r 3a_RT_match, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
# match trials
df3a.v.rt_m1 <- df3a.v %>%
  dplyr::filter(ACC == 1 & Matchness == "Match") %>%
  dplyr::group_by(Site, Subject, Matchness, Identity, Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup() %>%
  dplyr::mutate(Valence = factor(Valence, levels = c("Good","Neutral","Bad")),
                Identity = factor(Identity, levels = c('Self', 'Other')))

df3a_RT_anova_m <- afex::aov_ez('Subject','RT_m',df3a.v.rt_m1,     # using afex's function 
                                  within = c('Identity','Valence'))
df3a_RT_anova_m_apa <- df3a_RT_anova_m %>% papaja::apa_print()

posthoc_3a_rt <- emmeans::emmeans(df3a_RT_anova_m, c('Identity',"Valence")) # compare each valence for both self and other condition
# pairs(posthoc_3a_rt)

# Mismatch trials
df3a.v.rt_m2 <- df3a.v %>%
  dplyr::filter(ACC == 1 & Matchness == "Mismatch") %>%
  dplyr::group_by(Site,Subject,Matchness, Identity, Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup()

df3a_RT_anova_nm <- afex::aov_ez('Subject','RT_m',df3a.v.rt_m2,     # using afex's function 
                                  within = c('Identity','Valence'))
df3a_RT_anova_nm_apa <- df3a_RT_anova_nm %>% papaja::apa_print()
```
For the matched trials, we found that main effect of valence `r df3a_RT_anova_m_apa$full$Valence`, but not the effect of identity `r df3a_RT_anova_m_apa$full$Identity`, nor the interaction `r df3a_RT_anova_m_apa$full$Identity_Valence`. 
For the mismatched trials, we found the main effect of Identity `r df3a_RT_anova_nm_apa$full$Identity`, but not the main effect of valence `r df3a_RT_anova_nm_apa$full$Valence` or interaction between the two `r df3a_RT_anova_nm_apa$full$Identity_Valence`.

# Experiment 3b
In study 3a, participants had to remember 6 pairs of association, which cause high cogitive load during the whole exepriment. To eliminate the influence of cognitive load, we conducted study 3b, in which participant learn three aspect of self and stranger seperately in to consecutive task. We hypothesize that we will replicate the pattern of study 3a, i.e., the effect of moral valence only occurs for self-relevant conditions.

## Method
```{r loadingData_3b,echo=FALSE,results='hide'}
# data collected in Tsinghua U
df3b <- read.csv(".\\exp3b\\rawdata_behav_exp3b_2017.csv", header = TRUE,
                   sep = ",", stringsAsFactors=FALSE, na.strings=c("","NA")) %>%
  dplyr::mutate(Site = "WZU") %>%
  dplyr::rename(ACC = Target.ACC,           # rename columns
                RT  = Target.RT,
                CRESP = CorrectAnswer,
                #BlockNo = BlockList.Sample,
                #TrialNo = SubTrial,
                RESP = Target.RESP,
                Matchness = YesNoResp) %>%
                #Valence = morality,
                #Identity = self
  # in this experiment we need to get the value of valence and identity from shape
  dplyr::mutate(Valence = derivedFactor("Neutral" = (Shape == "Neutralself" | Shape == 'NeutralOther'), 
                                        "Good" = (Shape == "Goodself" | Shape == 'GoodOther'), 
                                        "Bad" = (Shape == "Badself" | Shape == 'BadOther'), 
                                        .method ="first", .default = NA),
                Identity  = ifelse(Identity == "Self" | Identity == 'self', "Self", "Other"),
                Matchness = ifelse(Matchness == "Yes", "Match", "Mismatch"),
                Age = ifelse(Age == 0, NA, Age),  # if the min age is 0, that age is missing
                BlockNo = coalesce (otherBlocklList.Sample, selfBlockList.Sample),
                Subject = factor(Subject))

df3b.T.basic     <- df3b %>%
  dplyr::select(Site, Subject, Age, Sex) %>%
  dplyr::distinct(Subject, .keep_all = TRUE) %>%
  dplyr::summarise(N = length(Subject),
                   N_thu = length(Site[Site == "THU"]),
                   N_wzu = length(Site[Site == "WZU"]),
                   Nf = length(Sex[Sex == "female"]),
                   Nm = length(Sex[Sex == "male"]),
                   Age_mean = round(mean(Age,na.rm=TRUE),2),
                   Age_sd = round(sd(Age,na.rm=TRUE),2))
  
# number of participant who practiced but not in the formal experiment
#nQuit <- length(unique(df3$Subject[is.na(df3a$BlockNo)])) - length(unique(df3a$Subject[!is.na(df3a$BlockNo)]))

# participants should be excluded
df3b.excld.sub <-  df3b %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::group_by(Subject) %>%
  #dplyr::mutate(ACC = ifelse(RT <= 200, 0, ACC)) %>%  # set less than 200 ms response as wrong
  #dplyr::filter(!(ACC == 1 & RT <= 200)) %>%
  dplyr::summarise(N = length(ACC),                   # caculate the overall accuracy for each subject
                   N_crrct = sum(ACC),
                   ACC = sum(ACC)/length(ACC)) %>%
  dplyr::filter(ACC < 0.6) %>%                        # exlucde the participants with less than 60% overall accuracy
  dplyr::select(Subject)

df3b.excld.sub2 <- df3b.excld.sub
df3b.excld.sub2[5,1] <- 31003 # the participant whose hit rate is zero under one condition.

# The rate of excluded trials in valid data
df3b.invalid_trial_rate   <- df3b %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::filter(!(Subject %in% df3b.excld.sub2$Subject)) %>%   # exclude the invalid subjects
  dplyr::summarize(rate = length(RT[RT <= 200 & ACC == 1])/length(RT)) %>%
  dplyr::pull()

df3b.v   <- df3b %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::filter(!(Subject %in% df3b.excld.sub2$Subject)) %>%   # exclude the invalid subjects
  dplyr::filter(!(RT <= 200 & ACC == 1))                      # exclude < 200 trials

df3b.v.basic     <- df3b.v %>%
  dplyr::select(Site, Subject, Age, Sex) %>%
  dplyr::distinct(Subject, .keep_all = TRUE) %>%
  dplyr::summarise(N = length(Subject),
                   N_thu = length(Site[Site == "THU"]),
                   N_wzu = length(Site[Site == "WZU"]),
                   Nf = length(Sex[Sex == "female"]),
                   Nm = length(Sex[Sex == "male"]),
                   Age_mean = round(mean(Age,na.rm=TRUE),2),
                   Age_sd = round(sd(Age,na.rm=TRUE),2))
```

### Participants
Study 3b were finished in 2017, at that time we have calculated that the effect size (Cohen’s d) of good-person (or good-self) vs. bad-person (or bad-other) was between 0.47 ~ 0.53, based on study 1a, 1b, 2, 3a, 4a, and 4b. Based on this effect size, we estimated that 54 participants would allow we to detect the effec size of Cohen’s = 0.5 with 95% power and alpha = 0.05, using G*power 3.192 (Faul, Erdfelder, Buchner, & Lang, 2009; Faul, Erdfelder, Lang, & Buchner, 2007). Therefore, we planned to stop after we arrived this number. During the data collected at Wenzhou University, `r df3b.T.basic$N` participants (`r df3b.T.basic$Nf` females; 19 to 25 years of age, age = `r df3b.T.basic$Age_mean` $\pm$ `r df3b.T.basic$Age_sd`) came to the testing room and we tested all of them during a single day. All participants were right-handed, and all had normalneutral or corrected-to-normal vision. Informed consent was obtained from all participants prior to the experiment according to procedures approved by a local ethics committee. `r nrow(df3b.excld.sub)` participants’ data were excluded from analysis because their over all accuracy was lower than 60%, 1 more participant waw excluded because of zero hit rate for one condition, leaving `r df3b.v.basic$N` participants (`r df3b.v.basic$Nf`  females; 19 to 25 years old, age = `r df3b.v.basic$Age_mean` $\pm$ `r df3b.v.basic$Age_sd`). 


### Design
Study 3b has the same experimental design as 3a, with a 2× 3× 2 within-subject design. The first variable was self-relevance, include two levels: self-relevant vs. stranger-relevant; the second variable was moral valence, include good, neutral and bad; the third variable was the matching between shape and label: match vs. mismatch.
 Stimuli.	The stimuli used in study 3b share the same parameters with experiment 3a. 6 shapes were included (triangle, square, circle, trapezoid, diamond, regular pentagon), as well as 6 labels, but the labels changed to “good self”, “neutral self”, “bad self”, “good him/her”, bad him/her”, “neutral him/her”, the stranger’s label is consistent with participants’ gender. Same as study 3a, we asked participant to chosen an unfamiliar name of their own gender to be the stranger before showing them the relationship. Note, because of implementing error, the personal distance data didn’t collect for this experiment.
 
### Procedure
In this experiment, participants finished two matching tasks, i.e., self-matching task, and other-matching task. In the self-matching task, participants first associate the three aspects of self to three different shapes, and then perform the matching task. In the other-matching task, participants first associate the three aspects of the stranger to three different shapes, and then perform the matching task. The order of self-task and other-task are counter-balanced among participants.
Different from experiment 3a, after presenting the stimuli pair for 100ms, participant has 1900 ms to response, and they were feedbacked with both accuracy and reaction time.
As in study 3a, before each task, the intruction showed the meaning of each label to participants. The self-matching task and other-matching task were randomized between participants. Each participant finished 6 blocks, each have 120 trials.

### Data Analysis
Data analysis is the same as study 3a.

## Results

### Analysis of *d* prime.

```{r 3b_dprime, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
# calculate d prime
df3b.v.dprime_l <- df3b.v %>%
  dplyr::mutate(sdt = mosaic::derivedFactor("hit" = (ACC ==1 & Matchness == "Match"), # code as hit
                                    "CR" = (ACC ==1  & Matchness == "Mismatch"),      # correct reject
                                    "miss" = (ACC == 0 & Matchness == "Match"),       # miss
                                    "FA" = (ACC == 0 & Matchness == "Mismatch"),      # false alarm
                                    .method ="first",  .default = NA)) %>% 
  dplyr::group_by(Site, Subject, Age, Sex, Valence,Identity, sdt) %>%
  dplyr::summarise(N = length(sdt)) %>%                                    # calculate the counts for each 
  dplyr::ungroup() %>%
  tidyr::spread(key = sdt, value = N,fill = 0) %>%                          # long-to-wide format
  dplyr::mutate(hitR = hit/(hit + miss),                                    # hit rate
                FAR  = FA/(FA+CR)) %>%                                      # fa rate
  dplyr::mutate(hitR = ifelse(hitR == 1, 1 - 1/(2*(hit + miss)), hitR),     # if hit rate is 1, standardize it
                FAR  = ifelse(FAR == 0, 1/(2*(hit + miss)), FAR)) %>%       # if FA rate is 0, standardize it
  dplyr::mutate(dprime = qnorm(hitR) - qnorm(FAR)) %>%
  dplyr::select(Site, Subject, Age, Sex, Valence, Identity, dprime) %>%   # select relevant columns
  dplyr::mutate(Valence = factor(Valence, levels = c("Good","Neutral","Bad")),
                Identity = factor(Identity, levels = c('Self', 'Other')))

### Long to wide
#df3b.v.dprime_w <- df3b.v.dprime_l %>%
#  tidyr::spread(key = Valence, value = dprime) %>%                                   # long to wide
#  dplyr::rename_at(vars(-Site,-Subject,-Age,-Sex),function(x) paste0("d_",x))           # add prefix to certain conditions

# anova for d prime
df3b_dprime_anova <- afex::aov_ez('Subject','dprime',df3b.v.dprime_l,  # using afex's function 
                                  within = c('Identity','Valence'))
# use LMM, random intercept for each participant
#df1b_d_mixed <- afex::mixed(dprime ~ Valence +(1|Subject), 
#                          df1b.v.dprime_l,
#                          method = "S",
#                          control = lmerControl(optCtrl = list(maxfun = 1e6)))

df3b_dprime_anova_apa <- df3b_dprime_anova$aov %>% papaja::apa_print()

posthoc_3b_d_1 <- emmeans::emmeans(df3b_dprime_anova, "Valence")  # main effect

posthoc_3b_d_val <- emmeans::emmeans(df3b_dprime_anova, "Identity", by = "Valence") # simple effect

pairs(posthoc_3b_d_1)

pairs(posthoc_3b_d_val)
```
There was evidence for the main effect of valence, `r df3b_dprime_anova_apa$full$Valence`, and main effect of self-relevance, `r df3b_dprime_anova_apa$full$Identity`, as well as the intercation, `r df3b_dprime_anova_apa$full$Identity_Valence`.

```{r 3b_dprime_id, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
# calculate d prime for self condition
df3b.v.dprime_l_s <- df3b.v.dprime_l %>%
  dplyr::filter(Identity == "Self")

df3b_dprime_anova_s <- afex::aov_ez('Subject','dprime',df3b.v.dprime_l_s,  # using afex's function 
                                  within = c('Valence'))

df3b_dprime_anova_s_apa <- df3b_dprime_anova_s$aov %>% papaja::apa_print()

df3b.v.dprime_l_o <- df3b.v.dprime_l %>%
  dplyr::filter(Identity == "Other")

df3b_dprime_anova_o <- afex::aov_ez('Subject','dprime',df3b.v.dprime_l_o,  # using afex's function 
                                  within = c('Valence'))

df3b_dprime_anova_o_apa <- df3b_dprime_anova_o$aov %>% papaja::apa_print()

posthoc_3b_d_s <- emmeans::emmeans(df3b_dprime_anova_s, "Valence")  # main effect

posthoc_3b_d_o <- emmeans::emmeans(df3b_dprime_anova_o, "Valence") # simple effect

pairs(posthoc_3b_d_s)

pairs(posthoc_3b_d_o)
```
We conducted two repeated measures ANOVA for self and other condition separately. For the results from self-condition aligned with previous experiments, showed an main effect of moral valence on *d’*: `r df3b_dprime_anova_s_apa$full$Valence`.  Simple effect analysis showed that the d’ was larger for good self (2.23 ± 0.81) than for bad self (1.66 ± 0.74), *t*(55) = 6.11, *p* < 0.001, Cohen’s *d* = 0.817, 95% CI [0.511 1.117] , BF10 = 8.43, and neutral self (1.91 ± 0.66), *t*(55) = 3.03, *p* = 0.0038, Cohen’s *d*  = 0.404, 95%CI [0.13 0.675] , BF10 = 1.33e+5. There was also higher d’ for neutral-self condition than bad-self conditions, *t*(34) = 3.02, *p* = 0.0039, Cohen’s *d*  = 0.403, 95% CI [0.129 0.674], BF10 = 8.22.

For the stranger condition, there was no strong evidence for the effect of the morality of the association on d’, `r df3b_dprime_anova_o_apa$full$Valence`.

We also tested the effect of personal association by comparing *d’* values for difference moral valence level. The results showed that the bad-self association condition was responded worse than the bad-stranger association condition (2.18 ± 0.911), *t*(55) = -4.1, *p* < 0.001, Cohen’s *d*  = -0.548, 95% CI [-0.827 -0.265], BF10 = 167.  The neutral-self was also worse than the neutral-stranger (2.28 ± 1), *t*(55) = -3.15, *p* = 0.0026 , Cohen’s *d*  = -0.422, 95% CI [-0.693 -0.146], BF10 = 11.7. While the good-self association condition and good-stranger conditions (2.03 ± 0.89) are not differ from each other, *t*(55) = 1.394, *p* = 0.169, Cohen’s *d* = 0.186, 95% CI[-0.079 0.449], BF10 = 0.364.

### Analaysis of reaction time.
The results of reaction times of matchness trials showed similiar pattern as the *d* prime data.
```{r 3b_RT, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
# anova for d RT with 2*2*3 design
df3b.v.rt_m <- df3b.v %>%
  dplyr::filter(ACC == 1) %>%
  dplyr::group_by(Site,Subject,Matchness, Identity, Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup()

df3b_RT_anova <- afex::aov_ez('Subject','RT_m',df3b.v.rt_m,     # using afex's function 
                                  within = c('Matchness','Identity','Valence'))
df3b_RT_anova_apa <- df3b_RT_anova %>% papaja::apa_print()

# use LMM, random intercept for each participant
#df1b_RT_mixed <- afex::mixed(RT_m ~ Matchness*Valence + (1|Subject), 
#                          df1b.v.rt_m,
#                          method = "S",
#                          control = lmerControl(optCtrl = list(maxfun = 1e6)))
```
We found three-way intercation between matchness, and valence (`r df3b_RT_anova_apa$full$Matchness_Valence`) and then analyzed the matched trials and mismatched trials separately, as in previous experiments.

```{r 3b_RT_match, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
# match trials
df3b.v.rt_m1 <- df3b.v %>%
  dplyr::filter(ACC == 1 & Matchness == "Match") %>%
  dplyr::group_by(Site, Subject, Matchness, Identity, Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup() %>%
  dplyr::mutate(Valence = factor(Valence, levels = c("Good","Neutral","Bad")),
                Identity = factor(Identity, levels = c('Self', 'Other')))

df3b_RT_anova_m <- afex::aov_ez('Subject','RT_m',df3b.v.rt_m1,     # using afex's function 
                                  within = c('Identity','Valence'))
df3b_RT_anova_m_apa <- df3b_RT_anova_m %>% papaja::apa_print()

posthoc_3b_rt <- emmeans::emmeans(df3b_RT_anova_m, c('Identity',"Valence")) # compare each valence for both self and other condition
# pairs(posthoc_3b_rt)

df3b.v.rt_m1_s_anova <- df3b.v %>%
  dplyr::filter(ACC == 1 & Matchness == "Match" & Identity == "Self") %>%
  dplyr::group_by(Site, Subject, Matchness, Identity, Valence) %>%
  dplyr::summarise(RT_m = mean(RT), Ntrial = length(RT)) %>%
  dplyr::ungroup() %>%
  dplyr::mutate(Valence = factor(Valence, levels = c("Good","Neutral","Bad"))) %>%
  afex::aov_ez('Subject','RT_m', ., within = c('Valence'))
df3b.v.rt_m1_s_anova_apa <- df3b.v.rt_m1_s_anova %>% papaja::apa_print()

df3b.v.rt_m1_o_anova <- df3b.v %>%
  dplyr::filter(ACC == 1 & Matchness == "Match" & Identity == "Other") %>%
  dplyr::group_by(Site, Subject, Matchness, Identity, Valence) %>%
  dplyr::summarise(RT_m = mean(RT), Ntrial = length(RT)) %>%
  dplyr::ungroup() %>%
  dplyr::mutate(Valence = factor(Valence, levels = c("Good","Neutral","Bad"))) %>%
  afex::aov_ez('Subject','RT_m', ., within = c('Valence'))

df3b.v.rt_m1_o_anova_apa <- df3b.v.rt_m1_o_anova %>% papaja::apa_print()

# Mismatch trials
df3b.v.rt_m2 <- df3b.v %>%
  dplyr::filter(ACC == 1 & Matchness == "Mismatch") %>%
  dplyr::group_by(Site,Subject,Matchness, Identity, Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup()

df3b_RT_anova_nm <- afex::aov_ez('Subject','RT_m',df3b.v.rt_m2,     # using afex's function 
                                  within = c('Identity','Valence'))
df3b_RT_anova_nm_apa <- df3b_RT_anova_nm %>% papaja::apa_print()
```
For the matched trials, we found that interaction between of valence and identity, `r df3b_RT_anova_m_apa$full$Identity_Valence`, BF10 = 1.17. Then, the matched trials were analyzed for the self-relevance and stranger-relevance pairs separately. The results showed a significant effect of moral valence for the self condition, `r df3b.v.rt_m1_s_anova_apa$full$Valence`, BF10 = 4.54e+6. Paired *t*-tests showed that responses to the good-self association (817 ± 119) were faster than to bad-self associations (915 ± 132), *t*(55) = -8.78, *p* < 0.001, Cohen’s *d* = -1.173, 95% CI [-1.511 -0.828], BF10 = 1.84e+9, and to neutral-self association (880 ± 116), *t*(55) = 3.748, *p* < 0.0001, Cohen’s *d* = -0.501, 95% CI [-0.777 -0.221], BF10 = 58.7. The neutral-self was faster than the bad-self associations, *t*(55) = -2.41, *p* = 0.019 , Cohen’s *d* = -0.321, 95% CI [-0.589 -0.051], BF10 = 2.03. 
The effect of moral valence was also significant for the stranger-relevance conditions, `r df3b.v.rt_m1_o_anova_apa$full$Valence`, BF10 = 8.55. the good-other condition (734 ± 158) didn’t differ from neutral-other condition (735 ±160), t(55) = -0.07, p = 0.946, Cohen’s *d* = -0.009, 95% CI [-0.271 -0.293], BF10 = 0.15, but faster than the bad other condition (776 ± 173), *t*(55) = -3.14, *p* = 0.0027, Cohen’s *d* = -0.419, 95% CI [-0.691 -0.144], BF10 = 11.3. The neutral-other condition also faster than the bad-other condition, *t*(55) = -3.232, *p* = 0.0021, Cohen’s *d* = -0.432, 95% CI [-0.704 -0.156], BF10 = 14.3. 

We also analyzed the effect of self-relevance on the different moral valence levels. The results showed that for all three different valence levels, there the self condition was responded slower than other condition: good-self  vs. good-stranger, *t*(55) = 4.29, *p* < 0.001, Cohen’s *d* = 0.573, 95% CI [0.288 0.854], BF10 = 297.2; neutral-self  vs. neutral -stranger, *t*(55) = 7.17, *p* < 0.001, Cohen’s *d* = 0.958, 95% CI [0.638 1.272]), BF10 = 5.77e+6; bad-self vs. bad-other, *t*(55) = 6.03, *p* < 0.001, Cohen’s *d* = 0.806, 95% CI [0.5 1.11], BF10 = 100208.03.

## Discussion
In experiment 3b, we separated the self-referential and other-referential tasks into different blocks so that participants had lower cognitive load when finish the task. We replicated the pattern from experiment 3a that the valence effect is stronger when the stimuli were self-referential. Contrast to experiment 3a, however, we found that the self-referential condition is out-performed by other-referential conditions. This pattern suggest that the self-referential enhanced the valence effect, and the advantage to self is relative instead of absolute.

# Experiment 4a
In study 1-3 participants made explicit judgements about moral associations. In Experiment 4, we examined whether the effects of moral valence occur even when the moral valence information might not be relevent to the task. In this study participants made perceptual match judgements to associations between self-referential labels and shapes (cf. Sui et al., 2012), but we presented labels of different moral valence levels in the shapes. 
```{r loadingData_4a,echo=FALSE,results='hide'}
df4a_1 <- read.csv(".\\exp4a\\rawdata_behav_exp4a_2015.csv",header = TRUE, sep = ",",stringsAsFactors=FALSE,na.strings=c("","NA")) %>%
  dplyr::rename(Morality = morality,
                Identity = self) %>%
  dplyr::mutate(Site = "THU")

df4a_2 <- read.csv(".\\exp4a\\rawdata_behav_exp4a_2017.csv",header = TRUE, sep = ",",stringsAsFactors=FALSE,na.strings=c("","NA")) %>%
  dplyr::mutate(Site = "WZU")

df4a <- rbind(df4a_1,df4a_2) %>%
  dplyr::rename(ACC = Target.ACC,           # rename columns
                RT  = Target.RT,
                CRESP = Target.CRESP,
                BlockNo = BlockList.Sample,
                TrialNo = SubTrial,
                RESP = Target.RESP,
                Matchness = YesNoResp,
                Valence = Morality) %>%
  dplyr::mutate(Valence  = ifelse(Valence == "Normal", "Neutral", Valence),
                Identity = ifelse(Identity == "self" | Identity == "Self", "Self", "Other"),
                Matchness = ifelse(Matchness == "Yes", "Match", "Mismatch"),
                Age = ifelse(Age == 0, NA, Age),                             # if the min age is 0, that age is missing
                Subject = factor(Subject))
rm(df4a_1,df4a_2) # remove the temporary variables.

df4a.T.basic     <- df4a %>%
  dplyr::select(Site, Subject, Age, Sex) %>%
  dplyr::distinct(Subject, .keep_all = TRUE) %>%
  dplyr::summarise(N = length(Subject),
                   N_thu = length(Site[Site == "THU"]),
                   N_wzu = length(Site[Site == "WZU"]),
                   Nf = length(Sex[Sex == "female"]),
                   Nm = length(Sex[Sex == "male"]),
                   Age_mean = round(mean(Age,na.rm=TRUE),2),
                   Age_sd = round(sd(Age,na.rm=TRUE),2))
  
# number of participant who practiced but not in the formal experiment
nQuit <- length(unique(df4a$Subject[is.na(df4a$BlockNo)])) - length(unique(df4a$Subject[!is.na(df4a$BlockNo)]))

# participants should be excluded
df4a.excld.sub <-  df4a %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::group_by(Subject) %>%
  #dplyr::mutate(ACC = ifelse(RT <= 200, 0, ACC)) %>%  # set less than 200 ms response as wrong
  #dplyr::filter(!(ACC == 1 & RT <= 200)) %>%
  dplyr::summarise(N = length(ACC),                   # caculate the overall accuracy for each subject
                   N_crrct = sum(ACC),
                   ACC = sum(ACC)/length(ACC)) %>%
  dplyr::filter(ACC < 0.6) %>%                        # exlucde the participants with less than 60% overall accuracy
  dplyr::select(Subject)

# The rate of excluded trials in valid data
df4a.invalid_trial_rate   <- df4a %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::filter(!(Subject %in% df4a.excld.sub$Subject)) %>%   # exclude the invalid subjects
  dplyr::summarize(rate = length(RT[RT <= 200 & ACC == 1])/length(RT)) %>%
  dplyr::pull()

df4a.v   <- df4a %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::filter(!(Subject %in% df4a.excld.sub$Subject)) %>%   # exclude the invalid subjects
  dplyr::filter(!(RT <= 200 & ACC == 1))                      # exclude < 200 trials

df4a.v.basic     <- df4a.v %>%
  dplyr::select(Site, Subject, Age, Sex) %>%
  dplyr::distinct(Subject, .keep_all = TRUE) %>%
  dplyr::summarise(N = length(Subject),
                   N_thu = length(Site[Site == "THU"]),
                   N_wzu = length(Site[Site == "WZU"]),
                   Nf = length(Sex[Sex == "female"]),
                   Nm = length(Sex[Sex == "male"]),
                   Age_mean = round(mean(Age,na.rm=TRUE),2),
                   Age_sd = round(sd(Age,na.rm=TRUE),2))
```
## Methods
### Participants
`r df4a.T.basic$N` participants (`r df4a.T.basic$Nf` female, age = `r df4a.T.basic$Age_mean` $\pm$ `r df4a.T.basic$Age_sd`) participated the current study, `r df4a.T.basic$N_thu` of them were from Tsinghua Universtiy in 2015, `r df4a.T.basic$N_wzu` were from Wenzhou University parpticipated in 2017. All participants were right-handed, and all had normalneutral or corrected-to-normalneutral vision. Informed consent was obtained from all participants prior to the experiment according to procedures approved by a local ethics committee. The data from `r nrow(df4a.excld.sub)` participants from Wenzhou site were excluded from analysis because their accuracy was close to chance (< 0.6). The results for the remaining `r df4a.v.basic$N` participants (`r df4a.v.basic$Nf` female, age = `r df4a.v.basic$Age_mean` $\pm$ `r df4a.v.basic$Age_sd`) were analyzed and reported.

### Experimental design
As in Experiment 3, a 2× 3× 2 within-subject design was used. The first variable was self-relevance (self and stranger associations); the second variable was moral valence (good, normalneutral and bad associations); the third variable was the matching between shape and label (matching vs. non-match for the personal association). 
However, in this the task, participants only learn the association between two geometric shapes and two labels (self and other), i.e., only self-relevance were related to the task. The moral valence manipulation was achieved by embeding the personal label of the labels in the geometric shapes, see below. For simplicity, the trials where shapes where paired with self and with a word of “good person” inside were shorted as good-self condition, similarly, the trials where shapes paired with the self and with a word of “bad person” inside were shorted as bad-self condition. Hence, we also have six conditions: good-self, neutral-self, bad-self, good-other, neutral-other, and bad-other.

### Stimuli
2 shapes were included (circle, square) and each appeared above a central fixation cross with the personal label appearing below.  However, the shapes were not empty but with a two-Chinese-character word in the middle, the word was one of three labels with different moral valence: “good person”, “bad person” and “neutral person”. Before the experiment, participants learned the self/other association, and were informed to only response to the association between shapes’ configure and the labels below the fixation, but ignore the words within shapes. Besides the behavioral experiments, participants from Tsinghua community also finished questionnaires as Experiments 3, and participants from Wenzhou community finished a series of questionnaire as the other experiment finished in Wenzhou.

### Procedure
The procedure was similar to Experiment 1. There were 6 blocks of trial, each with 120 trials for 2017 data. Due to procedure error, the data collected in 2015 in Tsinghua community only have 60 trials for each block, i.e., 30 trials per condition. 

### Data analysis
The data were analyzed in the same way as in experiment 3a and 3b.


## Results
### *d* prime.
We conducted 2 (Idenity: self v. other) by 3 (morlaity: good, neutral, bad) repeated measures ANOVA.
```{r analyzing for d prime_4a, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
# calculating the dprime 
df4a.v.dprime_l <- df4a.v %>%
  dplyr::mutate(sdt = mosaic::derivedFactor("hit" = (ACC ==1 & Matchness == "Match"), # code as hit
                                    "CR" = (ACC ==1  & Matchness == "Mismatch"),      # correct reject
                                    "miss" = (ACC == 0 & Matchness == "Match"),       # miss
                                    "FA" = (ACC == 0 & Matchness == "Mismatch"),      # false alarm
                                    .method ="first",  .default = NA)) %>% 
  dplyr::group_by(Site, Subject, Age, Sex, Valence,Identity, sdt) %>%
  dplyr::summarise(N = length(sdt)) %>%                                    # calculate the counts for each 
  dplyr::ungroup() %>%
  tidyr::spread(key = sdt, value = N,fill = 0) %>%                          # long-to-wide format
  dplyr::mutate(hitR = hit/(hit + miss),                                    # hit rate
                FAR  = FA/(FA+CR)) %>%                                      # fa rate
  dplyr::mutate(hitR = ifelse(hitR == 1, 1 - 1/(2*(hit + miss)), hitR),     # if hit rate is 1, standardize it
                FAR  = ifelse(FAR == 0, 1/(2*(hit + miss)), FAR)) %>%       # if FA rate is 0, standardize it
  dplyr::mutate(dprime = qnorm(hitR) - qnorm(FAR)) %>%
  dplyr::select(Site, Subject, Age, Sex, Valence, Identity, dprime) %>%   # select relevant columns
  dplyr::mutate(Valence = factor(Valence, levels = c("Good","Neutral","Bad")),
                Identity = factor(Identity, levels = c('Self', 'Other')))
# anova for d prime with 2*2 design
df4a_dprime_anova <- afex::aov_ez('Subject','dprime',df4a.v.dprime_l,  # using afex's function 
                                  within = c('Identity','Valence'))

# use LMM, random intercept for each participant
df4a_d_mixed <- afex::mixed(dprime ~ Identity*Valence +(1|Subject), 
                          df4a.v.dprime_l,
                          method = "S",
                          control = lmerControl(optCtrl = list(maxfun = 1e6)))

df4a_dprime_anova_apa <- df4a_dprime_anova$aov %>% papaja::apa_print()
```
The effect of identity (`r df4a_dprime_anova_apa$full$Identity`), also the interaction between identity and valence, (`r df4a_dprime_anova_apa$full$Identity_Valence`). But not the effect of valence was not found, `r df4a_dprime_anova_apa$full$Valence`.

```{r results='asis', echo = F}
#knitr::kable(nice(df4b_dprime_anova), caption = "ANOVA of d prime")
#apa_table(df4a_dprime_anova_apa$table
#  , caption = "A really beautiful ANOVA table."
#  , note = "Note that the column names contain beautiful mathematical copy: This is because the table has variable labels."
#)
```

We further examined the effect of valence for both self and other. 

```{r results='asis', echo = F}
posthoc_4a_d_m1 <- emmeans::emmeans(df4a_dprime_anova, "Valence", by = "Identity") # compare each valence for both self and other condition
#pairs(posthoc_4a_d_m1)
# summary(as.glht(pairs(m2)), test=adjusted("free"))
posthoc_4a_d_m2 <- emmeans(df4a_dprime_anova, "Identity", by = "Valence") # compare self vs. other for each valence condition
#pairs(posthoc_4a_d_m2)
```

### Reaction times.
We conducted 2 (Matchness: match v. mismatch) by 2 (Idenity: self v. other) by 3 (morlaity: good, neutral, bad) repeated measure ANOVA:
```{r analyzing for RT_4a, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
df4a.v.rt_m <- df4a.v %>%
  dplyr::filter(ACC == 1) %>%
  dplyr::group_by(Site,Subject,Matchness, Identity, Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup()

df4a_RT_anova <- afex::aov_ez('Subject','RT_m',df4a.v.rt_m,     # using afex's function 
                                  within = c('Matchness','Identity','Valence'))
df4a_RT_anova_apa <- df4a_RT_anova %>% papaja::apa_print()
```
There was a main effect of Matchness (`r df4a_RT_anova_apa$full$Matchness`) and intercation between Matchness and Identity(`r df4a_RT_anova_apa$full$Matchness_Identity`)

We carried out two separate ANOVA for both matched and mismatched trials.

```{r analyzing for RT_4a_match, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
# match trials
df4a.v.rt_m1 <- df4a.v %>%
  dplyr::filter(ACC == 1 & Matchness == "Match") %>%
  dplyr::group_by(Site, Subject, Matchness, Identity, Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup() %>%
  dplyr::mutate(Valence = factor(Valence, levels = c("Good","Neutral","Bad")),
                Identity = factor(Identity, levels = c('Self', 'Other')))

df4a_RT_anova_m <- afex::aov_ez('Subject','RT_m',df4a.v.rt_m1,     # using afex's function 
                                  within = c('Identity','Valence'))
df4a_RT_anova_m_apa <- df4a_RT_anova_m %>% papaja::apa_print()

posthoc_4a_rt <- emmeans::emmeans(df4a_RT_anova_m, c('Identity',"Valence")) # compare each valence for both self and other condition
# pairs(posthoc_4a_rt)

# Mismatch trials
df4a.v.rt_m2 <- df4a.v %>%
  dplyr::filter(ACC == 1 & Matchness == "Mismatch") %>%
  dplyr::group_by(Site,Subject,Matchness, Identity, Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup()

df4a_RT_anova_nm <- afex::aov_ez('Subject','RT_m',df4a.v.rt_m2,     # using afex's function 
                                  within = c('Identity','Valence'))
df4a_RT_anova_nm_apa <- df4a_RT_anova_nm %>% papaja::apa_print()

# match trials: self condition
df4a.v.rt_m1_s <- df4a.v %>%
  dplyr::filter(ACC == 1 & Matchness == "Match" & Identity == "Self") %>%
  dplyr::group_by(Site, Subject, Matchness, Identity, Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup() %>%
  dplyr::mutate(Valence = factor(Valence, levels = c("Good","Neutral","Bad")))

df4a_RT_anova_m_s <- afex::aov_ez('Subject','RT_m',df4a.v.rt_m1_s,     # using afex's function 
                                  within = c('Valence'))
df4a_RT_anova_m_s_apa <- df4a_RT_anova_m_s %>% papaja::apa_print()

posthoc_4a_rt_s <- emmeans::emmeans(df4a_RT_anova_m_s, c("Valence")) # compare each valence for both self and other condition
# pairs(posthoc_4a_rt_s)

# match trials: other condition
df4a.v.rt_m1_o <- df4a.v %>%
  dplyr::filter(ACC == 1 & Matchness == "Match" & Identity == "Other") %>%
  dplyr::group_by(Site, Subject, Matchness, Identity, Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup() %>%
  dplyr::mutate(Valence = factor(Valence, levels = c("Good","Neutral","Bad")))

df4a_RT_anova_m_o <- afex::aov_ez('Subject','RT_m',df4a.v.rt_m1_o,     # using afex's function 
                                  within = c('Valence'))
df4a_RT_anova_m_o_apa <- df4a_RT_anova_m_o %>% papaja::apa_print()

```
For matched trials, we found the effect of identity `r df4a_RT_anova_m_apa$full$Identity`, and the interaction between morality and identity,`r df4a_RT_anova_m_apa$full$Identity_Valence`. However, there is no main effect of valence (`r df4a_RT_anova_m_apa$full$Valence`). 

```{r results='asis', echo = F}
#knitr::kable(nice(df4b_dprime_anova), caption = "ANOVA of d prime")
apa_table(df4a_RT_anova_m_apa$table
  , caption = "A really beautiful ANOVA table."
  , note = "Note that the column names contain beautiful mathematical copy: This is because the table has variable labels."
)
```

We futher broke down the interaction by analyzing the data for self and other pairs separately. There was a significant effect of moral valence for self-stimuli, `r df4a_RT_anova_m_s_apa$full$Valence`, BF10 = 11.16. Paired t tests showed that good-self condition (654 ± 67) were faster relative to bad-self condition (665 ± 64.6), *t*(51) = -3.57, *p* = 0.0022, Cohen’s *d* = -0.451 CI [-0.718 -0.182], BF10 = 27.0, and  over neutral-self condition (664 ± 64), *t*(51) = -2.94, *p* = 0.013, Cohen’s  *d* = -0.362, 95% CI [-0.624 -0.097], BF10 = 4.63. The neutral-self and bad-self conditionsdid not differ, *t*(51) = -0.44, *p* = 0.89, Cohen’s *d* = 0.0499, CI [-0.305 0.206], BF10 = 0.153 (see Figure 5). 

For the stranger condition, the results showed that there was no difference among these conditions, `r df4a_RT_anova_m_o_apa$full$Valence`, BF10 = 0.077.

For non-matched trials, there was no significant effect. Morality (`r df4a_RT_anova_nm_apa$full$Identity`), Identity(`r df4a_RT_anova_nm_apa$full$Valence`), interaction (`r df4a_RT_anova_nm_apa$full$Identity_Valence`).

# Experiment 4b
In study 4b we further investigated whether the effects of moral valence would modulate by the presence of self. In this study, participants made perceptual match judgements to associations between different moral valence and shapes as in study 1-3. However, as in study 4, we made the self-referential task as an implicit task, to examine the interaction between self-referential effect and modulation of positive moral valence. 

## Method

```{r loadingData_4b,echo=FALSE,results='hide'}
df4b_1 <- read.csv(".\\exp4b\\rawdata_behav_exp4b_2015.csv",header = TRUE, sep = ",",stringsAsFactors=FALSE,na.strings=c("","NA")) %>%
  dplyr::rename(Morality = morality) %>%
  dplyr::mutate(Site = "THU")

df4b_2 <- read.csv(".\\exp4b\\rawdata_behav_exp4b_2017.csv",header = TRUE, sep = ",",stringsAsFactors=FALSE,na.strings=c("","NA")) %>%
  dplyr::rename(Morality = morality) %>%
  dplyr::mutate(Site = "WZU")

df4b <- rbind(df4b_1,df4b_2) %>%
  dplyr::rename(ACC = Target.ACC,           # rename columns
                RT  = Target.RT,
                CRESP = Target.CRESP,
                BlockNo = BlockList.Sample,
                TrialNo = SubTrial,
                RESP = Target.RESP,
                Matchness = YesNoResp,
                Valence = Morality) %>%
  dplyr::mutate(Valence  = ifelse(Valence == "Ord", "Neutral", Valence),
                Identity = ifelse(Identity == "self" | Identity == "Self", "Self", "Other"),
                Matchness = ifelse(Matchness == "Yes", "Match", "Mismatch"),
                Age = ifelse(Age == 0, NA, Age),                             # if the min age is 0, that age is missing
                Subject = factor(Subject))
rm(df4b_1,df4b_2) # remove the temporary variables.

df4b.T.basic     <- df4b %>%
  dplyr::select(Site, Subject, Age, Sex) %>%
  dplyr::distinct(Subject, .keep_all = TRUE) %>%
  dplyr::summarise(N = length(Subject),
                   N_thu = length(Site[Site == "THU"]),
                   N_wzu = length(Site[Site == "WZU"]),
                   Nf = length(Sex[Sex == "female"]),
                   Nm = length(Sex[Sex == "male"]),
                   Age_mean = round(mean(Age,na.rm=TRUE),2),
                   Age_sd = round(sd(Age,na.rm=TRUE),2))
  
# number of participant who practiced but not in the formal experiment
nQuit <- length(unique(df4b$Subject[is.na(df4b$BlockNo)])) - length(unique(df4b$Subject[!is.na(df4b$BlockNo)]))

# participants should be excluded
df4b.excld.sub <-  df4b %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::group_by(Subject) %>%
  #dplyr::mutate(ACC = ifelse(RT <= 200, 0, ACC)) %>%  # set less than 200 ms response as wrong
  dplyr::summarise(N = length(ACC),                   # caculate the overall accuracy for each subject
                   N_crrct = sum(ACC),
                   ACC = sum(ACC)/length(ACC)) %>%
  dplyr::filter(ACC < 0.6) %>%                        # exlucde the participants with less than 60% overall accuracy
  dplyr::select(Subject)

# The rate of excluded trials in valid data
df4b.invalid_trial_rate   <- df4b %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::filter(!(Subject %in% df4b.excld.sub$Subject)) %>%   # exclude the invalid subjects
  dplyr::summarize(rate = length(RT[RT <= 200 & ACC == 1])/length(RT)) %>%
  dplyr::pull()

df4b.v   <- df4b %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::filter(!(Subject %in% df4b.excld.sub$Subject)) %>%   # exclude the invalid subjects
  dplyr::filter(!(RT <= 200 & ACC == 1))                      # exclude < 200 trials

df4b.v.basic     <- df4b.v %>%
  dplyr::select(Site, Subject, Age, Sex) %>%
  dplyr::distinct(Subject, .keep_all = TRUE) %>%
  dplyr::summarise(N = length(Subject),
                   N_thu = length(Site[Site == "THU"]),
                   N_wzu = length(Site[Site == "WZU"]),
                   Nf = length(Sex[Sex == "female"]),
                   Nm = length(Sex[Sex == "male"]),
                   Age_mean = round(mean(Age,na.rm=TRUE),2),
                   Age_sd = round(sd(Age,na.rm=TRUE),2))
```
### Participants
`r df4b.T.basic$N` college students (`r df4b.T.basic$Nf` female, age = `r df4b.T.basic$Age_mean` $\pm$ `r df4b.T.basic$Age_sd`) participated the current study, `r df4b.T.basic$N_thu` of them were from Tsinghua Universtiy in 2015 `r df4b.T.basic$N_wzu` were from Wenzhou University parpticipated in 2017. All participants were right-handed, and all had normalneutral or corrected-to-normalneutral vision. Informed consent was obtained from all participants prior to the experiment according to procedures approved by a local ethics committee. The data from `r nrow(df4b.excld.sub)` participants were excluded from analysis because their accuracy was close to chance (< 0.6). The results for the remaining `r df4b.v.basic$N` participants (`r df4b.v.basic$Nf` female, age = `r df4b.v.basic$Age_mean` $\pm$ `r df4b.v.basic$Age_sd`) were analyzed and reported.

### Experimental design
The experimental design of this experiment is same as experiment 4a:  a 3× 2 × 2 within-subject design with moral valence (good, normalneutral and bad associations), self-relatedness (self vs. other), and matchness between shape and label (match vs. mismatch for the personal association) as within-subject variables. However, in the current task, the participants learned the associations between three shapes and three labels with different moral valence: good-person, neutral-person, and bad-person. While the word “self” or “other” were presented in the shapes (see below).

### Stimuli
In this task, 3 shapes were included (circle, square, and trapezoid) and were presented above a central fixation cross, as in previous experiments.  Similar to experiment 4a, the shapes were not empty but with a two-Chinese-character word in the middle corresponding to the labels “self” and “other”. Before the experiment, we informed participants only response to the relationship between shapes’shapes configure and the labels below the fixation, ignoring the wordswithin each shape. Besides the behavioral experiments, participants also finished questionnaires as Experiments 1-3.

### Procedure
The procedure was similar to Experiment 4 a. Both samples of participants finished 6 blocks of trial, each with 120 trials.

### Data analysis
The data were analyzed as in experiment 4a.

## Results
### *d* prime
```{r analyzing for d prime_e4b, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
# calculating the dprime 
df4b.v.dprime_l <- df4b.v %>%
  dplyr::mutate(sdt = mosaic::derivedFactor("hit" = (ACC ==1 & Matchness == "Match"), # code as hit
                                    "CR" = (ACC ==1  & Matchness == "Mismatch"),      # correct reject
                                    "miss" = (ACC == 0 & Matchness == "Match"),       # miss
                                    "FA" = (ACC == 0 & Matchness == "Mismatch"),      # false alarm
                                    .method ="first",  .default = NA)) %>% 
  dplyr::group_by(Site, Subject, Age, Sex, Valence,Identity, sdt) %>%
  dplyr::summarise(N = length(sdt)) %>%                                    # calculate the counts for each 
  dplyr::ungroup() %>%
  tidyr::spread(key = sdt, value = N,fill = 0) %>%                          # long-to-wide format
  dplyr::mutate(hitR = hit/(hit + miss),                                    # hit rate
                FAR  = FA/(FA+CR)) %>%                                      # fa rate
  dplyr::mutate(hitR = ifelse(hitR == 1, 1 - 1/(2*(hit + miss)), hitR),     # if hit rate is 1, standardize it
                FAR  = ifelse(FAR == 0, 1/(2*(hit + miss)), FAR)) %>%       # if FA rate is 0, standardize it
  dplyr::mutate(dprime = qnorm(hitR) - qnorm(FAR)) %>%
  dplyr::select(Site, Subject, Age, Sex, Valence, Identity, dprime) %>%   # select relevant columns
  dplyr::mutate(Valence = factor(Valence, levels = c("Good","Neutral","Bad")),
                Identity = factor(Identity, levels = c('Self', 'Other')))


# anova for d prime with 2*2 design
df4b_dprime_anova <- afex::aov_ez('Subject','dprime',df4b.v.dprime_l,  # using afex's function 
                                  within = c('Identity','Valence'))
df4b_dprime_anova_apa <- df4b_dprime_anova %>% papaja::apa_print()
#df4b_dprime_anova <- apa_print(df4b_dprime_anova)
```
We conducted 2 (Idenity: self v. other) by 3 (morlaity: good, neutral, bad) repeated measure ANOVA. The results revealed no effect of valence (`r df4b_dprime_anova_apa$full$Valence`), or identity, `r df4b_dprime_anova_apa$full$Identity`, or their interactions, `r df4b_dprime_anova_apa$full$Identity_Valence`.

```{r results='asis', echo = F}
#m2 <- emmeans::emmeans(df4b_dprime_anova, "Valence", by = "Identity") # compare each valence for both self and other condition
#pairs(m2)
#summary(as.glht(pairs(m2)), test=adjusted("free"))

#m3 <- emmeans(df4b_dprime_anova, "Identity", by = "Morality") # compare self vs. other for each valence condition
#pairs(m3)

```

### Reaction times
We conducted 2 (Matchness: match v. mismatch) by 2 (Idenity: self v. other) by 3 (morlaity: good, neutral, bad) repeated measure ANOVA:
```{r analyzing for RT_4b, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
df4b.v.rt_m <- df4b.v %>%
  dplyr::filter(ACC == 1) %>%
  dplyr::group_by(Site,Subject,Matchness, Identity, Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup()

df4b_RT_anova <- afex::aov_ez('Subject','RT_m',df4b.v.rt_m,     # using afex's function 
                                  within = c('Matchness','Identity','Valence'))
df4b_RT_anova_apa <- df4b_RT_anova %>% papaja::apa_print()
```
There was a main effect of Matchness (`r df4b_RT_anova_apa$full$Matchness`), main effect of valence (`r df4b_RT_anova_apa$full$Valence`),  intercation between Matchness and Valence(`r df4b_RT_anova_apa$full$Matchness_Valence`), and three way interaction (`r df4b_RT_anova_apa$full$Matchness_Identity_Valence`).

```{r analyzing for RT_4b_match, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
# match trials
df4b.v.rt_m1 <- df4b.v %>%
  dplyr::filter(ACC == 1 & Matchness == "Match") %>%
  dplyr::group_by(Site, Subject, Matchness, Identity, Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup() %>%
  dplyr::mutate(Valence = factor(Valence, levels = c("Good","Neutral","Bad")),
                Identity = factor(Identity, levels = c('Self', 'Other')))

df4b_RT_anova_m <- afex::aov_ez('Subject','RT_m',df4b.v.rt_m1,     # using afex's function 
                                  within = c('Identity','Valence'))
df4b_RT_anova_m_apa <- df4b_RT_anova_m %>% papaja::apa_print()

posthoc_4b_rt <- emmeans::emmeans(df4b_RT_anova_m, c('Identity',"Valence")) # compare each valence for both self and other condition
# pairs(posthoc_4b_rt)

# Mismatch trials
df4b.v.rt_m2 <- df4b.v %>%
  dplyr::filter(ACC == 1 & Matchness == "Mismatch") %>%
  dplyr::group_by(Site,Subject,Matchness, Identity, Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup()

df4b_RT_anova_nm <- afex::aov_ez('Subject','RT_m',df4b.v.rt_m2,     # using afex's function 
                                  within = c('Identity','Valence'))
df4b_RT_anova_nm_apa <- df4b_RT_anova_nm %>% papaja::apa_print()

# match trials: self condition
df4b.v.rt_m1_s <- df4b.v %>%
  dplyr::filter(ACC == 1 & Matchness == "Match" & Identity == "Self") %>%
  dplyr::group_by(Site, Subject, Matchness, Identity, Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup() %>%
  dplyr::mutate(Valence = factor(Valence, levels = c("Good","Neutral","Bad")))

df4b_RT_anova_m_s <- afex::aov_ez('Subject','RT_m',df4b.v.rt_m1_s,     # using afex's function 
                                  within = c('Valence'))
df4b_RT_anova_m_s_apa <- df4b_RT_anova_m_s %>% papaja::apa_print()

posthoc_4b_rt_s <- emmeans::emmeans(df4b_RT_anova_m_s, c("Valence")) # compare each valence for both self and other condition
# pairs(posthoc_4b_rt_s)

# match trials: other condition
df4b.v.rt_m1_o <- df4b.v %>%
  dplyr::filter(ACC == 1 & Matchness == "Match" & Identity == "Other") %>%
  dplyr::group_by(Site, Subject, Matchness, Identity, Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup() %>%
  dplyr::mutate(Valence = factor(Valence, levels = c("Good","Neutral","Bad")))

df4b_RT_anova_m_o <- afex::aov_ez('Subject','RT_m',df4b.v.rt_m1_o,     # using afex's function 
                                  within = c('Valence'))
df4b_RT_anova_m_o_apa <- df4b_RT_anova_m_o %>% papaja::apa_print()

posthoc_4b_rt_o <- emmeans::emmeans(df4b_RT_anova_m_o, c("Valence")) # compare each valence for both self and other condition
# pairs(posthoc_4b_rt_o)
```
We futher broke down the interaction by analyzing the data for self and other pairs separately. There was a significant effect of moral valence for self-stimuli, `r df4b_RT_anova_m_s_apa$full$Valence`, BF10 = 11.16. Paired t tests showed that good-self association (680 ± 65.7) were faster than bad-self associations (720  ± 60.2), *t*(44) = -4.22, *p* < .001, Cohen’s *d* = -0.629 CI [-0.947 -0.306], BF10 = 200, and  neutral-self association (712 ± 54.9), *t*(44) = -4.67, *p* < 0.001, Cohen’s *d* = -0.696, 95% CI [-1.019 -0.367], BF10 = 745.3. The neutral-self and bad-self associations did not differ, *t*(44) = -1.04, *p* = .31, Cohen’s *d* = -0.155, 95%CI [-0.448 0.14], BF10 = 0.267. RTs in good-self condition were facilitated but without performance being impaired for bad-self associations (relative to the normal neutral self)(see Figure 5). 
For the stranger condition, the main effect of moral valence was  also significant, `r df4b_RT_anova_m_o_apa$full$Valence`, BF10 = 21. The RT for good-other association condition (688 ± 66.9) is faster than the bad-other association condition (718 ± 49.7), t(44) = -3.353, p = 0.0017, Cohen’s d = -0.4999, 95%CI [-0.8075 -0.1872], BF10 = 18.84. The RT for good-other condition is slightly faster than neutral-other condition (704 ± 57.1), but the evidence is not strong, t (44) = -2.21, p = 0.0324, Cohen’s d = -0.3294, 95%CI [-6278 -0.0275], BF10 = 1.454. While there is is no strong evidence about the differences between bad-other vs. neutral-other conditions, t(44) = -1.8267, p = 0.0745, Cohen’s d = -0.2723, 95%CI [-0.5685 0.0268], BF10 = 0.743.

For non-matched trials, there was no significant effect. Idneity (`r df4b_RT_anova_nm_apa$full$Identity`), interaction (`r df4b_RT_anova_nm_apa$full$Identity_Valence`). But here are effect of Valence (`r df4b_RT_anova_nm_apa$full$Valence`)

## Discussion
In experiment 4, we manipulated the task so that the moral valence (experiment 4a) or the self-relatedness (experiment 4b) become irrelevant to the task. We found a robust effect of the task: when the self-relatedness is task related, the results showed a strong effect of self-relatedness; in contrast, when moral valence become task related the main effect of moral valence was strong. However, the task irrelevant stimuli in the shape exerted influence on the performance as well. The good self conditions (the shape associated the self and with a “good person” within the shape) performed better than bad self conditions. These results demonstrated that even when the moral valence and self-reference was separated by the task, participants can still couple the the self with the morally good, and facilitated the perceptual decision making.

# Experiment 5: Generalization of positive effect
So far, we have considered the modulation effect of morality and found that the positive moral valence could enhance the perception. However, we still not sure whether this effect was moral specific or reflecting a more general mechanism of effect of positive valence. To test the specificity of morality, we conducted experiment 5, in which three more categories of stimuli were used (people of different attractiveness, scene of diffenent attractivness, and emotional words with different valence). In this study, participants finished 4 session of association task, each with different categories of stimuli.

## Method

```{r loadingData_5,echo=FALSE,results='hide'}
df5 <- read.csv(".\\exp5_specificity\\rawdata_behav_5_specificity_2016.csv",header = TRUE, sep = ",",
                stringsAsFactors=FALSE, na.strings=c("","NA")) %>%
  dplyr::rename(BlockListM.Sample = BlockListMoral.Sample, Matchness = YesNoResp) %>%                            # rename the columns
  dplyr::mutate(Matchness = ifelse(Matchness == "Yes", "Match", "Mismatch"),
                taskType = derivedFactor("Emotion"  = (Label == "sad" | Label == "happy" | Label == "neutral"),
                                         "Morality" = (Label == "bad" | Label == "good" | Label == "ordinary"),
                                         "Person"   = (Label == "uglyP" | Label == "beautyP" | Label == "normalP"),
                                         "Scene"    = (Label == "uglyS" | Label == "beautyS" | Label == "normalS"), 
                                         .method ="first", .default = NA),
                Valence = derivedFactor("Good"= (Label ==  "good" | Label == "happy" | Label == "beautyP"  | Label == "beautyS"),
                                         "Bad" = (Label == "bad"  | Label == "sad"   | Label == "uglyP"    | Label == "uglyS"),
                                         "Neutral" = (Label == "ordinary" | Label == "neutral" | Label == "normalP" | Label == "normalS"),
                                         .method ="first", .default = NA)) %>%
  tidyr::replace_na(list(PracListE="",    PracListM="",    PracListP="",    PracListS="",          # replace NA with "" for later unite
                         BlockListE.Sample="", BlockListM.Sample="", BlockListP.Sample="", BlockListS.Sample="",
                         TrialListE.Sample="", TrialListM.Sample="", TrialListP.Sample="", TrialListS.Sample="",
                         TargetE.ACC="",  TargetM.ACC="",  TargetP.ACC="",  TargetS.ACC="",
                         TargetE.RESP="", TargetM.RESP="", TargetP.RESP="", TargetS.RESP="",
                         TargetE.RT="",   TargetM.RT="",   TargetP.RT="",   TargetS.RT="")) %>%
  tidyr::unite("PracList", PracListE,PracListM,PracListP,PracListS, sep = "")  %>%                # unite all praclist
  tidyr::unite("BlockNo", BlockListE.Sample,BlockListM.Sample,BlockListP.Sample,BlockListS.Sample, sep = "") %>% # unite all blocklist
  tidyr::unite("TrialNo", TrialListE.Sample,TrialListM.Sample,TrialListP.Sample,TrialListS.Sample, sep = "") %>% # unite all blocklist
  tidyr::unite("ACC", TargetE.ACC,  TargetM.ACC,  TargetP.ACC,  TargetS.ACC, sep = "") %>%        # unite all ACC
  tidyr::unite("RESP", TargetE.RESP,  TargetM.RESP,  TargetP.RESP,  TargetS.RESP, sep = "") %>%   # unite all RESP
  tidyr::unite("RT", TargetE.RT,  TargetM.RT,  TargetP.RT,  TargetS.RT, sep = "") %>%             # unite all RT
  dplyr::mutate(Site = "THU", 
                ACC = as.numeric(ACC), 
                RT = as.numeric(RT),
                BlockNo = as.numeric(BlockNo),
                TrialNo = as.numeric(TrialNo)) %>% 
  dplyr::mutate_if(is_character, list(~na_if(.,"")))     # blank to NA

df5.T.basic     <- df5 %>%
  dplyr::select(Site, Subject, Age, Sex) %>%
  dplyr::distinct(Subject, .keep_all = TRUE) %>%
  dplyr::summarise(N = length(Subject),
                   N_thu = length(Site[Site == "THU"]),
                   N_wzu = length(Site[Site == "WZU"]),
                   Nf = length(Sex[Sex == "female"]),
                   Nm = length(Sex[Sex == "male"]),
                   Age_mean = round(mean(Age,na.rm=TRUE),2),
                   Age_sd = round(sd(Age,na.rm=TRUE),2))
  
# find the participants who practiced but not finish experiment
subjPrac <- df5 %>% dplyr::filter(is.na(df5$BlockNo)) %>% dplyr::distinct(Subject)
subjFinish <- df5 %>% dplyr::filter(!is.na(df5$BlockNo)) %>% dplyr::distinct(Subject)
subjQuit <- subjPrac$Subject[which(!subjPrac$Subject %in% subjFinish$Subject)] 

# participants should be excluded
df5.excld.sub <-  df5 %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::group_by(Subject) %>%
  dplyr::summarise(N = length(ACC),                   # caculate the overall accuracy for each subject
                   N_crrct = sum(ACC),
                   ACC = sum(ACC)/length(ACC)) %>%
  dplyr::filter(ACC < 0.6) %>%                        # exlucde the participants with less than 60% overall accuracy
  dplyr::select(Subject)

# The rate of excluded trials in valid data
df5.invalid_trial_rate   <- df5 %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::filter(!(Subject %in% subjQuit)) %>%                 # exclude the invalid subjects
  dplyr::filter(!(Subject %in% df5.excld.sub$Subject)) %>%    # exclude the invalid subjects
  dplyr::summarize(rate = length(RT[RT <= 200 & ACC == 1])/length(RT)) %>%
  dplyr::pull()

df5.v   <- df5 %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::filter(!(Subject %in% subjQuit)) %>%                 # exclude the invalid subjects
  dplyr::filter(!(Subject %in% df5.excld.sub$Subject)) %>%   # exclude the invalid subjects
  dplyr::filter(!(RT <= 200 & ACC == 1)) %>%                      # exclude < 200 trials
  dplyr::arrange(Subject)

df5.v.basic     <- df5.v %>%
  dplyr::select(Site, Subject, Age, Sex) %>%
  dplyr::distinct(Subject, .keep_all = TRUE) %>%
  dplyr::summarise(N = length(Subject),
                   N_thu = length(Site[Site == "THU"]),
                   N_wzu = length(Site[Site == "WZU"]),
                   Nf = length(Sex[Sex == "female"]),
                   Nm = length(Sex[Sex == "male"]),
                   Age_mean = round(mean(Age,na.rm=TRUE),2),
                   Age_sd = round(sd(Age,na.rm=TRUE),2))
```

### Participants
`r df5.T.basic$N` participant recruited from Tsinghua University university community (`r df5.T.basic$Nf` females; age = `r df5.T.basic$Age_mean` $\pm$ `r df5.T.basic$Age_sd`). All participants were right-handed, and all had normal or corrected-to-normal vision. Informed consent was obtained from all participants prior to the experiment according to procedures approved by the local ethics committee. The data from 5 participants were excluded from analysis, `r length(subjQuit)` participant didn’t finished the experiment, and the other `r nrow(df5.excld.sub)` were exclued because of the overall accuracy was less than 60%. The results for the remaining `r df5.v.basic$N` subjects (`r df5.v.basic$Nf` female, age = `r df5.v.basic$Age_mean` $\pm$ `r df5.v.basic$Age_sd`) were included in data analyses.

### Experimental design
A 4 × 3 × 2 within-subject design was used. The first independent variable was stimuli categories (morality, atttractiveness of people, attractiveness of scene, and emotional words); the second independent variables is valence (positive, neutral and negative); the third variable was the matching between shape and label (match vs. mismatch for the association). The task was to learn  the association between each geometric shape and the self/other label.

### Stimuli
4 sets of shapes were included (three circle, three rectangle, three kind of triangle, and three kinds of  quadrangle), each set of shape were paired with one category of label, counter-balanced across subjects. Besides the behavioral experiments, participants also finished questionnaires XXXXXXXX.

### Procedure
Participants finish 4 session of experiment, and each include one experiment as in experiment 1. And the order of each category was randomnized for each participants. Each session started with a practice, and proceed to formal experiment when reached over 60% accuracy. Each session included 6 blocks of trial, each with 120 trials. 

## Results
### *d* prime
```{r analyzing for d prime_e5, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
# calculating the dprime 
df5.v.dprime_l <- df5.v %>%
  dplyr::mutate(sdt = mosaic::derivedFactor("hit" = (ACC ==1 & Matchness == "Match"), # code as hit
                                    "CR" = (ACC ==1  & Matchness == "Mismatch"),      # correct reject
                                    "miss" = (ACC == 0 & Matchness == "Match"),       # miss
                                    "FA" = (ACC == 0 & Matchness == "Mismatch"),      # false alarm
                                    .method ="first",  .default = NA)) %>% 
  dplyr::group_by(Site, taskType, Subject, Age, Sex, Valence,sdt) %>%
  dplyr::summarise(N = length(sdt)) %>%                                    # calculate the counts for each 
  dplyr::ungroup() %>%
  tidyr::spread(key = sdt, value = N,fill = 0) %>%                          # long-to-wide format
  dplyr::mutate(hitR = hit/(hit + miss),                                    # hit rate
                FAR  = FA/(FA+CR)) %>%                                      # fa rate
  dplyr::mutate(hitR = ifelse(hitR == 1, 1 - 1/(2*(hit + miss)), hitR),     # if hit rate is 1, standardize it
                FAR  = ifelse(FAR == 0, 1/(2*(hit + miss)), FAR)) %>%       # if FA rate is 0, standardize it
  dplyr::mutate(dprime = qnorm(hitR) - qnorm(FAR)) %>%
  dplyr::select(Site, Subject, Age, Sex, taskType,Valence, dprime) %>%   # select relevant columns
  dplyr::mutate(Valence = factor(Valence, levels = c("Good","Neutral","Bad")),
                taskType = factor(taskType, levels = c('Morality', 'Emotion',"Person", "Scene")))


# anova for d prime with 2*2 design
df5_dprime_anova <- afex::aov_ez('Subject','dprime',df5.v.dprime_l,  # using afex's function 
                                  within = c('taskType','Valence'))
df5_dprime_anova_apa <- df5_dprime_anova %>% papaja::apa_print()
#df4b_dprime_anova <- apa_print(df4b_dprime_anova)
```
We conducted 4 (task type: morality, emotion, person, scene) by 3 (morlaity: good, neutral, bad) repeated measure ANOVA. The results revealed no effect of task type (`r df5_dprime_anova_apa$full$taskType`), but revealed effect of valence, `r df5_dprime_anova_apa$full$Valence`, and their interactions, `r df5_dprime_anova_apa$full$taskType_Valence`. 

```{r analyzing for d prime_e5_tasks, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
# calculating the dprime 
df5.v.dprime_M_anova <- df5.v.dprime_l %>%
  dplyr::filter(taskType == "Morality") %>%
  afex::aov_ez('Subject','dprime', ., within = c('Valence'))
df5_dprime_M_anova_apa <- df5.v.dprime_M_anova %>% papaja::apa_print()
post_hoc_5_d_m <- emmeans::emmeans(df5.v.dprime_M_anova,'Valence')
pairs(post_hoc_5_d_m)

df5.v.dprime_E_anova <- df5.v.dprime_l %>%
  dplyr::filter(taskType == "Emotion") %>%
  afex::aov_ez('Subject','dprime', ., within = c('Valence'))
df5_dprime_E_anova_apa <- df5.v.dprime_E_anova %>% papaja::apa_print()

df5.v.dprime_P_anova <- df5.v.dprime_l %>%
  dplyr::filter(taskType == "Person") %>%
  afex::aov_ez('Subject','dprime', ., within = c('Valence'))
df5_dprime_P_anova_apa <- df5.v.dprime_P_anova %>% papaja::apa_print()

df5.v.dprime_S_anova <- df5.v.dprime_l %>%
  dplyr::filter(taskType == "Scene") %>%
  afex::aov_ez('Subject','dprime', ., within = c('Valence'))
df5_dprime_S_anova_apa <- df5.v.dprime_S_anova %>% papaja::apa_print()

```

To understand the interaction, we separated four different tasks. For the morality task, the valence effect `r df5_dprime_M_anova_apa$full$Valence`; for emotion, `r df5_dprime_E_anova_apa$full$Valence`; for the person appearance, `r df5_dprime_P_anova_apa$full$Valence`; for scene appearance, `r df5_dprime_S_anova_apa$full$Valence`.

# Experiment 6a: EEG study 1
Experiment 6a was conducted to study the neural correlates of the positive prioritization effect. The behavioral paradigm is same as experiment 2. 

## Method
```{r loadingData_6a,echo=FALSE,results='hide'}
df6a <- read.csv(".\\exp6a_erp1\\rawdata_erp_exp6a_2014.csv",header = TRUE, sep = ",",
                 stringsAsFactors=FALSE,na.strings=c("","NA")) %>%
  dplyr::filter(!is.na(BlockList.Sample)) %>%                                                   # select only form exp
  dplyr::rename(Subject = ï..Subject, 
                BlockNo = BlockList.Sample,
                TrialNo = SubTrial,
                Matchness = YesNoResp, 
                Valence = Shape,
                ACC = Target.ACC, 
                CRESP = Target.CRESP,                   # rename the columns
                RESP = Target.RESP, RT = Target.RT) %>%    #
  dplyr::mutate(Valence = ifelse(Valence == "Normal", "Neutral", Valence),                   # re-code the data
                Matchness = ifelse(Matchness == "Yes", "Match", "Mismatch"),
                Age = ifelse(Age == 0, NA, Age)) %>%
  dplyr::mutate(Site = "THU")

df6a.T.basic     <- df6a %>%
  dplyr::select(Site, Subject, Age, Sex) %>%
  dplyr::distinct(Subject, .keep_all = TRUE) %>%
  dplyr::summarise(N = length(Subject),
                   N_thu = length(Site[Site == "THU"]),
                   N_wzu = length(Site[Site == "WZU"]),
                   Nf = length(Sex[Sex == "female"]),
                   Nm = length(Sex[Sex == "male"]),
                   Age_mean = round(mean(Age,na.rm=TRUE),2),
                   Age_sd = round(sd(Age,na.rm=TRUE),2))
  
# number of participant who practiced but not in the formal experiment
#nQuit <- length(unique(df6a$Subject[is.na(df6a$BlockNo)])) - length(unique(df6a$Subject[!is.na(df6a$BlockNo)]))

# participants should be excluded
df6a.excld.sub <-  df6a %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::group_by(Subject) %>%
  #dplyr::mutate(ACC = ifelse(RT <= 200, 0, ACC)) %>%  # set less than 200 ms response as wrong
  dplyr::summarise(N = length(ACC),                   # caculate the overall accuracy for each subject
                   N_crrct = sum(ACC),
                   ACC = sum(ACC)/length(ACC)) %>%
  dplyr::filter(ACC < 0.6) %>%                        # exlucde the participants with less than 60% overall accuracy
  dplyr::select(Subject)

# The rate of excluded trials in valid data
df6a.invalid_trial_rate   <- df6a %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::filter(!(Subject %in% df6a.excld.sub$Subject)) %>%   # exclude the invalid subjects
  dplyr::summarize(rate = length(RT[RT <= 200 & ACC == 1])/length(RT)) %>%
  dplyr::pull()

df6a.v   <- df6a %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::filter(!(Subject %in% df6a.excld.sub$Subject)) %>%   # exclude the invalid subjects
  dplyr::filter(!(RT <= 200 & ACC == 1))                      # exclude < 200 trials

df6a.v.basic     <- df6a.v %>%
  dplyr::select(Site, Subject, Age, Sex) %>%
  dplyr::distinct(Subject, .keep_all = TRUE) %>%
  dplyr::summarise(N = length(Subject),
                   N_thu = length(Site[Site == "THU"]),
                   N_wzu = length(Site[Site == "WZU"]),
                   Nf = length(Sex[Sex == "female"]),
                   Nm = length(Sex[Sex == "male"]),
                   Age_mean = round(mean(Age,na.rm=TRUE),2),
                   Age_sd = round(sd(Age,na.rm=TRUE),2))
```

### Participants
`r df6a.T.basic$N` college students (`r df6a.T.basic$Nf` female, age = `r df6a.T.basic$Age_mean` $\pm$ `r df6a.T.basic$Age_sd`) participated the current study, all of them were from Tsinghua Universtiy in 2014. Informed consent was obtained from all participants prior to the experiment according to procedures approved by a local ethics committee. No participant was excluded from behavioral analysis.

### Experimental design
The experimental design of this experiment is same as experiment 2:  a 3 × 2 within-subject design with moral valence (good, neutral and bad associations) and matchness between shape and label (match vs. mismatch for the personal association) as within-subject variables. 

### Stimuli
Three geometric shapes (triangle, square and circle, each 4.6º × 4.6º of visual angle) were presented at the center of screen for 50 ms after 500ms of fixation (0.8º × 0.8º of visual angle). The association of the three shapes to bad person (“坏人, HuaiRen”), good person (“好人, HaoRen”) or ordinary  person (“常人, ChangRen”) was counterbalanced across participants. The words bad person, good person or ordinary  person (3.6º × 1.6º) was also displayed at the center fo the screen. Participants had to judge whether the pairings of label and shape matched (e.g., Does the circle represent a bad person?). The experiment was run on a PC using E-prime software (version 2.0). These stimuli were displayed on a 22-in CRT monitor (1024×768 at 100Hz).
We used backward masking to avoid over-processing of the moral words, in which a scrabmled picture were presented for 900 ms after the label. Also, to avoid the celling effect on accruacy, shapes were presented on a noisy background based on our pilot studies. The noisy images were made by scrambling a picutre of 3/4gray and ¼ white at resoluation of 2 × 2 pixel. 

### Procedure
The procedure was similar to Experiment 2. Participants finished 6 blocks of trial, each with 180 trials. In total, participants finished 180 trials for each combination of condition.

As in experiment 2 (Sui, He, & Humphreys, 2012), subjects first learned the associations between labels and shapes and then completed a shape-label matching task (e.g., good person-triangle). In each trial of the matching task, a fixation were first presented for 500 ms, followed by a 50 ms label; then, a scramled picture presented 900 ms. After the backward mask, the shape were presented on a noisy background for 50ms. Participant have to response in 1000ms after the presentation of the shape, and finnally, a feedback screen was presented for 500 ms (see figure 1). The inter-trial interval (ITI) were randomly varied at the range of 1000 ~ 1400 ms. 

All the stimuli were presented on a gray background (RGB: 127, 127, 127). E-primed 2.0 was used to present stimuli and collect behavioral results. Data were collected and analyzed when accuracy performance in total reached 60%. 

## Results
Only the behavioral results were reported here.

### *d* prime
```{r analyzing for d prime_e6a, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
# calculating the dprime 
df6a.v.dprime_l <- df6a.v %>%
  dplyr::mutate(sdt = mosaic::derivedFactor("hit" = (ACC ==1 & Matchness == "Match"), # code as hit
                                    "CR" = (ACC ==1  & Matchness == "Mismatch"),      # correct reject
                                    "miss" = (ACC == 0 & Matchness == "Match"),       # miss
                                    "FA" = (ACC == 0 & Matchness == "Mismatch"),      # false alarm
                                    .method ="first",  .default = NA)) %>% 
  dplyr::group_by(Site, Subject, Age, Sex, Valence, sdt) %>%
  dplyr::summarise(N = length(sdt)) %>%                                    # calculate the counts for each 
  dplyr::ungroup() %>%
  tidyr::spread(key = sdt, value = N,fill = 0) %>%                          # long-to-wide format
  dplyr::mutate(hitR = hit/(hit + miss),                                    # hit rate
                FAR  = FA/(FA+CR)) %>%                                      # fa rate
  dplyr::mutate(hitR = ifelse(hitR == 1, 1 - 1/(2*(hit + miss)), hitR),     # if hit rate is 1, standardize it
                FAR  = ifelse(FAR == 0, 1/(2*(hit + miss)), FAR)) %>%       # if FA rate is 0, standardize it
  dplyr::mutate(dprime = qnorm(hitR) - qnorm(FAR)) %>%
  dplyr::select(Site, Subject, Age, Sex, Valence, dprime) %>%   # select relevant columns
  dplyr::mutate(Valence = factor(Valence, levels = c("Good","Neutral","Bad")))


# anova for d prime with 2*2 design
df6a_dprime_anova <- afex::aov_ez('Subject','dprime',df6a.v.dprime_l,  # using afex's function 
                                  within = c('Valence'))
df6a_dprime_anova_apa <- df6a_dprime_anova %>% papaja::apa_print()

posthoc_5a_d <- lsmeans::lsmeans(df6a_dprime_anova, specs = 'Valence')
graphics::pairs(posthoc_5a_d)
# plot(posthoc_5a_d, comparisons = TRUE)
```
We conducted repeated measures ANOVA, with moral valence as independent variable. The results revealed the main effect of valence (`r df6a_dprime_anova_apa$full$Valence`). Post-hoc anlaysis revealed that shapes link with Good person (mean = 3.13, SE = 0.109) is greater than Neutral condition (mean = 2.88, SE = 0.14),*t* = 2.916, *df* = 24, *p* = 0.02, p-value adjusted by Tukey method, but the *d* prime between Good and bad (mean = 3.03, SE = 0.142) (*t* = 1.512, *df* = 24, *p* = 0.3034, p-value adjusted by Tukey method), bad and neutral (*t* = 1.599, *df* = 24, *p* = 0.2655, p-value adjusted by Tukey method) were not siginificant.

### Analaysis of reaction time.
The results of reaction times of matchness trials showed similiar pattern as the *d* prime data.
```{r 6a_RT, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
# anova for d prime with 2*2 design
df6a.v.rt_m <- df6a.v %>%
  dplyr::filter(ACC == 1) %>%
  dplyr::group_by(Site,Subject,Matchness, Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup()

df6a_RT_anova <- afex::aov_ez('Subject','RT_m',df6a.v.rt_m,     # using afex's function 
                                  within = c('Matchness','Valence'))
df6a_RT_anova_apa <- df6a_RT_anova %>% papaja::apa_print()
```


```{r 6a_RT_match, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
# match trials
df6a.v.rt_m1 <- df6a.v %>%
  dplyr::filter(ACC == 1 & Matchness == "Match") %>%
  dplyr::group_by(Site,Subject,Matchness, Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup() %>%
  dplyr::mutate(Valence = factor(Valence, levels = c("Good","Neutral","Bad")))

df6a_RT_anova_m <- afex::aov_ez('Subject','RT_m',df6a.v.rt_m1,     # using afex's function 
                                  within = c('Valence'))
df6a_RT_anova_m_apa <- df6a_RT_anova_m %>% papaja::apa_print()

posthoc_5a_rt <- emmeans::emmeans(df6a_RT_anova_m, "Valence") # compare each valence for both self and other condition
# pairs(posthoc_5a_rt)

# Mismatch trials
df6a.v.rt_m2 <- df6a.v %>%
  dplyr::filter(ACC == 1 & Matchness == "Mismatch") %>%
  dplyr::group_by(Site,Subject,Matchness, Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup()

df6a_RT_anova_nm <- afex::aov_ez('Subject','RT_m', df6a.v.rt_m2,     # using afex's function 
                                  within = c('Valence'))
df6a_RT_anova_nm_apa <- df6a_RT_anova_nm %>% papaja::apa_print()
```
We found intercation between Matchness and Valence (`r df6a_RT_anova_apa$full$Matchness_Valence`) and then analyzed the matched trials and mismatched trials separately, as in experiment 2. For matched trials, we found the effect of valence `r df6a_RT_anova_m_apa$full$Valence`. For non-matched trials, there was no significant effect of Valence (`r df6a_RT_anova_nm_apa$full$Valence`). Post-hoc *t*-tests revealed that shapes associated with Good Person (mean = 550, SE = 13.8) were responded faster than Neutral-Person (501, SE = 14.7), (*t*(24) = -5.171, *p* = 0.0001) and Bad Person (523, SE = 16.3), *t*(24) = -8.137, *p* < 0.0001)., and Neutral is faster than Bad-Person condition (*t*(32) = -3.282, *p* = 0.0085).


# Experiment 6b: EEG study 2
Experiment 6b was conducted to study the neural correlates of the prioritization effect of positive self, i.e., the neural underlying of the behavioral effect found int experiment 3a. However, as in experiment 5a, the procedure of this experiment was modified to adopted to ERP experiment. 

## Method
```{r loadingData_6b,echo=FALSE,results='hide'}
df6b_d1 <- read.csv(".\\exp6b_erp2\\rawdata_erp_exp6b_d1_2016.csv",header = TRUE, sep = ",",
                 stringsAsFactors=FALSE,na.strings=c("","NA")) %>%
  dplyr::filter(!is.na(BlockList.Sample)) %>%                                                   # select only form exp
  dplyr::rename(Subject = ï..Subject, 
                BlockNo = BlockList.Sample,
                TrialNo = SubTrial,
                Matchness = YesNoResp,
                Identity = identity,
                Valence = morality,
                ACC = Target.ACC, 
                CRESP = Target.CRESP,                   # rename the columns
                RESP = Target.RESP, RT = Target.RT) %>%    #
  dplyr::mutate(Identity = ifelse(Identity == "self" | Identity == 'Self', "Self", 'Other'),                   # re-code the data
                Valence = derivedFactor("Bad" = (Valence == "bad"), 
                                        "Good" = (Valence == "good"), 
                                        "Neutral" = (Valence == "normal"), 
                                        .method ="first", .default = NA),
                Matchness = ifelse(Matchness == "Yes", "Match", "Mismatch"),
                Age = ifelse(Age == 0, NA, Age)) %>%
  dplyr::mutate(Site = "THU")

df6b_d2 <- read.csv(".\\exp6b_erp2\\rawdata_erp_exp6b_d2_2016.csv",header = TRUE, sep = ",",
                 stringsAsFactors=FALSE,na.strings=c("","NA")) %>%
  dplyr::filter(!is.na(BlockList.Sample)) %>%                                                   # select only form exp
  dplyr::rename(Subject = ï..Subject, 
                BlockNo = BlockList.Sample,
                TrialNo = SubTrial,
                Matchness = YesNoResp,
                Identity = identity,
                Valence = morality,
                ACC = Target.ACC, 
                CRESP = Target.CRESP,                   # rename the columns
                RESP = Target.RESP, RT = Target.RT) %>%    #
  dplyr::mutate(Identity = ifelse(Identity == "self" | Identity == 'Self', "Self", 'Other'),                   # re-code the data
                Valence = derivedFactor("Bad" = (Valence == "bad"), 
                                        "Good" = (Valence == "good"), 
                                        "Neutral" = (Valence == "normal"), 
                                        .method ="first", .default = NA),
                Matchness = ifelse(Matchness == "Yes", "Match", "Mismatch"),
                Age = ifelse(Age == 0, NA, Age)) %>%
  dplyr::mutate(Site = "THU")

df6b_d1.T.basic     <- df6b_d1 %>%
  dplyr::select(Site, Subject, Age, Sex) %>%
  dplyr::distinct(Subject, .keep_all = TRUE) %>%
  dplyr::summarise(N = length(Subject),
                   N_thu = length(Site[Site == "THU"]),
                   N_wzu = length(Site[Site == "WZU"]),
                   Nf = length(Sex[Sex == "female"]),
                   Nm = length(Sex[Sex == "male"]),
                   Age_mean = round(mean(Age,na.rm=TRUE),2),
                   Age_sd = round(sd(Age,na.rm=TRUE),2))

df6b_d2.T.basic     <- df6b_d2 %>%
  dplyr::select(Site, Subject, Age, Sex) %>%
  dplyr::distinct(Subject, .keep_all = TRUE) %>%
  dplyr::summarise(N = length(Subject),
                   N_thu = length(Site[Site == "THU"]),
                   N_wzu = length(Site[Site == "WZU"]),
                   Nf = length(Sex[Sex == "female"]),
                   Nm = length(Sex[Sex == "male"]),
                   Age_mean = round(mean(Age,na.rm=TRUE),2),
                   Age_sd = round(sd(Age,na.rm=TRUE),2))
  
# number of participant who practiced but not in the formal experiment
#nQuit <- length(unique(df6a$Subject[is.na(df6a$BlockNo)])) - length(unique(df6a$Subject[!is.na(df6a$BlockNo)]))

# participants should be excluded
df6b_d1.excld.sub <-  df6b_d1 %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::group_by(Subject) %>%
  #dplyr::mutate(ACC = ifelse(RT <= 200, 0, ACC)) %>%  # set less than 200 ms response as wrong
  dplyr::summarise(N = length(ACC),                   # caculate the overall accuracy for each subject
                   N_crrct = sum(ACC),
                   ACC = sum(ACC)/length(ACC)) %>%
  dplyr::filter(ACC < 0.6) %>%                        # exlucde the participants with less than 60% overall accuracy
  dplyr::select(Subject)

# The rate of excluded trials in valid data
df6b_d1.invalid_trial_rate   <- df6b_d1 %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::filter(!(Subject %in% df6b_d1.excld.sub$Subject)) %>%   # exclude the invalid subjects
  dplyr::summarize(rate = length(RT[RT <= 200 & ACC == 1])/length(RT)) %>%
  dplyr::pull()

df6b_d1.v   <- df6b_d1 %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::filter(!(Subject %in% df6b_d1.excld.sub$Subject)) %>%   # exclude the invalid subjects
  dplyr::filter(!(RT <= 200 & ACC == 1))                      # exclude < 200 trials

df6b_d1.v.basic     <- df6b_d1.v %>%
  dplyr::select(Site, Subject, Age, Sex) %>%
  dplyr::distinct(Subject, .keep_all = TRUE) %>%
  dplyr::summarise(N = length(Subject),
                   N_thu = length(Site[Site == "THU"]),
                   N_wzu = length(Site[Site == "WZU"]),
                   Nf = length(Sex[Sex == "female"]),
                   Nm = length(Sex[Sex == "male"]),
                   Age_mean = round(mean(Age,na.rm=TRUE),2),
                   Age_sd = round(sd(Age,na.rm=TRUE),2))

df6b_d2.excld.sub <-  df6b_d2 %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::group_by(Subject) %>%
  #dplyr::mutate(ACC = ifelse(RT <= 200, 0, ACC)) %>%  # set less than 200 ms response as wrong
  dplyr::summarise(N = length(ACC),                   # caculate the overall accuracy for each subject
                   N_crrct = sum(ACC),
                   ACC = sum(ACC)/length(ACC)) %>%
  dplyr::filter(ACC < 0.6) %>%                        # exlucde the participants with less than 60% overall accuracy
  dplyr::select(Subject)


df6b_d2.v   <- df6b_d2 %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::filter(!(Subject %in% df6b_d2.excld.sub$Subject)) %>%   # exclude the invalid subjects
  dplyr::filter(!(RT <= 200 & ACC == 1))                      # exclude < 200 trials

df6b_d2.v.basic     <- df6b_d2.v %>%
  dplyr::select(Site, Subject, Age, Sex) %>%
  dplyr::distinct(Subject, .keep_all = TRUE) %>%
  dplyr::summarise(N = length(Subject),
                   N_thu = length(Site[Site == "THU"]),
                   N_wzu = length(Site[Site == "WZU"]),
                   Nf = length(Sex[Sex == "female"]),
                   Nm = length(Sex[Sex == "male"]),
                   Age_mean = round(mean(Age,na.rm=TRUE),2),
                   Age_sd = round(sd(Age,na.rm=TRUE),2))


```

### Participants
`r df6b_d1.T.basic$N` college students (`r df6b_d1.T.basic$Nf` female, age = `r df6b_d1.T.basic$Age_mean` $\pm$ `r df6b_d1.T.basic$Age_sd`) participated the current study, all of them were recruited from Tsinghua Universtiy in 2016. Informed consent was obtained from all participants prior to the experiment according to procedures approved by a local ethics committee. For day 1's data, `r nrow(df6b_d1.excld.sub)` participant was excluded from the current analysis because of lower than 60% overall accuracy.`r df6b_d1.v.basic$N` college students (`r df6b_d1.v.basic$Nf` female, age = `r df6b_d1.v.basic$Age_mean` $\pm$ `r df6b_d1.v.basic$Age_sd`). For day 2's data, one participant dropp out , and leaving 22 participants  (`r df6b_d2.v.basic$Nf` female, age = `r df6b_d2.v.basic$Age_mean` $\pm$ `r df6b_d2.v.basic$Age_sd`) in day 2, all of them has overall accuracy higher than 60%.

### Experimental design
The experimental design of this experiment is same as experiment 3:  a 2 × 3 × 2 within-subject design with self-relevance (self-relevant vs. other-relevant), moral valence (good, neutral and bad associations) and matchness between shape and label (match vs. mismatch for the personal association) as within-subject variables. 

### Stimuli
As in experiment 3 a & 3b, 6 shapes were included (triangle, square, circle, trapezoid, diamond, regular pentagon), as well as 6 labels (good self, neutral self, bad self, good person, bad person, neutral person). To match the concreteness of the label, we asked participant to chosen an unfamiliar name of their own gender to be the stranger.

### Procedure
The procedure was similar to Experiment 2 and 6b. Subjects first learned the associations between labels and shapes and then completed a shape-label matching task. In each trial of the matching task, a fixation were first presented for 500 ms, followed by a 50 ms label; then, a scramled picture presented 900 ms. After the backward mask, the shape were presented on a noisy background for 50ms. Participant have to response in 1000ms after the presentation of the shape, and finnally, a feedback screen was presented for 500 ms (see figure 1). The inter-trial interval (ITI) were randomly varied at the range of 1000 ~ 1400 ms. 

All the stimuli were presented on a gray background (RGB: 127, 127, 127). E-primed 2.0 was used to present stimuli and collect behavioral results. Data were collected and analyzed when accuracy performance in total reached 60%. 

Given that learning 6 association is more difficult than 3 association and participant has low accuracy at the begining, to maximizing the accurate trials that can be used in EEG data, the current experiment has two day session. At the first day, participants learnt the associations and finished XX blocks of the matching task, each had XX trials, without EEG recording. They came back to lab at the second day and finish the same task again, with EEG recorded.

## Results
Only the behavioral results were reported here.
```{r 6b_dprime_d1, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
# calculate d prime
df6b_d1.v.dprime_l <- df6b_d1.v %>%
  dplyr::mutate(sdt = mosaic::derivedFactor("hit" = (ACC ==1 & Matchness == "Match"), # code as hit
                                    "CR" = (ACC ==1  & Matchness == "Mismatch"),      # correct reject
                                    "miss" = (ACC == 0 & Matchness == "Match"),       # miss
                                    "FA" = (ACC == 0 & Matchness == "Mismatch"),      # false alarm
                                    .method ="first",  .default = NA)) %>% 
  dplyr::group_by(Site, Subject, Age, Sex, Valence,Identity, sdt) %>%
  dplyr::summarise(N = length(sdt)) %>%                                     # calculate the counts for each 
  dplyr::ungroup() %>%
  tidyr::spread(key = sdt, value = N,fill = 0) %>%                          # long-to-wide format
  dplyr::mutate(hitR = hit/(hit + miss),                                    # hit rate
                FAR  = FA/(FA+CR)) %>%                                      # fa rate
  dplyr::mutate(hitR = ifelse(hitR == 1, 1 - 1/(2*(hit + miss)), hitR),     # if hit rate is 1, standardize it
                FAR  = ifelse(FAR == 0, 1/(2*(hit + miss)), FAR)) %>%       # if FA rate is 0, standardize it
  dplyr::mutate(dprime = qnorm(hitR) - qnorm(FAR)) %>%
  dplyr::select(Site, Subject, Age, Sex, Valence, Identity, dprime) %>%     # select relevant columns
  dplyr::mutate(Valence = factor(Valence, levels = c("Good","Neutral","Bad")),
                Identity = factor(Identity, levels = c('Self', 'Other')))

# anova for d prime
df6b_d1_dprime_anova <- afex::aov_ez('Subject','dprime',df6b_d1.v.dprime_l,  # using afex's function 
                                  within = c('Identity','Valence'))
df6b_d1_dprime_anova_apa <- df6b_d1_dprime_anova$aov %>% papaja::apa_print()

# anova for self condition
df6b_d1_dprime_s_anova <- df6b_d1.v.dprime_l %>%
  dplyr::filter(Identity == "Self") %>%
  afex::aov_ez('Subject','dprime',., within = c('Valence'))

df6b_d1_dprime_s_anova_apa <- df6b_d1_dprime_s_anova$aov %>% papaja::apa_print()

posthoc_6b_d1_s_d <- emmeans::emmeans(df6b_d1_dprime_s_anova, "Valence") # compare each valence for both self and other condition
#pairs(posthoc_6b_d1_s_d)

# anova for Other condition
df6b_d1_dprime_o_anova <- df6b_d1.v.dprime_l %>%
  dplyr::filter(Identity == "Other") %>%
  afex::aov_ez('Subject','dprime',., within = c('Valence'))

df6b_d1_dprime_o_anova_apa <- df6b_d1_dprime_o_anova$aov %>% papaja::apa_print()
```
### Day one

#### *d* prime
There was evidence for the interaction between identity and valence, `r df6b_d1_dprime_anova_apa$full$Identity_Valence`. We further split the self- and other-relevant trials. For the self trials, there was significant effect of valence, `r df6b_d1_dprime_s_anova_apa$full$Valence`. Post-hoc comparison showed that the good-self condition (2.71, SE = 0.199) is better than both neutral-self (1.98, SE = 0.151), *t*(21) = 5.984, *p* < 0.001, and bad-self condition (2.07, SE = 0.154), *t*(21) = 6.555, *p* < 0.001. But there was no significant difference between bad-self and neutral-self, *t*(21) = -1.059, *p* = 0.549. For other trials, there was no significant effect of valuence, `r df6b_d1_dprime_o_anova_apa$full$Valence`.

```{r 6b_RT, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
# anova for RT with 2*2*3 design
df6b_d1.v.rt_m <- df6b_d1.v %>%
  dplyr::filter(ACC == 1) %>%
  dplyr::group_by(Site,Subject,Matchness, Identity, Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup()

df6b_d1_RT_anova <- afex::aov_ez('Subject','RT_m',df6b_d1.v.rt_m,     # using afex's function 
                                  within = c('Matchness','Identity','Valence'))
df6b_d1_RT_anova_apa <- df6b_d1_RT_anova %>% papaja::apa_print()

df6b_d2.v.rt_m <- df6b_d2.v %>%
  dplyr::filter(ACC == 1) %>%
  dplyr::group_by(Site,Subject,Matchness, Identity, Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup()

df6b_d2_RT_anova <- afex::aov_ez('Subject','RT_m',df6b_d2.v.rt_m,     # using afex's function 
                                  within = c('Matchness','Identity','Valence'))
df6b_d2_RT_anova_apa <- df6b_d2_RT_anova %>% papaja::apa_print()
```

```{r 6b_d1_RT_match, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
# Day 1: match trials
df6b_d1.v.rt_m1 <- df6b_d1.v %>%
  dplyr::filter(ACC == 1 & Matchness == "Match") %>%
  dplyr::group_by(Site, Subject, Matchness, Identity, Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup() %>%
  dplyr::mutate(Valence = factor(Valence, levels = c("Good","Neutral","Bad")),
                Identity = factor(Identity, levels = c('Self', 'Other')))

df6b_d1_RT_anova_m <- afex::aov_ez('Subject','RT_m',df6b_d1.v.rt_m1,     # using afex's function 
                                  within = c('Identity','Valence'))
df6b_d1_RT_anova_m_apa <- df6b_d1_RT_anova_m %>% papaja::apa_print()

### For matched, self trials
df6b_d1.v.rt_m1_s <- df6b_d1.v %>%
  dplyr::filter(ACC == 1 & Matchness == "Match" & Identity == "Self") %>%
  dplyr::group_by(Site, Subject, Matchness, Identity, Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup() %>%
  dplyr::mutate(Valence = factor(Valence, levels = c("Good","Neutral","Bad")))

df6b_d1_RT_anova_m_s <- afex::aov_ez('Subject','RT_m',df6b_d1.v.rt_m1_s,     # using afex's function 
                                  within = c('Valence'))
df6b_d1_RT_anova_m_s_apa <- df6b_d1_RT_anova_m_s %>% papaja::apa_print()

posthoc_6b_d1_rt_s <- emmeans::emmeans(df6b_d1_RT_anova_m_s, 'Valence') # compare each valence for both self and other condition
# pairs(posthoc_6b_d1_rt_s)

### For matched, other trials
df6b_d1.v.rt_m1_o <- df6b_d1.v %>%
  dplyr::filter(ACC == 1 & Matchness == "Match" & Identity == "Other") %>%
  dplyr::group_by(Site, Subject, Matchness, Identity, Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup() %>%
  dplyr::mutate(Valence = factor(Valence, levels = c("Good","Neutral","Bad")))

df6b_d1_RT_anova_m_o <- afex::aov_ez('Subject','RT_m',df6b_d1.v.rt_m1_o,     # using afex's function 
                                  within = c('Valence'))
df6b_d1_RT_anova_m_o_apa <- df6b_d1_RT_anova_m_o %>% papaja::apa_print()


# Day1: Mismatch trials
df6b_d1.v.rt_m2 <- df6b_d1.v %>%
  dplyr::filter(ACC == 1 & Matchness == "Mismatch") %>%
  dplyr::group_by(Site,Subject,Matchness, Identity, Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup()

df6b_d1_RT_anova_nm <- afex::aov_ez('Subject','RT_m',df6b_d1.v.rt_m2,     # using afex's function 
                                  within = c('Identity','Valence'))
df6b_d1_RT_anova_nm_apa <- df6b_d1_RT_anova_nm %>% papaja::apa_print()
```

#### RT
For the matched trials, there was interaction between identity and valence, `r df6b_d1_RT_anova_m_apa$full$Identity_Valence`. We split the self-relevant and other relevant trials separately. For the self condition, the valence effect is significant, `r df6b_d1_RT_anova_m_s_apa$full$Valence`. The Self-good (484, SE = 13.2) is faster than self-neutral (543, SE = 16.7) , *t* = -4.521, *p* = 0.0005, *df* = 21 and self-bad condition (535, SE = 18.4),  *t* = -4.489, *p* = 0.0006, *df* = 21. but not significant different between neutral and bad condition, *t* = 0.689, *p* = 0.772, *df* = 21. For other condition, there was no effect of valence, `r df6b_d1_RT_anova_m_o_apa$full$Valence`. 

### Day two
```{r 5b_dprime_d2, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
# calculate d prime
df6b_d2.v.dprime_l <- df6b_d2.v %>%
  dplyr::mutate(sdt = mosaic::derivedFactor("hit" = (ACC ==1 & Matchness == "Match"), # code as hit
                                    "CR" = (ACC ==1  & Matchness == "Mismatch"),      # correct reject
                                    "miss" = (ACC == 0 & Matchness == "Match"),       # miss
                                    "FA" = (ACC == 0 & Matchness == "Mismatch"),      # false alarm
                                    .method ="first",  .default = NA)) %>% 
  dplyr::group_by(Site, Subject, Age, Sex, Valence,Identity, sdt) %>%
  dplyr::summarise(N = length(sdt)) %>%                                    # calculate the counts for each 
  dplyr::ungroup() %>%
  tidyr::spread(key = sdt, value = N,fill = 0) %>%                          # long-to-wide format
  dplyr::mutate(hitR = hit/(hit + miss),                                    # hit rate
                FAR  = FA/(FA+CR)) %>%                                      # fa rate
  dplyr::mutate(hitR = ifelse(hitR == 1, 1 - 1/(2*(hit + miss)), hitR),     # if hit rate is 1, standardize it
                FAR  = ifelse(FAR == 0, 1/(2*(hit + miss)), FAR)) %>%       # if FA rate is 0, standardize it
  dplyr::mutate(dprime = qnorm(hitR) - qnorm(FAR)) %>%
  dplyr::select(Site, Subject, Age, Sex, Valence, Identity, dprime) %>%     # select relevant columns
  dplyr::mutate(Valence = factor(Valence, levels = c("Good","Neutral","Bad")),
                Identity = factor(Identity, levels = c('Self', 'Other')))

df6b_d2_dprime_anova <- afex::aov_ez('Subject','dprime',df6b_d2.v.dprime_l,  # using afex's function 
                                  within = c('Identity','Valence'))
df6b_d2_dprime_anova_apa <- df6b_d2_dprime_anova$aov %>% papaja::apa_print()
#posthoc_5b_d2_d <- emmeans::emmeans(df6b_d1_dprime_anova, "Valence") # compare each valence for both self and other condition
#pairs(posthoc_5b_d2_d)

# anova for self condition
df6b_d2_dprime_s_anova <- df6b_d2.v.dprime_l %>%
  dplyr::filter(Identity == "Self") %>%
  afex::aov_ez('Subject','dprime',., within = c('Valence'))

df6b_d2_dprime_s_anova_apa <- df6b_d2_dprime_s_anova$aov %>% papaja::apa_print()

posthoc_5b_d2_s_d <- emmeans::emmeans(df6b_d2_dprime_s_anova, "Valence") # compare each valence for both self and other condition
#pairs(posthoc_5b_d2_s_d)

# anova for Other condition
df6b_d2_dprime_o_anova <- df6b_d2.v.dprime_l %>%
  dplyr::filter(Identity == "Other") %>%
  afex::aov_ez('Subject','dprime',., within = c('Valence'))

df6b_d2_dprime_o_anova_apa <- df6b_d2_dprime_o_anova$aov %>% papaja::apa_print()

```
#### *d* prime
There was evidence for the interaction between identity and valence, `r df6b_d2_dprime_anova_apa$full$Identity_Valence`.  We further split the self- and other-relevant trials. For the self trials, there was significant effect of valence, `r df6b_d2_dprime_s_anova_apa$full$Valence`. Post-hoc comparison showed that the good-self condition (2.71, SE = 0.214) is better than both neutral-self (2.43, SE = 0.175), *t*(21) = 2.98, *p* = 0.0189, and bad-self condition (2.43, SE = 0.199), *t*(21) = 3.93, *p* = 0.0021. But there was no significant difference between bad-self and neutral-self, *t*(21) = -0.097, *p* = 0.995. For other trials, there was no significant effect of valuence, `r df6b_d2_dprime_o_anova_apa$full$Valence`.

```{r 5b_d2_RT_match, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
# Day2: match trials
df6b_d2.v.rt_m1 <- df6b_d2.v %>%
  dplyr::filter(ACC == 1 & Matchness == "Match") %>%
  dplyr::group_by(Site, Subject, Matchness, Identity, Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup() %>%
  dplyr::mutate(Valence = factor(Valence, levels = c("Good","Neutral","Bad")),
                Identity = factor(Identity, levels = c('Self', 'Other')))

df6b_d2_RT_anova_m <- afex::aov_ez('Subject','RT_m',df6b_d2.v.rt_m1,     # using afex's function 
                                  within = c('Identity','Valence'))
df6b_d2_RT_anova_m_apa <- df6b_d2_RT_anova_m %>% papaja::apa_print()

posthoc_5b_d2_rt <- emmeans::emmeans(df6b_d2_RT_anova_m, c('Identity',"Valence")) # compare each valence for both self and other condition
# pairs(posthoc_5b_d2_rt)

df6b_d2.v.rt_m1_s <- df6b_d2.v %>%
  dplyr::filter(ACC == 1 & Matchness == "Match" & Identity == "Self") %>%
  dplyr::group_by(Site, Subject, Matchness, Identity, Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup() %>%
  dplyr::mutate(Valence = factor(Valence, levels = c("Good","Neutral","Bad")))

df6b_d2_RT_anova_m_s <- afex::aov_ez('Subject','RT_m',df6b_d2.v.rt_m1_s,     # using afex's function 
                                  within = c('Valence'))
df6b_d2_RT_anova_m_s_apa <- df6b_d2_RT_anova_m_s %>% papaja::apa_print()

posthoc_5b_d2_rt_s <- emmeans::emmeans(df6b_d2_RT_anova_m_s, 'Valence') # compare each valence for both self and other condition
# pairs(posthoc_5b_d2_rt_s)

### For matched, other trials
df6b_d2.v.rt_m1_o <- df6b_d2.v %>%
  dplyr::filter(ACC == 1 & Matchness == "Match" & Identity == "Other") %>%
  dplyr::group_by(Site, Subject, Matchness, Identity, Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup() %>%
  dplyr::mutate(Valence = factor(Valence, levels = c("Good","Neutral","Bad")))

df6b_d2_RT_anova_m_o <- afex::aov_ez('Subject','RT_m',df6b_d2.v.rt_m1_o,     # using afex's function 
                                  within = c('Valence'))
df6b_d2_RT_anova_m_o_apa <- df6b_d2_RT_anova_m_o %>% papaja::apa_print()

# Day2: Mismatch trials
df6b_d2.v.rt_m2 <- df6b_d2.v %>%
  dplyr::filter(ACC == 1 & Matchness == "Mismatch") %>%
  dplyr::group_by(Site,Subject,Matchness, Identity, Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup()

df6b_d2_RT_anova_nm <- afex::aov_ez('Subject','RT_m',df6b_d2.v.rt_m2,     # using afex's function 
                                  within = c('Identity','Valence'))
df6b_d2_RT_anova_nm_apa <- df6b_d2_RT_anova_nm %>% papaja::apa_print()
```

#### RT
For the matched trials, the interaction between identity and valence, `r df6b_d2_RT_anova_m_apa$full$Identity_Valence`. As in previous studies, we splited the self- and other-relevant trials. For the self condition, the valence effect is significant, `r df6b_d2_RT_anova_m_s_apa$full$Valence`. The Self-good (480, SE = 16.9) is faster than self-neutral (504, SE = 17.3) , *t* = -2.289, *p* = 0.0795, *df* = 21 and self-bad condition (508, SE = 17.9),  *t* = -4.342, *p* = 0.0008, *df* = 21. but not significant different between neutral and bad condition, *t* = -0.503, *p* = 0.871, *df* = 21. For other condition, there was no effect of valence, `r df6b_d2_RT_anova_m_o_apa$full$Valence`. 

\newpage

# References
```{r create_r-references}
r_refs(file = "r-references.bib")
```

\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

<div id = "refs"></div>
\endgroup
