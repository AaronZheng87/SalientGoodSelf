---
title             : "Positivity bias in perceptual matching may reflect a spontaneous self-referential processing"
shorttitle        : "Positivity as spontaneous self-referential processing"

author: 
  - name          : "Hu Chuan-Peng"
    affiliation   : "1,2"
    corresponding : yes    # Define only one corresponding author
    address       : "Langenbeckstr. 1, Neuroimaging Center, University Medical Center Mainz, 55131 Mainz, Germany"
    email         : "hcp4715@gmail.com"
  - name          : "Kaiping Peng"
    affiliation   : "3"
  - name          : "Jie Sui"
    affiliation   : "3,4"

affiliation:
  - id            : "1"
    institution   : "TBA"
  - id            : "2"
    institution   : "Leibniz Institute for Resilience Research, 55131 Mainz, Germany"
  - id            : "3"
    institution   : "Tsinghua University, 100084 Beijing, China"
  - id            : "4"
    institution   : "University of Aberdeen, Aberdeen, Scotland"

authornote: |
  Hu Chuan-Peng, Leibniz Institute for Resilience Research (LIR).
  Kaiping Peng, Department of Psychology, Tsinghua University, 100084 Beijing, China.
  Jie Sui, School of Psychology, University of Aberdeen, Aberdeen, Scotland.

  Authors contriubtion: HCP, JS, & KP design the study, HCP collected the data, HCP analyzed the data and drafted the manuscript. KP & JS supported this project.

abstract: |
  To navigate in a complex social world, individual has learnt to prioritize valuable information. Previous studies suggested the moral related stimuli was prioritized [@gantman_moral_2014;@anderson_visual_2011]. Using social associative learning paradigm (self-tagging paradigm), we found that when geometric shapes, without soical meaning, were associated with different moral valence (morally good, neutral, or bad), the shapes that associated with positive moral valence were prioritized in a perceptual matching task. This patterns of results were robust across different procedures. Further, we tested whether this positive effect was modulated by self-relevance by manipulating the self-referential explicitly and found that this moral positivity effect only occured when the moral valence are self-relevant but evidence to support such effect when the moral valence are other-relevant is weak. We further found that this effect exist even when the self-relevance or the moral valence were presented as a task-irrelevant information, though the effect size become much smaller. We also tested whether the positivity effect only exist in moral domain and found that this effect was not limited to moral domain. Exploratory analyses on task-questionnaire relationship found that moral self-image score (how closely one feel they are to the ideal moral image of themselves) is positively correlated to the *d'* of morally positive condition in singal detection and the drift rate using DDM, while the self-esteem is negatively correlated with *d'* of neutral and morally negative conditions. These results suggest that the positive self prioritzation in perceptual decision-making may reflect ...
  
  <!-- https://tinyurl.com/ybremelq -->
  
keywords          : "Perceptual decision-making, Self, positive bias, morality"
wordcount         : "X"

bibliography      : 
  - r-references.bib
  - endnote.bib

floatsintext      : no
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : yes
mask              : no
draft             : no
figsintext        : no

documentclass     : "apa6"
classoption       : "man"
output            : 
  papaja::apa6_pdf:
    latex_engine  : xelatex

---
 <!-- This documents -->
 
```{r setup, include = FALSE}
#rm(list = ls())
source('Initial.r')

curDir = here::here() # dirname(rstudioapi::getActiveDocumentContext()$path)
figDir = here::here('figures')

# Seed for random number generation
set.seed(42)
options(tinytex.verbose = T) # debug the tex
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed)
```

# Introduction
XXXX
In perceptual matching, same is faster than different [@Krueger_1978; @Farell_1985].
Automatic processing [@Spruyt_de_Houwer_2017]

@van_zandt_comparison_2000: A comparison of two response time models applied to perceptual matching

Yakushijin, ReikoJacobs, Robert A (2020), Are People Successful at Learning Sequential Decisions on a Perceptual Matching Task?

Schooler, L. J., Shiffrin, R. M., & Raaijmakers, J. G. W. (2001). A Bayesian model for implicit effects in perceptual identification. Psychological Review, 108(1), 257â€“272. https://doi.org/10.1037/0033-295X.108.1.257

We reported results from eleven experiments. In first set of experiments, we found that shapes associated with morally positive person label were responded faster and more accurately. In the second set of experiments, we explore the potential role of good self in perceptual matching task and added one more independent variable, we found that the effect was mainly on good self. In the third part we tested whether the morality will automatically binds with person-relevance. Finally, we explore the correlation between behavioral task and questionnaire scores.

# Disclosures
We reported all the measurements, analyses, and results in all the experiments in the current study. Participants whose overall accuracy lower than 60% were excluded from analysis. Also, the accurate responses with less than 200ms reaction times were excluded from the analysis.  

All the experiments reported were not pre-registered. Most experiments (1a ~ 6b, except experiment 3b) reported in the current study were first finished between 2014 to 2016 in Tsinghua University, Beijing, China. Participants in these experiments were recruited in the local community. To increase the sample size of experiments to 50 or more [@Simmons_2013_life], we recruited additional participants in Wenzhou University, Wenzhou, China in 2017 for experiment 1a, 1b, 4a, and 4b. Experiment 3b was finished in Wenzhou University in 2017. To have a better estimation of the effect size, we included the data from two experiments (experiment 7a, 7b) that were reported in @Hu_2020_GoodSelf (See Table S1 for overview of these experiments). 

All participant received informed consent and compensated for their time. These experiments were approved by the ethic board in the Department of Tsinghua University. 

 <!-- 21-word solution (Simmons, Nelson & Simonsohn, 2012; retrieved from http://ssrn.com/abstract=2160588) -->


```{r loadingData,echo=FALSE,results='hide'}
load("AllData.RData")
```

```{r define_funs,echo=FALSE,results='hide'}
# define a function to run the sdt GLMM for all exp with Matchness * Valence design
# for 1a, 1b, 1c, 2, 6a
fun_sdt_val <- function(exp_name) {
  df_name <- paste('df', exp_name, '.v', sep = '')
  m_name <- paste("glmmModels/exp", exp_name, "_sdt_m1_DummyCode", sep = '')
  df <- get(df_name)  # get the data by string
  
  m <- df %>%
  dplyr::filter(!is.na(RESP)) %>% # filter trials without response
  dplyr::mutate(ismatch = ifelse(Matchness == 'Match', 1, 0),
                saymatch = ifelse((Matchness == 'Match' & ACC == 1) | 
                                    (Matchness == 'Mismatch' & ACC == 0), 1, 0),
                Valence = factor(Valence, levels = c('Neutral', 'Bad', 'Good'))) %>%
  brms::brm(saymatch ~ 0 + Valence + Valence:ismatch + 
              (0 + Valence + Valence:ismatch | Subject),
            family = bernoulli(link="probit"),
            data = .,
            control = list(adapt_delta = .99),
            iter = 4000,
            thin = 2,
            cores = parallel::detectCores(),
            file = here::here(m_name))
  return(m)
}

fun_plot_sdt_val <- function(m_sdt) {
    # extract c
    tmp_c <- m_sdt %>% 
      tidybayes::gather_draws(b_ValenceBad, b_ValenceNeutral, b_ValenceGood) %>%
      dplyr::rename(Valence = .variable, sdt_c = .value) %>% dplyr::ungroup() %>%
      dplyr::mutate(Valence = gsub("b_", "", Valence)) %>%
      dplyr::mutate(Valence = ifelse(stringr::str_detect(Valence, 'Bad'), 'Bad',
                                     ifelse(stringr::str_detect(Valence, 'Good'), 'Good', 'Neutral')))
    
    # dprime
    tmp_d <- m_sdt %>% 
      tidybayes::gather_draws(`b_ValenceBad:ismatch`, `b_ValenceNeutral:ismatch`, 
                              `b_ValenceGood:ismatch`) %>%
      dplyr::rename(Valence = .variable, sdt_d = .value) %>% dplyr::ungroup() %>%
      dplyr::mutate(Valence = gsub("b_", "", Valence)) %>%
      dplyr::mutate(Valence = ifelse(stringr::str_detect(Valence, 'Bad'), 'Bad',
                                     ifelse(stringr::str_detect(Valence, 'Good'), 'Good', 'Neutral')))
    
    # plot summaries with densities
    p_sdt_d_sum <- tmp_d %>%
      dplyr::mutate(Valence = factor(Valence, levels = c('Bad', 'Neutral', 'Good'))) %>%
      ggplot2::ggplot(aes(x = sdt_d, y = Valence)) +
      tidybayes::stat_halfeyeh() + 
      labs(x = "sensitivity (d')", y = 'Posterior') +
      theme_classic()
    
    p_sdt_c_sum <- tmp_c %>%
      dplyr::mutate(Valence = factor(Valence, levels = c('Bad', 'Neutral', 'Good'))) %>%
      ggplot2::ggplot(aes(x = sdt_c, y = Valence)) +
      tidybayes::stat_halfeyeh() + 
      labs(x = "criteria (c)", y = 'Posterior') +
      theme_classic()
    
    # plot comparison
    p_sdt_d <- tmp_d %>%
      dplyr::mutate(Valence = factor(Valence, levels = c('Neutral', 'Bad', 'Good'))) %>%
      tidybayes::compare_levels(sdt_d, by = Valence) %>%
      ggplot2::ggplot(aes(x = sdt_d, y = Valence, fill = stat(x > 0))) +
      tidybayes::stat_halfeyeh() + 
      geom_vline(xintercept =0, linetype = "dashed") +
      scale_fill_manual(values = c("gray80", "skyblue")) +
      labs(x = "sensitivity (d')", y = 'Comparison') +
      theme_classic()
    
    p_sdt_c <- tmp_c %>%
      dplyr::mutate(Valence = factor(Valence, levels = c('Neutral', 'Bad', 'Good'))) %>%
      tidybayes::compare_levels(sdt_c, by = Valence) %>%
      ggplot2::ggplot(aes(x = sdt_c, y = Valence, fill = stat(x > 0))) +
      tidybayes::stat_halfeyeh() + 
      geom_vline(xintercept =0, linetype = "dashed") +
      scale_fill_manual(values = c("gray80", "skyblue")) +
      labs(x = "criteria (c)", y = 'Comparison') +
      theme_classic()
    
    return(list(p_sdt_d_sum, p_sdt_c_sum, p_sdt_d, p_sdt_c))
}

# define a function to run the RT GLMM for all exp with Matchness * Valence design
fun_rt_val <- function(exp_name) {
  df_name <- paste('df', exp_name, '.v', sep = '')
  m_name <- paste("glmmModels/exp", exp_name, "_rt_m1_DummyCode", sep = '')
  df <- get(df_name)  # get the data by string
  m <- df %>%
    dplyr::mutate(RT_sec = RT/1000) %>% # log RT in seconds
    dplyr::filter(ACC == 1) %>%
    dplyr::mutate(ismatch = ifelse(Matchness == 'Match', 1, 0),
                  Valence = factor(Valence, levels = c('Neutral', 'Bad', 'Good'))) %>%
    brms::brm(RT_sec ~ Valence*ismatch + (Valence*ismatch | Subject),
              family = shifted_lognormal(),
              data = ., control = list(adapt_delta = .99),
              iter = 4000,
              thin = 2,
              cores = parallel::detectCores(),
              file = here::here(m_name))
  return(m)
}

fun_plot_rt_val <- function(m_rt) {
    tmp_rt <- m_rt %>% 
      tidybayes::spread_draws(b_Intercept, b_ValenceBad, b_ValenceGood, 
                              b_ismatch,   `b_ValenceBad:ismatch`, `b_ValenceGood:ismatch`) %>%
      dplyr::mutate(Neut_MM = b_Intercept,
                    Bad_MM = Neut_MM + b_ValenceBad,
                    Good_MM = Neut_MM + b_ValenceGood,
                    Neut_M = Neut_MM + b_ismatch,
                    Bad_M = Neut_MM + b_ismatch + `b_ValenceBad:ismatch`,
                    Good_M = Neut_MM + b_ismatch + `b_ValenceGood:ismatch`) %>%
      dplyr::select(-contains('b_')) %>%
      tidyr::pivot_longer(cols = Neut_MM:Good_M,
                          names_to = 'cond',
                          values_to = 'logRT') %>%
      dplyr::mutate(RT = exp(logRT)*1000,
                    Matchness = dplyr::case_when(cond == 'Neut_MM' | cond == 'Bad_MM' | cond == 'Good_MM' ~ 'Mismatch',
                                                 cond == 'Neut_M'  | cond == 'Bad_M'  | cond == 'Good_M' ~ 'Match'),
                    Valence = dplyr::case_when(cond == 'Neut_MM' | cond == 'Neut_M' ~ 'Neutral',
                                               cond == 'Bad_MM'  | cond == 'Bad_M'  ~ 'Bad', 
                                               cond == 'Good_MM' | cond == 'Good_M' ~ 'Good'))
    p_exp1b_rt_m_sum <- tmp_rt %>% dplyr::mutate(Valence = factor(Valence, levels = c('Bad', 'Neutral', 'Good'))) %>%
      dplyr::filter(Matchness == 'Match') %>%
      ggplot2::ggplot(aes(x = RT, y = Valence)) +
      tidybayes::stat_halfeyeh() + 
      labs(x = "RTs (Matching, ms)", y = 'Posterior') +
      theme_classic()
    p_exp1b_rt_mm_sum <- tmp_rt %>% dplyr::mutate(Valence = factor(Valence, levels = c('Bad', 'Neutral', 'Good'))) %>%
      dplyr::filter(Matchness == 'Mismatch') %>%
      ggplot2::ggplot(aes(x = RT, y = Valence)) +
      tidybayes::stat_halfeyeh() + 
      labs(tag = 'D', x = "RTs (Mismatching, ms)", y = 'Posterior') +
      theme_classic()
    
    # plot comparison
    p_exp1b_rt_m <- tmp_rt %>% dplyr::mutate(Valence = factor(Valence, levels = c('Neutral', 'Bad', 'Good'))) %>%
      dplyr::filter(Matchness == 'Match') %>%
      tidybayes::compare_levels(RT, by = Valence) %>%
      ggplot2::ggplot(aes(x = RT, y = Valence, fill = stat(x < 0))) +
      tidybayes::stat_halfeyeh() + 
      geom_vline(xintercept =0, linetype = "dashed") +
      scale_fill_manual(values = c("gray80", "skyblue")) +
      labs(tag = 'C', x = "RTs (Matching, ms)", y = 'Comparison') +
      theme_classic()
    p_exp1b_rt_mm <- tmp_rt %>% dplyr::mutate(Valence = factor(Valence, levels = c('Neutral', 'Bad', 'Good'))) %>%
      dplyr::filter(Matchness == 'Mismatch') %>%
      tidybayes::compare_levels(RT, by = Valence) %>%
      ggplot2::ggplot(aes(x = RT, y = Valence, fill = stat(x < 0))) +
      tidybayes::stat_halfeyeh() + 
      geom_vline(xintercept =0, linetype = "dashed") +
      scale_fill_manual(values = c("gray80", "skyblue")) +
      labs(tag = 'D', x = "RTs (Mismatching, ms)", y = 'Comparison') +
      theme_classic()
    return(list(p_exp1b_rt_m_sum, p_exp1b_rt_mm_sum, p_exp1b_rt_m, p_exp1b_rt_mm))
}

```

  <!-- A general method part describing experimental design and data analysis -->
```{r child = "general_method.rmd"}
```

# Part 1: Moral valence effect
In this part, we report five experiments that aimed at testing whether the instantly acquired association between shapes and good person would be prioritized in perceptual decision-making.

```{r child = "exp1a.rmd"}
```

```{r child = "exp1b.rmd"}
```

```{r child = "exp1c.rmd"}
```

```{r child = "exp2.rmd"}
```

```{r child = "exp6a.rmd"}
```

```{r remove repeated subj Data,echo=FALSE,results='hide'}
## exclude the repeating subjects
df1c.meta.d <- df1c.meta.d %>% dplyr::filter(!Subject %in% c(1206, 1207, 1208, 1210))
df1c.meta.rt <- df1c.meta.rt %>% dplyr::filter(!Subject %in% c(1206, 1207, 1208, 1210)) # exclude participants who participated exp1a or 1b

df2.meta.d <- df2.meta.d %>% dplyr::filter(Subject > 2000)    # exclude participant from exp 1a
df2.meta.rt <- df2.meta.rt %>% dplyr::filter(Subject > 2000)

df3a.meta.d <- df3a.meta.d %>% dplyr::filter(!Subject %in% c(3013, 3012, 3043, 3046)) # exclude participants from ex1b, 1c, and 2
df3a.meta.rt <- df3a.meta.rt %>% dplyr::filter(!Subject %in% c(3013, 3012, 3043, 3046)) # exclude participants from ex1b, 1c, and 2

df4b.meta.d <- df4b.meta.d %>% dplyr::filter(!Subject %in% c(4210, 4202, 4201))   # exclude participants from ex1b, 1c, and 2
df4b.meta.rt <- df4b.meta.rt %>% dplyr::filter(!Subject %in% c(4210, 4202, 4201)) # exclude participants from ex1b, 1c, and 2

df5.meta.d <- df5.meta.d %>% dplyr::filter(!Subject %in% c(5201))   # exclude participants from ex1b, 1c, and 2
df5.meta.rt <- df5.meta.rt %>% dplyr::filter(!Subject %in% c(5201)) # exclude participants from ex1b, 1c, and 2

df6a.meta.d <- df6a.meta.d %>% dplyr::filter(!Subject %in% c(6118,6119,6122,6123,6131))   # exclude participants from ex1b, 1c, and 2
df6a.meta.rt <- df6a.meta.rt %>% dplyr::filter(!Subject %in% c(6118,6119,6122,6123,6131)) # exclude participants from ex1b, 1c, and 2

df6b.meta.d <- df6b.meta.d %>% dplyr::filter(!Subject %in% c(6217))   # exclude participants from ex1b, 1c, and 2
df6b.meta.rt <- df6b.meta.rt %>% dplyr::filter(!Subject %in% c(6217)) # exclude participants from ex1b, 1c, and 2

df7a_m.meta.d <- df7a_m.meta.d %>% dplyr::filter(!Subject %in% c(7020))   # exclude participants from ex1b, 1c, and 2
df7a_m.meta.rt <- df7a_m.meta.rt %>% dplyr::filter(!Subject %in% c(7020)) # exclude participants from ex1b, 1c, and 2

```

# Results
```{r first meta,echo=FALSE,results='hide'}
# Combine the data -----
df.meta_d_1 <- rbind(df1a.meta.d, df1b.meta.d, df1c.meta.d, df2.meta.d, df4b.meta.d , df5.meta.d, df6a.meta.d) 
df.meta_rt_1 <- rbind(df1a.meta.rt, df1b.meta.rt, df1c.meta.rt, df2.meta.rt, df4b.meta.rt,df5.meta.rt, df6a.meta.rt)

# Prepare the data for meta ----
# calculate the mean, sd, n, and r for estimating the effect size and SE of effect size.
effectList_1 <- c('Good_Bad','Good_Neut','Bad_Neut')

df.ES_1 <- data.frame(matrix(nrow=length(unique(df.meta_d_1$ExpID))*length(effectList_1)*2, ncol=0)) %>%
  dplyr::mutate(DVtype = rep(c('RT', 'dprime'), each = length(unique(df.meta_d_1$ExpID))*length(effectList_1)),
                ExpID  = rep(rep(unique(df.meta_d_1$ExpID), each = length(effectList_1)), 2),
                Effect = rep(effectList_1, length(unique(df.meta_d_1$ExpID))*2),
                #Group  = rep(groupList, length(unique(df.meta_d$ExpID))*2),
                M1 = NA, SD1 = NA, M2 = NA, SD2 = NA, N = NA, r = NA, ES = NA, ES.var = NA)

for (DVName in c('RT','dprime')){
  if (DVName == 'RT'){
    metaData <- df.meta_rt_1 %>% dplyr::filter(Matchness == "Match") %>% dplyr::rename(Value = RT)
  } else{
    metaData <- df.meta_d_1 %>% dplyr::rename(Value = dprime)
  }
  
  for (expName in unique(metaData$ExpID)){
    for (effectName in effectList_1){
      tmpdata <- metaData %>% dplyr::filter(ExpID == expName & Domain == 'Morality')
      
      if (effectName == 'Good_Bad'){
        #print(paste('processing Good_Bad of ', expName, sep = ''))
        dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good")
        dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Bad")
        }
      else if (effectName == 'Good_Neut'){
        #print(paste('processing Good_Neut of ', expName, sep = ''))
        #if ('Neutral' %in% tmpdata$Valence){
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good")
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Neutral")
        #  }
        #else{
          #print(paste('There is no Neutral condition in', expName, sepe=''))
        #  next
        #  }
        }
      else if (effectName == 'Bad_Neut'){
        #if ('Neutral' %in% tmpdata$Valence)
        #  {
            dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Bad")
            dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Neutral")  
        #  }
        #else{
            #print(paste('There is no Neutral condition in', expName, sepe=''))
        #    next
        #  }
        }
      #}
      M1  <- mean(dataCond1$Value) -> df.ES_1$M1[df.ES_1$DVtype == DVName & df.ES_1$ExpID == expName & df.ES_1$Effect == effectName]
      SD1 <- sd(dataCond1$Value)   -> df.ES_1$SD1[df.ES_1$DVtype == DVName & df.ES_1$ExpID == expName & df.ES_1$Effect == effectName] 
      M2  <- mean(dataCond2$Value) -> df.ES_1$M2[df.ES_1$DVtype == DVName & df.ES_1$ExpID == expName & df.ES_1$Effect == effectName]
      SD2 <- sd(dataCond2$Value)   -> df.ES_1$SD2[df.ES_1$DVtype == DVName & df.ES_1$ExpID == expName & df.ES_1$Effect == effectName]
      N   <- length(unique(dataCond2$Subject)) -> df.ES_1$N[df.ES_1$DVtype == DVName & df.ES_1$ExpID == expName & df.ES_1$Effect == effectName]
      r   <- cor(dataCond1$Value,dataCond2$Value) -> df.ES_1$r[df.ES_1$DVtype == DVName & df.ES_1$ExpID == expName & df.ES_1$Effect == effectName] 
      tmp2 <- d.sgpp(m.1 = M1, m.2 = M2, sd.1 = SD1, sd.2 = SD2,n = N, r = r)
      df.ES_1$ES[df.ES_1$DVtype == DVName & df.ES_1$ExpID == expName & df.ES_1$Effect == effectName] <- tmp2[1,1]
      df.ES_1$ES.var[df.ES_1$DVtype == DVName & df.ES_1$ExpID == expName & df.ES_1$Effect == effectName] <- tmp2[1,2]
    }
  }
}

# Do the meta-analysis in a for loop ----
df.ES_1_sum <- df.ES_1 %>% 
  dplyr::group_by(DVtype, Effect) %>% 
  tidyr::drop_na() %>% 
  dplyr::summarise(Nexp = length(unique(ExpID)), Nsubj = sum(N, na.rm = T))

df.res.meta_1 <- data.frame(matrix(nrow= 3*2, ncol=0)) %>%
  dplyr::mutate(DVtype = rep(c('RT', 'dprime'), each = 3),
                #Group  = rep(groupList_1, 2),
                Effect = rep(effectList_1, 2),
                #Group  = rep(groupList, length(unique(df.meta_d$ExpID))*2),
                N_exp = NA, Cohen_d = NA, se = NA, CI_low = NA, CI_upp = NA, pval = NA)

for (DVName in c('RT','dprime')){
  for (effectName in effectList_1){
    df.res.meta <- df.ES_1 %>%
      dplyr::filter(DVtype == DVName & Effect == effectName) %>%
      tidyr::drop_na()
    
    tmp.meta.res <- metafor::rma(yi = df.res.meta$ES,
                           vi = df.res.meta$ES.var,
                           slab = df.res.meta$ExpID)
    df.res.meta_1$N_exp[df.res.meta_1$DVtype == DVName & df.res.meta_1$Effect == effectName] <- tmp.meta.res$k
    df.res.meta_1$Cohen_d[df.res.meta_1$DVtype == DVName & df.res.meta_1$Effect == effectName] <- tmp.meta.res$beta
    df.res.meta_1$se[df.res.meta_1$DVtype == DVName & df.res.meta_1$Effect == effectName] <- tmp.meta.res$se
    df.res.meta_1$CI_low[df.res.meta_1$DVtype == DVName & df.res.meta_1$Effect == effectName] <- tmp.meta.res$ci.lb
    df.res.meta_1$CI_upp[df.res.meta_1$DVtype == DVName & df.res.meta_1$Effect == effectName] <- tmp.meta.res$ci.ub
    df.res.meta_1$pval[df.res.meta_1$DVtype == DVName & df.res.meta_1$Effect == effectName] <- tmp.meta.res$pval
  }
}

# Prepare data for plotting the effect size ----
df.res.meta_1 <- df.res.meta_1 %>%
  dplyr::mutate(Identity = "No-Ref.",
                EffectType = Effect) 
```

```{r second meta,echo=FALSE,results='hide'}
# Results part 2: with self-referential, included experiments: 3a, 3b, 6b, 7a, 7b

# Combine the data  ----
df.meta_d_2 <- rbind(df3a.meta.d, df3b.meta.d, df6b.meta.d, df7a_m.meta.d, df7b_m.meta.d) 
df.meta_rt_2 <- rbind(df3a.meta.rt, df3b.meta.rt, df6b.meta.rt, df7a_m.meta.rt, df7b_m.meta.rt)

# Calculate the mean, sd, n, and r ----
# for estimating the effect size and SE of effect size.
effectList_2 <- c('Good_Bad_S','Good_Neut_S','Bad_Neut_S',
                'Good_Bad_O','Good_Neut_O','Bad_Neut_O')

df.ES_2 <- data.frame(matrix(nrow=length(unique(df.meta_d_2$ExpID))*length(effectList_2)*2, ncol=0)) %>%
  dplyr::mutate(DVtype = rep(c('RT', 'dprime'), each = length(unique(df.meta_d_2$ExpID))*length(effectList_2)),
                ExpID  = rep(rep(unique(df.meta_d_2$ExpID), each = length(effectList_2)), 2),
                Effect = rep(effectList_2, length(unique(df.meta_d_2$ExpID))*2),
                M1 = NA, SD1 = NA, M2 = NA, SD2 = NA, N = NA, r = NA, ES = NA, ES.var = NA)

for (DVName in c('RT','dprime')){
  if (DVName == 'RT'){
    metaData <- df.meta_rt_2 %>% dplyr::filter(Matchness == "Match") %>% dplyr::rename(Value = RT)
  } else{
    metaData <- df.meta_d_2 %>% dplyr::rename(Value = dprime)
  }
  
  for (expName in unique(metaData$ExpID)){
    for (effectName in effectList_2){
      tmpdata <- metaData %>% dplyr::filter(ExpID == expName & Domain == 'Morality')
      
      if (effectName == 'Good_Bad_S'){
        
        if (!all(is.na(tmpdata$Identity))){
          #print(paste('processing Good_Bad_S of ', expName, sep = ''))
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good" & Identity == 'Self')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Bad" & Identity == 'Self')  
          }
        else{
            #print(paste('Skip Good_Bad_S of ', expName, sep = ''))
          next
          }
        }
      else if (effectName == 'Good_Neut_S'){
        if (!all(is.na(tmpdata$Identity)) & 'Neutral' %in% tmpdata$Valence ){
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good" & Identity == 'Self')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Neutral" & Identity == 'Self')  
          }
        else{
          next
          }
        }  
      else if (effectName == 'Bad_Neut_S'){
        if (!all(is.na(tmpdata$Identity)) & 'Neutral' %in% tmpdata$Valence ){
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Bad" & Identity == 'Self')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Neutral" & Identity == 'Self')  
          }
        else{
          next
          }
        }
      else if (effectName == 'Good_Bad_O'){
        if (!all(is.na(tmpdata$Identity))){
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good" & Identity == 'Other')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Bad" & Identity == 'Other')  
          }
        else{
          next
          }
        }
      else if (effectName == 'Good_Neut_O'){
        if (!all(is.na(tmpdata$Identity)) & 'Neutral' %in% tmpdata$Valence )
          {
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good" & Identity == 'Other')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Neutral" & Identity == 'Other')  
          }
        else{
          next
          }
        }
      else if (effectName == 'Bad_Neut_O'){
        if (!all(is.na(tmpdata$Identity)) & 'Neutral' %in% tmpdata$Valence){
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Bad" & Identity == 'Other')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Neutral" & Identity == 'Other')  
          }
        else{
          next
          }
      }
      
      M1  <- mean(dataCond1$Value) -> df.ES_2$M1[df.ES_2$DVtype == DVName & df.ES_2$ExpID == expName & df.ES_2$Effect == effectName]
      SD1 <- sd(dataCond1$Value)   -> df.ES_2$SD1[df.ES_2$DVtype == DVName & df.ES_2$ExpID == expName & df.ES_2$Effect == effectName] 
      M2  <- mean(dataCond2$Value) -> df.ES_2$M2[df.ES_2$DVtype == DVName & df.ES_2$ExpID == expName & df.ES_2$Effect == effectName]
      SD2 <- sd(dataCond2$Value)   -> df.ES_2$SD2[df.ES_2$DVtype == DVName & df.ES_2$ExpID == expName & df.ES_2$Effect == effectName]
      N   <- length(unique(dataCond2$Subject)) -> df.ES_2$N[df.ES_2$DVtype == DVName & df.ES_2$ExpID == expName & df.ES_2$Effect == effectName]
      r   <- cor(dataCond1$Value,dataCond2$Value) -> df.ES_2$r[df.ES_2$DVtype == DVName & df.ES_2$ExpID == expName & df.ES_2$Effect == effectName] 
      tmp2 <- d.sgpp(m.1 = M1, m.2 = M2, sd.1 = SD1, sd.2 = SD2,n = N, r = r)
      df.ES_2$ES[df.ES_2$DVtype == DVName & df.ES_2$ExpID == expName & df.ES_2$Effect == effectName] <- tmp2[1,1]
      df.ES_2$ES.var[df.ES_2$DVtype == DVName & df.ES_2$ExpID == expName & df.ES_2$Effect == effectName] <- tmp2[1,2]
    }
  }
}

# Do the meta ----
# info about participants
df.ES_2_sum <- df.ES_2 %>% 
  dplyr::group_by(DVtype, Effect) %>% 
  tidyr::drop_na() %>% 
  dplyr::summarise(Nexp = length(unique(ExpID)), Nsubj = sum(N, na.rm = T))

df.res.meta_2 <- data.frame(matrix(nrow= (2*3)*2, ncol=0)) %>%
  dplyr::mutate(DVtype = rep(c('RT', 'dprime'), each = (2*3)),
                Effect = rep(effectList_2, 2),
                N_exp = NA, Cohen_d = NA, se = NA, CI_low = NA, CI_upp = NA, pval = NA)

# meta -analysis
for (DVName in c('RT','dprime')){
  for (effectName in effectList_2){
    df.res.meta <- df.ES_2 %>%
      dplyr::filter(DVtype == DVName & Effect == effectName) %>%
      tidyr::drop_na()
  
    tmp.meta.res <- metafor::rma(yi = df.res.meta$ES,
                           vi = df.res.meta$ES.var,
                           slab = df.res.meta$ExpID)
    df.res.meta_2$N_exp[df.res.meta_2$DVtype == DVName & df.res.meta_2$Effect == effectName] <- tmp.meta.res$k
    df.res.meta_2$Cohen_d[df.res.meta_2$DVtype == DVName & df.res.meta_2$Effect == effectName] <- tmp.meta.res$beta
    df.res.meta_2$se[df.res.meta_2$DVtype == DVName & df.res.meta_2$Effect == effectName] <- tmp.meta.res$se
    df.res.meta_2$CI_low[df.res.meta_2$DVtype == DVName & df.res.meta_2$Effect == effectName] <- tmp.meta.res$ci.lb
    df.res.meta_2$CI_upp[df.res.meta_2$DVtype == DVName & df.res.meta_2$Effect == effectName] <- tmp.meta.res$ci.ub
    df.res.meta_2$pval[df.res.meta_2$DVtype == DVName & df.res.meta_2$Effect == effectName] <- tmp.meta.res$pval
  }
}

# plot the effect size  ----
df.res.meta_2 <- df.res.meta_2 %>%
  dplyr::mutate(Identity = ifelse(Effect == "Good_Bad_S" | Effect == "Good_Neut_S" | Effect == "Bad_Neut_S",
                                  "Self-Ref.", "Other-Ref."),
                EffectType = ifelse(Effect == "Good_Bad_S" | Effect == "Good_Bad_O", "Good_Bad",
                                    ifelse(Effect == "Good_Neut_S" | Effect == "Good_Neut_O", "Good_Neut", "Bad_Neut")))

df.res_meta_pdata <- rbind(df.res.meta_1, df.res.meta_2) %>%
  dplyr::mutate(Identity = factor(Identity, levels = c("No-Ref.", "Self-Ref.", "Other-Ref.")),
                EffectType = factor(EffectType, levels = c("Good_Bad", "Good_Neut", "Bad_Neut" )))

```

## Effect of moral valence

```{r plot-all-effect, fig.cap="Effect size (Cohen's *d*) of Valence.", warning=FALSE}
# fig.width=8, 
df.res_meta_pdata %>%
  dplyr::filter(EffectType != 'Good_Bad') %>%
  ggplot2::ggplot(., aes(x = EffectType, y=Cohen_d, color=EffectType, fill=EffectType )) + # 
  geom_pointrange(aes(ymin=Cohen_d - 1.96*se, ymax = Cohen_d + 1.96*se), 
                  position = position_dodge(width = 0.5),
                  shape=18, size=0.8) +
  geom_hline(yintercept=0, size=1, color='grey', linetype = 'dashed') +
  coord_cartesian(ylim=c(-1.5, 1.5))+
  scale_color_brewer(palette = "Dark2")+
  scale_fill_brewer(palette = "Dark2")+
  ylab(expression(paste("Effect size: Cohen's ",italic("d"), sep = ' '))) +
  xlab('Contrasts between different valence') +
  apatheme_x +
  facet_grid(  DVtype ~ Identity)
```

In this part, we synthesized results from experiment 1a, 1b, 1c, 2, 5 and 6a. Data from 192 participants were included in these analyses. We found differences between positive and negative conditions on RT was Cohen's *d* = `r df.res.meta_1$Cohen_d[df.res.meta_1$DVtype == 'RT' & df.res.meta_1$Effect =='Good_Bad']` $\pm$ `r df.res.meta_1$se[df.res.meta_1$DVtype == 'RT' & df.res.meta_1$Effect =='Good_Bad']`, 95% CI [`r df.res.meta_1$CI_low[df.res.meta_1$DVtype == 'RT' & df.res.meta_1$Effect =='Good_Bad']` `r df.res.meta_1$CI_upp[df.res.meta_1$DVtype == 'RT' & df.res.meta_1$Effect =='Good_Bad']`]; on *d'* was Cohen's *d* = `r df.res.meta_1$Cohen_d[df.res.meta_1$DVtype == 'dprime' & df.res.meta_1$Effect =='Good_Bad']` $\pm$ `r df.res.meta_1$se[df.res.meta_1$DVtype == 'dprime' & df.res.meta_1$Effect =='Good_Bad']`, 95% CI [`r df.res.meta_1$CI_low[df.res.meta_1$DVtype == 'dprime' & df.res.meta_1$Effect =='Good_Bad']` `r df.res.meta_1$CI_upp[df.res.meta_1$DVtype == 'dprime' & df.res.meta_1$Effect =='Good_Bad']`]. The effect was also observed between positive and neutral condition, RT: Cohen's *d* = `r df.res.meta_1$Cohen_d[df.res.meta_1$DVtype == 'RT' & df.res.meta_1$Effect =='Good_Neut']` $\pm$ `r df.res.meta_1$se[df.res.meta_1$DVtype == 'RT' & df.res.meta_1$Effect =='Good_Neut']`, 95% CI [`r df.res.meta_1$CI_low[df.res.meta_1$DVtype == 'RT' & df.res.meta_1$Effect =='Good_Neut']` `r df.res.meta_1$CI_upp[df.res.meta_1$DVtype == 'RT' & df.res.meta_1$Effect =='Good_Neut']`]; *d'*: Cohen's *d* = `r df.res.meta_1$Cohen_d[df.res.meta_1$DVtype == 'dprime' & df.res.meta_1$Effect =='Good_Neut']` $\pm$ `r df.res.meta_1$se[df.res.meta_1$DVtype == 'dprime' & df.res.meta_1$Effect =='Good_Neut']`, 95% CI [`r df.res.meta_1$CI_low[df.res.meta_1$DVtype == 'dprime' & df.res.meta_1$Effect =='Good_Neut']` `r df.res.meta_1$CI_upp[df.res.meta_1$DVtype == 'dprime' & df.res.meta_1$Effect =='Good_Neut']`]. And the difference between neutral and bad conditions are not significant, RT: Cohen's *d* = `r df.res.meta_1$Cohen_d[df.res.meta_1$DVtype == 'RT' & df.res.meta_1$Effect =='Bad_Neut']` $\pm$ `r df.res.meta_1$se[df.res.meta_1$DVtype == 'RT' & df.res.meta_1$Effect =='Bad_Neut']`, 95% CI [`r df.res.meta_1$CI_low[df.res.meta_1$DVtype == 'RT' & df.res.meta_1$Effect =='Bad_Neut']` `r df.res.meta_1$CI_upp[df.res.meta_1$DVtype == 'RT' & df.res.meta_1$Effect =='Bad_Neut']`]; *d'*: Cohen's *d* = `r df.res.meta_1$Cohen_d[df.res.meta_1$DVtype == 'dprime' & df.res.meta_1$Effect =='Bad_Neut']` $\pm$ `r df.res.meta_1$se[df.res.meta_1$DVtype == 'dprime' & df.res.meta_1$Effect =='Bad_Neut']`, 95% CI [`r df.res.meta_1$CI_low[df.res.meta_1$DVtype == 'dprime' & df.res.meta_1$Effect =='Bad_Neut']` `r df.res.meta_1$CI_upp[df.res.meta_1$DVtype == 'dprime' & df.res.meta_1$Effect =='Bad_Neut']`]. See Figure \@ref(fig:plot-all-effect) left panel.

## Interaction between valence and self-reference
In this part, we combined the experiments that explicitly manipulated the self-reference and valence, which includes 3a, 3b, 6b, 7a, and 7b. For the positive versus negative contrast, data were from five experiments with 178 participants; for positive versus neutral and neutral versus negative contrasts, data were from three experiments ( 3a, 3b, and 6b) with 108 participants.

In most of these experiments, the interaction between self-reference and valence was significant (see results of each experiment in supplementary materials). In the mini-meta-analysis, we analyzed the valence effect for self-referential condition and other-referential condition separately.

For the self-referential condition, we found the same pattern as in the first part of results. That is we found significant differences between positive and neutral as well as positive and negative, but not neutral and negative. The effect size of RT between positive and negative is Cohen's *d* = `r df.res.meta_2$Cohen_d[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Good_Bad_S']` $\pm$ `r df.res.meta_2$se[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Good_Bad_S']`, 95% CI [`r df.res.meta_2$CI_low[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Good_Bad_S']` `r df.res.meta_2$CI_upp[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Good_Bad_S']`]; on *d'* was Cohen's *d* = `r df.res.meta_2$Cohen_d[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Good_Bad_S']` $\pm$ `r df.res.meta_2$se[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Good_Bad_S']`, 95% CI [`r df.res.meta_2$CI_low[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Good_Bad_S']` `r df.res.meta_2$CI_upp[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Good_Bad_S']`]. The effect was also observed between positive and neutral condition, RT: Cohen's *d* = `r df.res.meta_2$Cohen_d[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Good_Neut_S']` $\pm$ `r df.res.meta_2$se[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Good_Neut_S']`, 95% CI [`r df.res.meta_2$CI_low[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Good_Neut_S']` `r df.res.meta_2$CI_upp[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Good_Neut_S']`]; *d'*: Cohen's *d* = `r df.res.meta_2$Cohen_d[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Good_Neut_S']` $\pm$ `r df.res.meta_2$se[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Good_Neut_S']`, 95% CI [`r df.res.meta_2$CI_low[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Good_Neut_S']` `r df.res.meta_2$CI_upp[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Good_Neut_S']`]. And the difference between neutral and bad conditions are not significant, RT: Cohen's *d* = `r df.res.meta_2$Cohen_d[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Bad_Neut_S']` $\pm$ `r df.res.meta_2$se[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Bad_Neut_S']`, 95% CI [`r df.res.meta_2$CI_low[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Bad_Neut_S']` `r df.res.meta_2$CI_upp[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Bad_Neut_S']`]; *d'*: Cohen's *d* = `r df.res.meta_2$Cohen_d[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Bad_Neut_S']` $\pm$ `r df.res.meta_2$se[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Bad_Neut_S']`, 95% CI [`r df.res.meta_2$CI_low[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Bad_Neut_S']` `r df.res.meta_2$CI_upp[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Bad_Neut_S']`]. See Figure \@ref(fig:plot-all-effect) the middle panel.

For the other-referential condition, we found that only the difference between positive and negative on RT was significant, all the other conditions were not. The effect size of RT between positive and negative is Cohen's *d* = `r df.res.meta_2$Cohen_d[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Good_Bad_O']` $\pm$ `r df.res.meta_2$se[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Good_Bad_O']`, 95% CI [`r df.res.meta_2$CI_low[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Good_Bad_O']` `r df.res.meta_2$CI_upp[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Good_Bad_O']`]; on *d'* was Cohen's *d* = `r df.res.meta_2$Cohen_d[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Good_Bad_O']` $\pm$ `r df.res.meta_2$se[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Good_Bad_O']`, 95% CI [`r df.res.meta_2$CI_low[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Good_Bad_O']` `r df.res.meta_2$CI_upp[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Good_Bad_O']`]. The effect was not observed between positive and neutral condition, RT: Cohen's *d* = `r df.res.meta_2$Cohen_d[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Good_Neut_O']` $\pm$ `r df.res.meta_2$se[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Good_Neut_O']`, 95% CI [`r df.res.meta_2$CI_low[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Good_Neut_O']` `r df.res.meta_2$CI_upp[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Good_Neut_O']`]; *d'*: Cohen's *d* = `r df.res.meta_2$Cohen_d[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Good_Neut_O']` $\pm$ `r df.res.meta_2$se[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Good_Neut_O']`, 95% CI [`r df.res.meta_2$CI_low[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Good_Neut_O']` `r df.res.meta_2$CI_upp[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Good_Neut_O']`]. And the difference between neutral and bad conditions are not significant, RT: Cohen's *d* = `r df.res.meta_2$Cohen_d[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Bad_Neut_O']` $\pm$ `r df.res.meta_2$se[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Bad_Neut_O']`, 95% CI [`r df.res.meta_2$CI_low[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Bad_Neut_O']` `r df.res.meta_2$CI_upp[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Bad_Neut_O']`]; *d'*: Cohen's *d* = `r df.res.meta_2$Cohen_d[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Bad_Neut_O']` $\pm$ `r df.res.meta_2$se[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Bad_Neut_O']`, 95% CI [`r df.res.meta_2$CI_low[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Bad_Neut_O']` `r df.res.meta_2$CI_upp[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Bad_Neut_O']`]. See Figure \@ref(fig:plot-all-effect) right panel.

## Generalizibility of the valence effect
In this part, we reported the results from experiment 4 in which either moral valence or self-reference were manipulated as task-irrelevant stimuli. 

```{r analyzing exp4a, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
df.ES_4a <- data.frame(matrix(nrow=length(unique(df4a.meta.d$ExpID))*length(effectList_2)*2, ncol=0)) %>%
  dplyr::mutate(DVtype = rep(c('RT', 'dprime'), each = length(unique(df4a.meta.d$ExpID))*length(effectList_2)),
                ExpID  = rep(rep(unique(df4a.meta.d$ExpID), each = length(effectList_2)), 2),
                Effect = rep(effectList_2, length(unique(df4a.meta.d$ExpID))*2),
                M1 = NA, SD1 = NA, M2 = NA, SD2 = NA, N = NA, r = NA, ES = NA, ES.var = NA)

for (DVName in c('RT','dprime')){
  if (DVName == 'RT'){
    metaData <- df4a.meta.rt %>% dplyr::filter(Matchness == "Match") %>% dplyr::rename(Value = RT)
  } else{
    metaData <- df4a.meta.d %>% dplyr::rename(Value = dprime)
  }
  
  for (expName in unique(metaData$ExpID)){
    for (effectName in effectList_2){
      tmpdata <- metaData %>% dplyr::filter(ExpID == expName & Domain == 'Morality')
      
      if (effectName == 'Good_Bad_S'){
        
        if (!all(is.na(tmpdata$Identity))){
          #print(paste('processing Good_Bad_S of ', expName, sep = ''))
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good" & Identity == 'Self')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Bad" & Identity == 'Self')  
          }
        else{
            #print(paste('Skip Good_Bad_S of ', expName, sep = ''))
          next
          }
        }
      else if (effectName == 'Good_Neut_S'){
        if (!all(is.na(tmpdata$Identity)) & 'Neutral' %in% tmpdata$Valence ){
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good" & Identity == 'Self')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Neutral" & Identity == 'Self')  
          }
        else{
          next
          }
        }  
      else if (effectName == 'Bad_Neut_S'){
        if (!all(is.na(tmpdata$Identity)) & 'Neutral' %in% tmpdata$Valence ){
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Bad" & Identity == 'Self')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Neutral" & Identity == 'Self')  
          }
        else{
          next
          }
        }
      else if (effectName == 'Good_Bad_O'){
        if (!all(is.na(tmpdata$Identity))){
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good" & Identity == 'Other')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Bad" & Identity == 'Other')  
          }
        else{
          next
          }
        }
      else if (effectName == 'Good_Neut_O'){
        if (!all(is.na(tmpdata$Identity)) & 'Neutral' %in% tmpdata$Valence )
          {
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good" & Identity == 'Other')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Neutral" & Identity == 'Other')  
          }
        else{
          next
          }
        }
      else if (effectName == 'Bad_Neut_O'){
        if (!all(is.na(tmpdata$Identity)) & 'Neutral' %in% tmpdata$Valence){
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Bad" & Identity == 'Other')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Neutral" & Identity == 'Other')  
          }
        else{
          next
          }
      }
      
      M1  <- mean(dataCond1$Value) -> df.ES_4a$M1[df.ES_4a$DVtype == DVName & df.ES_4a$ExpID == expName & df.ES_4a$Effect == effectName]
      SD1 <- sd(dataCond1$Value)   -> df.ES_4a$SD1[df.ES_4a$DVtype == DVName & df.ES_4a$ExpID == expName & df.ES_4a$Effect == effectName] 
      M2  <- mean(dataCond2$Value) -> df.ES_4a$M2[df.ES_4a$DVtype == DVName & df.ES_4a$ExpID == expName & df.ES_4a$Effect == effectName]
      SD2 <- sd(dataCond2$Value)   -> df.ES_4a$SD2[df.ES_4a$DVtype == DVName & df.ES_4a$ExpID == expName & df.ES_4a$Effect == effectName]
      N   <- length(unique(dataCond2$Subject)) -> df.ES_4a$N[df.ES_4a$DVtype == DVName & df.ES_4a$ExpID == expName & df.ES_4a$Effect == effectName]
      r   <- cor(dataCond1$Value,dataCond2$Value) -> df.ES_4a$r[df.ES_4a$DVtype == DVName & df.ES_4a$ExpID == expName & df.ES_4a$Effect == effectName] 
      tmp2 <- d.sgpp(m.1 = M1, m.2 = M2, sd.1 = SD1, sd.2 = SD2,n = N, r = r)
      df.ES_4a$ES[df.ES_4a$DVtype == DVName & df.ES_4a$ExpID == expName & df.ES_4a$Effect == effectName] <- tmp2[1,1]
      df.ES_4a$ES.var[df.ES_4a$DVtype == DVName & df.ES_4a$ExpID == expName & df.ES_4a$Effect == effectName] <- tmp2[1,2]
    }
  }
}

df.ES_4a <- df.ES_4a %>%
  dplyr::mutate(Identity = ifelse(Effect == "Good_Bad_S" | Effect == "Good_Neut_S" | Effect == "Bad_Neut_S",
                                  "Self-ref.", "Other-ref."),
                EffectType = ifelse(Effect == "Good_Bad_S" | Effect == "Good_Bad_O", "Good_Bad",
                                    ifelse(Effect == "Good_Neut_S" | Effect == "Good_Neut_O", "Good_Neut", "Bad_Neut")),
                Identity = factor(Identity, levels = c("Self-ref.", "Other-ref.")),
                EffectType = factor(EffectType, levels = c("Good_Bad", "Good_Neut", "Bad_Neut")))
```

```{r 'plot-exp4a-effect', fig.cap="Effect size (Cohen's *d*) of Valence in Exp4a.", warning=FALSE}
df.ES_4a %>%
  dplyr::filter(EffectType != "Good_Bad") %>%
  ggplot(., aes(x=EffectType, y=ES, color=EffectType, fill=EffectType)) + 
  geom_pointrange(aes(ymin=ES - 1.96*sqrt(ES.var), ymax = ES + 1.96*sqrt(ES.var)), 
                  position = position_dodge(width = 0.5),
                  shape=18, size=0.8) +
  geom_hline(yintercept=0, size=1, color='grey', linetype = 'dashed') +
  # ggtitle('A: Valence effect') +
  coord_cartesian(ylim=c(-1.1, 1.1))+
  scale_color_brewer(palette = "Dark2")+
  scale_fill_brewer(palette = "Dark2")+
  ylab(expression(paste("Effect size: Cohen's ",italic("d"), sep = ' ')))+
  xlab('Contrasts between different valence')+
  apatheme_x +
  facet_grid(DVtype ~ Identity)
```

For experiment 4a, when self-reference was the target and moral valence was task-irrelevant, we found that only under the implicit self-referential condition, i.e., when the moral words were presented as task irrelevant stimuli, there was the main effect of valence and interaction between valence and reference for both *d* prime and RT (See supplementary results for the detailed statistics). For *d* prime, we found good-self condition (`r df.ES_4a$M1[df.ES_4a$DVtype == 'dprime' & df.ES_4a$Effect == 'Good_Bad_S']` $\pm$ `r df.ES_4a$SD1[df.ES_4a$DVtype == 'dprime' & df.ES_4a$Effect == 'Good_Bad_S']`) had higher *d* prime than bad-self condition (`r df.ES_4a$M2[df.ES_4a$DVtype == 'dprime' & df.ES_4a$Effect == 'Good_Bad_S']` $\pm$ `r df.ES_4a$SD2[df.ES_4a$DVtype == 'dprime' & df.ES_4a$Effect == 'Good_Bad_S']`); good self condition was also higher than neutral self (`r df.ES_4a$M2[df.ES_4a$DVtype == 'dprime' & df.ES_4a$Effect == 'Good_Neut_S']` $\pm$ `r df.ES_4a$SD2[df.ES_4a$DVtype == 'dprime' & df.ES_4a$Effect == 'Good_Neut_S']`) but there was not statistically significant, while the neutral-self condition was higher than bad self condition and not significant neither. For reaction times, good-self condition (`r df.ES_4a$M1[df.ES_4a$DVtype == 'RT' & df.ES_4a$Effect == 'Good_Bad_S']` $\pm$ `r df.ES_4a$SD1[df.ES_4a$DVtype == 'RT' & df.ES_4a$Effect == 'Good_Bad_S']`) were faster relative to bad-self condition (`r df.ES_4a$M2[df.ES_4a$DVtype == 'RT' & df.ES_4a$Effect == 'Good_Bad_S']` $\pm$ `r df.ES_4a$SD2[df.ES_4a$DVtype == 'RT' & df.ES_4a$Effect == 'Good_Bad_S']`), and over neutral-self condition (`r df.ES_4a$M2[df.ES_4a$DVtype == 'RT' & df.ES_4a$Effect == 'Good_Neut_S']` $\pm$ `r df.ES_4a$SD2[df.ES_4a$DVtype == 'RT' & df.ES_4a$Effect == 'Good_Neut_S']`). The difference between neutral-self and bad-self conditions were not significant. However, for the other-referential condition, there was no significant differences between different valence conditions. See Figure \@ref(fig:plot-exp4a-effect).

```{r analyzing exp4b, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
#### Approach 1: compared between self and other
effectList_3 <- c('Self_Other_G','Self_Other_N', 'Self_Other_B')

df.ES_4b <- data.frame(matrix(nrow=length(unique(df4b.meta.d$ExpID))*length(effectList_3)*2, ncol=0)) %>%
  dplyr::mutate(DVtype = rep(c('RT', 'dprime'), each = length(unique(df4b.meta.d$ExpID))*length(effectList_3)),
                ExpID  = rep(rep(unique(df4b.meta.d$ExpID), each = length(effectList_3)), 2),
                Effect = rep(effectList_3, length(unique(df4b.meta.d$ExpID))*2),
                M1 = NA, SD1 = NA, M2 = NA, SD2 = NA, N = NA, r = NA, ES = NA, ES.var = NA)

for (DVName in c('RT','dprime')){
  if (DVName == 'RT'){
    metaData <- df4b.meta.rt %>% dplyr::filter(Matchness == "Match") %>% dplyr::rename(Value = RT)
  } else{
    metaData <- df4b.meta.d %>% dplyr::rename(Value = dprime)
  }
  for (expName in unique(metaData$ExpID)){
    for (effectName in effectList_3){
      tmpdata <- metaData %>% dplyr::filter(ExpID == expName & Domain == 'Morality')

      if (effectName == 'Self_Other_G'){

        if (!all(is.na(tmpdata$Identity))){
          #print(paste('processing Good_Bad_S of ', expName, sep = ''))
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good" & Identity == 'Self')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Good" & Identity == 'Other')
          }
        else{
            #print(paste('Skip Good_Bad_S of ', expName, sep = ''))
          next
          }
        }
      else if (effectName == 'Self_Other_N'){
        if (!all(is.na(tmpdata$Identity)) & 'Neutral' %in% tmpdata$Valence ){
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Neutral" & Identity == 'Self')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Neutral" & Identity == 'Other')
          }
        else{
          next
          }
        }
      else if (effectName == 'Self_Other_B'){
        if (!all(is.na(tmpdata$Identity)) & 'Bad' %in% tmpdata$Valence ){
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Bad" & Identity == 'Self')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Bad" & Identity == 'Other')
          }
        else{
          next
          }
        }

      M1  <- mean(dataCond1$Value) -> df.ES_4b$M1[df.ES_4b$DVtype == DVName & df.ES_4b$ExpID == expName & df.ES_4b$Effect == effectName]
      SD1 <- sd(dataCond1$Value)   -> df.ES_4b$SD1[df.ES_4b$DVtype == DVName & df.ES_4b$ExpID == expName & df.ES_4b$Effect == effectName]
      M2  <- mean(dataCond2$Value) -> df.ES_4b$M2[df.ES_4b$DVtype == DVName & df.ES_4b$ExpID == expName & df.ES_4b$Effect == effectName]
      SD2 <- sd(dataCond2$Value)   -> df.ES_4b$SD2[df.ES_4b$DVtype == DVName & df.ES_4b$ExpID == expName & df.ES_4b$Effect == effectName]
      N   <- length(unique(dataCond2$Subject)) -> df.ES_4b$N[df.ES_4b$DVtype == DVName & df.ES_4b$ExpID == expName & df.ES_4b$Effect == effectName]
      r   <- cor(dataCond1$Value,dataCond2$Value) -> df.ES_4b$r[df.ES_4b$DVtype == DVName & df.ES_4b$ExpID == expName & df.ES_4b$Effect == effectName]
      tmp2 <- d.sgpp(m.1 = M1, m.2 = M2, sd.1 = SD1, sd.2 = SD2,n = N, r = r)
      df.ES_4b$ES[df.ES_4b$DVtype == DVName & df.ES_4b$ExpID == expName & df.ES_4b$Effect == effectName] <- tmp2[1,1]
      df.ES_4b$ES.var[df.ES_4b$DVtype == DVName & df.ES_4b$ExpID == expName & df.ES_4b$Effect == effectName] <- tmp2[1,2]
    }
  }
}

df.ES_4b <- df.ES_4b %>%
  dplyr::mutate(Val = ifelse(Effect == "Self_Other_G", "Good",
                                  ifelse(Effect == "Self_Other_N", 'Neutral', 'Bad')),
                EffectType = 'Self_Other',
                Val = factor(Val, levels = c("Good", "Neutral", "Bad")))

#### Approach 2: compared between self and other
# Added the interaction in the effect size calculation directly
df.ES_4b_2 <- data.frame(matrix(nrow= (length(unique(df4b.meta.d$ExpID))*length(effectList_2) +3)*2 , ncol=0)) %>%
  dplyr::mutate(DVtype = rep(c('RT', 'dprime'), each = length(unique(df4b.meta.d$ExpID))*length(effectList_2) + 3),
                ExpID  = rep(rep(unique(df4b.meta.d$ExpID), each = length(effectList_2) + 3), 2),
                Effect = rep(c(effectList_2, c('Good_Bad_SO', 'Good_Neut_SO', 'Bad_Neut_SO')), length(unique(df4b.meta.d$ExpID))*2),
                M1 = NA, SD1 = NA, M2 = NA, SD2 = NA, N = NA, r = NA, ES = NA, ES.var = NA)

for (DVName in c('RT','dprime')){
  if (DVName == 'RT'){
    metaData <- df4b.meta.rt %>% dplyr::filter(Matchness == "Match") %>% dplyr::rename(Value = RT)
  } else{
    metaData <- df4b.meta.d %>% dplyr::rename(Value = dprime)
  }

  for (expName in unique(metaData$ExpID)){
    for (effectName in c(effectList_2, c('Good_Bad_SO', 'Good_Neut_SO', 'Bad_Neut_SO'))){
      tmpdata <- metaData %>% dplyr::filter(ExpID == expName & Domain == 'Morality')

      if (effectName == 'Good_Bad_S'){

        if (!all(is.na(tmpdata$Identity))){
          #print(paste('processing Good_Bad_S of ', expName, sep = ''))
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good" & Identity == 'Self')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Bad" & Identity == 'Self')
          }
        else{
            #print(paste('Skip Good_Bad_S of ', expName, sep = ''))
          next
          }
        }
      else if (effectName == 'Good_Neut_S'){
        if (!all(is.na(tmpdata$Identity)) & 'Neutral' %in% tmpdata$Valence ){
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good" & Identity == 'Self')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Neutral" & Identity == 'Self')
          }
        else{
          next
          }
        }
      else if (effectName == 'Bad_Neut_S'){
        if (!all(is.na(tmpdata$Identity)) & 'Neutral' %in% tmpdata$Valence ){
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Bad" & Identity == 'Self')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Neutral" & Identity == 'Self')
          }
        else{
          next
          }
        }
      else if (effectName == 'Good_Bad_O'){
        if (!all(is.na(tmpdata$Identity))){
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good" & Identity == 'Other')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Bad" & Identity == 'Other')
          }
        else{
          next
          }
        }
      else if (effectName == 'Good_Neut_O'){
        if (!all(is.na(tmpdata$Identity)) & 'Neutral' %in% tmpdata$Valence )
          {
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good" & Identity == 'Other')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Neutral" & Identity == 'Other')
          }
        else{
          next
          }
        }
      else if (effectName == 'Bad_Neut_O'){
        if (!all(is.na(tmpdata$Identity)) & 'Neutral' %in% tmpdata$Valence){
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Bad" & Identity == 'Other')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Neutral" & Identity == 'Other')
          }
        else{
          next
          }
      }
      else if (effectName == 'Good_Bad_SO'){
        if (!all(is.na(tmpdata$Identity))){
          dataCond01 <- tmpdata %>% dplyr::filter(Valence == "Good" & Identity == 'Self')
          dataCond02 <- tmpdata %>% dplyr::filter(Valence == "Bad" & Identity == 'Self')
          dataCond03 <- tmpdata %>% dplyr::filter(Valence == "Good" & Identity == 'Other')
          dataCond04 <- tmpdata %>% dplyr::filter(Valence == "Bad" & Identity == 'Other') 
          
          dataCond1 <- dataCond01 %>% dplyr::mutate(Value = Value - dataCond02$Value)  # good-self - bad-self 
          dataCond2 <- dataCond03 %>% dplyr::mutate(Value = Value - dataCond04$Value)   # good-other - bad-other
          }
        else{
          next
          }
        }
      else if (effectName == 'Good_Neut_SO'){
        if (!all(is.na(tmpdata$Identity)) & 'Neutral' %in% tmpdata$Valence )
          {
          dataCond01 <- tmpdata %>% dplyr::filter(Valence == "Good" & Identity == 'Self') 
          dataCond02 <- tmpdata %>% dplyr::filter(Valence == "Neutral" & Identity == 'Self')
          dataCond03 <- tmpdata %>% dplyr::filter(Valence == "Good" & Identity == 'Other')
          dataCond04 <- tmpdata %>% dplyr::filter(Valence == "Neutral" & Identity == 'Other')
          
          dataCond1 <- dataCond01 %>% dplyr::mutate(Value = Value - dataCond02$Value)   # good-self - neutral-self 
          dataCond2 <- dataCond03 %>% dplyr::mutate(Value = Value - dataCond04$Value)   # good-other - neutral-other
          }
        else{
          next
          }
        }
      else if (effectName == 'Bad_Neut_SO'){
        if (!all(is.na(tmpdata$Identity)) & 'Neutral' %in% tmpdata$Valence){
          dataCond01 <- tmpdata %>% dplyr::filter(Valence == "Bad" & Identity == 'Self')
          dataCond02 <- tmpdata %>% dplyr::filter(Valence == "Neutral" & Identity == 'Self')
          dataCond03 <- tmpdata %>% dplyr::filter(Valence == "Bad" & Identity == 'Other')
          dataCond04 <- tmpdata %>% dplyr::filter(Valence == "Neutral" & Identity == 'Other')
          
          dataCond1 <- dataCond01 %>% dplyr::mutate(Value = Value - dataCond02$Value) # bad-self - neutral-self
          dataCond2 <- dataCond03 %>% dplyr::mutate(Value = Value - dataCond04$Value) # bad-other - neutral-other
          }
        else{
          next
          }
      }
      M1  <- mean(dataCond1$Value) -> df.ES_4b_2$M1[df.ES_4b_2$DVtype == DVName & df.ES_4b_2$ExpID == expName & df.ES_4b_2$Effect == effectName]
      SD1 <- sd(dataCond1$Value)   -> df.ES_4b_2$SD1[df.ES_4b_2$DVtype == DVName & df.ES_4b_2$ExpID == expName & df.ES_4b_2$Effect == effectName]
      M2  <- mean(dataCond2$Value) -> df.ES_4b_2$M2[df.ES_4b_2$DVtype == DVName & df.ES_4b_2$ExpID == expName & df.ES_4b_2$Effect == effectName]
      SD2 <- sd(dataCond2$Value)   -> df.ES_4b_2$SD2[df.ES_4b_2$DVtype == DVName & df.ES_4b_2$ExpID == expName & df.ES_4b_2$Effect == effectName]
      N   <- length(unique(dataCond2$Subject)) -> df.ES_4b_2$N[df.ES_4b_2$DVtype == DVName & df.ES_4b_2$ExpID == expName & df.ES_4b_2$Effect == effectName]
      r   <- cor(dataCond1$Value,dataCond2$Value) -> df.ES_4b_2$r[df.ES_4b_2$DVtype == DVName & df.ES_4b_2$ExpID == expName & df.ES_4b_2$Effect == effectName]
      tmp2 <- d.sgpp(m.1 = M1, m.2 = M2, sd.1 = SD1, sd.2 = SD2,n = N, r = r)
      df.ES_4b_2$ES[df.ES_4b_2$DVtype == DVName & df.ES_4b_2$ExpID == expName & df.ES_4b_2$Effect == effectName] <- tmp2[1,1]
      df.ES_4b_2$ES.var[df.ES_4b_2$DVtype == DVName & df.ES_4b_2$ExpID == expName & df.ES_4b_2$Effect == effectName] <- tmp2[1,2]
    }
  }
}

df.ES_4b_2 <- df.ES_4b_2 %>%
  dplyr::mutate(Identity = ifelse(Effect == "Good_Bad_S" | Effect == "Good_Neut_S" | Effect == "Bad_Neut_S",
                                  "Self-ref.", 
                                  ifelse(Effect == "Good_Bad_O" | Effect == "Good_Neut_O" | Effect == "Bad_Neut_O", 
                                         "Other-ref.", 'Interaction')),
                EffectType = ifelse(Effect == "Good_Bad_S" | Effect == "Good_Bad_O"  | Effect == "Good_Bad_SO", "Good_Bad",
                                    ifelse(Effect == "Good_Neut_S" | Effect == "Good_Neut_O"  | Effect == "Good_Neut_SO", "Good_Neut", "Bad_Neut")),
                Identity = factor(Identity, levels = c("Self-ref.", "Other-ref.", 'Interaction')),
                EffectType = factor(EffectType, levels = c("Good_Bad", "Good_Neut", "Bad_Neut")))
```

```{r 'plot-exp4b-effect-1', fig.cap="Effect size (Cohen's *d*) of Valence in Exp4b.", warning=FALSE}
df.ES_4b %>%
  #dplyr::filter(Identity == "Self") %>%
  ggplot(., aes(x=EffectType, y=ES, color=Val, fill=Val)) + # , color=Val, fill=Val
  geom_pointrange(aes(ymin=ES - 1.96*sqrt(ES.var), ymax = ES + 1.96*sqrt(ES.var)),
                  position = position_dodge(width = 0.5),
                  shape=18, size=0.8) +
  geom_hline(yintercept=0, size=0.5, color='grey', linetype = 'dashed') +
  # ggtitle('Self-reference effect') +
  coord_cartesian(ylim=c(-1.1, 1.1))+
  scale_color_brewer(palette = "Dark2")+
  scale_fill_brewer(palette = "Dark2")+
  ylab(expression(paste("Cohen's ",italic("d"), sep = ' '))) +
  xlab('Self-reference effect') + 
  apatheme_x +
  facet_grid(DVtype ~ .)
```

```{r 'plot-exp4b-effect-2', fig.cap="Effect size (Cohen's *d*) of Valence in Exp4b.", warning=FALSE}
df.ES_4b_2 %>%
  dplyr::filter(Effect %in% effectList_2) %>%
  dplyr::filter(EffectType != "Good_Bad") %>%
  ggplot(., aes(x=EffectType, y=ES, color=EffectType, fill=EffectType)) +
  geom_pointrange(aes(ymin=ES - 1.96*sqrt(ES.var), ymax = ES + 1.96*sqrt(ES.var)),
                  position = position_dodge(width = 0.5),
                  shape=18, size=1) +
  geom_hline(yintercept=0, size=1, color='grey', linetype = 'dashed') +
  # ggtitle('A: Valence effect') +
  coord_cartesian(ylim=c(-1.1, 1.1))+
  scale_color_brewer(palette = "Dark2")+
  scale_fill_brewer(palette = "Dark2")+
  ylab(expression(paste("Effect size: Cohen's ",italic("d"), sep = ' ')))+
  xlab('Valence effect')+
  apatheme_x +
  facet_grid(DVtype ~ Identity)
```

```{r 'plot-exp4b-diff-diff', fig.cap="Effect size (Cohen's *d*) of Valence in Exp4b.", warning=FALSE}
df.ES_4b_2 %>%
  #dplyr::filter(Effect %in% c('Good_Bad_SO', 'Good_Neut_SO', 'Bad_Neut_SO')) %>%
  dplyr::filter(Effect %in% c('Good_Neut_SO', 'Bad_Neut_SO')) %>%
  ggplot(., aes(x=EffectType, y=ES, color=EffectType, fill=EffectType)) + 
  geom_pointrange(aes(ymin=ES - 1.96*sqrt(ES.var), ymax = ES + 1.96*sqrt(ES.var)), 
                  position = position_dodge(width = 0.5),
                  shape=18, size=0.8) +
  geom_hline(yintercept=0, size=0.5, color='grey', linetype = 'dashed') +
  # ggtitle('Differences in valence effect (self-other)') +
  coord_cartesian(ylim=c(-1.1, 1.1))+
  scale_color_brewer(palette = "Dark2")+
  scale_fill_brewer(palette = "Dark2")+
  ylab(expression(paste("Effect size: Cohen's ",italic("d"), sep = ' ')))+
  xlab('Diff of valence effect between self vs. other condition')+
  apatheme_x +
  facet_grid(DVtype ~ .)
  # facet_wrap(~ DVtype, strip.position="right")
```

For experiment 4b, when valence was the target and the identity was task-irrelevant, we found a strong valence effect (see supplementary results and Figure \@ref(fig:plot-exp4b-effect-1), Figure \@ref(fig:plot-exp4b-effect-2)). 

In this experiment, the advantage of good-self condition can only be disentangled by comparing the self-referential and other-referential conditions. Therefore, we calculated the differences between the valence effect under self-referential and other referential conditions and used the weighted variance as the variance of this differences. We found this modulation effect on RT. The valence effect of RT was stronger in self-referential than other-referential for the Good vs. Neutral condition (`r df.ES_4b_2$ES[df.ES_4b_2$DVtype == 'RT' & df.ES_4b_2$Effect == 'Good_Neut_SO']` $\pm$ `r df.ES_4b_2$ES.var[df.ES_4b_2$DVtype == 'RT' & df.ES_4b_2$Effect == 'Good_Neut_SO']`), and to a less extent the Good vs. Bad condition (`r df.ES_4b_2$ES[df.ES_4b_2$DVtype == 'RT' & df.ES_4b_2$Effect == 'Good_Bad_SO']` $\pm$ `r df.ES_4b_2$ES.var[df.ES_4b_2$DVtype == 'RT' & df.ES_4b_2$Effect == 'Good_Bad_SO']`). While the size of the other effect's CI included zero, suggestion those effects didn't differ from zero. See Figure \@ref(fig:plot-exp4b-diff-diff).

## Specificity of valence effect

```{r analyzing exp5, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
effectList_exp5 <- c('Good_Bad_Mrl','Good_Neut_Mrl','Bad_Neut_Mrl',
                     'Good_Bad_BP','Good_Neut_BP','Bad_Neut_BP',
                     'Good_Bad_BS','Good_Neut_BS','Bad_Neut_BS',
                     'Good_Bad_Emo','Good_Neut_Emo','Bad_Neut_Emo')

df.ES_5 <- data.frame(matrix(nrow=length(unique(df5.meta.d$ExpID))*length(effectList_exp5)*2, ncol=0)) %>%
  dplyr::mutate(DVtype = rep(c('RT', 'dprime'), each = length(unique(df5.meta.d$ExpID))*length(effectList_exp5)),
                ExpID  = rep(rep(unique(df5.meta.d$ExpID), each = length(effectList_exp5)), 2),
                Effect = rep(effectList_exp5, length(unique(df5.meta.d$ExpID))*2),
                M1 = NA, SD1 = NA, M2 = NA, SD2 = NA, N = NA, r = NA, ES = NA, ES.var = NA)

for (DVName in c('RT','dprime')){
  if (DVName == 'RT'){
    metaData <- df5.meta.rt %>% dplyr::filter(Matchness == "Match") %>% dplyr::rename(Value = RT)
  } else{
    metaData <- df5.meta.d %>% dplyr::rename(Value = dprime)
  }
  
  for (expName in unique(metaData$ExpID)){
    for (effectName in effectList_exp5){
      if (effectName == 'Good_Bad_Mrl'){
        tmpdata <- metaData %>% dplyr::filter(ExpID == expName & Domain == 'Morality')
        dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good")
        dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Bad")  
        }
      else if (effectName == 'Good_Neut_Mrl'){
        tmpdata <- metaData %>% dplyr::filter(ExpID == expName & Domain == 'Morality')
        dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good")
        dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Neutral")  
        }  
      else if (effectName == 'Bad_Neut_Mrl'){
        tmpdata <- metaData %>% dplyr::filter(ExpID == expName & Domain == 'Morality')
        dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Bad")
        dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Neutral")
      }
      
      else if (effectName == 'Good_Bad_BP'){
        tmpdata <- metaData %>% dplyr::filter(ExpID == expName & Domain == 'Person')
        dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good")
        dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Bad")  
        }
      else if (effectName == 'Good_Neut_BP'){
        tmpdata <- metaData %>% dplyr::filter(ExpID == expName & Domain == 'Person')
        dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good")
        dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Neutral")  
        }  
      else if (effectName == 'Bad_Neut_BP'){
        tmpdata <- metaData %>% dplyr::filter(ExpID == expName & Domain == 'Person')
        dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Bad")
        dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Neutral")
      }
      
      else if (effectName == 'Good_Bad_BS'){
        tmpdata <- metaData %>% dplyr::filter(ExpID == expName & Domain == 'Scene')
        dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good")
        dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Bad")  
        }
      else if (effectName == 'Good_Neut_BS'){
        tmpdata <- metaData %>% dplyr::filter(ExpID == expName & Domain == 'Scene')
        dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good")
        dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Neutral")  
        }  
      else if (effectName == 'Bad_Neut_BS'){
        tmpdata <- metaData %>% dplyr::filter(ExpID == expName & Domain == 'Scene')
        dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Bad")
        dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Neutral")
      }
      
      else if (effectName == 'Good_Bad_Emo'){
        tmpdata <- metaData %>% dplyr::filter(ExpID == expName & Domain == 'Emotion')
        dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good")
        dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Bad")  
        }
      else if (effectName == 'Good_Neut_Emo'){
        tmpdata <- metaData %>% dplyr::filter(ExpID == expName & Domain == 'Emotion')
        dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good")
        dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Neutral")  
        }  
      else if (effectName == 'Bad_Neut_Emo'){
        tmpdata <- metaData %>% dplyr::filter(ExpID == expName & Domain == 'Emotion')
        dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Bad")
        dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Neutral")
        }
      
      M1  <- mean(dataCond1$Value) -> df.ES_5$M1[df.ES_5$DVtype == DVName & df.ES_5$ExpID == expName & df.ES_5$Effect == effectName]
      SD1 <- sd(dataCond1$Value)   -> df.ES_5$SD1[df.ES_5$DVtype == DVName & df.ES_5$ExpID == expName & df.ES_5$Effect == effectName] 
      M2  <- mean(dataCond2$Value) -> df.ES_5$M2[df.ES_5$DVtype == DVName & df.ES_5$ExpID == expName & df.ES_5$Effect == effectName]
      SD2 <- sd(dataCond2$Value)   -> df.ES_5$SD2[df.ES_5$DVtype == DVName & df.ES_5$ExpID == expName & df.ES_5$Effect == effectName]
      N   <- length(unique(dataCond2$Subject)) -> df.ES_5$N[df.ES_5$DVtype == DVName & df.ES_5$ExpID == expName & df.ES_5$Effect == effectName]
      r   <- cor(dataCond1$Value,dataCond2$Value) -> df.ES_5$r[df.ES_5$DVtype == DVName & df.ES_5$ExpID == expName & df.ES_5$Effect == effectName] 
      tmp2 <- d.sgpp(m.1 = M1, m.2 = M2, sd.1 = SD1, sd.2 = SD2,n = N, r = r)
      df.ES_5$ES[df.ES_5$DVtype == DVName & df.ES_5$ExpID == expName & df.ES_5$Effect == effectName] <- tmp2[1,1]
      df.ES_5$ES.var[df.ES_5$DVtype == DVName & df.ES_5$ExpID == expName & df.ES_5$Effect == effectName] <- tmp2[1,2]
    }
  }
}

df.ES_5 <- df.ES_5 %>%
  dplyr::mutate(Domain = ifelse(Effect == "Good_Bad_Mrl" | Effect == "Good_Neut_Mrl" | Effect == "Bad_Neut_Mrl",
                                  "Mrl",
                                ifelse(Effect == "Good_Bad_BP" | Effect == "Good_Neut_BP" | Effect == "Bad_Neut_BP",
                                  "AP",
                                  ifelse(Effect == "Good_Bad_BS" | Effect == "Good_Neut_BS" | Effect == "Bad_Neut_BS",
                                  "AS", 'Emo'))),
                Domain = factor(Domain, levels = c("Mrl", "AP", "AS", "Emo")),
                EffectType = ifelse(Effect == "Good_Bad_Mrl" | Effect == "Good_Bad_BP"  | Effect == "Good_Bad_BS"  | Effect == "Good_Bad_Emo", "Pos_Neg",
                                    ifelse(Effect == "Good_Neut_Mrl" | Effect == "Good_Neut_BP" | Effect == "Good_Neut_BS" | Effect == "Good_Neut_Emo", "Pos_Neut", "Neg_Neut")),
                EffectType = factor(EffectType, levels = c("Pos_Neg", "Pos_Neut", "Neg_Neut")))
```

```{r 'plot-exp5-effect', fig.cap="Effect size (Cohen's *d*) of Valence in Exp5.", warning=FALSE}
df.ES_5 %>%
  dplyr::filter(EffectType != "Pos_Neg") %>%
  ggplot(., aes(x=EffectType, y=ES, color=EffectType, fill=EffectType)) + 
  geom_pointrange(aes(ymin=ES - 1.96*sqrt(ES.var), ymax = ES + 1.96*sqrt(ES.var)), 
                  position = position_dodge(width = 0.4),
                  shape=18, size=1) +
  geom_hline(yintercept=0, size=1, color='black') +
  # ggtitle('Valence effect across different domains') +
  coord_cartesian(ylim=c(-1.5, 1.5))+
  scale_color_brewer(palette = "Dark2")+
  scale_fill_brewer(palette = "Dark2")+
  ylab(expression(paste("Effect size: Cohen's ",italic("d"), sep = ' '))) +
  xlab('Contrast between different valences') +
  facet_grid(DVtype ~ Domain) +
  apatheme_x
```

In this part, we analyzed the results from experiment 5, which included positive, neutral, and negative valence from four different domains: morality, emotion, aesthetics of human, and aesthetics of scene. We found interaction between valence and domain for both *d* prime and RT (match trials). A common pattern appeared in all four domains: each domain showed a binary results instead of gradient on both *d* prime and RT. For morality, aesthetics of human, and aesthetics of scene, the positive conditions had advantages over both neutral and negative conditions (greater *d* prime and faster RT), and neutral and negative conditions didn't differ from each other. But for the emotional stimuli, it was the positive and neutral had advantage over negative conditions, while positive and neutral conditions were not significantly different. See supplementary materials for detailed statistics. Also note that the effect size in moral domain is smaller than the aesthetic domains (beauty of people and beauty of scene). See Figure \@ref(fig:plot-exp5-effect).

## Self-reported personal distance

```{r personal distance, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
# prepare questionnaire data
df.scales <- read.csv(here::here("Scale_data", "FADGS_dataset4ID_clean.csv"), header = TRUE, sep = ",",
                 stringsAsFactors=FALSE,na.strings=c("","NA")) %>%
  dplyr::mutate(expID = derivedFactor("Exp1a" = (expID == "exp1.0"), 
                                      "Exp1b" = (expID == "exp1.1"),
                                      "Exp3a" = (expID == "exp3"),
                                      "Exp3b" = (expID == "exp3.1"),
                                      "Exp4a" = (expID == "exp4.1"),
                                      "Exp4b" = (expID == "exp4.2"),
                                      "Exp5" = (expID == "exp5.2"),
                                      "Exp6b" = (expID == "exp6.2"),
                                      "Exp7a" = (expID == "exp7.1"),
                                      "Exp7b" = (expID == "exp7r"),
                                      "Exp_dpr" = (expID == "exp6"),
                                      .method ="first", .default = NA),
                expID = as.character(expID))

## get the questionnaire names
# Self-esteem
SlfEstNames <- c("SES1","SES2","SES3","SES4","SES5","SES6","SES7","SES8","SES9","SES10")

# moral identity
mrlIdNames <- c("morId_1","morId_2","morId_3","morId_4", "morId_5","morId_6",
                "morId_7","morId_8","morId_9","morId_10","morId_11","morId_12",
                "morId_13","morId_14","morId_15","morId_16")
mrlIdIntNames <- c("morId_1","morId_2","morId_5","morId_8", "morId_10","morId_11",
                   "morId_12","morId_13","morId_14")
mrlIdExtNames <- c("morId_3","morId_4", "morId_6", "morId_7", "morId_9","morId_10",
                   "morId_15", "morId_16")

# moral self images
mrlslfImgNames <- c("morSlfImg_1","morSlfImg_2","morSlfImg_3","morSlfImg_4",
                    "morSlfImg_5","morSlfImg_6","morSlfImg_7","morSlfImg_8","morSlfImg_9")

# personal distance
perDistNames <- c("SelfSelf", 
                  "SelfGood_1", "SelfGood_2", "SelfGood_3", "SelfGood_4",
                  "SelfNeut_1", "SelfNeut_2", "SelfNeut_3", "SelfNeut_4",
                  "SelfBad_1",  "SelfBad_2",  "SelfBad_3",  "SelfBad_4",
                  "SelfStra_1", "SelfStra_2", "SelfStra_3", "SelfStra_4",
                  "GoodNeut_1", "GoodNeut_2", "GoodNeut_3", "GoodNeut_4", 
                  "GoodBad_1",  "GoodBad_2",  "GoodBad_3",  "GoodBad_4",
                  "NeutBad_1",  "NeutBad_2",  "NeutBad_3",  "NeutBad_4")

df.perdist <- df.scales %>%
  dplyr::select(c(expID, subjID),perDistNames) %>%
  #dplyr::rowwise() %>%
  dplyr::mutate(sumRaw = rowMeans(.[3:31], na.rm = T),
                SelfSelfraw = SelfSelf,
                SelfGoodraw = rowMeans(.[grep("SelfGood", names(.))], na.rm = T),
                SelfNeutraw = rowMeans(.[grep("SelfNeut", names(.))], na.rm = T),
                SelfBadraw  = rowMeans(.[grep("SelfBad", names(.))], na.rm = T),
                SelfStraraw = rowMeans(.[grep("SelfStra", names(.))], na.rm = T),
                GoodNeutraw = rowMeans(.[grep("GoodNeut", names(.))], na.rm = T),
                GoodBadraw  = rowMeans(.[grep("GoodBad", names(.))], na.rm = T),
                NeutBadraw  = rowMeans(.[grep("NeutBad", names(.))], na.rm = T)) %>%
  dplyr::select(expID, subjID, sumRaw, SelfSelfraw, 
                SelfGoodraw, SelfNeutraw, SelfBadraw,
                SelfStraraw, GoodNeutraw, GoodBadraw, NeutBadraw) %>%
  dplyr::mutate(SelfSelf = SelfSelfraw/sumRaw,
                SelfGood = SelfGoodraw/sumRaw,
                SelfNeut = SelfNeutraw/sumRaw,
                SelfBad = SelfBadraw/sumRaw,
                SelfStra = SelfStraraw/sumRaw, 
                GoodNeut = GoodNeutraw/sumRaw, 
                GoodBad = GoodBadraw/sumRaw, 
                NeutBad = NeutBadraw/sumRaw) %>%
  dplyr::select(subjID, SelfSelf, SelfGood, SelfNeut, SelfBad,
                SelfStra, GoodNeut, GoodBad, NeutBad) %>%
  tidyr::drop_na()
```

```{r plot-person-dist, fig.cap="Self-rated personal distance", fig.width=8, warning=FALSE}
df.plot <- df.perdist %>%
    dplyr::select(-c(SelfSelf, SelfStra)) %>%
    tidyr::pivot_longer(., cols = SelfGood:NeutBad, 
                        names_to = 'PerDist', 
                        values_to = "value") %>% # to longer format
    dplyr::mutate(PerDist =factor(PerDist, levels = c('SelfNeut', 'SelfGood', 'GoodNeut', 'NeutBad', 'GoodBad', 'SelfBad')),
                  # DVs = factor(DVs, levels = c('RT', 'dprime')),
                  # create an extra column for ploting the individual data cross different conditions.
                  Conds = mosaic::derivedFactor("1" = (PerDist == 'SelfNeut'), 
                                                "2" = (PerDist == 'SelfGood'),
                                                "3" = (PerDist == 'GoodNeut'),
                                                "4" = (PerDist == 'NeutBad'),
                                                "5" = (PerDist == 'GoodBad'),
                                                "6" = (PerDist == 'SelfBad'),
                                                method ="first", .default = NA),
                  Conds = as.numeric(as.character(Conds)),
    ) 
  
  df.plot$Conds_j <- jitter(df.plot$Conds, amount=.09) # add gitter to x
  
  # New facet label names for panel variable
  # https://stackoverflow.com/questions/34040376/cannot-italicize-facet-labels-with-labeller-label-parsed
  # levels(df.plot$DVs ) <- c("RT"=expression(paste("Reaction ", "times (ms)")),
  #                           "dprime"=expression(paste(italic("d"), ' prime')))
  # levels(df.plot$DVs ) <- c("RT"=expression(paste("Reaction ", "times (ms)")),
  #                           "dprime"=expression(paste(italic("d"), ' prime')))
  
  df.plot.sum_p <- summarySE(df.plot, measurevar = "value", groupvars = c('PerDist')) %>%
    dplyr::mutate(Cond_num = mosaic::derivedFactor("1" = (PerDist == 'SelfNeut'), 
                                                "2" = (PerDist == 'SelfGood'),
                                                "3" = (PerDist == 'GoodNeut'),
                                                "4" = (PerDist == 'NeutBad'),
                                                "5" = (PerDist == 'GoodBad'),
                                                "6" = (PerDist == 'SelfBad'),
                                                method ="first", .default = NA),
                  Cond_num = as.numeric(as.character(Cond_num)))
  
  pd1 <- position_dodge(0.5)
  # scaleFUN <- function(x) sprintf("%.2f", x)
  # scales_y <- list(
  #   RT = scale_y_continuous(limits = c(400, 900)),
  #   dprime = scale_y_continuous(labels=scaleFUN)
  #)
  
  df.plot  %>% # dplyr::filter(DVs== 'RT') %>%
    dplyr::rename(Subject=subjID) %>%
    ggplot(., aes(x = PerDist, y = value, colour = as.factor(Valence))) +
    geom_line(aes(x = Conds_j, y = value, group = Subject),         # link individual's points by transparent grey lines
              linetype = 1, size = 1, colour = "#000000", alpha = 0.03) + 
    geom_point(aes(x = Conds_j, y = value, group = Subject),   # plot individual points
               colour = "#000000",
               size = 1, shape = 20, alpha = 0.03) +
    geom_line(data = df.plot.sum_p, aes(x = as.numeric(PerDist), # plot the group means  
                                        y = value, 
                                        #group = Identity, 
                                        colour = PerDist,
    ), 
    linetype = 1, position = pd1, size = 2)+
    geom_point(data = df.plot.sum_p, aes(x = as.numeric(PerDist), # group mean
                                         y = value, 
                                         #group = Identity, 
                                         colour = PerDist,
    ), 
    shape = 18, position = pd1, size = 5) +
    geom_errorbar(data = df.plot.sum_p, aes(x = as.numeric(PerDist),  # group error bar.
                                            y = value, # group = Identity, 
                                            colour = PerDist,
                                            ymin = value- 1.96*se, 
                                            ymax = value+ 1.96*se), 
                  width = .05, size = 1, alpha = 0.75) +
    scale_colour_brewer(palette = "Dark2") +
    scale_x_continuous(breaks=c(1, 2, 3, 4, 5, 6),
                       labels=c("SelfNeut", "SelfGood", "GoodNeut", 'NeutBad', 'GoodBad', 'SelfBad')) +
    scale_fill_brewer(palette = "Dark2") +
    #ggtitle("A. Matching task") +
    theme_bw()+
    theme(panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          panel.background = element_blank(),
          panel.border = element_blank(),
          text=element_text(family='Times'),
          legend.title=element_blank(),
          legend.text = element_text(size =16),
          plot.title = element_text(lineheight=.8, face="bold", size = 18, margin=margin(0,0,20,0)),
          axis.text = element_text (size = 16, color = 'black'),
          axis.title = element_text (size = 16),
          axis.title.x = element_blank(),
          axis.title.y = element_blank(),
          axis.line.x = element_line(color='black', size = 1),    # increase the size of font
          axis.line.y = element_line(color='black', size = 1),    # increase the size of font
          strip.text = element_text (size = 16, color = 'black'), # size of text in strips, face = "bold"
          panel.spacing = unit(3, "lines")
    ) 
```

See Figure \@ref(fig:plot-person-dist).

## Correlation analyses
The reliability of questionnaires can be found in [@Liu_2020_JOPD]. We calculated the correlation between the data from behavioral task and the questionnaire data. 

```{r correlation analysis,echo=FALSE, results='hide', warning=FALSE, message=FALSE}
# get data for valence effect ---- 
## mean RT, SD of RT, and d prime for data without reference
tmp1 <- df.meta_rt_1 %>%
  dplyr::filter(Matchness == "Match" & Domain == 'Morality') %>%
  tidyr::pivot_wider(names_from = c(Valence), values_from = c(RT, RT_SD))
  
tmp2 <- df.meta_d_1 %>%
  dplyr::filter(Domain == 'Morality') %>%
  tidyr::pivot_wider(names_from = c(Valence), values_from = dprime) %>%
  dplyr::rename(dprime_Good = Good,
                dprime_Neut = Neutral,
                dprime_Bad = Bad)
  
df.meta_1_wide <- merge(tmp1,tmp2)
rm(tmp1,tmp2)

## parameters of HDDM for the data without reference
## read all the file name.
params.list <- list.files(here::here('HDDM'), pattern = '*_hddm_params.csv')
params.expname <- data.frame(params.list) %>%
  tidyr::separate(params.list, c('expName','B','C'),sep = '_') %>%
  dplyr::select(expName) %>%
  dplyr::pull()

df_hddm_ls_1 <- params.list[c(1:4, 9:10)]

for (indx in 1:6){
  if ((indx ==1) && exists('df_hddm_param_1')){   # if the variable already exist before the for loop start
    rm(df_hddm_param_1)
  }

  if (indx == 5 ){
    hddm_params_tmp <- read.csv(here::here("HDDM", df_hddm_ls_1[indx]), header = TRUE, sep = ",",
                   stringsAsFactors=FALSE,na.strings=c("","NA")) %>%
      dplyr::filter(domain == "Morality") %>%
      dplyr::rename(Subject = subj_idx, Matchness = match, Valence = val) %>%
      dplyr::select(Subject, Matchness, Valence, knode_name, mean) %>%
      tidyr::drop_na() %>%
      tidyr::separate(knode_name, into = paste('v', 1:2, sep= '')) %>%
      dplyr::rename(param = v1)  %>% dplyr::filter(Matchness=='Match') %>% dplyr::select(- c(v2, Matchness)) %>%
      tidyr::pivot_wider(., names_from = c('Valence', 'param'), values_from = 'mean')  
    
  } else {
    hddm_params_tmp <- read.csv(here::here("HDDM", df_hddm_ls_1[indx]), header = TRUE, sep = ",",
                   stringsAsFactors=FALSE,na.strings=c("","NA")) %>%
      dplyr::rename(Subject = subj_idx, Matchness = match, Valence = val) %>%
      dplyr::select(Subject, Matchness, Valence, knode_name, mean) %>%
      tidyr::drop_na() %>%
      tidyr::separate(knode_name, into = paste('v', 1:2, sep= '')) %>%
      dplyr::rename(param = v1)  %>% dplyr::filter(Matchness=='Match') %>% dplyr::select(- c(v2, Matchness)) %>%
      tidyr::pivot_wider(., names_from = c('Valence', 'param'), values_from = 'mean')   # %>%
      #dplyr::mutate(ExpID = 'Exp1a')
  }
  if (exists('df_hddm_param_1')) {
    df_hddm_param_1 <- rbind(df_hddm_param_1, hddm_params_tmp) 
  } else {
    df_hddm_param_1 <- hddm_params_tmp
  }
}

df.meta_1_wide <- merge(df.meta_1_wide, df_hddm_param_1) %>%
  dplyr::select(-c(Domain, Identity, Matchness))

## Get data for interaction between ID & Val ----
## mean RT, SD of RT, and d prime for data without reference
tmp1 <- df.meta_rt_2 %>%
  dplyr::filter(Matchness == "Match" & Domain == 'Morality') %>%
  tidyr::pivot_wider(names_from = c(Valence), values_from = c(RT, RT_SD))
  
tmp2 <- df.meta_d_2 %>%
  dplyr::filter(Domain == 'Morality') %>%
  tidyr::pivot_wider(names_from = c(Valence), values_from = dprime) %>%
  dplyr::rename(dprime_Good = Good,
                dprime_Neut = Neutral,
                dprime_Bad = Bad)
  
df.meta_2_wide <- merge(tmp1,tmp2); rm(tmp1,tmp2)

## parameters of HDDM 
## read all the file name.
df_hddm_ls_2 <- params.list[c(5, 6, 11:13)]

for (indx in 1:5){
  if ((indx ==1) && exists('df_hddm_param_1')){   # in case the variable exist in the env.
    rm(df_hddm_param_2)
  }
  hddm_params_tmp <- read.csv(paste(here::here("HDDM", df_hddm_ls_2[indx])), header = TRUE, sep = ",",
                 stringsAsFactors=FALSE,na.strings=c("","NA")) %>%
    dplyr::rename(Subject = subj_idx, Matchness = match, Valence = val, Identity = id) %>%
    dplyr::select(Subject, Matchness, Identity, Valence, knode_name, mean) %>%
    tidyr::drop_na() %>%
    tidyr::separate(knode_name, into = paste('v', 1:2, sep= '')) %>%
    dplyr::rename(param = v1)  %>% dplyr::filter(Matchness=='Match') %>% dplyr::select(- c(v2, Matchness)) %>%
    tidyr::pivot_wider(., names_from = c('Valence', 'param'), values_from = 'mean')   # %>%
    #dplyr::mutate(ExpID = 'Exp1a')
  if (indx == 4 | indx == 5){
    hddm_params_tmp <- hddm_params_tmp %>%
      dplyr::mutate(Neutral_a = NA,
                    Neutral_t = NA,
                    Neutral_v = NA) %>%
      dplyr::select(Subject, Identity, Bad_a, Good_a, Neutral_a, Bad_v, Good_v, Neutral_v, Bad_t, Good_t,
                    Neutral_t)
  }
  
  if (exists('df_hddm_param_2')) {
    df_hddm_param_2 <- rbind(df_hddm_param_2, hddm_params_tmp) 
  } else {
    df_hddm_param_2 <- hddm_params_tmp
  }
}

df.meta_2_wide <- merge(df.meta_2_wide, df_hddm_param_2) %>%
  dplyr::select(-c(Domain, Matchness))

df.meta_1_wide <- df.meta_1_wide %>%
  dplyr::mutate(Identity = NA) %>%
  dplyr::select(colnames(df.meta_2_wide))

df.meta_all_wide <- df.meta_2_wide %>%
  dplyr::filter(Identity == "Self") %>%
  rbind(df.meta_1_wide, .)

# intersection between participant from behavioral task and scales and get the data
subj.common <- intersect(df.scales$subjID, unique(df.meta_all_wide$Subject))  # 253

df.scales.v <- df.scales %>% dplyr::filter(subjID %in% subj.common) %>%
  dplyr::select_if(~sum(!is.na(.)) > 0) # remove columns that only have NA.


df.mrlID <- df.scales.v[c('subjID', mrlIdIntNames, mrlIdExtNames)] %>%
  #tidyr::drop_na() %>%
  dplyr::mutate(mrlIdInt = rowMeans(.[, mrlIdIntNames], na.rm = F),
                mrlIdExt = rowMeans(.[, mrlIdExtNames], na.rm = F),)
# plot(df.mrlID$mrlIdInt)

# calculate the average score of each relevant scale
df.q_scores.v <- df.scales.v %>%
  dplyr::mutate(SlfEst = rowMeans(.[, SlfEstNames],na.rm = F),
                mrlIdInt = rowMeans(.[, mrlIdIntNames], na.rm = F),
                mrlIdExt = rowMeans(.[, mrlIdExtNames], na.rm = F),
                mrlslfImg = rowMeans(.[, mrlslfImgNames], na.rm = F),
                ) %>%
  dplyr::select(subjID, SlfEst, mrlIdInt, mrlIdExt, mrlslfImg)

df.perdist.v <- df.scales.v %>%
  dplyr::select(c(expID, subjID),perDistNames) %>%
  #dplyr::rowwise() %>%
  dplyr::mutate(sumRaw = rowMeans(.[3:31], na.rm = T),
                SelfSelfraw = SelfSelf,
                SelfGoodraw = rowMeans(.[grep("SelfGood", names(.))], na.rm = T),
                SelfNeutraw = rowMeans(.[grep("SelfNeut", names(.))], na.rm = T),
                SelfBadraw  = rowMeans(.[grep("SelfBad", names(.))], na.rm = T),
                SelfStraraw = rowMeans(.[grep("SelfStra", names(.))], na.rm = T),
                GoodNeutraw = rowMeans(.[grep("GoodNeut", names(.))], na.rm = T),
                GoodBadraw  = rowMeans(.[grep("GoodBad", names(.))], na.rm = T),
                NeutBadraw  = rowMeans(.[grep("NeutBad", names(.))], na.rm = T)) %>%
  dplyr::select(expID, subjID, sumRaw, SelfSelfraw, 
                SelfGoodraw, SelfNeutraw, SelfBadraw,
                SelfStraraw, GoodNeutraw, GoodBadraw, NeutBadraw) %>%
  dplyr::mutate(SelfSelf = SelfSelfraw/sumRaw,
                SelfGood = SelfGoodraw/sumRaw,
                SelfNeut = SelfNeutraw/sumRaw,
                SelfBad = SelfBadraw/sumRaw,
                SelfStra = SelfStraraw/sumRaw, 
                GoodNeut = GoodNeutraw/sumRaw, 
                GoodBad = GoodBadraw/sumRaw, 
                NeutBad = NeutBadraw/sumRaw) %>%
  dplyr::select(subjID, SelfSelf, SelfGood, SelfNeut, SelfBad,
                SelfStra, GoodNeut, GoodBad, NeutBad)

df.q_scores.v <- merge(df.q_scores.v, df.perdist.v)

## calculate correlation ----
df.corr <- merge(df.q_scores.v, df.meta_all_wide, by.x = 'subjID', by.y = 'Subject') %>%
  dplyr::select(-c(14)) %>%
  dplyr::select(-c(SelfSelf, SelfStra)) %>%
  dplyr::select(12, 13, 1, 14:15, everything()) %>%
  dplyr::mutate(subjID = as.character(subjID),
                Age = as.character(Age)) %>%
  dplyr::na_if("NaN")

# sapply(df.corr, class)

# standardize within each experiment.
df.corr_norm <- df.corr %>%
  dplyr::group_by(ExpID, Site) %>%
  mutate_if(is.numeric, scale) %>%
  dplyr::ungroup() %>%
  dplyr::mutate(RT_Good_Bad = RT_Good - RT_Bad,
                RT_Good_Neutral = RT_Good - RT_Neutral,
                RT_Bad_Neutral = RT_Bad -RT_Neutral,
                d_Good_Bad = dprime_Good - dprime_Bad,
                d_Good_Neutral = dprime_Good - dprime_Neut,
                d_Bad_Neutral = dprime_Bad - dprime_Neut) %>%
  dplyr::select(-contains("SD"))

# library(corrr)
res.cor_all <- df.corr_norm %>%
  dplyr::select(-c(ExpID:Sex)) %>%
  correlation::correlation(., method="pearson", p_adjust = 'none')

res.cor_1 <- df.corr_norm %>%
  dplyr::filter(ExpID %in% unique(df.meta_1_wide$ExpID)) %>%
  dplyr::select(-c(ExpID:Sex)) %>%
  correlation::correlation(., method="pearson", p_adjust = 'none')

res.cor_2 <- df.corr_norm %>%
  dplyr::filter(ExpID %in% unique(df.meta_2_wide$ExpID)) %>%
  dplyr::select(-c(ExpID:Sex)) %>%
  correlation::correlation(., method="pearson", p_adjust = 'none')

cor_pairs_all <- res.cor_all %>%
  dplyr::filter(Parameter1 %in% colnames(df.q_scores.v)) %>%
  dplyr::filter(Parameter2 %in% colnames(df.meta_all_wide[7:24])) %>%
  dplyr::filter(p <= 0.05) %>%
  dplyr::arrange(p)

cor_pairs_1 <- res.cor_1 %>%
  dplyr::filter(Parameter1 %in% colnames(df.q_scores.v)) %>%
  dplyr::filter(Parameter2 %in% colnames(df.meta_all_wide[7:24])) %>%
  dplyr::filter(p <= 0.05) %>%
  dplyr::arrange(p)

cor_pairs_2 <- res.cor_2 %>%
  dplyr::filter(Parameter1 %in% colnames(df.q_scores.v)) %>%
  dplyr::filter(Parameter2 %in% colnames(df.meta_all_wide[7:24])) %>%
  dplyr::filter(p <= 0.05) %>%
  dplyr::arrange(p)

write.csv(cor_pairs_all, 'sig_behav_quest_corr_pairs.csv', row.names = F)

```

```{r get plots of correlation, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
# Permutation
set.seed(12345)
permutation <- function(df) {
  v1 <- df[, 1] %>% base::sample(.)
  v2 <- df[, 2] %>% base::sample(.)
  tmp_cor <- cor(v1, v2, method = "pearson")
  tmp_cor
}

# plot for all
boot_plot_list <- list()
corr_plot_list <- list()
for (row_id in 1:nrow(cor_pairs_all)){
  
  # select variables
  var1 <- df.corr_norm %>% dplyr::select(cor_pairs_all$Parameter1[row_id])
  var2 <- df.corr_norm %>% dplyr::select(cor_pairs_all$Parameter2[row_id])
  var_tmp <- data.frame(var1, var2) %>%
    tidyr::drop_na()
  
  # boot
  boot_var <- var_tmp %>%
    bootES::bootES(., R = 5000, effect.type = 'r')
  
  cor_pairs_all$BootES_cor[row_id] <- boot_var$t0[1]
  cor_pairs_all$BootES_lb[row_id] <- boot_var$bounds[[1]]
  cor_pairs_all$BootES_ub[row_id] <- boot_var$bounds[[2]]
  
  # permutation
  per_cor <- rep(NA, 5000)
  for (i in 1:length(per_cor)){
    per_cor[i] <- permutation(var_tmp)
  }
  
  # plot scatter plot
  corr_plot_list[[row_id]] <- data.frame(var1, var2) %>%
    ggplot(., aes_string(x = cor_pairs_all$Parameter1[row_id], y = cor_pairs_all$Parameter2[row_id])) + 
    geom_point() + 
    geom_smooth(method=lm) +
    labs(title=paste(cor_pairs_all$Parameter1[row_id], '&', cor_pairs_all$Parameter2[row_id], sep = ' '), 
       x = cor_pairs_all$Parameter1[row_id], 
       y = cor_pairs_all$Parameter2[row_id]) +
    apatheme_s
  
  # plot permutation and boot 
  boot_cor <- boot_var$t %>%
    as.data.frame(.) %>%
    dplyr::arrange(V1) %>%
    dplyr::rename(corcoef = V1) %>%
    dplyr::mutate(Method = 'bootstrap')
    # dplyr::pull(V1)
  per_cor <- data.frame(per_cor) %>%
    dplyr::rename(corcoef = per_cor) %>%
    dplyr::mutate(Method = 'permutation')
  
  probs <- c(0.025, 0.975)
  quantiles <- quantile(per_cor$corcoef, prob=probs)
  
  # p_dist_df <- rbind(boot_cor, per_cor)
  
  xd <- data.frame(density(per_cor$corcoef)[c("x", "y")]) %>% dplyr::mutate(Method = 'permutation')
  yd <- data.frame(density(boot_cor$corcoef)[c("x", "y")]) %>% dplyr::mutate(Method = 'bootstrap')
  zd <- rbind(xd, yd)
  
  label_r <- paste("r = ", round(cor_pairs_all$r[row_id], 3), sep = '')
  
  boot_plot_list[[row_id]] <- ggplot(zd, aes(x, y, group=Method, colour = Method)) + 
      geom_area(data = subset(xd, x > quantiles[1] & x < quantiles[2]), fill = "grey") + # plot the 95 % area of zero
      geom_line() + 
      geom_vline(xintercept = cor_pairs_all$r[row_id], colour = 'blue') +
      geom_vline(xintercept = quantiles[1], colour = 'grey', linetype="dashed") + 
      geom_vline(xintercept = quantiles[2], colour = 'grey', linetype="dashed") + 
      geom_vline(xintercept = 0, colour = 'grey', linetype="dashed") + 
      # geom_text(aes(x = cor_pairs_all$r[row_id]*2, y = 6, label = label_r), colour = 'blue') +
      scale_color_grey() +
      apatheme_s
}
```
We focused on the task-questionnaire correlation, the results revealed that the score from three questionnaire are related to behavioral responses data. 
First, the external moral identity is positively correlated with boundary separation of moral good condition, $r = 0.194$, 95% CI [0.023 0.350]); the moral self image is positively correlated with the drift rate ($r = 0.191$, 95% CI [-0.016 0.354]) of the morally good condition. See Figure \@ref(fig:plot-corr-1).

```{r plot-corr-1, fig.cap="Correlation between moral identity and boundary separation of good condition; moral self-image and drift rate of good condition", fig.width=8, warning=FALSE}
library(patchwork)
corr_plot_list[[3]] + corr_plot_list[[5]]  + 
           boot_plot_list[[3]] + boot_plot_list[[5]] + plot_layout(ncol = 2)
```

Second, we found the personal distance between self and good is positively correlated with the boundary separation of neutral condition and the self-neutral distance is negatively correlated with the boundary separation of neutral condition. See figure \@ref(fig:plot-corr-2)


```{r plot-corr-2, fig.cap="Correlation between personal distance and boundary separation of neutral condition", fig.width=8, warning=FALSE}
library(patchwork)
corr_plot_list[[4]] + corr_plot_list[[6]] + 
           boot_plot_list[[4]] + boot_plot_list[[6]] + plot_layout(ncol = 2)
```

Third, we found the self esteem score was negative correlated with the $d'$ of bad conditions ($r = -0.16$, 95% CI [-0.277 -0.038]) and the neutral conditions ($r = -.197$, 95% CI [-0.348	-0.026]). See Figure \@ref(fig:plot-corr-3).

We also explored the correlation between behavioral data and questionnaire scores separately for experiments with and without self-referential. For experiments without self-referential (Valence effect), we found the personal distance between Good-person and self is positively correlated with boundary separation of good conditions, r = 0.292, 95% [0.071 0.485]. also personal distance between the bad and neutral person is positively correlated with non-responding time of bad and neutral conditions, r = 0.249, 0.233, respectively.

For experiments with self-referential (Valence effect for the self), we found self-esteem is negatively correlated with d prime of neutral condition, r = -0.272, [-0.468	-0.052], the self-good distance is positively correlated with d prime for Bad condition, r = 0.185, 95%CI[0.004 0.354].

```{r plot-corr-3, fig.cap="Correlation between self esteem and d prime of bad and neutral conditions", fig.width=8, warning=FALSE}
library(patchwork)
corr_plot_list[[1]] + corr_plot_list[[2]] +
  boot_plot_list[[1]] + boot_plot_list[[2]] + plot_layout(ncol = 2)
```

# Discussion

# References
```{r create_r-references, echo=FALSE,results='hide'}
#r_refs(file = "r-references.bib"))
```

\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

<div id = "refs"></div>
\endgroup
