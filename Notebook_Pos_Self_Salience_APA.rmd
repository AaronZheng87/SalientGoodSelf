---
title             : "Open notebook of perpecptual salience of positive self"
shorttitle        : "Moral-self as the spontaneous self"

author: 
  - name          : "Chuan-Peng Hu"
    affiliation   : "1,2"
    corresponding : yes    # Define only one corresponding author
    address       : "Langenbeckstr. 1, Neuroimaging Center, University Medical Center Mainz, 55131 Mainz, Germany"
    email         : "hcp4715@gmail.com"
  - name          : "Kaiping Peng"
    affiliation   : "1"
  - name          : "Jie Sui"
    affiliation   : "1,3"

affiliation:
  - id            : "1"
    institution   : "Tsinghua University, 100084 Beijing, China"
  - id            : "2"
    institution   : "German Resilience Center, 55131 Mainz, Germany"
  - id            : "3"
    institution   : "University of Aberdeen, Aberdeen, Scotland"

authornote: |
  Chuan-Peng Hu, Department of Psychology, Tsinghua University, 100084 Beijing, China; Germany Resilience Center, 55131 Mainz, Germany.
  Kaiping Peng, Department of Psychology, Tsinghua University, 100084 Beijing, China.
  Jie Sui, Department of Psychology, the University of Bath, Bath, UK.

  Authors contriubtion: CPH, JS, & KP design the study, CPH collected the data, CPH analyzed the data and drafted the manuscript. KP & JS supported this project.

abstract: |
  To navigate in a complex social world, individual has learnt to prioritize valuable information. Previous studies suggested the moral related stimuli was prioritized (Anderson, Siegel, et al., 2011, Science; Gantman & Van Bavel, 2014, Cognition). Using social associative learning paradigm, we found that geometric shapes, without soical meaning, that associated with different moral valence (morally good, neutral, or bad) results in different process performance. More specifically, the shape associated with morally good were prioritized. This patterns of results were robust across three different procedures. Howver, this effect no simply reflect positive bias in perception, but rather a spontaneous self-referential process that relative subjective value. To test this hypothesis, we manipulated the self-referential factor explicitly (exp3a, 3b) and found that the positive bias showed a large effect when positive valued stimuli involved self. Even when we only implicitly mention self-referential (exp4a), there is small effect of facilitation effect for moral good condition; the same is true when we implicitly mention moral good in self-association task. Finally, we found that this perceptual self-referential positive bias is robust across different perceptual tasks. Interestingly, the better performance in reaction time is not correpsonding to self-rated psychological distance between self and a morally good-person, but with distance between self and morall bad-person. These results may suggest that our participants (College students in two different cities in China) have a positive moral self bias in perceptual processing, which drive the facilitated processing of morally good stimuli because of the spontaneous self-referential processing, and this trendency is not correlated with explicit rating of moral self.
  
  <!-- https://tinyurl.com/ybremelq -->
  
keywords          : "Perceptual decision-making, Self, positive bias, morality"
wordcount         : "X"

bibliography      : 
  - r-references.bib
  - endnote.bib

floatsintext      : no
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : yes
mask              : no
draft             : no

documentclass     : "apa6"
classoption       : "man"
output            : 
  papaja::apa6_pdf:
    latex_engine  : xelatex

---

```{r setup, include = FALSE}
#rm(list = ls())
#library("papaja")
source('Initial.r')
curDir = here::here() #dirname(rstudioapi::getActiveDocumentContext()$path)
#curDir = '.'#dirname(rstudioapi::getSourceEditorContext()$path)
figDir = paste(curDir, '/figures', sep = '')
# using afex and emmeans to do the ANOVA and emmeans for post-hoc comparison
#afex_options(emmeans_model = "multivariate")
options(tinytex.verbose = F) # debug the tex
knitr::opts_chunk$set(message = FALSE)
```

```{r analysis-preferences}
# Seed for random number generation
set.seed(42)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed)

CommonColnames_d  <- c("ExpID", "Site", "Subject", "Age", "Sex", 'Domain', "Identity", "Valence", "dprime")
CommonColnames_rt <- c("ExpID", "Site", "Subject", "Age", "Sex", 'Domain', "Matchness", "Identity", "Valence", "RT")
```

# Methods
## Participants.
All experiments (1a ~ 6b, except experiment 3b) reported in the current study were first finished between 2014 to 2016 in Tsinghua University, Beijing. Participants of these experiments were recruited in the local community. To increase the sample size so that each experiment has 50 or more valid data [@Simmons_2013_life], we recruited additional participants in Wenzhou University, Wenzhou, China in 2017 for experiment 1a, 1b, 4a, and 4b. Experiment 3b was finished in Wenzhou University in 2017. To have a better estimation of the effect size, we included the data from two experiments (experiment 7a, 7b) that were reported in @Hu_2019_GoodSelf (See Table 1 for overview of these experiments). 

 <!-- 21-word solution (Simmons, Nelson & Simonsohn, 2012; retrieved from http://ssrn.com/abstract=2160588) -->

## Design and Procedure
This series of experiments started to test the effect of instantly acquired moral valence on perceptual decision-making. For this purpose, we used the social associative learning paradigm (or self-tagging paradigm)[@Sui_2012_JEPHPP], in which participants first learn the associations between geometric shapes and labels of person with different moral valence (e.g., in first three studies, the triangle, square, and circle and good person, neutral person, and bad person, respectively). The associations of the shapes and label were counterbalanced across participants. After learning phase, participants finished a practice phase to familiar with the task, in which they viewed one of the shapes upon the fixation while one of the labels below the fixation and judged whether the shape and the label matched the association they just learnt. When participants reached 60% or higher accuracy at the end of the practicing session, they started the experimental task which was the same as in the practice phase. These experiments shared a similar two (matchness: matched vs. mismatched) by three (moral valence: good vs. neutral vs. bad) within-subject design. The dependent variables reported in this manuscript were reaction times and accuracy in the experimental task, i.e., the perceptual matching task. 

Across all experiment, experiment 1a, 1b, 1c, 2, and 6a shared the two by three within-subject design. Of which the experiment 1a was the first experiment and 1b, 1c, and 2 were conducted to exclude other confounding variables' influence. More specifically, experiment 1b used different Chinese words as label to test whether the effect only occure with certain familiar words. Experiment 1c manipulated the moral valence indirectly: participants first learnt to associate different moral behaviors with different names, which is neutral at begining, after remembered the association, they then performed the perceptual matching task by associating names with different shapes. Experiment 2 tested whether the way we presented the stimuli influence the effect of valence, by sequently presenting labels and shapes. Note that part of participants of experiment 2 were from experiment 1a because we originally planned a cross task comparison. Experiment 6a, which shared the same design as experiment 2, was an EEG experiment which aimed at exploring the neural correlates of the effect. But we will focus on the behavioral results of experiment 6a in the current manuscript.

For experiment 3a, 3b, 4a, 4b, 6b, 7a, and 7b, we added self-referential as another within-subject variable. The experiment 3a directly extend experiment 1a in to a two (matchness: matched vs. mismatched) by three (moral valence: good vs. neutral vs. bad) by two (reference: self vs. other) within-subject design. Thus in experiment 3a, there were six conditions (good-self, neutral-self, bad-self, good-other, neutral-other, and bad-other) and six shapes (triangle, square, circle, diamond, pentagon, and trapezois). The experiment 6b was an EEG experiment extended from experiment 3a. The difference between 6b and 3a is that 6b presented label and shape sequentially. Because of the relatively high working memory load (six label-shape pairs), experiment 6b were conducted in two days: the first day participants finished perceptual matching task as a practice, and the second day, they finished the task again while the EEG signals were recorded. Experiment 3b was designed to separate the self-referential trials and other-referential trials. That is, participants finished two different blocks: for the self-referential blocks, they only response to good-self, neutral-self, and bad-self, with half of the trials was matched and half was not; for the other-reference blocks, they only reponded to good-other, neutral-other, and bad-other. Experiment 4a and 4b were design to test the automaticity of the binding between self/other and moral valence. In 4a, we used only two labels (self vs. other) and two shapes (circle, square). To manipulate the moral valence, we added labels within the shape and instructed participants to ignore the presence of these moral related words. In 4b, we reversed self-referential and valence: participant learnt three labels (good-person, neutral-person, and bad-person) and three shapes (circle, square, and triangle), and the words "self" or "other" were presented in the shapes. As in 4a, participants were told to ignore the words inside the shape. Experiment 7a and 7b are almost identical, they are designed to test the cross task robustness of the effect we observed in the aforementioned experiments [@Hu_2019_GoodSelf]. As we found that the neutral and bad conditions constantly show nonsignificant results, we only used two conditions of moral valence, i.e., good vs. bad, in experiment 7a and 7b.

Finally, experiment 5 was design to test the specificity of the moral valence. We extended experiment 1a with an additional independnet variable: domains of the valence words. More specifically, besides the moral valence, we also added valence from other domains: appearance of person (beautiful, neutral, ugly), apperance of a scene (beautiful, neutral, ugly), and emotion (happy, neutral, and sad). Label-shape pairs from different domains were separated into different blocks. 

If not noted, E-prime 2.0 was used for presenting stimuli and collecting behavioral responses. For participants recruited in Tsinghua University, they finished the experiment individually in a dim-lighted chamber, stimuli were presented on 22-inch CRT monitors and their head were fixed by a chin-rest brace. The distance between participants' eyes and the screen was about 60 cm. The visual angle of geometric shapes was about 3.7º × 3.7º, the finxation cross is of (0.8º × 0.8º of visual angle) at the center of the screen. The words were of 3.6º × 1.6º visual angle. The distance between the center of the shape or the word and the fixation cross was 3.5º of visual angle. For participants recruited in Wenzhou University, they finished the experiment in a group consisted of 3 ~ 12 participants in a dim-lighted testing room. Participants were required to finished the whole experiment independently. Also, they were instructed to start the experiment at the same time, so that the distraction between participants were minimized. The stimuli were presented on 19-inch CRT monitor. The visual angles are could not be exactly controlled because participants’s chin were not fixed.


```{r 'Table1_exp_info', ehco = FALSE, results = 'asis'}
exp_table <- read.csv('Exp_info_all.csv') %>%
  dplyr::rename(ExpID = 1)
# knitr::kable(exp_table, caption = "Information about all experiments")

apa_table(
  exp_table
  , caption = "Information about all experiments."
  , note = "DV = dependent variables; Valence = how valence was manipulated; Shape & Label = how shapes & labels were presented."
  , escape = TRUE
)

```
In most of these experiments, participant were also asked to fill a battery of questionnaire after they finish the behavioral tasks. All the questionnaire data are open [see, dataset 4 in @Liu_2019_JOPD]. See Table 1 for a summary information about all the experiments reported here. 


## Data analysis
We reported all the measurements, analyses, and results in all the experiments in the current study. Participants whose overall accuracy lower than 60% were excluded from analysis. Also, the accurate responses with less than 200ms reaction times were excluded from the analysis.

All data were first pre-processed using `r cite_r("r-references.bib")`. Individual experiment's results were analyzed as in @Sui_2012_JEPHPP. we analyzed the accuracy performance using a signal detection approach. The performance in each match condition was combined with that in the nonmatching condition with the same shape to form a measure of *d’*. Trials without response were coded either as “miss” (matched trials) or “false alarm” (mismatched trials). The *d’* were then analyzed using repeated measures analyses of variance (repeated measures ANOVA). The reaction times of accurate trials were also analyzed using repeated measures ANOVA. These analyses were based on the pre-processed data and finished byusing JASP [0.8.6.0, www.jasp-stats.org, @Love_etal_2019_JASP]. To control the false positive when conducting the post-hoc comparisons, we used Bonferroni correction. See supplementary materials for the results of each experiment's method and results, which included the significance test resuts, effect size [@Bakeman_2015_eff_size; @Lakens_2013], and Bayes factor calculated by JASP [@Hu_2018_JASP; @Wagenmakers_2018_JASP]. 

Based on our experimental design, here we reported our results across experiments using a meta-analytical apporach [@Goh_2016_mini]. More specifically, we reported results in four parts. The first part of the results focused on the effect of moral valence on the performance of perceptual matching task. We synthesized effect size of *d* prime and RT from experiment 1a, 1b, 1c, 2, 5 and 6a. 

The second part we synthesized the results from experiment 3a, 3b, 6b, 7a, and 7b. These experiments explicitedly included both moral valence and self-reference. 

In the third part, we examined the change of effect size brought by change of design, with a focus on 4a and 4b, which were designed to examine the implicit effect of the interaction between moral valence and self-referential processing. We are interested in one particular question: will self-referential and morally positive valence had a mutual facilitation effect. That is, when moral valence (experiment 4a) or self-referential (experiment 4a) was presented as task-irrelevant stimuli, whether they would facilitate self-referential or valence effect on perceptual decision-making. For experiment 4a, we report the comparisons between different valence conditions under the self-referential task, not the other-referential task; for experiment 4b, we reported the comparison between the self- vs. other-referential conditions for positive moral condition, not for the neutral or negative conditions. Note that the results were also analyzed in a standard repeated measure ANOVAs (see supplementary materials).

We then reported the specificity of the valence effect. 

Finally, we explored correlation between self-reported psychological distance and more objective responses bias (i.e., reaction times and *d* prime). To do this, we first normalized the personal distance by taking the percentage of the mean distance between each two persons in the sum of all 6 distances (self-good, self-normal, self-bad, good-normal, good-bad, normal-bad), and then calculated the bias score (indexed by the differences between good-normal, good-bad). Also, as exploratory analysis, we analyzed the correlation between behavioral response and moral identity, self-esteem, if data are available. As recent study showed that small size leads to unstable correlation estimates [@Schönbrodt_Perugini_2013], we only reported the correlation based on data pooled from all experiments, while the results of each experiment were reported in supplementary results.

Mini meta-analyses were carried out in R 3.6. As for the meta-analysis of the effect size of *d*’ and RTs, we used “metafor” package (Viechtbauer, 2010). We first calculated the mean of *d*' and RT of each condition for each participant, then calculate the effect size (Cohen's d) and variance of the effect size for all contrast we interested: Good v. Bad, Good v. Neutral, and Neutral v. Bad for the effect of valence, and self vs. other for the effect of self-relevance. Cohen'd and its variance were estimated using the following formula [@Cooper_2009_handbook]:

$$d = \frac {(M_{1} - M_{2})}{\sqrt {(sd_{1}^2 + sd_{2}^2) - 2*r*sd_{1}*sd_{2}}} * \sqrt {2*(1-r)}$$

$$var.d = 2*(1-r) * (\frac{1}{n} + \frac{d^2}{2*n})$$

$M_1$ is the mean of the first condition, $sd_1$ is the standard deviation of the first condition, while $M_2$ is the mean of the second condition, $sd_2$ is the standard deviation of the second condition. $r$ is the correlation coefficient between data from first and second condition. $n$ is the number of data point (in our case the number of participants included in our research).

To avoid the cases that some participants participated more than one experiments, we inspected the all available information of participants and only included participants' results from their first participation. As mentioned above, 24 participants were intentionally recruited to participate both exp 1a and exp 2, we only included their results from exp 1a in the meta-analysis.

```{r loadingData_All,echo=FALSE,results='hide'}
# Exp 1a ----
# data from THU
df1a_1 <- read.csv(".\\exp1a\\rawdata_behav_exp1a_201404_2019_export.csv", header = TRUE,
                   sep = ",", stringsAsFactors=FALSE, na.strings=c("","NA"), encoding="UTF-8") %>%
  dplyr::rename(Subject = 1) %>%
  dplyr::mutate(Site = "THU", Subject = Subject + 1000,
                Val_lab = ifelse(Label == "好人", "Good",                      # re-code the label
                                 ifelse(Label == "常人", "Neutral", "Bad")))

# data collected in Wenzhou U
df1a_2 <- read.csv(".\\exp1a\\rawdata_behav_exp1a_201704_2019_export.csv",header = TRUE,
                   sep = ",",stringsAsFactors=FALSE,na.strings=c("","NA"), encoding="UTF-8") %>%
  dplyr::rename(Subject = 1) %>%
  dplyr::mutate(Site = "WZU",
                Val_lab = ifelse(Label == "好人", "Good", 
                                 ifelse(Label == "常人", "Neutral", "Bad")))
# combine data and clean
df1a   <- rbind(df1a_1,df1a_2) %>%
        dplyr::rename(ACC = Target.ACC,           # rename columns
                      RT  = Target.RT,
                      CRESP = Target.CRESP,
                      BlockNo = BlockList.Sample,
                      TrialNo = SubTrial,
                      RESP = Target.RESP,
                      Matchness = YesNoResp,
                      Valence = Shape) %>%
        dplyr::mutate(Valence = ifelse(Valence == "Normal", "Neutral", Valence),   # recode values
                      Matchness = ifelse(Matchness == "Yes", "Match", "Mismatch"),
                      Age = ifelse(Age == 0, NA, Age), # if the min age is 0, that age is missing
                      Site = factor(Site),
                      Shape = ifelse(Target == "C.bmp", "circle",  # the shape of each target picture.
                                     ifelse(Target == "S.bmp", "square", 'triangle')))%>%
        dplyr::arrange(Subject) %>%
        dplyr::select(-Label, -Target)

rm(df1a_1,df1a_2)

df1a.T.basic     <- df1a %>%
  dplyr::select(Site, Subject, Age, Sex) %>%
  dplyr::distinct(Subject, .keep_all = TRUE) %>%
  dplyr::summarise(N = length(Subject),
                   N_thu = length(Site[Site == "THU"]),
                   N_wzu = length(Site[Site == "WZU"]),
                   Nf = length(Sex[Sex == "female"]),
                   Nm = length(Sex[Sex == "male"]),
                   Age_mean = round(mean(Age,na.rm=TRUE),2),
                   Age_sd = round(sd(Age,na.rm=TRUE),2),
                   Age_missing = sum(is.na(Age)),
                   Sex_missing = sum(is.na(Sex)))

# number of participant who didn't finished the experiment
nQuit <- length(unique(df1a$Subject[is.na(df1a$BlockNo)])) - length(unique(df1a$Subject[!is.na(df1a$BlockNo)]))

df1a.excld.sub <-  df1a %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::group_by(Subject) %>%
  dplyr::summarise(N = length(ACC),                    # caculate the overall accuracy for each subject
                   N_crrct = sum(ACC),
                   ACC = sum(ACC)/length(ACC)) %>%
  dplyr::filter(ACC < 0.6) %>%                        # exlucde the participants with less than 60% overall accuracy
  dplyr::select(Subject)

# The rate of excluded trials in valid data
df1a.invalid_trial_rate   <- df1a %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::filter(!(Subject %in% df1a.excld.sub$Subject)) %>%   # exclude the invalid subjects
  dplyr::summarize(rate = length(RT[RT <= 200 & ACC == 1])/length(RT))

df1a.v   <- df1a %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::filter(!(Subject %in% df1a.excld.sub$Subject)) %>%   # exclude the invalid subjects
  dplyr::filter(!(RT <= 200 & ACC == 1))                      # exclude < 200 trials

df1a.v.basic <- df1a.v %>%
  dplyr::select(Site, Subject, Age, Sex) %>%
  dplyr::distinct(Subject, .keep_all = TRUE) %>%
  dplyr::summarise(N = length(Subject),
                   N_thu = length(Site[Site == "THU"]),
                   N_wzu = length(Site[Site == "WZU"]),
                   Nf = length(Sex[Sex == "female"]),
                   Nm = length(Sex[Sex == "male"]),
                   Age_mean = round(mean(Age,na.rm=TRUE),2),
                   Age_sd = round(sd(Age,na.rm=TRUE),2),
                   Age_missing = sum(is.na(Age)),
                   Sex_missing = sum(is.na(Sex)))

# calculate d prime
df1a.v.dprime_l <- df1a.v %>%
  dplyr::mutate(sdt = mosaic::derivedFactor("hit" = (ACC ==1 & Matchness == "Match"),   # code as hit
                                    "CR" = (ACC ==1  & Matchness == "Mismatch"),        # code as correct reject
                                    "miss" = (ACC == 0 & Matchness == "Match"),         # code as miss
                                    "FA" = (ACC == 0 & Matchness == "Mismatch"),        # code as false alarm
                                    .method ="first",  .default = NA)) %>% 
  dplyr::group_by(Site, Subject, Age, Sex, Valence, sdt) %>%
  dplyr::summarise(N = length(sdt)) %>%                                      # calculate the counts for each 
  dplyr::ungroup() %>%
  tidyr::spread(key = sdt, value = N, fill = 0) %>%                          # long-to-wide format
  dplyr::mutate(hitR = hit/(hit + miss),                                     # hit rate
                FAR  = FA/(FA+CR)) %>%                                       # fa rate
  dplyr::mutate(hitR = ifelse(hitR == 1, 1 - 1/(2*(hit + miss)), hitR),      # if hit rate is 1, standardize it
                FAR  = ifelse(FAR == 0, 1/(2*(hit + miss)), FAR)) %>%        # if FA rate is 0, standardize it
  dplyr::mutate(dprime = qnorm(hitR) - qnorm(FAR)) %>%
  dplyr::select(Site, Subject, Age, Sex, Valence, dprime) %>%                # select relevant columns
  dplyr::mutate(Valence = factor(Valence, levels = c("Good","Neutral","Bad")))


# get the mean RT for each particpant and each condition for ANOVA
df1a.v.rt_m <- df1a.v %>%
  dplyr::filter(ACC == 1) %>%
  dplyr::group_by(Site,Subject, Age, Sex, Matchness, Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup() %>%
  dplyr::mutate(Valence = factor(Valence, levels = c("Good","Neutral","Bad")))


### prepare for the later meta-analysis
df1a.meta.d <- df1a.v.dprime_l %>% 
  dplyr::mutate(Identity = NA,
                ExpID = 'Exp1a',
                Domain = "Morality") %>%        # add domain as morality, to be comparable with experiment 5.
  dplyr::select(CommonColnames_d)

df1a.meta.rt <- df1a.v.rt_m %>% 
  dplyr::rename(RT = RT_m) %>%
  dplyr::mutate(Identity = NA,
                ExpID = 'Exp1a',
                Domain = "Morality") %>%        # add domain as morality, to be comparable with experiment 5.
  dplyr::select(CommonColnames_rt)

# Exp 1b ====
# data collected in Tsinghua U
df1b_1 <- read.csv(".\\exp1b\\rawdata_behav_exp1b_201410_2019_export.csv", header = TRUE,
                   sep = ",", stringsAsFactors=FALSE, na.strings=c("","NA"), encoding="UTF-8") %>%
  dplyr::rename(Subject = 1) %>%
  dplyr::mutate(Site = "THU", Subject = Subject + 1100,
                Val_lab = ifelse(Label == "善人", "Good",                      # re-code the label
                                 ifelse(Label == "常人", "Neutral", "Bad")))

# data collected in Wenzhou U
df1b_2 <- read.csv(".\\exp1b\\rawdata_behav_exp1b_201705_2019_export.csv",header = TRUE,
                   sep = ",",stringsAsFactors=FALSE,na.strings=c("","NA"), encoding="UTF-8") %>%
  dplyr::rename(Subject = 1) %>%
  dplyr::mutate(Site = "WZU", Subject = Subject + 1100,
                Val_lab = ifelse(Label == "善人", "Good",                      # re-code the label
                                 ifelse(Label == "常人", "Neutral", "Bad")))

# combine data and clean
df1b   <- rbind(df1b_1,df1b_2) %>%
        dplyr::rename(ACC = Target.ACC,           # rename columns
                      RT  = Target.RT,
                      CRESP = Target.CRESP,
                      BlockNo = BlockList.Sample,
                      TrialNo = SubTrial,
                      RESP = Target.RESP,
                      Matchness = YesNoResp,
                      Valence = Shape) %>%
        dplyr::mutate(Valence = ifelse(Valence == "Normal", "Neutral", Valence),   # recode values
                      Matchness = ifelse(Matchness == "Yes", "Match", "Mismatch"),
                      Age = ifelse(Age == 0, NA, Age),
                      #Subject = factor(Subject),
                      #ExpID = 'Exp_1b',
                      Identity = NA,
                      #Domain = "Morality",
                      Site = factor(Site)) %>% # if the min age is 0, that age is missing
        #dplyr::select(CommonColnames)%>%
        dplyr::arrange(Subject)

rm(df1b_1,df1b_2)

df1b.T.basic     <- df1b %>%
  dplyr::select(Site, Subject, Age, Sex) %>%
  dplyr::distinct(Subject, .keep_all = TRUE) %>%
  dplyr::summarise(N = length(Subject),
                   N_thu = length(Site[Site == "THU"]),
                   N_wzu = length(Site[Site == "WZU"]),
                   Nf = length(Sex[Sex == "female"]),
                   Nm = length(Sex[Sex == "male"]),
                   Age_mean = round(mean(Age,na.rm=TRUE),2),
                   Age_sd = round(sd(Age,na.rm=TRUE),2))

# number of participant who didn't finished the experiment
nQuit <- length(unique(df1b$Subject[is.na(df1b$BlockNo)])) - length(unique(df1b$Subject[!is.na(df1b$BlockNo)]))

# participants should be excluded
df1b.excld.sub <-  df1b %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::group_by(Subject) %>%
#  dplyr::mutate(ACC = ifelse(RT <= 200, 0, ACC)) %>%  # set less than 200 ms response as wrong
  dplyr::summarise(N = length(ACC),                   # caculate the overall accuracy for each subject
                   N_crrct = sum(ACC),
                   ACC = sum(ACC)/length(ACC)) %>%
  dplyr::filter(ACC < 0.6) %>%                        # exlucde the participants with less than 60% overall accuracy
  dplyr::select(Subject)

# The rate of excluded trials in valid data
df1b.invalid_trial_rate   <- df1b %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::filter(!(Subject %in% df1b.excld.sub$Subject)) %>%   # exclude the invalid subjects
  dplyr::summarize(rate = length(RT[RT <= 200 & ACC == 1])/length(RT))

df1b.v   <- df1b %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::filter(!(Subject %in% df1b.excld.sub$Subject)) %>%   # exclude the invalid subjects
  dplyr::filter(!(RT <= 200 & ACC == 1))                      # exclude < 200 trials

df1b.v.basic     <- df1b.v %>%
  dplyr::select(Site, Subject, Age, Sex) %>%
  dplyr::distinct(Subject, .keep_all = TRUE) %>%
  dplyr::summarise(N = length(Subject),
                   N_thu = length(Site[Site == "THU"]),
                   N_wzu = length(Site[Site == "WZU"]),
                   Nf = length(Sex[Sex == "female"]),
                   Nm = length(Sex[Sex == "male"]),
                   Age_mean = round(mean(Age,na.rm=TRUE),2),
                   Age_sd = round(sd(Age,na.rm=TRUE),2))

# calculate d prime
df1b.v.dprime_l <- df1b.v %>%
  dplyr::mutate(sdt = mosaic::derivedFactor("hit" = (ACC ==1 & Matchness == "Match"),     # code as hit
                                    "CR" = (ACC ==1  & Matchness == "Mismatch"),  # code as correct reject
                                    "miss" = (ACC == 0 & Matchness == "Match"),   # code as miss
                                    "FA" = (ACC == 0 & Matchness == "Mismatch"),  # code as false alarm
                                    .method ="first",  .default = NA)) %>% 
  dplyr::group_by(Site, Subject, Age, Sex, Valence, sdt) %>%
  dplyr::summarise(N = length(sdt)) %>%                                      # calculate the counts for each 
  dplyr::ungroup() %>%
  tidyr::spread(key = sdt, value = N,fill = 0) %>%                           # long-to-wide format
  dplyr::mutate(hitR = hit/(hit + miss),                                     # hit rate
                FAR  = FA/(FA+CR)) %>%                                       # fa rate
  dplyr::mutate(hitR = ifelse(hitR == 1, 1 - 1/(2*(hit + miss)), hitR),      # if hit rate is 1, standardize it
                FAR  = ifelse(FAR == 0, 1/(2*(hit + miss)), FAR)) %>%        # if FA rate is 0, standardize it
  dplyr::mutate(dprime = qnorm(hitR) - qnorm(FAR)) %>%
  dplyr::select(Site, Subject, Age, Sex, Valence, dprime) %>%                # select relevant columns
  dplyr::mutate(Valence = factor(Valence, levels = c("Good","Neutral","Bad")))

# calculate the mean RT of each condition for each participants for ANOVA
df1b.v.rt_m <- df1b.v %>%
  dplyr::filter(ACC == 1) %>%
  dplyr::group_by(Site, Subject, Age, Sex, Matchness, Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup()

### prepare for the later meta-analysis
df1b.meta.d <- df1b.v.dprime_l %>% 
  dplyr::mutate(Identity = NA,
                ExpID = 'Exp1b',
                Domain = "Morality") %>%        # add domain as morality, to be comparable with experiment 5.
  dplyr::select(CommonColnames_d)

df1b.meta.rt <- df1b.v.rt_m %>% 
  dplyr::rename(RT = RT_m) %>%
  dplyr::mutate(Identity = NA,
                ExpID = 'Exp1b',
                Domain = "Morality") %>%        # add domain as morality, to be comparable with experiment 5.
  dplyr::select(CommonColnames_rt)

# Exp 1c ====
df1c <- read.csv(".\\exp1c\\rawdata_behav_exp1c_export2019.csv", header = TRUE,
                   sep = ",", stringsAsFactors=FALSE, na.strings=c("","NA"), encoding="UTF-8") %>%
  dplyr::rename(Subject = 1) %>%
  dplyr::mutate(Site = "THU", Subject = Subject + 1200,
                Val_lab = ifelse(Label == "好人", "Good",                      # re-code the label
                                 ifelse(Label == "常人", "Neutral", "Bad"))) %>%
  dplyr::select(Site, Subject,Age, Handedness,Sex,TrialList1,BlockList,
                 SubTrial, Shape,Val_lab, YesNoResp,Target1.CRESP,             # select necessary columns
                 Target1.ACC,Target1.RESP, Target1.RT) %>%
  dplyr::rename(BlockNo = BlockList,
                TrialNo = SubTrial,
                ACC = Target1.ACC,                         # rename columns
                CRESP = Target1.CRESP,
                RT = Target1.RT, RESP =Target1.RESP,
                Matchness = YesNoResp, Valence = Shape) %>%
  dplyr::mutate(Valence = ifelse(Valence == "Normal", "Neutral", Valence),    # change value
                Valence = factor(Valence, levels=c("Good", "Neutral","Bad")),
                Matchness = ifelse(Matchness == "Yes", "Match", "Mismatch"),
                Matchness = factor(Matchness, levels=c("Match", "Mismatch"))) %>%
  dplyr::arrange(Subject)

# distinguish between practice and formal data
df1c.subj_P <- df1c %>%                      # subjet for practice
  dplyr::filter(is.na(BlockNo)) %>%
  dplyr::distinct(Subject)

df1c.subj_T <- df1c %>%                       # subjects in formal exp
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::distinct(Subject)

# number of participant who didn't finished the experiment
nQuit <- length(df1c.subj_P) - length(df1c.subj_T)

df1c.T.basic     <- df1c %>%
  dplyr::select(Site, Subject, Age, Sex) %>%
  dplyr::distinct(Subject, .keep_all = TRUE) %>%
  dplyr::summarise(N = length(Subject),
                   N_thu = length(Site[Site == "THU"]),
                   N_wzu = length(Site[Site == "WZU"]),
                   Nf = length(Sex[Sex == "female"]),
                   Nm = length(Sex[Sex == "male"]),
                   Age_mean = round(mean(Age,na.rm=TRUE),2),
                   Age_sd = round(sd(Age,na.rm=TRUE),2))

# participants should be excluded
df1c.excld.sub <-  df1c %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::group_by(Subject) %>%
  dplyr::summarise(N = length(ACC),                   # caculate the overall accuracy for each subject
                   N_crrct = sum(ACC),
                   ACC = sum(ACC)/length(ACC)) %>%
  dplyr::filter(ACC < 0.6) %>%                        # exlucde the participants with less than 60% overall accuracy
  dplyr::select(Subject)

# The rate of excluded trials in valid data
df1c.invalid_trial_rate   <- df1c %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::filter(!(Subject %in% df1c.excld.sub$Subject)) %>%   # exclude the invalid subjects
  dplyr::summarize(rate = length(RT[RT <= 200 & ACC == 1])/length(RT))

df1c.v   <- df1c %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::filter(!(Subject %in% df1c.excld.sub$Subject)) %>%   # exclude the invalid subjects
  dplyr::filter(!(RT <= 200 & ACC == 1))                      # exclude < 200 trials

df1c.v.basic     <- df1c.v %>%
  dplyr::select(Site, Subject, Age, Sex) %>%
  dplyr::distinct(Subject, .keep_all = TRUE) %>%
  dplyr::summarise(N = length(Subject),
                   N_thu = length(Site[Site == "THU"]),
                   N_wzu = length(Site[Site == "WZU"]),
                   Nf = length(Sex[Sex == "female"]),
                   Nm = length(Sex[Sex == "male"]),
                   Age_mean = round(mean(Age,na.rm=TRUE),2),
                   Age_sd = round(sd(Age,na.rm=TRUE),2))

# calculate d prime
df1c.v.dprime_l <- df1c.v %>%
  dplyr::mutate(sdt = mosaic::derivedFactor("hit" = (ACC ==1 & Matchness == "Match"),     # code as hit
                                    "CR" = (ACC ==1  & Matchness == "Mismatch"),  # code as correct reject
                                    "miss" = (ACC == 0 & Matchness == "Match"),   # code as miss
                                    "FA" = (ACC == 0 & Matchness == "Mismatch"),  # code as false alarm
                                    .method ="first",  .default = NA)) %>% 
  dplyr::group_by(Site, Subject, Age, Sex, Valence, sdt) %>%
  dplyr::summarise(N = length(sdt)) %>%                                      # calculate the counts for each 
  dplyr::ungroup() %>%
  tidyr::spread(key = sdt, value = N,fill = 0) %>%                           # long-to-wide format
  dplyr::mutate(hitR = hit/(hit + miss),                                     # hit rate
                FAR  = FA/(FA+CR)) %>%                                       # fa rate
  dplyr::mutate(hitR = ifelse(hitR == 1, 1 - 1/(2*(hit + miss)), hitR),      # if hit rate is 1, standardize it
                FAR  = ifelse(FAR == 0, 1/(2*(hit + miss)), FAR)) %>%        # if FA rate is 0, standardize it
  dplyr::mutate(dprime = qnorm(hitR) - qnorm(FAR)) %>%
  dplyr::select(Site, Subject, Age, Sex, Valence, dprime) %>%                # select relevant columns
  dplyr::mutate(Valence = factor(Valence, levels = c("Good","Neutral","Bad")))

# calculate mean RT for anova
df1c.v.rt_m <- df1c.v %>%
  dplyr::filter(ACC == 1) %>%
  dplyr::group_by(Site, Subject, Age, Sex, Matchness, Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup()

### prepare for the later meta-analysis
df1c.meta.d <- df1c.v.dprime_l %>% 
  dplyr::mutate(Identity = NA,
                ExpID = 'Exp1c',
                Domain = "Morality") %>%        # add domain as morality, to be comparable with experiment 5.
  dplyr::select(CommonColnames_d)

df1c.meta.rt <- df1c.v.rt_m %>% 
  dplyr::rename(RT = RT_m) %>%
  dplyr::mutate(Identity = NA,
                ExpID = 'Exp1c',
                Domain = "Morality") %>%        # add domain as morality, to be comparable with experiment 5.
  dplyr::select(CommonColnames_rt)

# Exp 2 ----
# data collected in Tsinghua U
df2 <- read.csv(".\\exp2\\rawdata_behav_exp2_201405_2019_export.csv", header = TRUE,
                   sep = ",", stringsAsFactors=FALSE, na.strings=c("","NA"), encoding="UTF-8") %>%
  dplyr::rename(Subject = 1) %>%
  dplyr::rename(ACC = Target.ACC,           # rename columns
                RT  = Target.RT,
                CRESP = Target.CRESP,
                BlockNo = BlockList.Sample,
                TrialNo = SubTrial,
                RESP = Target.RESP,
                Matchness = YesNoResp,
                Valence = Shape) %>%
  dplyr::mutate(Site = "THU", 
                Subject = ifelse(Subject < 40, Subject + 1000, Subject + 2000), # recode subject ID, some from exp 1a
                Val_lab = ifelse(Label == "好人", "Good",                       # re-code the label
                                 ifelse(Label == "常人", "Neutral", "Bad")),
                Valence = ifelse(Valence == "Normal", "Neutral", Valence),      # recode values
                Matchness = ifelse(Matchness == "Yes", "Match", "Mismatch"),
                Age = ifelse(Age == 0, NA, Age))  

df2.T.basic     <- df2 %>%
  dplyr::select(Site, Subject, Age, Sex) %>%
  dplyr::distinct(Subject, .keep_all = TRUE) %>%
  dplyr::summarise(N = length(Subject),
                   N_thu = length(Site[Site == "THU"]),
                   N_wzu = length(Site[Site == "WZU"]),
                   Nf = length(Sex[Sex == "female"]),
                   Nm = length(Sex[Sex == "male"]),
                   Age_mean = round(mean(Age,na.rm=TRUE),2),
                   Age_sd = round(sd(Age,na.rm=TRUE),2))
  
# number of participant who practiced but not in the formal experiment
nQuit <- length(unique(df2$Subject[is.na(df2$BlockNo)])) - length(unique(df2$Subject[!is.na(df2$BlockNo)]))

# participants should be excluded
df2.excld.sub <-  df2 %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::group_by(Subject) %>%
  #dplyr::mutate(ACC = ifelse(RT <= 200, 0, ACC)) %>%  # set less than 200 ms response as wrong
  dplyr::summarise(N = length(ACC),                   # caculate the overall accuracy for each subject
                   N_crrct = sum(ACC),
                   ACC = sum(ACC)/length(ACC)) %>%
  dplyr::filter(ACC < 0.6) %>%                        # exlucde the participants with less than 60% overall accuracy
  dplyr::select(Subject)

# The rate of excluded trials in valid data
df2.invalid_trial_rate   <- df2 %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::filter(!(Subject %in% df2.excld.sub$Subject)) %>%   # exclude the invalid subjects
  dplyr::summarize(rate = length(RT[RT <= 200 & ACC == 1])/length(RT))

df2.v   <- df2 %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::filter(!(Subject %in% df2.excld.sub$Subject)) %>%   # exclude the invalid subjects
  dplyr::filter(!(RT <= 200 & ACC == 1))                      # exclude < 200 trials

df2.v.basic     <- df2.v %>%
  dplyr::select(Site, Subject, Age, Sex) %>%
  dplyr::distinct(Subject, .keep_all = TRUE) %>%
  dplyr::summarise(N = length(Subject),
                   N_thu = length(Site[Site == "THU"]),
                   N_wzu = length(Site[Site == "WZU"]),
                   Nf = length(Sex[Sex == "female"]),
                   Nm = length(Sex[Sex == "male"]),
                   Age_mean = round(mean(Age,na.rm=TRUE),2),
                   Age_sd = round(sd(Age,na.rm=TRUE),2))

# calculate d prime
df2.v.dprime_l <- df2.v %>%
  dplyr::mutate(sdt = mosaic::derivedFactor("hit" = (ACC ==1 & Matchness == "Match"),     # code as hit
                                    "CR" = (ACC ==1  & Matchness == "Mismatch"),  # code as correct reject
                                    "miss" = (ACC == 0 & Matchness == "Match"),   # code as miss
                                    "FA" = (ACC == 0 & Matchness == "Mismatch"),  # code as false alarm
                                    .method ="first",  .default = NA)) %>% 
  dplyr::group_by(Site, Subject, Age, Sex, Valence, sdt) %>%
  dplyr::summarise(N = length(sdt)) %>%                                      # calculate the counts for each 
  dplyr::ungroup() %>%
  tidyr::spread(key = sdt, value = N,fill = 0) %>%                           # long-to-wide format
  dplyr::mutate(hitR = hit/(hit + miss),                                     # hit rate
                FAR  = FA/(FA+CR)) %>%                                       # fa rate
  dplyr::mutate(hitR = ifelse(hitR == 1, 1 - 1/(2*(hit + miss)), hitR),      # if hit rate is 1, standardize it
                FAR  = ifelse(FAR == 0, 1/(2*(hit + miss)), FAR)) %>%        # if FA rate is 0, standardize it
  dplyr::mutate(dprime = qnorm(hitR) - qnorm(FAR)) %>%
  dplyr::select(Site, Subject, Age, Sex, Valence, dprime) %>%                # select relevant columns
  dplyr::mutate(Valence = factor(Valence, levels = c("Good","Neutral","Bad")))

# calculated means RT for ANOVA
df2.v.rt_m <- df2.v %>%
  dplyr::filter(ACC == 1) %>%
  dplyr::group_by(Site, Subject, Age, Sex, Matchness, Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup()

### prepare for the later meta-analysis
df2.meta.d <- df2.v.dprime_l %>% 
  dplyr::mutate(Identity = NA,
                ExpID = 'Exp2',
                Domain = "Morality") %>%        # add domain as morality, to be comparable with experiment 5.
  dplyr::select(CommonColnames_d)

df2.meta.rt <- df2.v.rt_m %>% 
  dplyr::rename(RT = RT_m) %>%
  dplyr::mutate(Identity = NA,
                ExpID = 'Exp2',
                Domain = "Morality") %>%        # add domain as morality, to be comparable with experiment 5.
  dplyr::select(CommonColnames_rt)

# Exp 3a ----
# data collected in Tsinghua U
df3a <- read.csv(".\\exp3a\\rawdata_behav_exp3a_2014_export_2019.csv", header = TRUE,
                   sep = ",", stringsAsFactors=FALSE, na.strings=c("","NA"), encoding="UTF-8") %>%
  dplyr::rename(Subject = 1) %>%
  dplyr::rename(ACC = Target.ACC,           # rename columns
                RT  = Target.RT,
                CRESP = Target.CRESP,
                BlockNo = BlockList.Sample,
                TrialNo = SubTrial,
                RESP = Target.RESP,
                Matchness = YesNoResp,
                Valence = morality,
                Identity = self) %>%
  # in this experiment we need to get the value of valence and identity from shape
  dplyr::mutate(Valence = ifelse(Shape == "Goodself" | Shape == "Goodother", "Good", 
                                 ifelse(Shape == "Normalself" | Shape == "Normalother","Neutral", "Bad")),
                Identity = ifelse(Shape == "Goodself" | Shape == "Normalself" | Shape == "Badself", 
                                  "Self", "Other"),
                Val_lab = ifelse(Label == "好人" | Label == "好我", "Good",                       # re-code the label
                                 ifelse(Label == "凡人"| Label == "凡我", "Neutral", "Bad")),
                ID_lab = ifelse(Label == "好我" | Label == "凡我" | Label == "坏我", "Self", "Other"),  # re-code the label
                Matchness = ifelse(Matchness == "Yes", "Match", "Mismatch"),
                Age = ifelse(Age == 0, NA, Age),
                Site = "THU",
                Subject = Subject + 3000)                                       # re-code the subject id

df3a.T.basic     <- df3a %>%
  dplyr::select(Site, Subject, Age, Sex) %>%
  dplyr::distinct(Subject, .keep_all = TRUE) %>%
  dplyr::summarise(N = length(Subject),
                   N_thu = length(Site[Site == "THU"]),
                   N_wzu = length(Site[Site == "WZU"]),
                   Nf = length(Sex[Sex == "female"]),
                   Nm = length(Sex[Sex == "male"]),
                   Age_mean = round(mean(Age,na.rm=TRUE),2),
                   Age_sd = round(sd(Age,na.rm=TRUE),2))
  
# number of participant who practiced but not in the formal experiment
nQuit <- length(unique(df3a$Subject[is.na(df3a$BlockNo)])) - length(unique(df3a$Subject[!is.na(df3a$BlockNo)]))

# participants should be excluded
df3a.excld.sub <-  df3a %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::group_by(Subject) %>%
  #dplyr::mutate(ACC = ifelse(RT <= 200, 0, ACC)) %>%  # set less than 200 ms response as wrong
  #dplyr::filter(!(ACC == 1 & RT <= 200)) %>%
  dplyr::summarise(N = length(ACC),                   # caculate the overall accuracy for each subject
                   N_crrct = sum(ACC),
                   ACC = sum(ACC)/length(ACC)) %>%
  dplyr::filter(ACC < 0.6) %>%                        # exlucde the participants with less than 60% overall accuracy
  dplyr::select(Subject)

# The rate of excluded trials in valid data
df3a.invalid_trial_rate   <- df3a %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::filter(!(Subject %in% df3a.excld.sub$Subject)) %>%   # exclude the invalid subjects
  dplyr::summarize(rate = length(RT[RT <= 200 & ACC == 1])/length(RT)) %>%
  dplyr::pull()

df3a.v   <- df3a %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::filter(!(Subject %in% df3a.excld.sub$Subject)) %>%   # exclude the invalid subjects
  dplyr::filter(!(RT <= 200 & ACC == 1))                      # exclude < 200 trials

df3a.v.basic     <- df3a.v %>%
  dplyr::select(Site, Subject, Age, Sex) %>%
  dplyr::distinct(Subject, .keep_all = TRUE) %>%
  dplyr::summarise(N = length(Subject),
                   N_thu = length(Site[Site == "THU"]),
                   N_wzu = length(Site[Site == "WZU"]),
                   Nf = length(Sex[Sex == "female"]),
                   Nm = length(Sex[Sex == "male"]),
                   Age_mean = round(mean(Age,na.rm=TRUE),2),
                   Age_sd = round(sd(Age,na.rm=TRUE),2))

# calculate d prime
df3a.v.dprime_l <- df3a.v %>%
  dplyr::mutate(sdt = mosaic::derivedFactor("hit" = (ACC ==1 & Matchness == "Match"), # code as hit
                                    "CR" = (ACC ==1  & Matchness == "Mismatch"),      # correct reject
                                    "miss" = (ACC == 0 & Matchness == "Match"),       # miss
                                    "FA" = (ACC == 0 & Matchness == "Mismatch"),      # false alarm
                                    .method ="first",  .default = NA)) %>% 
  dplyr::group_by(Site, Subject, Age, Sex, Valence,Identity, sdt) %>%
  dplyr::summarise(N = length(sdt)) %>%                                    # calculate the counts for each 
  dplyr::ungroup() %>%
  tidyr::spread(key = sdt, value = N,fill = 0) %>%                          # long-to-wide format
  dplyr::mutate(hitR = hit/(hit + miss),                                    # hit rate
                FAR  = FA/(FA+CR)) %>%                                      # fa rate
  dplyr::mutate(hitR = ifelse(hitR == 1, 1 - 1/(2*(hit + miss)), hitR),     # if hit rate is 1, standardize it
                FAR  = ifelse(FAR == 0, 1/(2*(hit + miss)), FAR)) %>%       # if FA rate is 0, standardize it
  dplyr::mutate(dprime = qnorm(hitR) - qnorm(FAR)) %>%
  dplyr::select(Site, Subject, Age, Sex, Valence, Identity, dprime) %>%     # select relevant columns
  dplyr::mutate(Valence = factor(Valence, levels = c("Good","Neutral","Bad")),
                Identity = factor(Identity, levels = c('Self', 'Other')))

# calculate the mean RT for each condition of each participant
df3a.v.rt_m <- df3a.v %>%
  dplyr::filter(ACC == 1) %>%
  dplyr::group_by(Site,Subject, Age, Sex, Matchness, Identity, Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup()

### prepare for the later meta-analysis
df3a.meta.d <- df3a.v.dprime_l %>% 
  dplyr::mutate(ExpID = 'Exp3a',
                Domain = "Morality") %>%        # add domain as morality, to be comparable with experiment 5.
  dplyr::select(CommonColnames_d)

df3a.meta.rt <- df3a.v.rt_m %>% 
  dplyr::rename(RT = RT_m) %>%
  dplyr::mutate(ExpID = 'Exp3a',
                Domain = "Morality") %>%        # add domain as morality, to be comparable with experiment 5.
  dplyr::select(CommonColnames_rt)

# Exp 3b ----
# data collected in Wenzhou U
df3b <- read.csv(".\\exp3b\\rawdata_behav_exp3b_201704_export_2019.csv", header = TRUE,
                   sep = ",", stringsAsFactors=FALSE, na.strings=c("","NA"), encoding="UTF-8") %>%
  dplyr::rename(Subject = 1) %>%
  dplyr::rename(ACC = Target.ACC,           # rename columns
                RT  = Target.RT,
                CRESP = Target.CRESP,
                RESP = Target.RESP,
                Matchness = YesNoResp,
                Valence = Morality) %>%
                
  # in this experiment we need to get the value of valence and identity from shape
  dplyr::mutate(#Valence = ifelse(Shape == "Goodself" | Shape == "Goodother", "Good", 
                #                 ifelse(Shape == "Neutralself" | Shape == "NeutralOther","Neutral", "Bad")),
                Identity = ifelse(Identity == "self" | Identity == "Self", 
                                  "Self", "Other"),
                Val_lab = ifelse(Label == "好他" | Label == "好我" | Label == "好她" , "Good",         # re-code the label
                                 ifelse(Label == "常他"| Label == "常我" | Label == "常她", "Neutral", "Bad")),
                ID_lab = ifelse(Label == "好我" | Label == "常我" | Label == "坏我", "Self", "Other"),  # re-code the label
                Matchness = ifelse(Matchness == "Yes", "Match", "Mismatch"),
                Age = ifelse(Age == 0, NA, Age),  # if the min age is 0, that age is missing
                BlockNo = dplyr::coalesce(otherBlocklList.Sample, selfBlockList.Sample),
                TrialNo = dplyr::coalesce(OtherTrialist.Sample, selfTrialList.Sample),
                Site = "WZU") 

df3b.T.basic     <- df3b %>%
  dplyr::select(Site, Subject, Age, Sex) %>%
  dplyr::distinct(Subject, .keep_all = TRUE) %>%
  dplyr::summarise(N = length(Subject),
                   N_thu = length(Site[Site == "THU"]),
                   N_wzu = length(Site[Site == "WZU"]),
                   Nf = length(Sex[Sex == "female"]),
                   Nm = length(Sex[Sex == "male"]),
                   Age_mean = round(mean(Age,na.rm=TRUE),2),
                   Age_sd = round(sd(Age,na.rm=TRUE),2))
  
# participants should be excluded
df3b.excld.sub <-  df3b %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::group_by(Subject) %>%
  #dplyr::mutate(ACC = ifelse(RT <= 200, 0, ACC)) %>%  # set less than 200 ms response as wrong
  #dplyr::filter(!(ACC == 1 & RT <= 200)) %>%
  dplyr::summarise(N = length(ACC),                   # caculate the overall accuracy for each subject
                   N_crrct = sum(ACC),
                   ACC = sum(ACC)/length(ACC)) %>%
  dplyr::filter(ACC < 0.6) %>%                        # exlucde the participants with less than 60% overall accuracy
  dplyr::select(Subject)

df3b.excld.sub2 <- df3b.excld.sub
df3b.excld.sub2[5,1] <- 31003 # the participant whose hit rate is zero under one condition.

# The rate of excluded trials in valid data
df3b.invalid_trial_rate   <- df3b %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::filter(!(Subject %in% df3b.excld.sub2$Subject)) %>%   # exclude the invalid subjects
  dplyr::summarize(rate = length(RT[RT <= 200 & ACC == 1])/length(RT)) %>%
  dplyr::pull()

df3b.v   <- df3b %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::filter(!(Subject %in% df3b.excld.sub2$Subject)) %>%   # exclude the invalid subjects
  dplyr::filter(!(RT <= 200 & ACC == 1))                      # exclude < 200 trials

df3b.v.basic     <- df3b.v %>%
  dplyr::select(Site, Subject, Age, Sex) %>%
  dplyr::distinct(Subject, .keep_all = TRUE) %>%
  dplyr::summarise(N = length(Subject),
                   N_thu = length(Site[Site == "THU"]),
                   N_wzu = length(Site[Site == "WZU"]),
                   Nf = length(Sex[Sex == "female"]),
                   Nm = length(Sex[Sex == "male"]),
                   Age_mean = round(mean(Age,na.rm=TRUE),2),
                   Age_sd = round(sd(Age,na.rm=TRUE),2))

# calculate d prime
df3b.v.dprime_l <- df3b.v %>%
  dplyr::mutate(sdt = mosaic::derivedFactor("hit" = (ACC ==1 & Matchness == "Match"), # code as hit
                                    "CR" = (ACC ==1  & Matchness == "Mismatch"),      # correct reject
                                    "miss" = (ACC == 0 & Matchness == "Match"),       # miss
                                    "FA" = (ACC == 0 & Matchness == "Mismatch"),      # false alarm
                                    .method ="first",  .default = NA)) %>% 
  dplyr::group_by(Site, Subject, Age, Sex, Valence,Identity, sdt) %>%
  dplyr::summarise(N = length(sdt)) %>%                                    # calculate the counts for each 
  dplyr::ungroup() %>%
  tidyr::spread(key = sdt, value = N,fill = 0) %>%                          # long-to-wide format
  dplyr::mutate(hitR = hit/(hit + miss),                                    # hit rate
                FAR  = FA/(FA+CR)) %>%                                      # fa rate
  dplyr::mutate(hitR = ifelse(hitR == 1, 1 - 1/(2*(hit + miss)), hitR),     # if hit rate is 1, standardize it
                FAR  = ifelse(FAR == 0, 1/(2*(hit + miss)), FAR)) %>%       # if FA rate is 0, standardize it
  dplyr::mutate(dprime = qnorm(hitR) - qnorm(FAR)) %>%
  dplyr::select(Site, Subject, Age, Sex, Valence, Identity, dprime) %>%   # select relevant columns
  dplyr::mutate(Valence = factor(Valence, levels = c("Good","Neutral","Bad")),
                Identity = factor(Identity, levels = c('Self', 'Other')))

# calculate mean RT for each condition of each participant
df3b.v.rt_m <- df3b.v %>%
  dplyr::filter(ACC == 1) %>%
  dplyr::group_by(Site, Subject, Age, Sex, Matchness, Identity, Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup()

### prepare for the later meta-analysis
df3b.meta.d <- df3b.v.dprime_l %>% 
  dplyr::mutate(ExpID = 'Exp3b',
                Domain = "Morality") %>%        # add domain as morality, to be comparable with experiment 5.
  dplyr::select(CommonColnames_d)

df3b.meta.rt <- df3b.v.rt_m %>% 
  dplyr::rename(RT = RT_m) %>%
  dplyr::mutate(ExpID = 'Exp3b',
                Domain = "Morality") %>%        # add domain as morality, to be comparable with experiment 5.
  dplyr::select(CommonColnames_rt)

# Exp 4a ----

df4a_1 <- read.csv(".\\exp4a\\rawdata_behav_exp4a_2015_export_2019.csv",header = TRUE, sep = ",",stringsAsFactors=FALSE,na.strings=c("","NA"), encoding="UTF-8") %>%
  dplyr::rename(Subject = 1) %>%
  dplyr::rename(Morality = morality,
                Identity = self) %>%
  dplyr::mutate(Site = "THU") %>%
  dplyr::mutate(Subject = Subject + 4100)  

df4a_2 <- read.csv(".\\exp4a\\rawdata_behav_exp4a_2017_export_2019.csv",header = TRUE, sep = ",",stringsAsFactors=FALSE,na.strings=c("","NA"), encoding="UTF-8") %>%
  dplyr::rename(Subject = 1) %>%
  dplyr::mutate(Site = "WZU")

df4a <- rbind(df4a_1,df4a_2) %>%
  dplyr::rename(ACC = Target.ACC,           # rename columns
                RT  = Target.RT,
                CRESP = Target.CRESP,
                BlockNo = BlockList.Sample,
                TrialNo = SubTrial,
                RESP = Target.RESP,
                Matchness = YesNoResp,
                Valence = Morality) %>%
  dplyr::mutate(Valence  = ifelse(Valence == "Normal", "Neutral", Valence),
                Identity = ifelse(Identity == "self" | Identity == "Self", "Self", "Other"),
                ID_lab = ifelse(Label == "自己", 'Self', 'Other'),
                Matchness = ifelse(Matchness == "Yes", "Match", "Mismatch"),
                Age = ifelse(Age == 0, NA, Age))
                #Subject = factor(Subject))

rm(df4a_1,df4a_2) # remove the temporary variables.

df4a.T.basic     <- df4a %>%
  dplyr::select(Site, Subject, Age, Sex) %>%
  dplyr::distinct(Subject, .keep_all = TRUE) %>%
  dplyr::summarise(N = length(Subject),
                   N_thu = length(Site[Site == "THU"]),
                   N_wzu = length(Site[Site == "WZU"]),
                   Nf = length(Sex[Sex == "female"]),
                   Nm = length(Sex[Sex == "male"]),
                   Age_mean = round(mean(Age,na.rm=TRUE),2),
                   Age_sd = round(sd(Age,na.rm=TRUE),2))
  
# number of participant who practiced but not in the formal experiment
nQuit <- length(unique(df4a$Subject[is.na(df4a$BlockNo)])) - length(unique(df4a$Subject[!is.na(df4a$BlockNo)]))

# participants should be excluded
df4a.excld.sub <-  df4a %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::group_by(Subject) %>%
  #dplyr::mutate(ACC = ifelse(RT <= 200, 0, ACC)) %>%  # set less than 200 ms response as wrong
  #dplyr::filter(!(ACC == 1 & RT <= 200)) %>%
  dplyr::summarise(N = length(ACC),                   # caculate the overall accuracy for each subject
                   N_crrct = sum(ACC),
                   ACC = sum(ACC)/length(ACC)) %>%
  dplyr::filter(ACC < 0.6) %>%                        # exlucde the participants with less than 60% overall accuracy
  dplyr::select(Subject)

# The rate of excluded trials in valid data
df4a.invalid_trial_rate   <- df4a %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::filter(!(Subject %in% df4a.excld.sub$Subject)) %>%   # exclude the invalid subjects
  dplyr::summarize(rate = length(RT[RT <= 200 & ACC == 1])/length(RT)) %>%
  dplyr::pull()

df4a.v   <- df4a %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::filter(!(Subject %in% df4a.excld.sub$Subject)) %>%   # exclude the invalid subjects
  dplyr::filter(!(RT <= 200 & ACC == 1))                      # exclude < 200 trials

df4a.v.basic     <- df4a.v %>%
  dplyr::select(Site, Subject, Age, Sex) %>%
  dplyr::distinct(Subject, .keep_all = TRUE) %>%
  dplyr::summarise(N = length(Subject),
                   N_thu = length(Site[Site == "THU"]),
                   N_wzu = length(Site[Site == "WZU"]),
                   Nf = length(Sex[Sex == "female"]),
                   Nm = length(Sex[Sex == "male"]),
                   Age_mean = round(mean(Age,na.rm=TRUE),2),
                   Age_sd = round(sd(Age,na.rm=TRUE),2))

# calculating the dprime 
df4a.v.dprime_l <- df4a.v %>%
  dplyr::mutate(sdt = mosaic::derivedFactor("hit" = (ACC ==1 & Matchness == "Match"), # code as hit
                                    "CR" = (ACC ==1  & Matchness == "Mismatch"),      # correct reject
                                    "miss" = (ACC == 0 & Matchness == "Match"),       # miss
                                    "FA" = (ACC == 0 & Matchness == "Mismatch"),      # false alarm
                                    .method ="first",  .default = NA)) %>% 
  dplyr::group_by(Site, Subject, Age, Sex, Valence,Identity, sdt) %>%
  dplyr::summarise(N = length(sdt)) %>%                                    # calculate the counts for each 
  dplyr::ungroup() %>%
  tidyr::spread(key = sdt, value = N,fill = 0) %>%                          # long-to-wide format
  dplyr::mutate(hitR = hit/(hit + miss),                                    # hit rate
                FAR  = FA/(FA+CR)) %>%                                      # fa rate
  dplyr::mutate(hitR = ifelse(hitR == 1, 1 - 1/(2*(hit + miss)), hitR),     # if hit rate is 1, standardize it
                FAR  = ifelse(FAR == 0, 1/(2*(hit + miss)), FAR)) %>%       # if FA rate is 0, standardize it
  dplyr::mutate(dprime = qnorm(hitR) - qnorm(FAR)) %>%
  dplyr::select(Site, Subject, Age, Sex, Valence, Identity, dprime) %>%   # select relevant columns
  dplyr::mutate(Valence = factor(Valence, levels = c("Good","Neutral","Bad")),
                Identity = factor(Identity, levels = c('Self', 'Other')))

df4a.v.rt_m <- df4a.v %>%
  dplyr::filter(ACC == 1) %>%
  dplyr::group_by(Site,Subject, Age, Sex, Matchness, Identity, Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup()

### prepare for the later meta-analysis
df4a.meta.d <- df4a.v.dprime_l %>% 
  dplyr::mutate(ExpID = 'Exp4a',
                Domain = "Morality") %>%        # add domain as morality, to be comparable with experiment 5.
  dplyr::select(CommonColnames_d)

df4a.meta.rt <- df4a.v.rt_m %>% 
  dplyr::rename(RT = RT_m) %>%
  dplyr::mutate(ExpID = 'Exp4a',
                Domain = "Morality") %>%        # add domain as morality, to be comparable with experiment 5.
  dplyr::select(CommonColnames_rt)

# Exp 4b ----

df4b_1 <- read.csv(".\\exp4b\\rawdata_behav_exp4b_2015_export_2019.csv",header = TRUE, sep = ",",stringsAsFactors=FALSE,na.strings=c("","NA"), encoding="UTF-8") %>%
  dplyr::rename(Subject = 1) %>%
  dplyr::rename(Morality = morality) %>%
  dplyr::mutate(Site = "THU")

df4b_2 <- read.csv(".\\exp4b\\rawdata_behav_exp4b_2017_export_2019.csv",header = TRUE, sep = ",",stringsAsFactors=FALSE,na.strings=c("","NA"), encoding="UTF-8") %>%
  dplyr::rename(Subject = 1) %>%
  dplyr::rename(Morality = morality) %>%
  dplyr::mutate(Site = "WZU")

df4b <- rbind(df4b_1,df4b_2) %>%
  dplyr::rename(ACC = Target.ACC,           # rename columns
                RT  = Target.RT,
                CRESP = Target.CRESP,
                BlockNo = BlockList.Sample,
                TrialNo = SubTrial,
                RESP = Target.RESP,
                Matchness = YesNoResp,
                Valence = Morality) %>%
  dplyr::mutate(Valence  = ifelse(Valence == "Ord", "Neutral", Valence),
                Val_sh = ifelse(Label == "好人", "Good",
                                ifelse(Label == "常人",'Neutral', 'Bad')),
                Identity = ifelse(Identity == "self" | Identity == "Self", "Self", "Other"),
                Matchness = ifelse(Matchness == "Yes", "Match", "Mismatch"),
                Age = ifelse(Age == 0, NA, Age))                             # if the min age is 0, that age is missing
                #ExpID = 'Exp4b', Domain = "Morality") %>%
#  dplyr::select(CommonColnames)

rm(df4b_1,df4b_2) # remove the temporary variables.

df4b.T.basic     <- df4b %>%
  dplyr::select(Site, Subject, Age, Sex) %>%
  dplyr::distinct(Subject, .keep_all = TRUE) %>%
  dplyr::summarise(N = length(Subject),
                   N_thu = length(Site[Site == "THU"]),
                   N_wzu = length(Site[Site == "WZU"]),
                   Nf = length(Sex[Sex == "female"]),
                   Nm = length(Sex[Sex == "male"]),
                   Age_mean = round(mean(Age,na.rm=TRUE),2),
                   Age_sd = round(sd(Age,na.rm=TRUE),2))
  
# number of participant who practiced but not in the formal experiment
nQuit <- length(unique(df4b$Subject[is.na(df4b$BlockNo)])) - length(unique(df4b$Subject[!is.na(df4b$BlockNo)]))

# participants should be excluded
df4b.excld.sub <-  df4b %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::group_by(Subject) %>%
  #dplyr::mutate(ACC = ifelse(RT <= 200, 0, ACC)) %>%  # set less than 200 ms response as wrong
  dplyr::summarise(N = length(ACC),                   # caculate the overall accuracy for each subject
                   N_crrct = sum(ACC),
                   ACC = sum(ACC)/length(ACC)) %>%
  dplyr::filter(ACC < 0.6) %>%                        # exlucde the participants with less than 60% overall accuracy
  dplyr::select(Subject)

# The rate of excluded trials in valid data
df4b.invalid_trial_rate   <- df4b %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::filter(!(Subject %in% df4b.excld.sub$Subject)) %>%   # exclude the invalid subjects
  dplyr::summarize(rate = length(RT[RT <= 200 & ACC == 1])/length(RT)) %>%
  dplyr::pull()

df4b.v   <- df4b %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::filter(!(Subject %in% df4b.excld.sub$Subject)) %>%   # exclude the invalid subjects
  dplyr::filter(!(RT <= 200 & ACC == 1))                      # exclude < 200 trials

df4b.v.basic     <- df4b.v %>%
  dplyr::select(Site, Subject, Age, Sex) %>%
  dplyr::distinct(Subject, .keep_all = TRUE) %>%
  dplyr::summarise(N = length(Subject),
                   N_thu = length(Site[Site == "THU"]),
                   N_wzu = length(Site[Site == "WZU"]),
                   Nf = length(Sex[Sex == "female"]),
                   Nm = length(Sex[Sex == "male"]),
                   Age_mean = round(mean(Age,na.rm=TRUE),2),
                   Age_sd = round(sd(Age,na.rm=TRUE),2))

# calculating the dprime 
df4b.v.dprime_l <- df4b.v %>%
  dplyr::mutate(sdt = mosaic::derivedFactor("hit" = (ACC ==1 & Matchness == "Match"), # code as hit
                                    "CR" = (ACC ==1  & Matchness == "Mismatch"),      # correct reject
                                    "miss" = (ACC == 0 & Matchness == "Match"),       # miss
                                    "FA" = (ACC == 0 & Matchness == "Mismatch"),      # false alarm
                                    .method ="first",  .default = NA)) %>% 
  dplyr::group_by(Site, Subject, Age, Sex, Valence,Identity, sdt) %>%
  dplyr::summarise(N = length(sdt)) %>%                                    # calculate the counts for each 
  dplyr::ungroup() %>%
  tidyr::spread(key = sdt, value = N,fill = 0) %>%                          # long-to-wide format
  dplyr::mutate(hitR = hit/(hit + miss),                                    # hit rate
                FAR  = FA/(FA+CR)) %>%                                      # fa rate
  dplyr::mutate(hitR = ifelse(hitR == 1, 1 - 1/(2*(hit + miss)), hitR),     # if hit rate is 1, standardize it
                FAR  = ifelse(FAR == 0, 1/(2*(hit + miss)), FAR)) %>%       # if FA rate is 0, standardize it
  dplyr::mutate(dprime = qnorm(hitR) - qnorm(FAR)) %>%
  dplyr::select(Site, Subject, Age, Sex, Valence, Identity, dprime) %>%   # select relevant columns
  dplyr::mutate(Valence = factor(Valence, levels = c("Good","Neutral","Bad")),
                Identity = factor(Identity, levels = c('Self', 'Other')))

df4b.v.rt_m <- df4b.v %>%
  dplyr::filter(ACC == 1) %>%
  dplyr::group_by(Site,Subject, Age, Sex, Matchness, Identity, Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup()

### prepare for the later meta-analysis
df4b.meta.d <- df4b.v.dprime_l %>% 
  dplyr::mutate(ExpID = 'Exp4b',
                Domain = "Morality") %>%        # add domain as morality, to be comparable with experiment 5.
  dplyr::select(CommonColnames_d)

df4b.meta.rt <- df4b.v.rt_m %>% 
  dplyr::rename(RT = RT_m) %>%
  dplyr::mutate(ExpID = 'Exp4b',
                Domain = "Morality") %>%        # add domain as morality, to be comparable with experiment 5.
  dplyr::select(CommonColnames_rt)

# Exp 5 ----

df5 <- read.csv(".\\exp5_specificity\\rawdata_behav_exp5_2016_export2019.csv",header = TRUE, sep = ",",
                stringsAsFactors=FALSE, na.strings=c("","NA"), encoding="UTF-8") %>%
  dplyr::rename(Subject = 1) %>%
  dplyr::rename(BlockListM.Sample = BlockListMoral.Sample, 
                Matchness = YesNoResp, CRESP = CorrectAnswer) %>%                            # rename the columns
  dplyr::mutate(Matchness = ifelse(Matchness == "Yes", "Match", "Mismatch"),
                taskType = derivedFactor("Emotion"  = (Label == "sad" | Label == "happy" | Label == "neutral"),
                                         "Morality" = (Label == "bad" | Label == "good" | Label == "ordinary"),
                                         "Person"   = (Label == "uglyP" | Label == "beautyP" | Label == "normalP"),
                                         "Scene"    = (Label == "uglyS" | Label == "beautyS" | Label == "normalS"), 
                                         .method ="first", .default = NA),
                Valence = derivedFactor("Good"= (Label ==  "good" | Label == "happy" | Label == "beautyP"  | Label == "beautyS"),
                                         "Bad" = (Label == "bad"  | Label == "sad"   | Label == "uglyP"    | Label == "uglyS"),
                                         "Neutral" = (Label == "ordinary" | Label == "neutral" | Label == "normalP" | Label == "normalS"),
                                         .method ="first", .default = NA)) %>%
  tidyr::replace_na(list(PracListE="",    PracListM="",    PracListP="",    PracListS="")) %>%          # replace NA with "" for later unite
  tidyr::unite("PracList", PracListE,PracListM,PracListP,PracListS, sep = "")  %>%                # unite all praclist
  dplyr::mutate(Site = "THU", 
                ExpID = "Exp5",
                RESP = dplyr::coalesce(TargetE.RESP,  TargetM.RESP,  TargetP.RESP,  TargetS.RESP),
                ACC = dplyr::coalesce(TargetE.ACC,  TargetM.ACC,  TargetP.ACC,  TargetS.ACC), 
                RT = dplyr::coalesce(TargetE.RT,  TargetM.RT,  TargetP.RT,  TargetS.RT),
                BlockNo = dplyr::coalesce(BlockListE.Sample,BlockListM.Sample,BlockListP.Sample,BlockListS.Sample),
                TrialNo = dplyr::coalesce(TrialListE.Sample,TrialListM.Sample,TrialListP.Sample,TrialListS.Sample)) %>% 
                #BlockNo = as.numeric(BlockNo),
                #TrialNo = as.numeric(TrialNo)) %>% 
  dplyr::mutate_if(is_character, list(~na_if(.,""))) %>%    # blank to NA
  dplyr::select(-c(TargetE.RESP,  TargetM.RESP, TargetP.RESP,  TargetS.RESP,
                  TargetE.ACC,  TargetM.ACC,  TargetP.ACC,  TargetS.ACC,
                  TargetE.RT,  TargetM.RT,  TargetP.RT,  TargetS.RT,
                  BlockListE.Sample,BlockListM.Sample,BlockListP.Sample,BlockListS.Sample,
                  TrialListE.Sample,TrialListM.Sample,TrialListP.Sample,TrialListS.Sample))

df5.T.basic     <- df5 %>%
  dplyr::select(Site, Subject, Age, Sex) %>%
  dplyr::distinct(Subject, .keep_all = TRUE) %>%
  dplyr::summarise(N = length(Subject),
                   N_thu = length(Site[Site == "THU"]),
                   N_wzu = length(Site[Site == "WZU"]),
                   Nf = length(Sex[Sex == "female"]),
                   Nm = length(Sex[Sex == "male"]),
                   Age_mean = round(mean(Age,na.rm=TRUE),2),
                   Age_sd = round(sd(Age,na.rm=TRUE),2))
  
# find the participants who practiced but not finish experiment
subjPrac <- df5 %>% dplyr::filter(is.na(df5$BlockNo)) %>% dplyr::distinct(Subject)
subjFinish <- df5 %>% dplyr::filter(!is.na(df5$BlockNo)) %>% dplyr::distinct(Subject)
subjQuit <- subjPrac$Subject[which(!subjPrac$Subject %in% subjFinish$Subject)] 

# participants should be excluded
df5.excld.sub <-  df5 %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::group_by(Subject) %>%
  dplyr::summarise(N = length(ACC),                   # caculate the overall accuracy for each subject
                   N_crrct = sum(ACC),
                   ACC = sum(ACC)/length(ACC)) %>%
  dplyr::filter(ACC < 0.6) %>%                        # exlucde the participants with less than 60% overall accuracy
  dplyr::select(Subject)

# The rate of excluded trials in valid data
df5.invalid_trial_rate   <- df5 %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::filter(!(Subject %in% subjQuit)) %>%                 # exclude the invalid subjects
  dplyr::filter(!(Subject %in% df5.excld.sub$Subject)) %>%    # exclude the invalid subjects
  dplyr::summarize(rate = length(RT[RT <= 200 & ACC == 1])/length(RT)) %>%
  dplyr::pull()

df5.v   <- df5 %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::filter(!(Subject %in% subjQuit)) %>%                 # exclude the invalid subjects
  dplyr::filter(!(Subject %in% df5.excld.sub$Subject)) %>%   # exclude the invalid subjects
  dplyr::filter(!(RT <= 200 & ACC == 1)) %>%                      # exclude < 200 trials
  dplyr::arrange(Subject)

df5.v.basic     <- df5.v %>%
  dplyr::select(Site, Subject, Age, Sex) %>%
  dplyr::distinct(Subject, .keep_all = TRUE) %>%
  dplyr::summarise(N = length(Subject),
                   N_thu = length(Site[Site == "THU"]),
                   N_wzu = length(Site[Site == "WZU"]),
                   Nf = length(Sex[Sex == "female"]),
                   Nm = length(Sex[Sex == "male"]),
                   Age_mean = round(mean(Age,na.rm=TRUE),2),
                   Age_sd = round(sd(Age,na.rm=TRUE),2))

# calculating the dprime 
df5.v.dprime_l <- df5.v %>%
  dplyr::mutate(sdt = mosaic::derivedFactor("hit" = (ACC ==1 & Matchness == "Match"), # code as hit
                                    "CR" = (ACC ==1  & Matchness == "Mismatch"),      # correct reject
                                    "miss" = (ACC == 0 & Matchness == "Match"),       # miss
                                    "FA" = (ACC == 0 & Matchness == "Mismatch"),      # false alarm
                                    .method ="first",  .default = NA)) %>% 
  dplyr::group_by(Site, taskType, Subject, Age, Sex, Valence,sdt) %>%
  dplyr::summarise(N = length(sdt)) %>%                                    # calculate the counts for each 
  dplyr::ungroup() %>%
  tidyr::spread(key = sdt, value = N,fill = 0) %>%                          # long-to-wide format
  dplyr::mutate(hitR = hit/(hit + miss),                                    # hit rate
                FAR  = FA/(FA+CR)) %>%                                      # fa rate
  dplyr::mutate(hitR = ifelse(hitR == 1, 1 - 1/(2*(hit + miss)), hitR),     # if hit rate is 1, standardize it
                FAR  = ifelse(FAR == 0, 1/(2*(hit + miss)), FAR)) %>%       # if FA rate is 0, standardize it
  dplyr::mutate(dprime = qnorm(hitR) - qnorm(FAR)) %>%
  dplyr::select(Site, Subject, Age, Sex, taskType,Valence, dprime) %>%   # select relevant columns
  dplyr::mutate(Valence = factor(Valence, levels = c("Good","Neutral","Bad")),
                taskType = factor(taskType, levels = c('Morality', 'Emotion',"Person", "Scene")))
# anova for RT with 2*2 design
df5.v.rt_m <- df5.v %>%
  dplyr::filter(ACC == 1) %>%
  dplyr::group_by(Site,Subject, Age, Sex, Matchness,taskType,Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup() %>%
  dplyr::mutate(Valence = factor(Valence, levels = c("Good","Neutral","Bad")),
                taskType = factor(taskType, levels = c('Morality', 'Emotion',"Person", "Scene")))

### prepare for the later meta-analysis
df5.meta.d <- df5.v.dprime_l %>% 
  dplyr::rename(Domain = taskType) %>%
  dplyr::mutate(ExpID = 'Exp5',
                Identity = NA) %>%        # add domain as morality, to be comparable with experiment 5.
  dplyr::select(CommonColnames_d)

df5.meta.rt <- df5.v.rt_m %>% 
  dplyr::rename(Domain = taskType,
                RT = RT_m) %>%
  dplyr::mutate(ExpID = 'Exp5',
                Identity = NA) %>%        # add domain as morality, to be comparable with experiment 5.
  dplyr::select(CommonColnames_rt)

# Exp 6a ----
df6a <- read.csv(".\\exp6a_erp1\\rawdata_ERP_exp6a_201412_export_2019.csv",header = TRUE, sep = ",",
                 stringsAsFactors=FALSE,na.strings=c("","NA"), encoding="UTF-8") %>%
  dplyr::rename(Subject = 1) %>%
  dplyr::rename(BlockNo = BlockList.Sample,
                TrialNo = SubTrial,
                Matchness = YesNoResp, 
                Valence = Shape,
                ACC = Target.ACC, 
                CRESP = CorrectAnswer,                   # rename the columns
                RESP = Target.RESP, RT = Target.RT) %>%    #
  dplyr::mutate(Valence = ifelse(Valence == "Normal", "Neutral", Valence),                   # re-code the data
                Val_sh = ifelse(Label == "好人", 'Good',
                                ifelse(Label == '常人', 'Neutral', 'Bad')),
                Matchness = ifelse(Matchness == "Yes", "Match", "Mismatch"),
                Age = ifelse(Age == 0, NA, Age)) %>%
  dplyr::mutate(Site = "THU",
                Subject = Subject + 6100) # here started with 61XX instead of 60XX, which is the id for anther project.

# number of participant who practiced but not in the formal experiment
nQuit <- length(unique(df6a$Subject[is.na(df6a$BlockNo)])) - length(unique(df6a$Subject[!is.na(df6a$BlockNo)]))

df6a.T.basic     <- df6a %>%
  dplyr::select(Site, Subject, Age, Sex) %>%
  dplyr::distinct(Subject, .keep_all = TRUE) %>%
  dplyr::summarise(N = length(Subject),
                   N_thu = length(Site[Site == "THU"]),
                   N_wzu = length(Site[Site == "WZU"]),
                   Nf = length(Sex[Sex == "female"]),
                   Nm = length(Sex[Sex == "male"]),
                   Age_mean = round(mean(Age,na.rm=TRUE),2),
                   Age_sd = round(sd(Age,na.rm=TRUE),2))
  
# participants should be excluded
df6a.excld.sub <-  df6a %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::group_by(Subject) %>%
  #dplyr::mutate(ACC = ifelse(RT <= 200, 0, ACC)) %>%  # set less than 200 ms response as wrong
  dplyr::summarise(N = length(ACC),                   # caculate the overall accuracy for each subject
                   N_crrct = sum(ACC),
                   ACC = sum(ACC)/length(ACC)) %>%
  dplyr::filter(ACC < 0.6) %>%                        # exlucde the participants with less than 60% overall accuracy
  dplyr::select(Subject)

# The rate of excluded trials in valid data
df6a.invalid_trial_rate   <- df6a %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::filter(!(Subject %in% df6a.excld.sub$Subject)) %>%   # exclude the invalid subjects
  dplyr::summarize(rate = length(RT[RT <= 200 & ACC == 1])/length(RT)) %>%
  dplyr::pull()

df6a.v   <- df6a %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::filter(!(Subject %in% df6a.excld.sub$Subject)) %>%   # exclude the invalid subjects
  dplyr::filter(!(RT <= 200 & ACC == 1))                      # exclude < 200 trials

df6a.v.basic     <- df6a.v %>%
  dplyr::select(Site, Subject, Age, Sex) %>%
  dplyr::distinct(Subject, .keep_all = TRUE) %>%
  dplyr::summarise(N = length(Subject),
                   N_thu = length(Site[Site == "THU"]),
                   N_wzu = length(Site[Site == "WZU"]),
                   Nf = length(Sex[Sex == "female"]),
                   Nm = length(Sex[Sex == "male"]),
                   Age_mean = round(mean(Age,na.rm=TRUE),2),
                   Age_sd = round(sd(Age,na.rm=TRUE),2))

# calculating the dprime 
df6a.v.dprime_l <- df6a.v %>%
  dplyr::mutate(sdt = mosaic::derivedFactor("hit" = (ACC ==1 & Matchness == "Match"), # code as hit
                                    "CR" = (ACC ==1  & Matchness == "Mismatch"),      # correct reject
                                    "miss" = (ACC == 0 & Matchness == "Match"),       # miss
                                    "FA" = (ACC == 0 & Matchness == "Mismatch"),      # false alarm
                                    .method ="first",  .default = NA)) %>% 
  dplyr::group_by(Site, Subject, Age, Sex, Valence, sdt) %>%
  dplyr::summarise(N = length(sdt)) %>%                                    # calculate the counts for each 
  dplyr::ungroup() %>%
  tidyr::spread(key = sdt, value = N,fill = 0) %>%                          # long-to-wide format
  dplyr::mutate(hitR = hit/(hit + miss),                                    # hit rate
                FAR  = FA/(FA+CR)) %>%                                      # fa rate
  dplyr::mutate(hitR = ifelse(hitR == 1, 1 - 1/(2*(hit + miss)), hitR),     # if hit rate is 1, standardize it
                FAR  = ifelse(FAR == 0, 1/(2*(hit + miss)), FAR)) %>%       # if FA rate is 0, standardize it
  dplyr::mutate(dprime = qnorm(hitR) - qnorm(FAR)) %>%
  dplyr::select(Site, Subject, Age, Sex, Valence, dprime) %>%   # select relevant columns
  dplyr::mutate(Valence = factor(Valence, levels = c("Good","Neutral","Bad")))

# Mean RT for each condition of each participant.
df6a.v.rt_m <- df6a.v %>%
  dplyr::filter(ACC == 1) %>%
  dplyr::group_by(Site,Subject, Age, Sex, Matchness, Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup()

### prepare for the later meta-analysis
df6a.meta.d <- df6a.v.dprime_l %>% 
  dplyr::mutate(ExpID = 'Exp6a',
                Domain = "Morality",
                Identity = NA) %>%        # add domain as morality, to be comparable with experiment 5.
  dplyr::select(CommonColnames_d)

df6a.meta.rt <- df6a.v.rt_m %>% 
  dplyr::rename(RT = RT_m) %>%
  dplyr::mutate(ExpID = 'Exp6a',
                Domain = "Morality",
                Identity = NA) %>%        # add domain as morality, to be comparable with experiment 5.
  dplyr::select(CommonColnames_rt)

# Exp 6b ----
df6b_d1 <- read.csv(".\\exp6b_erp2\\rawdata_erp_exp6b_d1_2016_export_2019.csv",header = TRUE, sep = ",",
                 stringsAsFactors=FALSE,na.strings=c("","NA"), encoding="UTF-8") %>%
  dplyr::rename(Subject = 1) %>%
  #dplyr::filter(!is.na(BlockList.Sample)) %>%                                                   # select only form exp
  dplyr::rename(BlockNo = BlockList.Sample,
                TrialNo = SubTrial,
                Matchness = YesNoResp,
                Identity = identity,
                Valence = morality,
                CRESP = CorrectAnswer) %>%                   # rename the columns
  dplyr::mutate(RT = dplyr::coalesce(Target.RT, Targetprac.RT),
                ACC = dplyr::coalesce(Target.ACC, Targetprac.ACC),
                RESP = dplyr::coalesce(Target.RESP,Targetprac.RESP),
                Identity = ifelse(Identity == "self" | Identity == 'Self', "Self", 'Other'),     # re-code the data
                Valence = derivedFactor("Bad" = (Valence == "bad" | Valence == "immoral"), 
                                        "Good" = (Valence == "good" | Valence == 'moral'), 
                                        "Neutral" = (Valence == "normal"), 
                                        .method ="first", .default = NA),
                Matchness = ifelse(Matchness == "Yes", "Match", "Mismatch"),
                Age = ifelse(Age == 0, NA, Age),
                Val_lab = derivedFactor("Bad" = (Label == "BadSelf.bmp" | Label == "BadOther.bmp"), 
                                        "Good" = (Label == "GoodSelf.bmp" | Label == 'GoodOther.bmp'), 
                                        "Neutral" = (Label == "NormalSelf.bmp" | Label == 'NormalOther.bmp'), 
                                        .method ="first", .default = NA),
                ID_lab = ifelse(Label == "BadSelf.bmp" | Label == "GoodSelf.bmp" | Label == "NormalSelf.bmp", 
                                "Self", 'Other'),
                Site = "THU")

df6b_d2 <- read.csv(".\\exp6b_erp2\\rawdata_erp_exp6b_d2_2016_export_2019.csv",header = TRUE, sep = ",",
                 stringsAsFactors=FALSE,na.strings=c("","NA"), encoding="UTF-8") %>%
  dplyr::rename(Subject = 1) %>%
  #dplyr::filter(!is.na(BlockList.Sample)) %>%                                                   # select only form exp
  dplyr::rename(BlockNo = BlockList.Sample,
                TrialNo = SubTrial,
                Matchness = YesNoResp,
                Identity = identity,
                Valence = morality,
                CRESP = CorrectAnswer) %>%    #
  dplyr::mutate(RT = dplyr::coalesce(Target.RT, Targetprac.RT),
                ACC = dplyr::coalesce(Target.ACC, Targetprac.ACC),
                RESP = dplyr::coalesce(Target.RESP,Targetprac.RESP),
                Identity = ifelse(Identity == "self" | Identity == 'Self', "Self", 'Other'),     # re-code the data
                Valence = derivedFactor("Bad" = (Valence == "bad"), 
                                        "Good" = (Valence == "good"), 
                                        "Neutral" = (Valence == "normal"), 
                                        .method ="first", .default = NA),
                Matchness = ifelse(Matchness == "Yes", "Match", "Mismatch"),
                Age = ifelse(Age == 0, NA, Age),
                Val_lab = derivedFactor("Bad" = (Label == "BadSelf.bmp" | Label == "BadOther.bmp"), 
                                        "Good" = (Label == "GoodSelf.bmp" | Label == 'GoodOther.bmp'), 
                                        "Neutral" = (Label == "NormalSelf.bmp" | Label == 'NormalOther.bmp'), 
                                        .method ="first", .default = NA),
                ID_lab = ifelse(Label == "BadSelf.bmp" | Label == "GoodSelf.bmp" | Label == "NormalSelf.bmp", 
                                "Self", 'Other'),
                Site = "THU")

# number of participant who practiced but not in the formal experiment
nQuit <- length(unique(df6b_d1$Subject[is.na(df6b_d1$BlockNo)])) - length(unique(df6b_d1$Subject[!is.na(df6b_d1$BlockNo)]))

df6b_d1.T.basic     <- df6b_d1 %>%
  dplyr::select(Site, Subject, Age, Sex) %>%
  dplyr::distinct(Subject, .keep_all = TRUE) %>%
  dplyr::summarise(N = length(Subject),
                   N_thu = length(Site[Site == "THU"]),
                   N_wzu = length(Site[Site == "WZU"]),
                   Nf = length(Sex[Sex == "female"]),
                   Nm = length(Sex[Sex == "male"]),
                   Age_mean = round(mean(Age,na.rm=TRUE),2),
                   Age_sd = round(sd(Age,na.rm=TRUE),2))

df6b_d2.T.basic     <- df6b_d2 %>%
  dplyr::select(Site, Subject, Age, Sex) %>%
  dplyr::distinct(Subject, .keep_all = TRUE) %>%
  dplyr::summarise(N = length(Subject),
                   N_thu = length(Site[Site == "THU"]),
                   N_wzu = length(Site[Site == "WZU"]),
                   Nf = length(Sex[Sex == "female"]),
                   Nm = length(Sex[Sex == "male"]),
                   Age_mean = round(mean(Age,na.rm=TRUE),2),
                   Age_sd = round(sd(Age,na.rm=TRUE),2))
  
# participants should be excluded
df6b_d1.excld.sub <-  df6b_d1 %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::group_by(Subject) %>%
  #dplyr::mutate(ACC = ifelse(RT <= 200, 0, ACC)) %>%  # set less than 200 ms response as wrong
  dplyr::summarise(N = length(ACC),                   # caculate the overall accuracy for each subject
                   N_crrct = sum(ACC),
                   ACC = sum(ACC)/length(ACC)) %>%
  dplyr::filter(ACC < 0.6) %>%                        # exlucde the participants with less than 60% overall accuracy
  dplyr::select(Subject)

# The rate of excluded trials in valid data
df6b_d1.invalid_trial_rate   <- df6b_d1 %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::filter(!(Subject %in% df6b_d1.excld.sub$Subject)) %>%   # exclude the invalid subjects
  dplyr::summarize(rate = length(RT[RT <= 200 & ACC == 1])/length(RT)) %>%
  dplyr::pull()

df6b_d1.v   <- df6b_d1 %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::filter(!(Subject %in% df6b_d1.excld.sub$Subject)) %>%   # exclude the invalid subjects
  dplyr::filter(!(RT <= 200 & ACC == 1))                      # exclude < 200 trials

df6b_d1.v.basic     <- df6b_d1.v %>%
  dplyr::select(Site, Subject, Age, Sex) %>%
  dplyr::distinct(Subject, .keep_all = TRUE) %>%
  dplyr::summarise(N = length(Subject),
                   N_thu = length(Site[Site == "THU"]),
                   N_wzu = length(Site[Site == "WZU"]),
                   Nf = length(Sex[Sex == "female"]),
                   Nm = length(Sex[Sex == "male"]),
                   Age_mean = round(mean(Age,na.rm=TRUE),2),
                   Age_sd = round(sd(Age,na.rm=TRUE),2))

df6b_d2.excld.sub <-  df6b_d2 %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::group_by(Subject) %>%
  #dplyr::mutate(ACC = ifelse(RT <= 200, 0, ACC)) %>%  # set less than 200 ms response as wrong
  dplyr::summarise(N = length(ACC),                   # caculate the overall accuracy for each subject
                   N_crrct = sum(ACC),
                   ACC = sum(ACC)/length(ACC)) %>%
  dplyr::filter(ACC < 0.6) %>%                        # exlucde the participants with less than 60% overall accuracy
  dplyr::select(Subject)


df6b_d2.v   <- df6b_d2 %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::filter(!(Subject %in% df6b_d2.excld.sub$Subject)) %>%   # exclude the invalid subjects
  dplyr::filter(!(RT <= 200 & ACC == 1))                      # exclude < 200 trials

df6b_d2.v.basic     <- df6b_d2.v %>%
  dplyr::select(Site, Subject, Age, Sex) %>%
  dplyr::distinct(Subject, .keep_all = TRUE) %>%
  dplyr::summarise(N = length(Subject),
                   N_thu = length(Site[Site == "THU"]),
                   N_wzu = length(Site[Site == "WZU"]),
                   Nf = length(Sex[Sex == "female"]),
                   Nm = length(Sex[Sex == "male"]),
                   Age_mean = round(mean(Age,na.rm=TRUE),2),
                   Age_sd = round(sd(Age,na.rm=TRUE),2))

# calculate d prime
df6b_d1.v.dprime_l <- df6b_d1.v %>%
  dplyr::mutate(sdt = mosaic::derivedFactor("hit" = (ACC ==1 & Matchness == "Match"), # code as hit
                                    "CR" = (ACC ==1  & Matchness == "Mismatch"),      # correct reject
                                    "miss" = (ACC == 0 & Matchness == "Match"),       # miss
                                    "FA" = (ACC == 0 & Matchness == "Mismatch"),      # false alarm
                                    .method ="first",  .default = NA)) %>% 
  dplyr::group_by(Site, Subject, Age, Sex, Valence,Identity, sdt) %>%
  dplyr::summarise(N = length(sdt)) %>%                                     # calculate the counts for each 
  dplyr::ungroup() %>%
  tidyr::spread(key = sdt, value = N,fill = 0) %>%                          # long-to-wide format
  dplyr::mutate(hitR = hit/(hit + miss),                                    # hit rate
                FAR  = FA/(FA+CR)) %>%                                      # fa rate
  dplyr::mutate(hitR = ifelse(hitR == 1, 1 - 1/(2*(hit + miss)), hitR),     # if hit rate is 1, standardize it
                FAR  = ifelse(FAR == 0, 1/(2*(hit + miss)), FAR)) %>%       # if FA rate is 0, standardize it
  dplyr::mutate(dprime = qnorm(hitR) - qnorm(FAR)) %>%
  dplyr::select(Site, Subject, Age, Sex, Valence, Identity, dprime) %>%     # select relevant columns
  dplyr::mutate(Valence = factor(Valence, levels = c("Good","Neutral","Bad")),
                Identity = factor(Identity, levels = c('Self', 'Other')))

#  prepare the mean RT for each participant
df6b_d1.v.rt_m <- df6b_d1.v %>%
  dplyr::filter(ACC == 1) %>%
  dplyr::group_by(Site,Subject, Age, Sex, Matchness, Identity, Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup()

### prepare for the later meta-analysis
df6b.meta.d <- df6b_d1.v.dprime_l %>% 
  dplyr::mutate(ExpID = 'Exp6b',
                Domain = "Morality") %>%        # add domain as morality, to be comparable with experiment 5.
  dplyr::select(CommonColnames_d)

df6b.meta.rt <- df6b_d1.v.rt_m %>% 
  dplyr::rename(RT = RT_m) %>%
  dplyr::mutate(ExpID = 'Exp6b',
                Domain = "Morality") %>%        # add domain as morality, to be comparable with experiment 5.
  dplyr::select(CommonColnames_rt)

# Exp 7a matching task ----
## load data and clean data of exp 7a (copy the code from Hu et al., 2019) 
df7a_m <- read.csv(".\\exp7\\rawdata_behav_exp7a_2016.csv",header = TRUE, sep = ",",
                 stringsAsFactors=FALSE,na.strings=c("","NA")) %>%
  #dplyr::filter(!is.na(BlockList.Sample)) %>%                                                   # select only form exp
  dplyr::rename(Subject = SubjectID, 
                Sex = Gender,
                Matchness = Match,
                Valence = Morality,
                ACC = Accuracy, 
                RESP = ResponseKey) %>%    #
  dplyr::mutate(Identity = ifelse(Identity == "self" | Identity == 'Self', "Self", 'Other'),    # re-code the data
                Valence = ifelse(Valence == "moral" | Valence == "Moral", "Good", "Bad"),
                Matchness = ifelse(Matchness == "Match" | Matchness == "match", "Match", "Mismatch"),
                Age = ifelse(Age == 0, NA, Age)) %>%
  dplyr::filter(!Subject %in% c(2027, 7, 8, 7035))   # exclude participants

# exclude trials, criterio 2: practicing trials in matching task (first 48 trials)
subNo <- unique(df7a_m$Subject)
for (subj in subNo) {
      if (exists('df.M.fm')){
            df.tmp <- df7a_m[df7a_m$Subject == subj,]
            df.tmp <- df.tmp[49:nrow(df.tmp),]
            df.M.fm <- rbind(df.M.fm,df.tmp)
      } else {
            df.M.fm <- df7a_m[df7a_m$Subject == subj,]
            df.M.fm <- df.M.fm[49:nrow(df.M.fm),]
      }
}   # df.M.fm should be 14880 rows

df7a_m <- df.M.fm %>%          # all the experimental trials
  dplyr::mutate(ACC = ifelse(ACC == -1, 0, ACC))
rm(subNo,df.M.fm,df.tmp) # remove the intermedia variables

# calculate the overall accuracy for matching task
df7a_m.M.acc.g <-  df7a_m %>%
      dplyr::group_by(Subject) %>%
      dplyr::summarise(N = length(ACC),
                     countN = sum(ACC),
                     ACC = sum(ACC)/length(ACC)) %>%
      dplyr::ungroup()

df7a_m.excldSub2.M <- df7a_m.M.acc.g %>% dplyr::filter(ACC < 0.5) %>%
  dplyr::select(Subject) %>% dplyr::pull()# < 50% accuracy in matching task

df7a_m.v <- df7a_m %>%
  dplyr::filter(!Subject %in% df7a_m.excldSub2.M) %>% # exclude the invalid subjects
  dplyr::mutate(RT = RT * 1000, Site = "THU") %>%
  dplyr::filter(RT > 200) 

# calculate d prime
df7a_m.v.dprime_l <- df7a_m.v %>%
  dplyr::mutate(sdt = mosaic::derivedFactor("hit" = (ACC ==1 & Matchness == "Match"), # code as hit
                                    "CR" = (ACC ==1  & Matchness == "Mismatch"),      # correct reject
                                    "miss" = (ACC == 0 & Matchness == "Match"),       # miss
                                    "FA" = (ACC == 0 & Matchness == "Mismatch"),      # false alarm
                                    .method ="first",  .default = NA)) %>% 
  dplyr::group_by(Site, Subject, Age, Sex, Valence,Identity, sdt) %>%
  dplyr::summarise(N = length(sdt)) %>%                                     # calculate the counts for each 
  dplyr::ungroup() %>%
  tidyr::spread(key = sdt, value = N,fill = 0) %>%                          # long-to-wide format
  dplyr::mutate(hitR = hit/(hit + miss),                                    # hit rate
                FAR  = FA/(FA+CR)) %>%                                      # fa rate
  dplyr::mutate(hitR = ifelse(hitR == 1, 1 - 1/(2*(hit + miss)), hitR),     # if hit rate is 1, standardize it
                FAR  = ifelse(FAR == 0, 1/(2*(hit + miss)), FAR)) %>%       # if FA rate is 0, standardize it
  dplyr::mutate(dprime = qnorm(hitR) - qnorm(FAR)) %>%
  dplyr::select(Site, Subject, Age, Sex, Valence, Identity, dprime) %>%     # select relevant columns
  dplyr::mutate(Valence = factor(Valence, levels = c("Good","Bad")),
                Identity = factor(Identity, levels = c('Self', 'Other')))

#  prepare the mean RT for each participant
df7a_m.v.rt_m <- df7a_m.v %>%
  dplyr::filter(ACC == 1) %>%
  dplyr::group_by(Site,Subject, Age, Sex, Matchness, Identity, Valence) %>%
  dplyr::summarise(RT_m = mean(RT), Ntrial = length(RT)) %>%
  dplyr::ungroup()

### prepare for the later meta-analysis
df7a_m.meta.d <- df7a_m.v.dprime_l %>% 
  dplyr::mutate(ExpID = 'Exp7a',
                Domain = "Morality") %>%        # add domain as morality, to be comparable with experiment 5.
  dplyr::select(CommonColnames_d)

df7a_m.meta.rt <- df7a_m.v.rt_m %>% 
  dplyr::rename(RT = RT_m) %>%
  dplyr::mutate(ExpID = 'Exp7a',
                Domain = "Morality") %>%        # add domain as morality, to be comparable with experiment 5.
  dplyr::select(CommonColnames_rt)

## Load and prepare for exp7b
df7b_m <- read.csv(".\\exp7\\rawdata_behav_exp7b_2018.csv",header = TRUE, sep = ",",
                 stringsAsFactors=FALSE,na.strings=c("","NA"))

### Rule 1: wrong trials numbers because of procedure errors
df7b.excldSub1_M <- df7b_m %>%
   dplyr::mutate(ACC = ifelse(ACC == 1, 1, 0))  %>%  # no response as wrong
   dplyr::group_by(Subject, Match, Identity,Morality) %>%
   dplyr::summarise(N = length(ACC)) %>%  # count the trial # for each condition of each subject
   dplyr::ungroup() %>%
   dplyr::filter(N != 75) %>%             # filter the rows that trial Number is not 75
   dplyr::distinct(Subject) %>%           # find the unique subject ID
   dplyr::pull(Subject)                   # pull the subj ID as vector

### Rule 2:  overall accuracy < 0.5
df7b.excldSub2_M <- df7b_m %>%
   dplyr::mutate(ACC = ifelse(ACC == 1, 1, 0))  %>%  # no response as wrong
   dplyr::group_by(Subject) %>%
   dplyr::summarise(N = length(ACC),
                    countN = sum(ACC),
                    ACC = sum(ACC)/length(ACC)) %>%  # count the trial # for each condition of each subject
   dplyr::ungroup() %>%
   dplyr::filter(ACC < .5) %>%             # filter the subjects with over all ACC < 0.5
   dplyr::distinct(Subject) %>%             # find the unique subject ID
   dplyr::pull(Subject)                     # pull the subj ID as vector

### Rule 3:  one condition with zero ACC
df7b.excldSub3_M <- df7b_m %>%
   dplyr::mutate(ACC = ifelse(ACC == 1, 1, 0))  %>%  # no response as wrong
   dplyr::group_by(Subject, Match, Identity,Morality) %>%
   dplyr::summarise(N = length(ACC),
                    countN = sum(ACC),
                    ACC = sum(ACC)/length(ACC)) %>%  # count the trial # for each condition of each subject
   dplyr::ungroup() %>%
   dplyr::filter(ACC == 0) %>%             # filter the subjects with over all ACC < 0.5
   dplyr::distinct(Subject) %>%             # find the unique subject ID
   dplyr::pull(Subject)                     # pull the subj ID as vector

# all participants excluded
df7b.excldSub_M   <- c(df7b.excldSub1_M, df7b.excldSub2_M, df7b.excldSub3_M) # 7302, 7303

# select valid data for further analysis
df7b_m.V <- df7b_m %>%
  dplyr::rename(Matchness = Match,
                Valence = Morality) %>%
  dplyr::mutate(ACC = ifelse(ACC == 1, 1, 0),                  # no response as wrong
                Site = "THU",
                Matchness = ifelse(Matchness == 'match', 'Match', 'Mismatch'))  %>% 
  dplyr::filter(Subject,!Subject %in% df7b.excldSub_M)    # exclude the invalid subjects
  

# calculate d prime
df7b_m.v.dprime_l <- df7b_m.V %>%
  dplyr::mutate(sdt = mosaic::derivedFactor("hit" = (ACC ==1 & Matchness == "Match"), # code as hit
                                    "CR" = (ACC ==1  & Matchness == "Mismatch"),      # correct reject
                                    "miss" = (ACC == 0 & Matchness == "Match"),       # miss
                                    "FA" = (ACC == 0 & Matchness == "Mismatch"),      # false alarm
                                    .method ="first",  .default = NA)) %>% 
  dplyr::group_by(Site, Subject, Age, Sex, Valence,Identity, sdt) %>%
  dplyr::summarise(N = length(sdt)) %>%                                     # calculate the counts for each 
  dplyr::ungroup() %>%
  tidyr::spread(key = sdt, value = N,fill = 0) %>%                          # long-to-wide format
  dplyr::mutate(hitR = hit/(hit + miss),                                    # hit rate
                FAR  = FA/(FA+CR)) %>%                                      # fa rate
  dplyr::mutate(hitR = ifelse(hitR == 1, 1 - 1/(2*(hit + miss)), hitR),     # if hit rate is 1, standardize it
                FAR  = ifelse(FAR == 0, 1/(2*(hit + miss)), FAR)) %>%       # if FA rate is 0, standardize it
  dplyr::mutate(dprime = qnorm(hitR) - qnorm(FAR)) %>%
  dplyr::select(Site, Subject, Age, Sex, Valence, Identity, dprime) %>%     # select relevant columns
  dplyr::mutate(Valence = factor(Valence, levels = c("Good","Bad")),
                Identity = factor(Identity, levels = c('Self', 'Other')))

#  prepare the mean RT for each participant
df7b_m.v.rt_m <- df7b_m.V %>%
  dplyr::filter(ACC == 1) %>%
  dplyr::group_by(Site,Subject, Age, Sex, Matchness, Identity, Valence) %>%
  dplyr::summarise(RT_m = mean(RT)*1000,
                   Ntrial = length(RT)) %>%
  dplyr::ungroup()

### prepare for the later meta-analysis
df7b_m.meta.d <- df7b_m.v.dprime_l %>% 
  dplyr::mutate(ExpID = 'Exp7b',
                Domain = "Morality") %>%        # add domain as morality, to be comparable with experiment 5.
  dplyr::select(CommonColnames_d)

df7b_m.meta.rt <- df7b_m.v.rt_m %>% 
  dplyr::rename(RT = RT_m) %>%
  dplyr::mutate(ExpID = 'Exp7b',
                Domain = "Morality") %>%        # add domain as morality, to be comparable with experiment 5.
  dplyr::select(CommonColnames_rt)

```

```{r remove repeated subj Data,echo=FALSE,results='hide'}

## exclude the repeating subjects
df1c.meta.d <- df1c.meta.d %>% dplyr::filter(!Subject %in% c(1206, 1207, 1208, 1210))
df1c.meta.rt <- df1c.meta.rt %>% dplyr::filter(!Subject %in% c(1206, 1207, 1208, 1210)) # exclude participants who participated exp1a or 1b

df2.meta.d <- df2.meta.d %>% dplyr::filter(Subject > 2000)    # exclude participant from exp 1a
df2.meta.rt <- df2.meta.rt %>% dplyr::filter(Subject > 2000)

df3a.meta.d <- df3a.meta.d %>% dplyr::filter(!Subject %in% c(3013, 3012, 3043, 3046)) # exclude participants from ex1b, 1c, and 2
df3a.meta.rt <- df3a.meta.rt %>% dplyr::filter(!Subject %in% c(3013, 3012, 3043, 3046)) # exclude participants from ex1b, 1c, and 2

df4b.meta.d <- df4b.meta.d %>% dplyr::filter(!Subject %in% c(4210, 4202, 4201))   # exclude participants from ex1b, 1c, and 2
df4b.meta.rt <- df4b.meta.rt %>% dplyr::filter(!Subject %in% c(4210, 4202, 4201)) # exclude participants from ex1b, 1c, and 2

df5.meta.d <- df5.meta.d %>% dplyr::filter(!Subject %in% c(5201))   # exclude participants from ex1b, 1c, and 2
df5.meta.rt <- df5.meta.rt %>% dplyr::filter(!Subject %in% c(5201)) # exclude participants from ex1b, 1c, and 2

df6a.meta.d <- df6a.meta.d %>% dplyr::filter(!Subject %in% c(6118,6119,6122,6123,6131))   # exclude participants from ex1b, 1c, and 2
df6a.meta.rt <- df6a.meta.rt %>% dplyr::filter(!Subject %in% c(6118,6119,6122,6123,6131)) # exclude participants from ex1b, 1c, and 2

df6b.meta.d <- df6b.meta.d %>% dplyr::filter(!Subject %in% c(6217))   # exclude participants from ex1b, 1c, and 2
df6b.meta.rt <- df6b.meta.rt %>% dplyr::filter(!Subject %in% c(6217)) # exclude participants from ex1b, 1c, and 2

df7a_m.meta.d <- df7a_m.meta.d %>% dplyr::filter(!Subject %in% c(7020))   # exclude participants from ex1b, 1c, and 2
df7a_m.meta.rt <- df7a_m.meta.rt %>% dplyr::filter(!Subject %in% c(7020)) # exclude participants from ex1b, 1c, and 2

```

# Results
```{r first meta,echo=FALSE,results='hide'}
# Combine the data -----
df.meta_d_1 <- rbind(df1a.meta.d, df1b.meta.d, df1c.meta.d, df2.meta.d, df5.meta.d, df6a.meta.d) 

df.meta_rt_1 <- rbind(df1a.meta.rt, df1b.meta.rt, df1c.meta.rt, df2.meta.rt, df5.meta.rt, df6a.meta.rt)

# Prepare the data for meta ----
# calculate the mean, sd, n, and r for estimating the effect size and SE of effect size.
effectList_1 <- c('Good_Bad','Good_Neut','Neut_Bad')

df.ES_1 <- data.frame(matrix(, nrow=length(unique(df.meta_d_1$ExpID))*length(effectList_1)*2, ncol=0)) %>%
  dplyr::mutate(DVtype = rep(c('RT', 'dprime'), each = length(unique(df.meta_d_1$ExpID))*length(effectList_1)),
                ExpID  = rep(rep(unique(df.meta_d_1$ExpID), each = length(effectList_1)), 2),
                Effect = rep(effectList_1, length(unique(df.meta_d_1$ExpID))*2),
                #Group  = rep(groupList, length(unique(df.meta_d$ExpID))*2),
                M1 = NA, SD1 = NA, M2 = NA, SD2 = NA, N = NA, r = NA, ES = NA, ES.var = NA)

for (DVName in c('RT','dprime')){
  if (DVName == 'RT'){
    metaData <- df.meta_rt_1 %>% dplyr::filter(Matchness == "Match") %>% dplyr::rename(Value = RT)
  } else{
    metaData <- df.meta_d_1 %>% dplyr::rename(Value = dprime)
  }
  
  for (expName in unique(metaData$ExpID)){
    for (effectName in effectList_1){
      tmpdata <- metaData %>% dplyr::filter(ExpID == expName & Domain == 'Morality')
      
      if (effectName == 'Good_Bad'){
        #print(paste('processing Good_Bad of ', expName, sep = ''))
        dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good")
        dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Bad")
        }
      else if (effectName == 'Good_Neut'){
        #print(paste('processing Good_Neut of ', expName, sep = ''))
        #if ('Neutral' %in% tmpdata$Valence){
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good")
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Neutral")
        #  }
        #else{
          #print(paste('There is no Neutral condition in', expName, sepe=''))
        #  next
        #  }
        }
      else if (effectName == 'Neut_Bad'){
        #if ('Neutral' %in% tmpdata$Valence)
        #  {
            dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Neutral")
            dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Bad")  
        #  }
        #else{
            #print(paste('There is no Neutral condition in', expName, sepe=''))
        #    next
        #  }
        }
      #}
      M1  <- mean(dataCond1$Value) -> df.ES_1$M1[df.ES_1$DVtype == DVName & df.ES_1$ExpID == expName & df.ES_1$Effect == effectName]
      SD1 <- sd(dataCond1$Value)   -> df.ES_1$SD1[df.ES_1$DVtype == DVName & df.ES_1$ExpID == expName & df.ES_1$Effect == effectName] 
      M2  <- mean(dataCond2$Value) -> df.ES_1$M2[df.ES_1$DVtype == DVName & df.ES_1$ExpID == expName & df.ES_1$Effect == effectName]
      SD2 <- sd(dataCond2$Value)   -> df.ES_1$SD2[df.ES_1$DVtype == DVName & df.ES_1$ExpID == expName & df.ES_1$Effect == effectName]
      N   <- length(unique(dataCond2$Subject)) -> df.ES_1$N[df.ES_1$DVtype == DVName & df.ES_1$ExpID == expName & df.ES_1$Effect == effectName]
      r   <- cor(dataCond1$Value,dataCond2$Value) -> df.ES_1$r[df.ES_1$DVtype == DVName & df.ES_1$ExpID == expName & df.ES_1$Effect == effectName] 
      tmp2 <- d.sgpp(m.1 = M1, m.2 = M2, sd.1 = SD1, sd.2 = SD2,n = N, r = r)
      df.ES_1$ES[df.ES_1$DVtype == DVName & df.ES_1$ExpID == expName & df.ES_1$Effect == effectName] <- tmp2[1,1]
      df.ES_1$ES.var[df.ES_1$DVtype == DVName & df.ES_1$ExpID == expName & df.ES_1$Effect == effectName] <- tmp2[1,2]
    }
  }
}


# Do the meta-analysis in a for loop ----
df.ES_1_sum <- df.ES_1 %>% 
  dplyr::group_by(DVtype, Effect) %>% 
  tidyr::drop_na() %>% 
  dplyr::summarise(Nexp = length(unique(ExpID)), Nsubj = sum(N, na.rm = T))

df.res.meta_1 <- data.frame(matrix(, nrow= 3*2, ncol=0)) %>%
  dplyr::mutate(DVtype = rep(c('RT', 'dprime'), each = 3),
                Group  = rep(groupList_1, 2),
                Effect = rep(effectList_1, 2),
                #Group  = rep(groupList, length(unique(df.meta_d$ExpID))*2),
                N_exp = NA, Cohen_d = NA, se = NA, CI_low = NA, CI_upp = NA, pval = NA)

for (DVName in c('RT','dprime')){
  for (effectName in effectList_1){
    df.res.meta <- df.ES_1 %>%
      dplyr::filter(DVtype == DVName & Effect == effectName) %>%
      tidyr::drop_na()
    
    tmp.meta.res <- metafor::rma(yi = df.res.meta$ES,
                           vi = df.res.meta$ES.var,
                           slab = df.res.meta$ExpID)
    df.res.meta_1$N_exp[df.res.meta_1$DVtype == DVName & df.res.meta_1$Effect == effectName] <- tmp.meta.res$k
    df.res.meta_1$Cohen_d[df.res.meta_1$DVtype == DVName & df.res.meta_1$Effect == effectName] <- tmp.meta.res$beta
    df.res.meta_1$se[df.res.meta_1$DVtype == DVName & df.res.meta_1$Effect == effectName] <- tmp.meta.res$se
    df.res.meta_1$CI_low[df.res.meta_1$DVtype == DVName & df.res.meta_1$Effect == effectName] <- tmp.meta.res$ci.lb
    df.res.meta_1$CI_upp[df.res.meta_1$DVtype == DVName & df.res.meta_1$Effect == effectName] <- tmp.meta.res$ci.ub
    df.res.meta_1$pval[df.res.meta_1$DVtype == DVName & df.res.meta_1$Effect == effectName] <- tmp.meta.res$pval
  }
}

# Plot the effect size ----
p_meta_val_1 <- ggplot(df.res.meta_1, aes(x=DVtype, y=Cohen_d, color=Effect, fill=Effect)) + 
  geom_pointrange(aes(ymin=Cohen_d - 1.96*se, ymax = Cohen_d + 1.96*se), 
                  position = position_dodge(width = 0.4),
                  shape=18, size=1) +
  geom_hline(yintercept=0, size=1, color='black') +
  ggtitle('A: Valence effect (No-reference)') +
  #ggplot(df.res.meta_1, aes(x=DVtype, y=Cohen_d, fill=Effect)) + 
  #geom_bar(stat="identity", color=NA, 
  #         position=position_dodge()) +
  #geom_errorbar(aes(ymin=Cohen_d - 1.96*se, ymax = Cohen_d + 1.96*se), width=.2,
  #               position=position_dodge(.9)) +
  coord_cartesian(ylim=c(-1.1, 1.1))+
  scale_color_brewer(palette = "Dark2")+
  scale_fill_brewer(palette = "Dark2")+
  ylab(expression(paste("Cohen's  ",italic("d"), sep = ' ')))+
#  theme(plot.title = element_text(hjust = 0.5)) +
  apatheme
  
```

```{r second meta,echo=FALSE,results='hide'}
# Results part 2: with self-referential
# included experiments: 3a, 3b, 6b, 7a, 7b

# Combine the data  ----
df.meta_d_2 <- rbind(df3a.meta.d, df3b.meta.d, df6b.meta.d, df7a_m.meta.d, df7b_m.meta.d) 
df.meta_rt_2 <- rbind(df3a.meta.rt, df3b.meta.rt, df6b.meta.rt, df7a_m.meta.rt, df7b_m.meta.rt)

# Calculate the mean, sd, n, and r ----
# for estimating the effect size and SE of effect size.
effectList_2 <- c('Good_Bad_S','Good_Neut_S','Neut_Bad_S',
                'Good_Bad_O','Good_Neut_O','Neut_Bad_O')

df.ES_2 <- data.frame(matrix(, nrow=length(unique(df.meta_d_2$ExpID))*length(effectList_2)*2, ncol=0)) %>%
  dplyr::mutate(DVtype = rep(c('RT', 'dprime'), each = length(unique(df.meta_d_2$ExpID))*length(effectList_2)),
                ExpID  = rep(rep(unique(df.meta_d_2$ExpID), each = length(effectList_2)), 2),
                Effect = rep(effectList_2, length(unique(df.meta_d_2$ExpID))*2),
                M1 = NA, SD1 = NA, M2 = NA, SD2 = NA, N = NA, r = NA, ES = NA, ES.var = NA)

for (DVName in c('RT','dprime')){
  if (DVName == 'RT'){
    metaData <- df.meta_rt_2 %>% dplyr::filter(Matchness == "Match") %>% dplyr::rename(Value = RT)
  } else{
    metaData <- df.meta_d_2 %>% dplyr::rename(Value = dprime)
  }
  
  for (expName in unique(metaData$ExpID)){
    for (effectName in effectList_2){
      tmpdata <- metaData %>% dplyr::filter(ExpID == expName & Domain == 'Morality')
      
      if (effectName == 'Good_Bad_S'){
        
        if (!all(is.na(tmpdata$Identity))){
          #print(paste('processing Good_Bad_S of ', expName, sep = ''))
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good" & Identity == 'Self')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Bad" & Identity == 'Self')  
          }
        else{
            #print(paste('Skip Good_Bad_S of ', expName, sep = ''))
          next
          }
        }
      else if (effectName == 'Good_Neut_S'){
        if (!all(is.na(tmpdata$Identity)) & 'Neutral' %in% tmpdata$Valence ){
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good" & Identity == 'Self')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Neutral" & Identity == 'Self')  
          }
        else{
          next
          }
        }  
      else if (effectName == 'Neut_Bad_S'){
        if (!all(is.na(tmpdata$Identity)) & 'Neutral' %in% tmpdata$Valence ){
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Neutral" & Identity == 'Self')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Bad" & Identity == 'Self')  
          }
        else{
          next
          }
        }
      else if (effectName == 'Good_Bad_O'){
        if (!all(is.na(tmpdata$Identity))){
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good" & Identity == 'Other')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Bad" & Identity == 'Other')  
          }
        else{
          next
          }
        }
      else if (effectName == 'Good_Neut_O'){
        if (!all(is.na(tmpdata$Identity)) & 'Neutral' %in% tmpdata$Valence )
          {
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good" & Identity == 'Other')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Neutral" & Identity == 'Other')  
          }
        else{
          next
          }
        }
      else if (effectName == 'Neut_Bad_O'){
        if (!all(is.na(tmpdata$Identity)) & 'Neutral' %in% tmpdata$Valence){
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Neutral" & Identity == 'Other')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Bad" & Identity == 'Other')  
          }
        else{
          next
          }
      }
      
      M1  <- mean(dataCond1$Value) -> df.ES_2$M1[df.ES_2$DVtype == DVName & df.ES_2$ExpID == expName & df.ES_2$Effect == effectName]
      SD1 <- sd(dataCond1$Value)   -> df.ES_2$SD1[df.ES_2$DVtype == DVName & df.ES_2$ExpID == expName & df.ES_2$Effect == effectName] 
      M2  <- mean(dataCond2$Value) -> df.ES_2$M2[df.ES_2$DVtype == DVName & df.ES_2$ExpID == expName & df.ES_2$Effect == effectName]
      SD2 <- sd(dataCond2$Value)   -> df.ES_2$SD2[df.ES_2$DVtype == DVName & df.ES_2$ExpID == expName & df.ES_2$Effect == effectName]
      N   <- length(unique(dataCond2$Subject)) -> df.ES_2$N[df.ES_2$DVtype == DVName & df.ES_2$ExpID == expName & df.ES_2$Effect == effectName]
      r   <- cor(dataCond1$Value,dataCond2$Value) -> df.ES_2$r[df.ES_2$DVtype == DVName & df.ES_2$ExpID == expName & df.ES_2$Effect == effectName] 
      tmp2 <- d.sgpp(m.1 = M1, m.2 = M2, sd.1 = SD1, sd.2 = SD2,n = N, r = r)
      df.ES_2$ES[df.ES_2$DVtype == DVName & df.ES_2$ExpID == expName & df.ES_2$Effect == effectName] <- tmp2[1,1]
      df.ES_2$ES.var[df.ES_2$DVtype == DVName & df.ES_2$ExpID == expName & df.ES_2$Effect == effectName] <- tmp2[1,2]
    }
  }
}

# Do the meta ----
# info about participants
df.ES_2_sum <- df.ES_2 %>% 
  dplyr::group_by(DVtype, Effect) %>% 
  tidyr::drop_na() %>% 
  dplyr::summarise(Nexp = length(unique(ExpID)), Nsubj = sum(N, na.rm = T))

df.res.meta_2 <- data.frame(matrix(, nrow= (2*3)*2, ncol=0)) %>%
  dplyr::mutate(DVtype = rep(c('RT', 'dprime'), each = (2*3)),
                Effect = rep(effectList_2, 2),
                N_exp = NA, Cohen_d = NA, se = NA, CI_low = NA, CI_upp = NA, pval = NA)

# meta -analysis
for (DVName in c('RT','dprime')){
  for (effectName in effectList_2){
    df.res.meta <- df.ES_2 %>%
      dplyr::filter(DVtype == DVName & Effect == effectName) %>%
      tidyr::drop_na()
  
    tmp.meta.res <- metafor::rma(yi = df.res.meta$ES,
                           vi = df.res.meta$ES.var,
                           slab = df.res.meta$ExpID)
    df.res.meta_2$N_exp[df.res.meta_2$DVtype == DVName & df.res.meta_2$Effect == effectName] <- tmp.meta.res$k
    df.res.meta_2$Cohen_d[df.res.meta_2$DVtype == DVName & df.res.meta_2$Effect == effectName] <- tmp.meta.res$beta
    df.res.meta_2$se[df.res.meta_2$DVtype == DVName & df.res.meta_2$Effect == effectName] <- tmp.meta.res$se
    df.res.meta_2$CI_low[df.res.meta_2$DVtype == DVName & df.res.meta_2$Effect == effectName] <- tmp.meta.res$ci.lb
    df.res.meta_2$CI_upp[df.res.meta_2$DVtype == DVName & df.res.meta_2$Effect == effectName] <- tmp.meta.res$ci.ub
    df.res.meta_2$pval[df.res.meta_2$DVtype == DVName & df.res.meta_2$Effect == effectName] <- tmp.meta.res$pval
  }
}

# plot the effect size  ----
df.res.meta_2 <- df.res.meta_2 %>%
  dplyr::mutate(Identity = ifelse(Effect == "Good_Bad_S" | Effect == "Good_Neut_S" | Effect == "Neut_Bad_S",
                                  "Self", "Other"),
                EffectType = ifelse(Effect == "Good_Bad_S" | Effect == "Good_Bad_O", "Good_Bad",
                                    ifelse(Effect == "Good_Neut_S" | Effect == "Good_Neut_O", "Good_Neut", "Neut_Bad")))

p_meta_val_2_self <- df.res.meta_2 %>%
  dplyr::filter(Identity == "Self") %>%
  ggplot(., aes(x=DVtype, y=Cohen_d, color=EffectType, fill=EffectType)) + 
  geom_pointrange(aes(ymin=Cohen_d - 1.96*se, ymax = Cohen_d + 1.96*se), 
                  position = position_dodge(width = 0.4),
                  shape=18, size=1) +
  geom_hline(yintercept=0, size=1, color='black') +
  ggtitle('B: Valence effect (Self-reference)') +
  #geom_bar(stat="identity", color=NA, 
  #         position=position_dodge()) +
  #geom_errorbar(aes(ymin=Cohen_d - 1.96*se, ymax = Cohen_d + 1.96*se), width=.2,
  #               position=position_dodge(.9)) +
  coord_cartesian(ylim=c(-1.5, 1.5))+
  scale_color_brewer(palette = "Dark2")+
  scale_fill_brewer(palette = "Dark2")+
  ylab(expression(paste("Cohen's ",italic("d"), sep = ' ')))+
  apatheme

p_meta_val_2_other <- df.res.meta_2 %>%
  dplyr::filter(Identity == "Other") %>%
  ggplot(., aes(x=DVtype, y=Cohen_d, color=EffectType, fill=EffectType)) + 
  geom_pointrange(aes(ymin=Cohen_d - 1.96*se, ymax = Cohen_d + 1.96*se), 
                  position = position_dodge(width = 0.4),
                  shape=18, size=1) +
  geom_hline(yintercept=0, size=1, color='black') +
  ggtitle('C: Valence effect (Other-reference)') +
  #geom_bar(stat="identity", color=NA, 
  #         position=position_dodge()) +
  #geom_errorbar(aes(ymin=Cohen_d - 1.96*se, ymax = Cohen_d + 1.96*se), width=.2,
  #               position=position_dodge(.9)) +
  coord_cartesian(ylim=c(-1.1, 1.1))+
  scale_color_brewer(palette = "Dark2")+
  scale_fill_brewer(palette = "Dark2")+
  ylab(expression(paste("Cohen's ",italic("d"), sep = ' ')))+
  apatheme
```

```{r 'plot_all_effect', fig.cap="Effect size (Cohen's d) across experiments.", fig.height=18, fig.width=6, warning=FALSE}
multiplot(p_meta_val_1, p_meta_val_2_self,p_meta_val_2_other)
```
## Effect of moral valence

In this part, we synthesized results from experiment 1a, 1b, 1c, 2, 5 and 6a. Data from 192 participants were included in these analysis. We found differences between positive and negative conditions on RT was Cohen's *d* = `r df.res.meta_1$Cohen_d[df.res.meta_1$DVtype == 'RT' & df.res.meta_1$Effect =='Good_Bad']` $\pm$ `r df.res.meta_1$se[df.res.meta_1$DVtype == 'RT' & df.res.meta_1$Effect =='Good_Bad']`, 95% CI [`r df.res.meta_1$CI_low[df.res.meta_1$DVtype == 'RT' & df.res.meta_1$Effect =='Good_Bad']` `r df.res.meta_1$CI_upp[df.res.meta_1$DVtype == 'RT' & df.res.meta_1$Effect =='Good_Bad']`]; on *d'* was Cohen's *d* = `r df.res.meta_1$Cohen_d[df.res.meta_1$DVtype == 'dprime' & df.res.meta_1$Effect =='Good_Bad']` $\pm$ `r df.res.meta_1$se[df.res.meta_1$DVtype == 'dprime' & df.res.meta_1$Effect =='Good_Bad']`, 95% CI [`r df.res.meta_1$CI_low[df.res.meta_1$DVtype == 'dprime' & df.res.meta_1$Effect =='Good_Bad']` `r df.res.meta_1$CI_upp[df.res.meta_1$DVtype == 'dprime' & df.res.meta_1$Effect =='Good_Bad']`]. The effect was also observed between positive and neutral condition, RT: Cohen's *d* = `r df.res.meta_1$Cohen_d[df.res.meta_1$DVtype == 'RT' & df.res.meta_1$Effect =='Good_Neut']` $\pm$ `r df.res.meta_1$se[df.res.meta_1$DVtype == 'RT' & df.res.meta_1$Effect =='Good_Neut']`, 95% CI [`r df.res.meta_1$CI_low[df.res.meta_1$DVtype == 'RT' & df.res.meta_1$Effect =='Good_Neut']` `r df.res.meta_1$CI_upp[df.res.meta_1$DVtype == 'RT' & df.res.meta_1$Effect =='Good_Neut']`]; *d'*: Cohen's *d* = `r df.res.meta_1$Cohen_d[df.res.meta_1$DVtype == 'dprime' & df.res.meta_1$Effect =='Good_Neut']` $\pm$ `r df.res.meta_1$se[df.res.meta_1$DVtype == 'dprime' & df.res.meta_1$Effect =='Good_Neut']`, 95% CI [`r df.res.meta_1$CI_low[df.res.meta_1$DVtype == 'dprime' & df.res.meta_1$Effect =='Good_Neut']` `r df.res.meta_1$CI_upp[df.res.meta_1$DVtype == 'dprime' & df.res.meta_1$Effect =='Good_Neut']`]. And the difference between neutral and bad conditions are not significant, RT: Cohen's *d* = `r df.res.meta_1$Cohen_d[df.res.meta_1$DVtype == 'RT' & df.res.meta_1$Effect =='Neut_Bad']` $\pm$ `r df.res.meta_1$se[df.res.meta_1$DVtype == 'RT' & df.res.meta_1$Effect =='Neut_Bad']`, 95% CI [`r df.res.meta_1$CI_low[df.res.meta_1$DVtype == 'RT' & df.res.meta_1$Effect =='Neut_Bad']` `r df.res.meta_1$CI_upp[df.res.meta_1$DVtype == 'RT' & df.res.meta_1$Effect =='Neut_Bad']`]; *d'*: Cohen's *d* = `r df.res.meta_1$Cohen_d[df.res.meta_1$DVtype == 'dprime' & df.res.meta_1$Effect =='Neut_Bad']` $\pm$ `r df.res.meta_1$se[df.res.meta_1$DVtype == 'dprime' & df.res.meta_1$Effect =='Neut_Bad']`, 95% CI [`r df.res.meta_1$CI_low[df.res.meta_1$DVtype == 'dprime' & df.res.meta_1$Effect =='Neut_Bad']` `r df.res.meta_1$CI_upp[df.res.meta_1$DVtype == 'dprime' & df.res.meta_1$Effect =='Neut_Bad']`]. See Figure \@ref(fig:plot_all_effect) upper panel.

## Interaction between valence and self-reference
In this part, we combined the experiments that explicitly manipulated the self-reference and valence, which includes 3a, 3b, 6b, 7a, and 7b. For the positive versus negative contrast, data were from five experiments whith 178 participants; for positive versus neutral and neutral versus negative contrasts, data were from three experiments with 108 participants.

In most of these experiments, the interaction between self-reference and valence was signficant (see results of each experiment in supplementary materials). In the mini-meta-analysis, we analyzed the valence effect for self-referential condition and other-referential condition separately.

For the self-referential condition, we found the same pattern as in the first part of results. That is we found significant differences between positive and neutral as well as positive and negative, but not neutral and negative. The effect size of RT between positive and negative is Cohen's *d* = `r df.res.meta_2$Cohen_d[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Good_Bad_S']` $\pm$ `r df.res.meta_2$se[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Good_Bad_S']`, 95% CI [`r df.res.meta_2$CI_low[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Good_Bad_S']` `r df.res.meta_2$CI_upp[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Good_Bad_S']`]; on *d'* was Cohen's *d* = `r df.res.meta_2$Cohen_d[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Good_Bad_S']` $\pm$ `r df.res.meta_2$se[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Good_Bad_S']`, 95% CI [`r df.res.meta_2$CI_low[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Good_Bad_S']` `r df.res.meta_2$CI_upp[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Good_Bad_S']`]. The effect was also observed between positive and neutral condition, RT: Cohen's *d* = `r df.res.meta_2$Cohen_d[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Good_Neut_S']` $\pm$ `r df.res.meta_2$se[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Good_Neut_S']`, 95% CI [`r df.res.meta_2$CI_low[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Good_Neut_S']` `r df.res.meta_2$CI_upp[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Good_Neut_S']`]; *d'*: Cohen's *d* = `r df.res.meta_2$Cohen_d[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Good_Neut_S']` $\pm$ `r df.res.meta_2$se[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Good_Neut_S']`, 95% CI [`r df.res.meta_2$CI_low[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Good_Neut_S']` `r df.res.meta_2$CI_upp[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Good_Neut_S']`]. And the difference between neutral and bad conditions are not significant, RT: Cohen's *d* = `r df.res.meta_2$Cohen_d[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Neut_Bad_S']` $\pm$ `r df.res.meta_2$se[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Neut_Bad_S']`, 95% CI [`r df.res.meta_2$CI_low[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Neut_Bad_S']` `r df.res.meta_2$CI_upp[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Neut_Bad_S']`]; *d'*: Cohen's *d* = `r df.res.meta_2$Cohen_d[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Neut_Bad_S']` $\pm$ `r df.res.meta_2$se[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Neut_Bad_S']`, 95% CI [`r df.res.meta_2$CI_low[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Neut_Bad_S']` `r df.res.meta_2$CI_upp[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Neut_Bad_S']`]. See Figure \@ref(fig:plot_all_effect) middle panel.

For the other-referential condition, we found that only the difference between positive and negative on RT was significant, all the other conditions were not. The effect size of RT between positive and negative is Cohen's *d* = `r df.res.meta_2$Cohen_d[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Good_Bad_O']` $\pm$ `r df.res.meta_2$se[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Good_Bad_O']`, 95% CI [`r df.res.meta_2$CI_low[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Good_Bad_O']` `r df.res.meta_2$CI_upp[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Good_Bad_O']`]; on *d'* was Cohen's *d* = `r df.res.meta_2$Cohen_d[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Good_Bad_O']` $\pm$ `r df.res.meta_2$se[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Good_Bad_O']`, 95% CI [`r df.res.meta_2$CI_low[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Good_Bad_O']` `r df.res.meta_2$CI_upp[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Good_Bad_O']`]. The effect was also observed between positive and neutral condition, RT: Cohen's *d* = `r df.res.meta_2$Cohen_d[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Good_Neut_O']` $\pm$ `r df.res.meta_2$se[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Good_Neut_O']`, 95% CI [`r df.res.meta_2$CI_low[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Good_Neut_O']` `r df.res.meta_2$CI_upp[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Good_Neut_O']`]; *d'*: Cohen's *d* = `r df.res.meta_2$Cohen_d[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Good_Neut_O']` $\pm$ `r df.res.meta_2$se[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Good_Neut_O']`, 95% CI [`r df.res.meta_2$CI_low[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Good_Neut_O']` `r df.res.meta_2$CI_upp[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Good_Neut_O']`]. And the difference between neutral and bad conditions are not significant, RT: Cohen's *d* = `r df.res.meta_2$Cohen_d[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Neut_Bad_O']` $\pm$ `r df.res.meta_2$se[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Neut_Bad_O']`, 95% CI [`r df.res.meta_2$CI_low[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Neut_Bad_O']` `r df.res.meta_2$CI_upp[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Neut_Bad_O']`]; *d'*: Cohen's *d* = `r df.res.meta_2$Cohen_d[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Neut_Bad_O']` $\pm$ `r df.res.meta_2$se[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Neut_Bad_O']`, 95% CI [`r df.res.meta_2$CI_low[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Neut_Bad_O']` `r df.res.meta_2$CI_upp[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Neut_Bad_O']`]. See Figure \@ref(fig:plot_all_effect) lower panel.

## Generalizibility of the effect
In this part, we reported the results from experiment 4 in which either moral valence or self-reference were manipulated as task-irrelevant stimuli. 

```{r analyzing for d prime_4a, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
#effectList_2 <- c('Good_Bad_S','Good_Neut_S','Neut_Bad_S',
#                'Good_Bad_O','Good_Neut_O','Neut_Bad_O')

df.ES_4a <- data.frame(matrix(, nrow=length(unique(df4a.meta.d$ExpID))*length(effectList_2)*2, ncol=0)) %>%
  dplyr::mutate(DVtype = rep(c('RT', 'dprime'), each = length(unique(df4a.meta.d$ExpID))*length(effectList_2)),
                ExpID  = rep(rep(unique(df4a.meta.d$ExpID), each = length(effectList_2)), 2),
                Effect = rep(effectList_2, length(unique(df4a.meta.d$ExpID))*2),
                M1 = NA, SD1 = NA, M2 = NA, SD2 = NA, N = NA, r = NA, ES = NA, ES.var = NA)

for (DVName in c('RT','dprime')){
  if (DVName == 'RT'){
    metaData <- df4a.meta.rt %>% dplyr::filter(Matchness == "Match") %>% dplyr::rename(Value = RT)
  } else{
    metaData <- df4a.meta.d %>% dplyr::rename(Value = dprime)
  }
  
  for (expName in unique(metaData$ExpID)){
    for (effectName in effectList_2){
      tmpdata <- metaData %>% dplyr::filter(ExpID == expName & Domain == 'Morality')
      
      if (effectName == 'Good_Bad_S'){
        
        if (!all(is.na(tmpdata$Identity))){
          #print(paste('processing Good_Bad_S of ', expName, sep = ''))
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good" & Identity == 'Self')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Bad" & Identity == 'Self')  
          }
        else{
            #print(paste('Skip Good_Bad_S of ', expName, sep = ''))
          next
          }
        }
      else if (effectName == 'Good_Neut_S'){
        if (!all(is.na(tmpdata$Identity)) & 'Neutral' %in% tmpdata$Valence ){
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good" & Identity == 'Self')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Neutral" & Identity == 'Self')  
          }
        else{
          next
          }
        }  
      else if (effectName == 'Neut_Bad_S'){
        if (!all(is.na(tmpdata$Identity)) & 'Neutral' %in% tmpdata$Valence ){
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Neutral" & Identity == 'Self')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Bad" & Identity == 'Self')  
          }
        else{
          next
          }
        }
      else if (effectName == 'Good_Bad_O'){
        if (!all(is.na(tmpdata$Identity))){
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good" & Identity == 'Other')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Bad" & Identity == 'Other')  
          }
        else{
          next
          }
        }
      else if (effectName == 'Good_Neut_O'){
        if (!all(is.na(tmpdata$Identity)) & 'Neutral' %in% tmpdata$Valence )
          {
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good" & Identity == 'Other')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Neutral" & Identity == 'Other')  
          }
        else{
          next
          }
        }
      else if (effectName == 'Neut_Bad_O'){
        if (!all(is.na(tmpdata$Identity)) & 'Neutral' %in% tmpdata$Valence){
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Neutral" & Identity == 'Other')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Bad" & Identity == 'Other')  
          }
        else{
          next
          }
      }
      
      M1  <- mean(dataCond1$Value) -> df.ES_4a$M1[df.ES_4a$DVtype == DVName & df.ES_4a$ExpID == expName & df.ES_4a$Effect == effectName]
      SD1 <- sd(dataCond1$Value)   -> df.ES_4a$SD1[df.ES_4a$DVtype == DVName & df.ES_4a$ExpID == expName & df.ES_4a$Effect == effectName] 
      M2  <- mean(dataCond2$Value) -> df.ES_4a$M2[df.ES_4a$DVtype == DVName & df.ES_4a$ExpID == expName & df.ES_4a$Effect == effectName]
      SD2 <- sd(dataCond2$Value)   -> df.ES_4a$SD2[df.ES_4a$DVtype == DVName & df.ES_4a$ExpID == expName & df.ES_4a$Effect == effectName]
      N   <- length(unique(dataCond2$Subject)) -> df.ES_4a$N[df.ES_4a$DVtype == DVName & df.ES_4a$ExpID == expName & df.ES_4a$Effect == effectName]
      r   <- cor(dataCond1$Value,dataCond2$Value) -> df.ES_4a$r[df.ES_4a$DVtype == DVName & df.ES_4a$ExpID == expName & df.ES_4a$Effect == effectName] 
      tmp2 <- d.sgpp(m.1 = M1, m.2 = M2, sd.1 = SD1, sd.2 = SD2,n = N, r = r)
      df.ES_4a$ES[df.ES_4a$DVtype == DVName & df.ES_4a$ExpID == expName & df.ES_4a$Effect == effectName] <- tmp2[1,1]
      df.ES_4a$ES.var[df.ES_4a$DVtype == DVName & df.ES_4a$ExpID == expName & df.ES_4a$Effect == effectName] <- tmp2[1,2]
    }
  }
}

df.ES_4a <- df.ES_4a %>%
  dplyr::mutate(Identity = ifelse(Effect == "Good_Bad_S" | Effect == "Good_Neut_S" | Effect == "Neut_Bad_S",
                                  "Self", "Other"),
                EffectType = ifelse(Effect == "Good_Bad_S" | Effect == "Good_Bad_O", "Good_Bad",
                                    ifelse(Effect == "Good_Neut_S" | Effect == "Good_Neut_O", "Good_Neut", "Neut_Bad")))

p_df_4a_self <- df.ES_4a %>%
  dplyr::filter(Identity == "Self") %>%
  ggplot(., aes(x=DVtype, y=ES, color=EffectType, fill=EffectType)) + 
  geom_pointrange(aes(ymin=ES - 1.96*sqrt(ES.var), ymax = ES + 1.96*sqrt(ES.var)), 
                  position = position_dodge(width = 0.4),
                  shape=18, size=1) +
  geom_hline(yintercept=0, size=1, color='black') +
  ggtitle('A: Valence effect (Self-ref.)') +
  coord_cartesian(ylim=c(-1.1, 1.1))+
  scale_color_brewer(palette = "Dark2")+
  scale_fill_brewer(palette = "Dark2")+
  ylab(expression(paste("Cohen's ",italic("d"), sep = ' ')))+
  apatheme

p_df_4a_other <- df.ES_4a %>%
  dplyr::filter(Identity == "Other") %>%
  ggplot(., aes(x=DVtype, y=ES, color=EffectType, fill=EffectType)) + 
  geom_pointrange(aes(ymin=ES - 1.96*sqrt(ES.var), ymax = ES + 1.96*sqrt(ES.var)), 
                  position = position_dodge(width = 0.4),
                  shape=18, size=1) +
  geom_hline(yintercept=0, size=1, color='black') +
  ggtitle('B: Valence effect (Other-ref.)') +
  coord_cartesian(ylim=c(-1.1, 1.1))+
  scale_color_brewer(palette = "Dark2")+
  scale_fill_brewer(palette = "Dark2")+
  ylab(expression(paste("Cohen's ",italic("d"), sep = ' ')))+
  apatheme

multiplot(p_df_4a_self, p_df_4a_other, cols=2)
```

For exmperiment 4a, we found that the main effect of valence for *d* prime under the self-referential condtions was marginally significant, `r df4a_dprime_s_anova_apa$full$Valence`. We comparied three conditions then, which showed that good-self condition () had higher *d* prime than bad-self condition (); good self condition was also higher than neutral self but there was not statistically significant. For reaction times, paired *t*-tests showed that good-self condition (654 ± 67) were faster relative to bad-self condition (665 ± 64.6), *t*(58) = -3.47, *p* = 0.0028, Cohen’s *d* = -0.451 CI [-0.718 -0.182], BF10 = 27.0, and  over neutral-self condition (664 ± 64), *t*(58) = -2.78, *p* = 0.013, Cohen’s  *d* = -0.362, 95% CI [-0.624 -0.097], BF10 = 4.63. The neutral-self and bad-self conditionsdid not differ, *t*(58) = -0.44, *p* = 0.89, Cohen’s *d* = 0.0499, CI [-0.305 0.206], BF10 = 0.153.

For experiemnt 4b, we found that the d prime was not significant different between self- vs. other-referential condition for positive condition. The RT for good-other association condition (688 ± 66.9) is faster than the bad-other association condition (718 ± 49.7), t(44) = -3.353, p = 0.0017, Cohen’s d = -0.4999, 95%CI [-0.8075 -0.1872], BF10 = 18.84. The RT for good-other condition is slightly faster than neutral-other condition (704 ± 57.1), but the evidence is not strong, t (44) = -2.21, p = 0.0324, Cohen’s d = -0.3294, 95%CI [-6278 -0.0275], BF10 = 1.454. While there is is no strong evidence about the differences between bad-other vs. neutral-other conditions, t(44) = -1.8267, p = 0.0745, Cohen’s d = -0.2723, 95%CI [-0.5685 0.0268], BF10 = 0.743.

## Specificity of moral valence effect

## Individual difference

we conducted 13 meta-analyses for both reaction times and *d* prime for both valence effect and self-relevance effect. For the valence effect, we compared the differences between valences for over all effect as well as for self-referential and other-referential separately. The Good-Bad contrast included 13 experiments (1a - 7b, N = `r df.ES_sum$Nsubj[df.ES_sum$Effect == 'Good_Bad' & df.ES_sum$DVtype == 'dprime']`) while the Good-Neutral and Neutral-Bad contrasts included 11 experiments (1a ~ 6b, N = `r df.ES_sum$Nsubj[df.ES_sum$Effect == 'Neut_Bad' & df.ES_sum$DVtype == 'dprime']`). Then we combined the experiments with the variable of self-referential, and calculated the effect of valence for self-referential and other-referential separately. For the Good-Bad contrast, both self- and other-referential condition included 7 experiments (3a, 3b, 4a, 4b, 6b, 7a, 7b, N = `r df.ES_sum$Nsubj[df.ES_sum$Effect == 'Good_Bad_S' & df.ES_sum$DVtype == 'dprime']`), while for the Good-Neutral and Neutroal contrast, both conditions included 5 experiments (3a, 3b, 4a, 4b, 6b, N = `r df.ES_sum$Nsubj[df.ES_sum$Effect == 'Neut_Bad_S' & df.ES_sum$DVtype == 'dprime']`).

The self-referential effect was also calculated overall as well as under three valence conditions. The overall self-referential effect and the self-referential effect under good and bad conditions was estimated from 7 experiments (3a, 3b, 4a, 4b, 6b, 7a, 7b, N = `r df.ES_sum$Nsubj[df.ES_sum$Effect == 'Self_Other' & df.ES_sum$DVtype == 'dprime']`), while the self-referential effect under the neutral condition were estimated from 5 experiments (3a, 3b, 4a, 4b, 6b, N = `r df.ES_sum$Nsubj[df.ES_sum$Effect == 'Self_Other_N' & df.ES_sum$DVtype == 'dprime']`)


```{r third meta,echo=FALSE,results='hide'}
df.meta_d <- rbind(df1a.meta.d, df1b.meta.d, df1c.meta.d, df2.meta.d, df3a.meta.d, df3b.meta.d, df4a.meta.d,
                   df4b.meta.d, df5.meta.d, df6a.meta.d, df6b.meta.d, df7a_m.meta.d, df7b_m.meta.d) 

df.meta_rt <- rbind(df1a.meta.rt, df1b.meta.rt, df1c.meta.rt, df2.meta.rt, df3a.meta.rt, df3b.meta.rt, df4a.meta.rt,
                   df4b.meta.rt, df5.meta.rt, df6a.meta.rt, df6b.meta.rt, df7a_m.meta.rt, df7b_m.meta.rt)

# calculate the mean, sd, n, and r for estimating the effect size and SE of effect size.
effectList <- c('Good_Bad','Good_Neut','Neut_Bad',
                'Good_Bad_S','Good_Neut_S','Neut_Bad_S',
                'Good_Bad_O','Good_Neut_O','Neut_Bad_O',
                'Self_Other','Self_Other_G','Self_Other_N',
                'Self_Other_B')

df.ES <- data.frame(matrix(, nrow=length(unique(df.meta_d$ExpID))*length(effectList)*2, ncol=0)) %>%
  dplyr::mutate(DVtype = rep(c('RT', 'dprime'), each = length(unique(df.meta_d$ExpID))*length(effectList)),
                ExpID  = rep(rep(unique(df.meta_d$ExpID), each = length(effectList)), 2),
                Effect = rep(effectList, length(unique(df.meta_d$ExpID))*2),
                #Group  = rep(groupList, length(unique(df.meta_d$ExpID))*2),
                M1 = NA, SD1 = NA, M2 = NA, SD2 = NA, N = NA, r = NA, ES = NA, ES.var = NA)

for (DVName in c('RT','dprime')){
  if (DVName == 'RT'){
    metaData <- df.meta_rt %>% dplyr::filter(Matchness == "Match") %>% dplyr::rename(Value = RT)
  } else{
    metaData <- df.meta_d %>% dplyr::rename(Value = dprime)
  }
  
  for (expName in unique(metaData$ExpID)){
    for (effectName in effectList){
      tmpdata <- metaData %>% dplyr::filter(ExpID == expName & Domain == 'Morality')
      
      if (effectName == 'Good_Bad'){
        #print(paste('processing Good_Bad of ', expName, sep = ''))
        dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good")
        dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Bad")
        }
      else if (effectName == 'Good_Neut'){
        #print(paste('processing Good_Neut of ', expName, sep = ''))
        if ('Neutral' %in% tmpdata$Valence){
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good")
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Neutral")
          }
        else{
          #print(paste('There is no Neutral condition in', expName, sepe=''))
          next
          }
        }
      else if (effectName == 'Neut_Bad'){
        if ('Neutral' %in% tmpdata$Valence)
          {
            dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Neutral")
            dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Bad")  
          }
        else{
            #print(paste('There is no Neutral condition in', expName, sepe=''))
            next
          }
        }
      else if (effectName == 'Good_Bad_S'){
        if (!all(is.na(tmpdata$Identity))){
          #print(paste('processing Good_Bad_S of ', expName, sep = ''))
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good" & Identity == 'Self')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Bad" & Identity == 'Self')  
          }
        else{
            #print(paste('Skip Good_Bad_S of ', expName, sep = ''))
          next
          }
        }
      else if (effectName == 'Good_Neut_S'){
        if (!all(is.na(tmpdata$Identity)) & 'Neutral' %in% tmpdata$Valence )
          {
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good" & Identity == 'Self')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Neutral" & Identity == 'Self')  
          }
        else{
          next
          }
        }  
      else if (effectName == 'Neut_Bad_S'){
        if (!all(is.na(tmpdata$Identity)) & 'Neutral' %in% tmpdata$Valence ){
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Neutral" & Identity == 'Self')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Bad" & Identity == 'Self')  
          }
        else{
          next
          }
        }
      else if (effectName == 'Good_Bad_O'){
        if (!all(is.na(tmpdata$Identity))){
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good" & Identity == 'Other')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Bad" & Identity == 'Other')  
          }
        else{
          next
          }
        }
      else if (effectName == 'Good_Neut_O'){
        if (!all(is.na(tmpdata$Identity)) & 'Neutral' %in% tmpdata$Valence )
          {
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good" & Identity == 'Other')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Neutral" & Identity == 'Other')  
          }
        else{
          next
          }
        }  
      else if (effectName == 'Neut_Bad_O'){
        if (!all(is.na(tmpdata$Identity)) & 'Neutral' %in% tmpdata$Valence){
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Neutral" & Identity == 'Other')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Bad" & Identity == 'Other')  
          }
        else{
          next
          }
      }
      else if (effectName == 'Self_Other'){
        if (!all(is.na(tmpdata$Identity))){
          dataCond1 <- tmpdata %>% dplyr::filter(Identity == 'Self')
          dataCond2 <- tmpdata %>% dplyr::filter(Identity == 'Other')  
          }
        else{
          next
          }
      }
      else if (effectName == 'Self_Other_G'){
        if (!all(is.na(tmpdata$Identity))){
          dataCond1 <- tmpdata %>% dplyr::filter(Identity == 'Self' & Valence == "Good")
          dataCond2 <- tmpdata %>% dplyr::filter(Identity == 'Other' & Valence == "Good")  
          }
        else{
          next
          }
      }
      else if (effectName == 'Self_Other_N'){
        if (!all(is.na(tmpdata$Identity)) & 'Neutral' %in% tmpdata$Valence){
          dataCond1 <- tmpdata %>% dplyr::filter(Identity == 'Self' & Valence == "Neutral")
          dataCond2 <- tmpdata %>% dplyr::filter(Identity == 'Other' & Valence == "Neutral")  
          }
        else{
          next
          }
      }
      else if (effectName == 'Self_Other_B'){
        if (!all(is.na(tmpdata$Identity))){
          dataCond1 <- tmpdata %>% dplyr::filter(Identity == 'Self' & Valence == "Bad")
          dataCond2 <- tmpdata %>% dplyr::filter(Identity == 'Other' & Valence == "Bad")  
          }
        else{
          next
          }
      }
      
      M1  <- mean(dataCond1$Value) -> df.ES$M1[df.ES$DVtype == DVName & df.ES$ExpID == expName & df.ES$Effect == effectName]
      SD1 <- sd(dataCond1$Value)   -> df.ES$SD1[df.ES$DVtype == DVName & df.ES$ExpID == expName & df.ES$Effect == effectName] 
      M2  <- mean(dataCond2$Value) -> df.ES$M2[df.ES$DVtype == DVName & df.ES$ExpID == expName & df.ES$Effect == effectName]
      SD2 <- sd(dataCond2$Value)   -> df.ES$SD2[df.ES$DVtype == DVName & df.ES$ExpID == expName & df.ES$Effect == effectName]
      N   <- length(unique(dataCond2$Subject)) -> df.ES$N[df.ES$DVtype == DVName & df.ES$ExpID == expName & df.ES$Effect == effectName]
      r   <- cor(dataCond1$Value,dataCond2$Value) -> df.ES$r[df.ES$DVtype == DVName & df.ES$ExpID == expName & df.ES$Effect == effectName] 
      tmp2 <- d.sgpp(m.1 = M1, m.2 = M2, sd.1 = SD1, sd.2 = SD2,n = N, r = r)
      df.ES$ES[df.ES$DVtype == DVName & df.ES$ExpID == expName & df.ES$Effect == effectName] <- tmp2[1,1]
      df.ES$ES.var[df.ES$DVtype == DVName & df.ES$ExpID == expName & df.ES$Effect == effectName] <- tmp2[1,2]
    }
  }
}

df.ES_sum <- df.ES %>% 
  dplyr::group_by(DVtype, Effect) %>% 
  tidyr::drop_na() %>% 
  dplyr::summarise(Nexp = length(unique(ExpID)), Nsubj = sum(N, na.rm = T))

groupList <- rep(c('Overall','Self','Other'), each = 3)
groupList[10:13] <- c('Self_Other', 'Self_Other_G', 'Self_Other_N', 'Self_Other_B')

df.res.meta.all <- data.frame(matrix(, nrow= (3*3 + 4)*2, ncol=0)) %>%
  dplyr::mutate(DVtype = rep(c('RT', 'dprime'), each = (3*3 + 4)),
                Group  = rep(groupList, 2),
                Effect = rep(effectList, 2),
                #Group  = rep(groupList, length(unique(df.meta_d$ExpID))*2),
                N_exp = NA, Cohen_d = NA, se = NA, CI_low = NA, CI_upp = NA, pval = NA)

#magicfor::magic_for(silent = TRUE)
p_meta_list = list() # create a empty list to store the forest plot

for (DVName in c('RT','dprime')){
  for (effectName in effectList){
    df.res.meta <- df.ES %>%
      dplyr::filter(DVtype == DVName & Effect == effectName) %>%
      tidyr::drop_na()
  
    tmp.meta.res <- metafor::rma(yi = df.res.meta$ES,
                           vi = df.res.meta$ES.var,
                           slab = df.res.meta$ExpID)
    df.res.meta.all$N_exp[df.res.meta.all$DVtype == DVName & df.res.meta.all$Effect == effectName] <- tmp.meta.res$k
    df.res.meta.all$Cohen_d[df.res.meta.all$DVtype == DVName & df.res.meta.all$Effect == effectName] <- tmp.meta.res$beta
    df.res.meta.all$se[df.res.meta.all$DVtype == DVName & df.res.meta.all$Effect == effectName] <- tmp.meta.res$se
    df.res.meta.all$CI_low[df.res.meta.all$DVtype == DVName & df.res.meta.all$Effect == effectName] <- tmp.meta.res$ci.lb
    df.res.meta.all$CI_upp[df.res.meta.all$DVtype == DVName & df.res.meta.all$Effect == effectName] <- tmp.meta.res$ci.ub
    df.res.meta.all$pval[df.res.meta.all$DVtype == DVName & df.res.meta.all$Effect == effectName] <- tmp.meta.res$pval
  }
}

#magicfor::magic_result()
df.res.meta.all_val <- df.res.meta.all[c(1:9, 14:22),]
df.res.meta.all_val$EffectType <- rep(c('Good_Bad','Good_Neut','Neut_Bad'), 3*2)

df.res.meta.all_id  <- df.res.meta.all[c(10:13, 23:26),]
df.res.meta.all_id$Group <- rep(c('Overall','Good', 'Neutral','Bad'), 2)
df.res.meta.all_id$EffectType <- 'Self-Other'
df.res.meta.all_id <- df.res.meta.all_id %>% 
  dplyr::mutate(Group = factor(Group, levels = c('Good', 'Neutral','Bad', 'Overall')),
                DVtype = factor(DVtype, levels = c("RT", "dprime")))

df.res.meta.dprime_val <- df.res.meta.all_val %>% dplyr::filter(DVtype == 'dprime') %>%
  dplyr::mutate(Group = factor(Group, levels = c("Overall", "Self", "Other")),
                EffectType = factor(EffectType, levels = c('Good_Bad','Good_Neut', 'Neut_Bad')))

df.res.meta.rt_val <- df.res.meta.all_val %>% dplyr::filter(DVtype == 'RT') %>%
  dplyr::mutate(Group = factor(Group, levels = c("Overall", "Self", "Other")),
                EffectType = factor(EffectType, levels = c('Good_Bad','Good_Neut', 'Neut_Bad')))

p_meta_dprime_val <- ggplot(df.res.meta.dprime_val, aes(x=Group, y=Cohen_d, fill=EffectType)) + 
  geom_bar(stat="identity", color=NA, 
           position=position_dodge()) +
  geom_errorbar(aes(ymin=Cohen_d - 1.96*se, ymax = Cohen_d + 1.96*se), width=.2,
                 position=position_dodge(.9)) +
  coord_cartesian(ylim=c(-0.2, 1))+
  scale_color_brewer(palette = "Dark2")+
  scale_fill_brewer(palette = "Dark2")+
  ylab(expression(paste("Cohen' d of ",italic("d"), "prime", sep = ' ')))+
  apatheme

p_meta_rt_val <- ggplot(df.res.meta.rt_val, aes(x=Group, y=Cohen_d, fill=EffectType)) + 
  geom_bar(stat="identity", color=NA, 
           position=position_dodge()) +
  geom_errorbar(aes(ymin=Cohen_d - 1.96*se, ymax=Cohen_d + 1.96*se), width=.2,
                 position=position_dodge(.9)) +
  coord_cartesian(ylim=c(-1, 0.2))+
  scale_y_reverse()+
  scale_color_brewer(palette = "Dark2")+
  scale_fill_brewer(palette = "Dark2")+
  ylab("Cohen' d of  RTs")+
  apatheme


p_meta_id <- ggplot(df.res.meta.all_id, aes(x=DVtype, y=Cohen_d, fill=Group)) + 
  geom_bar(stat="identity", color=NA, 
           position=position_dodge()) +
  geom_errorbar(aes(ymin=Cohen_d - 1.96*se, ymax = Cohen_d + 1.96*se), width=.2,
                 position=position_dodge(.9)) +
  coord_cartesian(ylim=c(-1, 1))+
  scale_color_brewer(palette = "Dark2")+
  scale_fill_brewer(palette = "Dark2")+
  ylab(expression(paste("Cohen' d", sep = ' ')))+
  apatheme

```



## Results

```{r 'meta-all-val', fig.cap="Meta-analysis of RT and *d* prime for valence effect.", fig.height=6, fig.width=15, fig.align="center", warning=FALSE}

multiplot(p_meta_rt_val, p_meta_dprime_val, cols = 2)

```


Figure \@ref(fig:meta-all-val) shows meta-analytic results for the effect of *d* prime and reaction times from Good-Bad, Good-Neutral, and Neutral-Bad contrast. 

Across all experiments, we found that the good-association condition has advantage over bad conditions for both RT (Cohen's d = `r df.res.meta.all$Cohen_d[df.res.meta.all$DVtype == 'RT' & df.res.meta.all$Group == 'Overall' & df.res.meta.all$Effect == 'Good_Bad']`, 95%CI[`r df.res.meta.all$CI_low[df.res.meta.all$DVtype == 'RT' & df.res.meta.all$Group == 'Overall' & df.res.meta.all$Effect == 'Good_Bad']` `r df.res.meta.all$CI_upp[df.res.meta.all$DVtype == 'RT' & df.res.meta.all$Group == 'Overall' & df.res.meta.all$Effect == 'Good_Bad']`]) and *d* prime (Cohen's *d* = `r df.res.meta.all$Cohen_d[df.res.meta.all$DVtype == 'dprime' & df.res.meta.all$Group == 'Overall' & df.res.meta.all$Effect == 'Good_Bad']`, 95%CI[`r df.res.meta.all$CI_low[df.res.meta.all$DVtype == 'dprime' & df.res.meta.all$Group == 'Overall' & df.res.meta.all$Effect == 'Good_Bad']` `r df.res.meta.all$CI_upp[df.res.meta.all$DVtype == 'dprime' & df.res.meta.all$Group == 'Overall' & df.res.meta.all$Effect == 'Good_Bad']`]). Also the good-association has advantages over the neutral condition for both RT (Cohen's *d* = `r df.res.meta.all$Cohen_d[df.res.meta.all$DVtype == 'RT' & df.res.meta.all$Group == 'Overall' & df.res.meta.all$Effect == 'Good_Neut']`, 95%CI[`r df.res.meta.all$CI_low[df.res.meta.all$DVtype == 'RT' & df.res.meta.all$Group == 'Overall' & df.res.meta.all$Effect == 'Good_Neut']` `r df.res.meta.all$CI_upp[df.res.meta.all$DVtype == 'RT' & df.res.meta.all$Group == 'Overall' & df.res.meta.all$Effect == 'Good_Neut']`]) and *d* prime (Cohen's *d* = `r df.res.meta.all$Cohen_d[df.res.meta.all$DVtype == 'dprime' & df.res.meta.all$Group == 'Overall' & df.res.meta.all$Effect == 'Good_Neut']`, 95%CI[`r df.res.meta.all$CI_low[df.res.meta.all$DVtype == 'dprime' & df.res.meta.all$Group == 'Overall' & df.res.meta.all$Effect == 'Good_Neut']` `r df.res.meta.all$CI_upp[df.res.meta.all$DVtype == 'dprime' & df.res.meta.all$Group == 'Overall' & df.res.meta.all$Effect == 'Good_Neut']`]). But the neutral condition did not differ from the bad conditions for d prime (Cohen's *d* = `r df.res.meta.all$Cohen_d[df.res.meta.all$DVtype == 'dprime' & df.res.meta.all$Group == 'Overall' & df.res.meta.all$Effect == 'Neut_Bad']`, 95%CI[`r df.res.meta.all$CI_low[df.res.meta.all$DVtype == 'dprime' & df.res.meta.all$Group == 'Overall' & df.res.meta.all$Effect == 'Neut_Bad']` `r df.res.meta.all$CI_upp[df.res.meta.all$DVtype == 'dprime' & df.res.meta.all$Group == 'Overall' & df.res.meta.all$Effect == 'Neut_Bad']`]) but slightly faster on RT, RT Cohen's (Cohen's *d* = `r df.res.meta.all$Cohen_d[df.res.meta.all$DVtype == 'RT' & df.res.meta.all$Group == 'Overall' & df.res.meta.all$Effect == 'Neut_Bad']`, 95%CI[`r df.res.meta.all$CI_low[df.res.meta.all$DVtype == 'RT' & df.res.meta.all$Group == 'Overall' & df.res.meta.all$Effect == 'Neut_Bad']` `r df.res.meta.all$CI_upp[df.res.meta.all$DVtype == 'RT' & df.res.meta.all$Group == 'Overall' & df.res.meta.all$Effect == 'Neut_Bad']`]).

When we distinguish between self-referential and other-referential conditions, it is clear that the over all effect was mainly stem from the self-referential conditions: The good-association condition has advantage over bad conditions for both RT (Cohen's d = `r df.res.meta.all$Cohen_d[df.res.meta.all$DVtype == 'RT' & df.res.meta.all$Group == 'Self' & df.res.meta.all$Effect == 'Good_Bad']`, 95%CI[`r df.res.meta.all$CI_low[df.res.meta.all$DVtype == 'RT' & df.res.meta.all$Group == 'Self' & df.res.meta.all$Effect == 'Good_Bad']` `r df.res.meta.all$CI_upp[df.res.meta.all$DVtype == 'RT' & df.res.meta.all$Group == 'Self' & df.res.meta.all$Effect == 'Good_Bad']`]) and *d* prime (Cohen's *d* = `r df.res.meta.all$Cohen_d[df.res.meta.all$DVtype == 'dprime' & df.res.meta.all$Group == 'Self' & df.res.meta.all$Effect == 'Good_Bad']`, 95%CI[`r df.res.meta.all$CI_low[df.res.meta.all$DVtype == 'dprime' & df.res.meta.all$Group == 'Self' & df.res.meta.all$Effect == 'Good_Bad']` `r df.res.meta.all$CI_upp[df.res.meta.all$DVtype == 'dprime' & df.res.meta.all$Group == 'Self' & df.res.meta.all$Effect == 'Good_Bad']`]), and over neutral condition for both  both RT (Cohen's *d* = `r df.res.meta.all$Cohen_d[df.res.meta.all$DVtype == 'RT' & df.res.meta.all$Group == 'Self' & df.res.meta.all$Effect == 'Good_Neut']`, 95%CI[`r df.res.meta.all$CI_low[df.res.meta.all$DVtype == 'RT' & df.res.meta.all$Group == 'Self' & df.res.meta.all$Effect == 'Good_Neut']` `r df.res.meta.all$CI_upp[df.res.meta.all$DVtype == 'RT' & df.res.meta.all$Group == 'Self' & df.res.meta.all$Effect == 'Good_Neut']`]) and *d* prime (Cohen's *d* = `r df.res.meta.all$Cohen_d[df.res.meta.all$DVtype == 'dprime' & df.res.meta.all$Group == 'Self' & df.res.meta.all$Effect == 'Good_Neut']`, 95%CI[`r df.res.meta.all$CI_low[df.res.meta.all$DVtype == 'dprime' & df.res.meta.all$Group == 'Self' & df.res.meta.all$Effect == 'Good_Neut']` `r df.res.meta.all$CI_upp[df.res.meta.all$DVtype == 'dprime' & df.res.meta.all$Group == 'Self' & df.res.meta.all$Effect == 'Good_Neut']`]), but not for the *d* prime between neutral and bad on RT (Cohen's *d* = `r df.res.meta.all$Cohen_d[df.res.meta.all$DVtype == 'RT' & df.res.meta.all$Group == 'Self' & df.res.meta.all$Effect == 'Neut_Bad']`, 95%CI[`r df.res.meta.all$CI_low[df.res.meta.all$DVtype == 'RT' & df.res.meta.all$Group == 'Self' & df.res.meta.all$Effect == 'Neut_Bad']` `r df.res.meta.all$CI_upp[df.res.meta.all$DVtype == 'RT' & df.res.meta.all$Group == 'Self' & df.res.meta.all$Effect == 'Neut_Bad']`]) or *d* prime (Cohen's *d* = `r df.res.meta.all$Cohen_d[df.res.meta.all$DVtype == 'dprime' & df.res.meta.all$Group == 'Self' & df.res.meta.all$Effect == 'Neut_Bad']`, 95%CI[`r df.res.meta.all$CI_low[df.res.meta.all$DVtype == 'dprime' & df.res.meta.all$Group == 'Self' & df.res.meta.all$Effect == 'Neut_Bad']` `r df.res.meta.all$CI_upp[df.res.meta.all$DVtype == 'dprime' & df.res.meta.all$Group == 'Self' & df.res.meta.all$Effect == 'Neut_Bad']`]). 

For the other condition, no differences were observed for *d* prime: Good vs. Bad  (Cohen's *d* = `r df.res.meta.all$Cohen_d[df.res.meta.all$DVtype == 'dprime' & df.res.meta.all$Group == 'Other' & df.res.meta.all$Effect == 'Good_Bad']`, 95%CI[`r df.res.meta.all$CI_low[df.res.meta.all$DVtype == 'dprime' & df.res.meta.all$Group == 'Other' & df.res.meta.all$Effect == 'Good_Bad']` `r df.res.meta.all$CI_upp[df.res.meta.all$DVtype == 'dprime' & df.res.meta.all$Group == 'Other' & df.res.meta.all$Effect == 'Good_Bad']`]); good vs. neutral (Cohen's *d* = `r df.res.meta.all$Cohen_d[df.res.meta.all$DVtype == 'dprime' & df.res.meta.all$Group == 'Other' & df.res.meta.all$Effect == 'Good_Neut']`, 95%CI[`r df.res.meta.all$CI_low[df.res.meta.all$DVtype == 'dprime' & df.res.meta.all$Group == 'Other' & df.res.meta.all$Effect == 'Good_Neut']` `r df.res.meta.all$CI_upp[df.res.meta.all$DVtype == 'dprime' & df.res.meta.all$Group == 'Other' & df.res.meta.all$Effect == 'Good_Neut']`]); neutral vs. bad (Cohen's *d* = `r df.res.meta.all$Cohen_d[df.res.meta.all$DVtype == 'dprime' & df.res.meta.all$Group == 'Other' & df.res.meta.all$Effect == 'Neut_Bad']`, 95%CI[`r df.res.meta.all$CI_low[df.res.meta.all$DVtype == 'dprime' & df.res.meta.all$Group == 'Other' & df.res.meta.all$Effect == 'Neut_Bad']` `r df.res.meta.all$CI_upp[df.res.meta.all$DVtype == 'dprime' & df.res.meta.all$Group == 'Other' & df.res.meta.all$Effect == 'Neut_Bad']`]). But the effect on RT has the similar pattern as the overall effect, with much small effect size on Good vs. Bad, (Cohen's *d* = `r df.res.meta.all$Cohen_d[df.res.meta.all$DVtype == 'RT' & df.res.meta.all$Group == 'Other' & df.res.meta.all$Effect == 'Good_Bad']`, 95%CI[`r df.res.meta.all$CI_low[df.res.meta.all$DVtype == 'RT' & df.res.meta.all$Group == 'Other' & df.res.meta.all$Effect == 'Good_Bad']` `r df.res.meta.all$CI_upp[df.res.meta.all$DVtype == 'RT' & df.res.meta.all$Group == 'Other' & df.res.meta.all$Effect == 'Good_Bad']`]) and Good vs. Neutral, (Cohen's *d* = `r df.res.meta.all$Cohen_d[df.res.meta.all$DVtype == 'RT' & df.res.meta.all$Group == 'Other' & df.res.meta.all$Effect == 'Good_Neut']`, 95%CI[`r df.res.meta.all$CI_low[df.res.meta.all$DVtype == 'RT' & df.res.meta.all$Group == 'Other' & df.res.meta.all$Effect == 'Good_Neut']` `r df.res.meta.all$CI_upp[df.res.meta.all$DVtype == 'RT' & df.res.meta.all$Group == 'Other' & df.res.meta.all$Effect == 'Good_Neut']`]), and similar effect size on neutral vs. bad condition,  (Cohen's *d* = `r df.res.meta.all$Cohen_d[df.res.meta.all$DVtype == 'RT' & df.res.meta.all$Group == 'Other' & df.res.meta.all$Effect == 'Neut_Bad']`, 95%CI[`r df.res.meta.all$CI_low[df.res.meta.all$DVtype == 'RT' & df.res.meta.all$Group == 'Other' & df.res.meta.all$Effect == 'Neut_Bad']` `r df.res.meta.all$CI_upp[df.res.meta.all$DVtype == 'RT' & df.res.meta.all$Group == 'Other' & df.res.meta.all$Effect == 'Neut_Bad']`]).

```{r 'meta-all-self-ref', fig.cap="Meta-analysis of RT and *d* prime for self-referential effect.", fig.height=6, fig.width=9, fig.align="center", warning=FALSE}

p_meta_id

```


Figure \@ref(fig:meta-all-self-ref) shows meta-analytic results for the effect of *d* prime and reaction times from Good-Bad, Good-Neutral, and Neutral-Bad contrast. 

As for the self-relevance effect, we found that there was no overall self-relevance effect on both *d* prime (Cohen's *d* = `r df.res.meta.all$Cohen_d[df.res.meta.all$DVtype == 'dprime' & df.res.meta.all$Effect == 'Self_Other']`, 95%CI[`r df.res.meta.all$CI_low[df.res.meta.all$DVtype == 'dprime' & df.res.meta.all$Effect == 'Self_Other']` `r df.res.meta.all$CI_upp[df.res.meta.all$DVtype == 'dprime' & df.res.meta.all$Effect == 'Self_Other']`]) and RT (Cohen's *d* = `r df.res.meta.all$Cohen_d[df.res.meta.all$DVtype == 'RT' & df.res.meta.all$Effect == 'Self_Other']`, 95%CI[`r df.res.meta.all$CI_low[df.res.meta.all$DVtype == 'RT' & df.res.meta.all$Effect == 'Self_Other']` `r df.res.meta.all$CI_upp[df.res.meta.all$DVtype == 'RT' & df.res.meta.all$Effect == 'Self_Other']`]). When looking at different valence conditions, we found that self condition was performed better than the other condition for the good condition for *d* (Cohen's *d* = `r df.res.meta.all$Cohen_d[df.res.meta.all$DVtype == 'dprime' & df.res.meta.all$Effect == 'Self_Other_G']`, 95%CI[`r df.res.meta.all$CI_low[df.res.meta.all$DVtype == 'dprime' & df.res.meta.all$Effect == 'Self_Other_G']` `r df.res.meta.all$CI_upp[df.res.meta.all$DVtype == 'dprime' & df.res.meta.all$Effect == 'Self_Other_G']`]), and also marginal for RT (Cohen's *d* = `r df.res.meta.all$Cohen_d[df.res.meta.all$DVtype == 'RT' & df.res.meta.all$Effect == 'Self_Other_G']`, 95%CI[`r df.res.meta.all$CI_low[df.res.meta.all$DVtype == 'RT' & df.res.meta.all$Effect == 'Self_Other_G']` `r df.res.meta.all$CI_upp[df.res.meta.all$DVtype == 'RT' & df.res.meta.all$Effect == 'Self_Other_G']`]). but not for neutral or bad conditions. see Figure \@ref(fig:meta-all-self-ref). 

# Representational Similarity Analysis
To test the hypothesis that the valence effect of morality in the associative learning was driven by the spontaneous self-referential processing, we conducted a representional similarity analysis on the behavioral data (Kiani et al., 2007; Op de Beeck et al, 2001). The logic is as follow: if the valence effect in morality is driven by self-referential process, then it representations of different moral valence shoudl be in a pattern that similar to the pattern of moral valence when self is explicitly activated, i.e., the self-relevant condition, but dissimilar to the pattern of moral valence when the self is explicit not referred.

More specifically, we split all experiments into two categories: experiments that only concerned about the valence of morality and experiments with orthorgal design in which both self-relevance and moral valence were manipulated. The former included experiment 1a ~ 1c, experiment 2, and 6a; the later included: experiment 3a, 3b, 6b, 7a, 7b (see table X). 

To qunatify the representational similarity, we used the standard way. First, we used the reation times to construct the disimilarity matrices. To get more nuanced picture, we included nine shape-label pairs: good-good, good-neutral, good-bad, neutral-good, neutral-neutral, neutral-bad, bad-good, bad-neutral, bad-bad. Then we calculated the median RT of correct trials for each participants, by combine all experiment that only included moral valence as IV, we calculated the correlation matrix, and used 1-r to get the dissimilarity matrix. Also, we constructed an error rate matrix in which the parttern used the error rate of each condition.

Then we compared this matrix to the same matrix under self-relevant and other-relevant conditions in the experiments in which self-relevance were manipulated. based on the dissimilarity index, we can infer whether the moral valence condition is more similar to the self or to the other conditions.

We used two indices to quantify the representation similarity: data from each condition and the difference between two conditions. The former index will focus on the drift rate decomposed from DDM, which may represent the processing speed for different conditions. For the later approach, we used the standardized effect size between different conditions. The latter approach can be further compared with the behavioral data in which participants reported the personal distance. We used the Good-Bad, Good-Neutral, Neutral-Bad distance.

We hypothesize that for the firs index, the similarity between selfcondition and the moral valence condition is higher than the similarity between other condition and moral valence condition. For the second index, we also expect that the similarity will be higher for the self condition and moral valence condition than between other condition and valence condition. More interesting, we would expect the similar would also high between the personal rating.

(mean RT, sd of RT, d prime, and three parameters derived from HDDM across all three valence levels, which will result a 20 by 20 correlation matrix. For the experiment included the self-relevance, we do the same analysis for self condition and other conditions separately, result in one 21 by 21 matrix for self and 21 by 21 matrix for other condition. Then, we will compare the representational matrix of morality (without self-relevence) to the matrix of morality of the self and of the other.

The dissimilarity values could come from reaction times, accuracy, and the derived the indcies.  
To test the We also analyzed the relationship between behavioral response and self-reported psychological traits. First, we conducted repeated measure ANOVAs for the psychological distance across all experiment, to check the validity of psychological distance. We predicted that the distance between self and good person should be the shortest, while self and bad-person would show longest distance. Second, we conducted a correlation analysis for behavioral data and score data, i.e., between psychological distance and the bias in perceptual matching task. 

```{r RSA analysis,echo=FALSE, results='hide', warning=FALSE, message=FALSE}
# data for moral valence effect: 1a ~ 1c, experiment 2, 5, and 6a
colnames(df1a.v)
colnames(df1b.v)
colnames(df1c.v)
colnames(df2.v)
#head(df5.v)
colnames(df6a.v)
# df.val <- 

# data from conditions with self-reference

```

## Methods
### Data
All data were collected after participants finished the behavioral tasks. In some experiments, the participants were also asked to re-filled the questionnaire after about 4 weeks. All the detailed information of these questionnaire data can be found in Liu et al. (2019, https://psyarxiv.com/7ngey/).

### Data Analysis
#### Correlation Analysis
We reported all the reliability of the questionnaires. Then we calculated the correlation between the data from behavioral task and the questionnaire data. 

For the behavioral task part, we derived different indices. First, we used the mean and SD of the RT data from each participants of each condition. We included the RT variation because it has been shown to be meaningful as individual differences [Jensen, 1992; Ouyang et al., 2017]. Second, we used drift diffusion model to estimate four parameters of DDM for each participants. Third, we also calculated the differences between different conditions (valence effect: good-self vs. bad-self, good-self vs. neutral-self, bad-self vs. neutral-self; good-other vs. bad-other, good-other vs. neutral-other, bad-other vs. neutral-other; Self-reference effect: good-self vs. good-other, neutral-self vs. neutral-other, bad-self vs. bad-other), as indexed by Cohen's d and se of Cohen's *d*.

The DDM analyses were finished by HDDM, as reported in Hu et al., (2019: https://psyarxiv.com/9fczh/). That is, we used the reponse code approach, matched response were coded as 1 and mismatched responses were coded as 0. To fully explore all parameters, we allow all four parameters of DDM free to vary. We then extracted the estimation of all the four parameters for each participants for the correlation analyses.

For the questinnaire part, we are most interested in the self-rated distance between different person and self-evaluation related questionnaires: self-esteem, moral-self identity, and moral self-image. Other questionnaires (e.g., personality) were not planned to correlated with behavioral data were not included.


```{r prepare correlational data, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
library(mosaic) # using this library for its derivedFactor function
# prepare questionnare data
df.scales <- read.csv(".\\Scale_data\\FADGS_dataset4_1_clean.csv",header = TRUE, sep = ",",
                 stringsAsFactors=FALSE,na.strings=c("","NA")) %>%
  dplyr::mutate(expID = derivedFactor("Exp1a" = (expID == "exp1.0"), 
                                      "Exp1b" = (expID == "exp1.1"),
                                      "Exp3a" = (expID == "exp3"),
                                      "Exp3b" = (expID == "exp3.1"),
                                      "Exp4a" = (expID == "exp4.1"),
                                      "Exp4b" = (expID == "exp4.2"),
                                      "Exp5" = (expID == "exp5.2"),
                                      "Exp6b" = (expID == "exp6.2"),
                                      "Exp7a" = (expID == "exp7.1"),
                                      "Exp7b" = (expID == "exp7r"),
                                      "Exp_dpr" = (expID == "exp6"),
                                      .method ="first", .default = NA),
                expID = as.character(expID))

# intersection between participant from behavioral task and scales and get the data
subj.common <- intersect(df.scales$subjID, unique(df.meta_d$Subject))  # 352

df.scales.v <- df.scales %>% dplyr::filter(subjID %in% subj.common) %>%
  dplyr::select_if(~sum(!is.na(.)) > 0) # remove columns that only have NA.

## get the questionnaire names
# Self-esteem
SlfEstNames <- c("SES1","SES2","SES3","SES4","SES5","SES6","SES7","SES8","SES9","SES10")

# moral identity
mrlIdNames <- c("morId_1","morId_2","morId_3","morId_4", "morId_5","morId_6",
                "morId_7","morId_8","morId_9","morId_10","morId_11","morId_12",
                "morId_13","morId_14","morId_15","morId_16")
mrlIdIntNames <- c("morId_1","morId_2","morId_5","morId_8", "morId_10","morId_11",
                   "morId_12","morId_13","morId_14")
mrlIdExtNames <- c("morId_3","morId_4", "morId_6", "morId_7", "morId_9","morId_10",
                   "morId_15", "morId_16")

# moral self images
mrlslfImgNames <- c("morSlfImg_1","morSlfImg_2","morSlfImg_3","morSlfImg_4",
                    "morSlfImg_5","morSlfImg_6","morSlfImg_7","morSlfImg_8","morSlfImg_9")

# personal distance
perDistNames <- c("SelfSelf", 
                  "SelfGood_1", "SelfGood_2", "SelfGood_3", "SelfGood_4",
                  "SelfNeut_1", "SelfNeut_2", "SelfNeut_3", "SelfNeut_4",
                  "SelfBad_1",  "SelfBad_2",  "SelfBad_3",  "SelfBad_4",
                  "SelfStra_1", "SelfStra_2", "SelfStra_3", "SelfStra_4",
                  "GoodNeut_1", "GoodNeut_2", "GoodNeut_3", "GoodNeut_4", 
                  "GoodBad_1",  "GoodBad_2",  "GoodBad_3",  "GoodBad_4",
                  "NeutBad_1",  "NeutBad_2",  "NeutBad_3",  "NeutBad_4")

# calculate the average score of each relevant scale
df.q_scores.v <- df.scales.v %>%
  dplyr::mutate(SlfEst = rowMeans(.[, SlfEstNames],na.rm = F),
                mrlIdInt = rowMeans(.[, mrlIdIntNames], na.rm = F),
                mrlIdExt = rowMeans(.[, mrlIdExtNames], na.rm = F),
                mrlslfImg = rowMeans(.[, mrlslfImgNames], na.rm = F),
                ) %>%
  dplyr::select(subjID, SlfEst, mrlIdInt, mrlIdExt, mrlslfImg)


df.perdist <- df.scales.v %>%
  dplyr::select(c(expID, subjID),perDistNames) %>%
  #dplyr::rowwise() %>%
  dplyr::mutate(sumRaw = rowMeans(.[3:31], na.rm = T),
                SelfSelfraw = SelfSelf,
                SelfGoodraw = rowMeans(.[grep("SelfGood", names(.))], na.rm = T),
                SelfNeutraw = rowMeans(.[grep("SelfNeut", names(.))], na.rm = T),
                SelfBadraw  = rowMeans(.[grep("SelfBad", names(.))], na.rm = T),
                SelfStraraw = rowMeans(.[grep("SelfStra", names(.))], na.rm = T),
                GoodNeutraw = rowMeans(.[grep("GoodNeut", names(.))], na.rm = T),
                GoodBadraw  = rowMeans(.[grep("GoodBad", names(.))], na.rm = T),
                NeutBadraw  = rowMeans(.[grep("NeutBad", names(.))], na.rm = T)) %>%
  dplyr::select(expID, subjID, sumRaw, SelfSelfraw, 
                SelfGoodraw, SelfNeutraw, SelfBadraw,
                SelfStraraw, GoodNeutraw, GoodBadraw, NeutBadraw) %>%
  dplyr::mutate(SelfSelf = SelfSelfraw/sumRaw,
                SelfGood = SelfGoodraw/sumRaw,
                SelfNeut = SelfNeutraw/sumRaw,
                SelfBad = SelfBadraw/sumRaw,
                SelfStra = SelfStraraw/sumRaw, 
                GoodNeut = GoodNeutraw/sumRaw, 
                GoodBad = GoodBadraw/sumRaw, 
                NeutBad = NeutBadraw/sumRaw) %>%
  dplyr::select(subjID, SelfSelf, SelfGood, SelfNeut, SelfBad,
                SelfStra, GoodNeut, GoodBad, NeutBad)

### Reliability of these scales
# self-esteem
#SESKeys <- c(1,2,-3,4,-5,6,7,8,-9,-10)   # original reverse coding
SlfEstKeys <- c(1,2,3,4,5,6,7,8,9,10)        # reverse coded as negative
SlfEstAlpha <-  psych::alpha(df.scales.v[,SlfEstNames], keys=SlfEstKeys)  # calculate the alpha coefficient of self esteem
SlfEstOmega <- psych::omega(df.scales.v[,SlfEstNames])  
print(c(SlfEstOmega$omega_h,SlfEstOmega$omega.tot)) 
# omega.tot = .90

# moral identity
mrlIdKeys <- c(1:16)
mrlIdIntKeys <- c(1:9)
mrlIdExtKeys <- c(1:7)

# moral self images

### Prepare the data for hddm
#expNameList <- unique(df.scales.v$expID)
#dataList <- list(df1a.v, df1b.v, df4a.v, df4b.v, df5.v, df6b_d1.v, df7a_m.v, df7b_m.V, df3b.v)
#hddmNameList <- c('df1a.v', 'df1b.v', 'df4a.v', 'df4b.v', 'df5.v', 'df6b_d1.v', 'df7a_m.v', 'df7b_m.V', 'df3b.v')
#for (indx in 1:length(unique(df.scales.v$expID))) {
##for (dfname in hddmNameList){
#  current.df <- dataList[[indx]]
#  if ('Resp' %in% colnames(current.df)){
#    current.df <- current.df %>% dplyr::rename(RESP = Resp)
#  }
#  current.name <- paste(hddmNameList[indx],'.hddm_stim.csv', sep = '')
#  if (indx == 1 | indx == 2){                                           # for exp 1a and 1b, 2*3 design
#      cur.df.hddm_stim <- current.df %>%
#      #dplyr::filter(Subject %in% subj.common) %>%                       # only participants with Questionnaire data
#      dplyr::filter(!is.na(RESP)) %>%                                   # exclude trials without response or with wrong keys
#      dplyr::mutate(RT = RT/1000,
#                    stim = ifelse(Matchness == "Match", 1, 0),          
#                    response = ifelse((Matchness == "Match" & ACC ==1) | (Matchness == "Mismatch" & ACC ==0), 1, 0)) %>%
#      dplyr::select(Subject, Matchness, Valence, stim, response, RT) %>%           # select columns
#      dplyr::rename(subj_idx = Subject, match = Matchness, val = Valence, rt = RT) # rename columns
#  } else if (indx == 5){    # exp5                                      # for exp 5, only select morality task
#      cur.df.hddm_stim <- current.df %>%
#      dplyr::filter(taskType == 'Morality') %>%
#      #dplyr::filter(Subject %in% subj.common) %>%                       # only participants with Questionnaire data
#      dplyr::filter(!is.na(RESP)) %>%                                   # exclude trials without response or with wrong keys
#      dplyr::mutate(RT = RT/1000,
#                    stim = ifelse(Matchness == "Match", 1, 0),          
#                    response = ifelse((Matchness == "Match" & ACC ==1) | (Matchness == "Mismatch" & ACC ==0), 1, 0)) %>%
#      dplyr::select(Subject, Matchness, Valence, stim, response, RT) %>%           # select columns
#      dplyr::rename(subj_idx = Subject, match = Matchness, val = Valence, rt = RT) # rename columns
#    
#  } 
#    else if (indx %in% c(3, 4, 6, 7, 9))                               # for expa4a, 4b, 6b, 7a, 3b,  three-way design,
#      {
#      cur.df.hddm_stim <- current.df %>%
#      #dplyr::filter(Subject %in% subj.common) %>%                       # only participants with Questionnaire data
#      dplyr::filter(!is.na(RESP)) %>%                                   # exclude trials without response or with wrong keys
#      dplyr::mutate(RT = RT/1000,
#                    stim = ifelse(Matchness == "Match", 1, 0),          
#                    response = ifelse((Matchness == "Match" & ACC ==1) | (Matchness == "Mismatch" & ACC ==0), 1, 0)) %>%
#      dplyr::select(Subject, Matchness, Identity,Valence, stim, response, RT) %>%           # select columns
#      dplyr::rename(subj_idx = Subject, match = Matchness, id = Identity, val = Valence, rt = RT) # rename columns
#  } 
#    else if (indx == 8)
#    {                                                                   # for exp7b,  three-way design, the RT already in seconds
#      cur.df.hddm_stim <- current.df %>%
#      #dplyr::filter(Subject %in% subj.common) %>%                       # only participants with Questionnaire data
#      dplyr::filter(!is.na(RESP)) %>%                                   # exclude trials without response or with wrong keys
#      dplyr::mutate(stim = ifelse(Matchness == "Match", 1, 0),          
#                    response = ifelse((Matchness == "Match" & ACC ==1) | (Matchness == "Mismatch" & ACC ==0), 1, 0)) %>%
#      dplyr::select(Subject, Matchness, Identity,Valence, stim, response, RT) %>%           # select columns
#      dplyr::rename(subj_idx = Subject, match = Matchness, id = Identity, val = Valence, rt = RT) # rename columns
#  } 
# write.csv(cur.df.hddm_stim, file = paste(curDir,'/HDDM/', current.name, sep = ''), row.names = F) 
#}

# rm(dataList)

# get the parameters from hddm
## read all the file name.
params.list <- list.files('.\\HDDM\\', pattern = '*_hddm_params.csv')
params.expname <- data.frame(params.list) %>%
  tidyr::separate(params.list, c('expName','B','C'),sep = '_') %>%
  dplyr::select(expName) %>%
  dplyr::pull()

#for (indx in 1:length(params.list)){
#  
#  df.params.tmp <- read.csv(paste('.\\HDDM\\', params.list[indx], sep = ''), header = TRUE, sep = ",",
#                 stringsAsFactors=FALSE,na.strings=c("","NA")) %>%
#    #tidyr::separate(X, into = c("X", "subjects"), sep = '[)]') %>%
#    #tidyr::separate(X, into = c("paramName", "Condition"), sep = '[(]')
#    dplyr::select(subj_idx, match, id, val, knode_name, mean:map) %>%
#    tidyr::separate(knode_name, into = c('param_Name', 'postfix')) %>%
#    dplyr::filter(!is.na(mean))  %>%
#    tidyr::pivot_wider(id_cols = subj_idx, names_from = c(match, id, val, param_Name), values_from = mean) %>%
#    mutate(subj_idx = as.numeric(subj_idx)) %>%
#    dplyr::filter(subj_idx %in% subj.common)
    
  
#  if (params.expname[indx] %in% c('df1a', 'df1b','df5')){
#    print(params.list[indx])
#    df.params.tmp <- df.params.tmp %>%
#      dplyr::mutate(ExpID = params.expname[indx]) %>%
#      dplyr::rename_("Subject" = "subj_idx", "Matchness" = "match", "Valence" = "val") %>%
#      dplyr::select(ExpID, Subject, Matchness, id, Valence, knode_name, mean) %>%
#      tidyr::drop_na() %>%
#      tidyr::separate(knode_name, into = paste('v', 1:2, sep= '')) %>%
#      dplyr::rename(param = v1)  %>% dplyr::filter(Matchness=='Match') %>% dplyr::select(- c(v2, Matchness)) %>%
#      tidyr::pivot_wider(., names_from = c('id','Valence', 'param'), values_from = 'mean')

#  }
  
#  Sys.sleep(0.01)
#  flush.console()
#}

df1a.v.hddm_params <- read.csv(".\\HDDM\\df1a_hddm_params.csv",header = TRUE, sep = ",",
                 stringsAsFactors=FALSE,na.strings=c("","NA")) %>%
  dplyr::rename(Subject = subj_idx, Matchness = match, Valence = val) %>%
  dplyr::select(Subject, Matchness, Valence, knode_name, mean) %>%
  tidyr::drop_na() %>%
  tidyr::separate(knode_name, into = paste('v', 1:2, sep= '')) %>%
  dplyr::rename(param = v1)  %>% dplyr::filter(Matchness=='Match') %>% dplyr::select(- c(v2, Matchness)) %>%
  tidyr::pivot_wider(., names_from = c('Valence', 'param'), values_from = 'mean')

# prepare behavioral task data for exp1b
df1a.v.cor.anal <- df1a.v %>%
  dplyr::filter(Subject %in% subj.common) %>%   # only participants with Questionnaire data
  dplyr::filter(ACC == 1 & Matchness == 'Match') %>%
  dplyr::group_by(Subject, Valence) %>%
  dplyr::summarise(RT_Mean = mean(RT, na.rm = T),
                   RT_SD   = sd(RT, na.rm = T)) %>%
  dplyr::ungroup() %>%
  dplyr::mutate(Valence = as.factor(Valence)) %>%
  dplyr::inner_join(., df1a.v.dprime_l, by = c("Subject","Valence")) %>%  # merge with d prime
  dplyr::select("Site", "Subject", "Sex", "Age", "Valence", "RT_Mean", "RT_SD","dprime") %>%
  tidyr::pivot_wider(., names_from = 'Valence', values_from = c("RT_Mean", "RT_SD","dprime"))

df1a.v.cor.anal <- df1a.v.cor.anal %>% dplyr::inner_join(., df1a.v.hddm_params, by = 'Subject') # merge to cor dataframe
df1a.v.cor.anal <- df1a.v.cor.anal %>% dplyr::inner_join(., df.perdist, by = c('Subject' = 'subjID'))
df1a.v.cor.anal <- df1a.v.cor.anal %>% dplyr::inner_join(., df.q_scores.v, by = c('Subject' = 'subjID'))

library(corrr)
res.cor <- df1a.v.cor.anal %>%
  dplyr::select(-c(Site:Age)) %>%
  dplyr::select_if(~sum(!is.na(.)) > 0) %>%
  cor()
res.cor

corrplot::corrplot(res.cor, method="circle")

### Exp1b

# prepare the data for hddm for exp1a
# This data is for stim-coding. for both stimuli and resposne: match stim and button press for match is 1; for mismatch is 0;
df1b.v.hddm_stim <- df1b.v %>%
  dplyr::filter(Subject %in% subj.common) %>%                       # only participants with Questionnaire data
  dplyr::filter(!is.na(RESP)) %>%                                   # exclude trials without response or with wrong keys
  dplyr::mutate(RT = RT/1000,
                stim = ifelse(Matchness == "Match", 1, 0),          
                response = ifelse((Matchness == "Match" & ACC ==1) | (Matchness == "Mismatch" & ACC ==0), 1, 0)) %>%
  dplyr::select(Subject, Matchness, Valence, stim, response, RT) %>%           # select columns
  dplyr::rename(subj_idx = Subject, match = Matchness, val = Valence, rt = RT) # rename columns

# write csv for the HDDM analyses
# write.csv(df1b.v.hddm_stim, file = paste(curDir,'/HDDM/df1b.v.hddm_stim.csv', sep = ''), row.names = F)

# get the parameters from hddm
df1b.v.hddm_params <- read.csv(".\\HDDM\\df1b_hddm_params.csv",header = TRUE, sep = ",",
                 stringsAsFactors=FALSE,na.strings=c("","NA")) %>%
  dplyr::rename(Subject = subj_idx, Matchness = match, Valence = val) %>%
  dplyr::select(Subject, Matchness, Valence, knode_name, mean) %>%
  tidyr::drop_na() %>%
  tidyr::separate(knode_name, into = paste('v', 1:2, sep= '')) %>%
  dplyr::rename(param = v1)  %>% dplyr::filter(Matchness=='Match') %>% dplyr::select(- c(v2, Matchness)) %>%
  tidyr::pivot_wider(., names_from = c('Valence', 'param'), values_from = 'mean')

# prepare behavioral task data for exp1b
#df1b.v.cor.anal <- df1b.v %>%
#  dplyr::filter(Subject %in% subj.common) %>%   # only participants with Questionnaire data
#  dplyr::filter(ACC == 1 & Matchness == 'Match') %>%
#  dplyr::group_by(Subject, Valence) %>%
#  dplyr::summarise(RT_Mean = mean(RT, na.rm = T),
#                   RT_SD   = sd(RT, na.rm = T)) %>%
#  dplyr::inner_join(., df1a.v.dprime_l, by = c("Subject","Valence")) %>%  # merge with d prime
#  dplyr::select("Site", "Subject", "Sex", "Age", "Valence", "RT_Mean", "RT_SD","dprime") %>%
#  tidyr::pivot_wider(., names_from = 'Valence', values_from = c("RT_Mean", "RT_SD","dprime"))

#df1b.v.cor.anal <- df1b.v.cor.anal %>% dplyr::right_join(., df1b.v.hddm_params, by = 'Subject') # merge to cor dataframe

library(corrr)
res.cor <- cor(df1a.v.cor.anal[,5:30])
res.cor

corrplot::corrplot(res.cor, method="circle")
```



# References
```{r create_r-references, echo=FALSE,results='hide'}
#r_refs(file = "r-references.bib"))
```

\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

<div id = "refs"></div>
\endgroup
