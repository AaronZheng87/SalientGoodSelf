---
title             : "Open notebook of perpecptual salience of positive self"
shorttitle        : "Salient Positive Self"

author: 
  - name          : "Chuan-Peng Hu"
    affiliation   : "1,2"
    corresponding : yes    # Define only one corresponding author
    address       : "55131"
    email         : "hcp4715@email.com"
  - name          : "Jie Sui"
    affiliation   : "3"
  - name          : "Kaiping Peng"
    affiliation   : "1"

affiliation:
  - id            : "1"
    institution   : "Tsinghua University, 100084 Beijing, China"
  - id            : "2"
    institution   : "German Resilience Center, 55131 Mainz, Germany"
  - id            : "3"
    institution   : "University of Bath, Bath, UK"

authornote: |
  Add complete departmental affiliations for each author here. Each new line herein must be indented, like this line.

  Enter author note here.

abstract: |
  One or two sentences providing a **basic introduction** to the field,  comprehensible to a scientist in any discipline.
  
  Two to three sentences of **more detailed background**, comprehensible  to scientists in related disciplines.
  
  One sentence clearly stating the **general problem** being addressed by  this particular study.
  
  One sentence summarizing the main result (with the words "**here we show**" or their equivalent).
  
  Two or three sentences explaining what the **main result** reveals in direct comparison to what was thought to be the case previously, or how the  main result adds to previous knowledge.
  
  One or two sentences to put the results into a more **general context**.
  
  Two or three sentences to provide a **broader perspective**, readily comprehensible to a scientist in any discipline.
  
  <!-- https://tinyurl.com/ybremelq -->
  
keywords          : "Perceptual decision-making, Self"
wordcount         : "X"

bibliography      : ["r-references.bib"]

floatsintext      : no
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : yes
mask              : no
draft             : no

documentclass     : "apa6"
classoption       : "man"
output            : 
  papaja::apa6_pdf:
    latex_engine  : xelatex

---

```{r setup, include = FALSE}
#library("papaja")
source('Initial.r')

# using afex and emmeans to do the ANOVA and emmeans for post-hoc comparison
afex_options(emmeans_model = "multivariate")
```

```{r, include=FALSE}
options(tinytex.verbose = F) # debug the tex
```

```{r analysis-preferences}
# Seed for random number generation
set.seed(42)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed)
```

# General Methods
## Participants.
The experiments (except experiment 3b) reported in the current study were first conducted between 2014 to 2016 in Tsinghua University, Beijing, participants of these experiments were recruited in Tsinghua University community. To increase the power by adding collecting more data so that each experiment has 50 or more valid data (Simmons, Nelson, & Simonsohn, 2013) , we recruited additional participants in Wenzhou University, Wenzhou, China in 2017. However, duo to the limited time and resources, additional data were not collected for experiment 2, 3, and 4b. 

 <!-- 21-word solution (Simmons, Nelson & Simonsohn, 2012; retrieved from http://ssrn.com/abstract=2160588) -->

## Material and Procedure
In the current study, we used the social associative learning paradigm (Sui, He, & Humphreys, 2012), in which participants first learn the associations between geometric shapes and labels of person with different moral valence (e.g., in first three studies, the triangle, square, and circle and good person, neutral person, and bad person, respectively). The associations of the shapes and label were counterbalanced across participants. After learning phase, participants finish a practice phase to familiar with the task, in which they viewed one of the shapes upon the fixation while one of the labels below the fixation and judged whether the shape and the label were matched. When participants can get 60% or higher accuracy at the end of the practicing session, they can start the experimental task which is the same as in the practice phase.

If not noted, E-prime 2.0 was used in all experiments. For participants recruited in Tsinghua University, they finished the experiment individually in a dim-lighted chamber, stimuli were presented on 22-inch CRT monitors, with a chin-rest brace. The visual angle of geometric shapes was about 3.7º × 3.7º, the finxation cross is of (0.8º × 0.8º of visual angle) at the center of the screen. The words were of 3.6º × 1.6º visual angle. The distance between the center of the shape or the word and the fixation cross was 3.5º of visual angle. Participant fixed their head on a chin-fixation, about 60 cm from the screen. 

For participants recruited in Wenzhou University, they finished the experiment in a group consist of 3 ~ 12 participants in a dim-lighted testing room. Participants were required to finished the whole experiment independently. Also, they were instructed to start the experiment at the same time, so that the distraction between participants were minimized. The stimuli were presented on 19-inch CRT monitor. The visual angles are could not be exactly controlled because participants’s chin were not fixed.


## Data analysis
We reported all the measurements, analysis and results in all the experiments in the current study. All data were first pre-processed using R `r cite_r("r-references.bib")`. The clean data were analyzed using JASP (0.8.6.0, www.jasp-stats.org, (Love et al., 2019)). Participants whose overall accuracy lower than 60% were excluded from analysis. Also, the accurate responses with less than 200ms reaction times were excluded from the analysis.

We analyzed accuracy performance using a signal detection approach, as in Sui et al. (2012). The performance in each match condition was combined with that in the nonmatching condition with the same shape to form a measure of d’. Trials without response were coded either as “miss” (matched trials) or “false alarm” (mismatched trials). The d’ were then analyzed using repeated measures analyses of variance (repeated measures ANOVA). 

The reaction times of accurate trials were also analyzed using repeated measures ANOVA. To control the false positive when conducting the post-hoc comparisons, we used Bonferroni correction. Please note that in the first two experiment (experiment 1a and 1b), we included the variable matchness (matched vs. mismatched) in our ANOVA of reaction times and then examine matched trials and mismatched trials separately when the interaction between matchness and other variables are significant. In both experiments, we found significant interaction between matchness and valence. Then, as previous study, we focused on the matched trial for the rest of the experiment (Sui et al., 2012). 

We reported the effect size of repeated measures ANOVA (omega squared) (Bakeman, 2005; Lakens, 2013). Also, we reported Cohen’s d and its 95% confidence intervals for the post-hoc comparisons. To provide more information about the results, we also reported the Bayes Factor using JASP (Hu, Kong, Wagenmakers, Ly, & Peng, 2018; Wagenmakers et al., 2018). The Bayes factor is the ratio of the probability of the current data pattern under alternative hypothesis (H1) and the probability of the current data pattern under null hypothesis (H0), which index the relative evidence for these two hypotheses from the current data. The BF10 represents the evidence for alternative hypothesis (H1) vs. evidence for null hypothesis (H0); in contrast, BF01 represents that evidence for null hypothesis over the evidence for althernative hypothesis. We used the default prior in JASP for all the Bayes Factor analyses, and used Jeffreys (1961)’s convention for the strength of evidence: the BF10 > 3 means there are some evidence for H1 as compared with H0,  BF10 great or equal to 10 means strong evidence for H1.

To assess the individual difference, we explored correlation between self-reported psychological distance and more objective responses bias (i.e., reaction times and d prime). To do this, we first normalized the personal distance by taking the percentage of the mean distance between each two persons in the sum of all 6 distances (self-good, self-normal, self-bad, good-normal, good-bad, normal-bad), and then calculated the bias score (indexed by the differences between good-normal, good-bad). Also, as exploratory analysis, we analyzed the correlation between behavioral response and moral identity, self-esteem, if data are available. As recent study showed that small size leads to unstable correlation estimates (Schönbrodt & Perugini, 2013), we only reported the correlation based on data pooled from all experiments, while the results of each experiment were reported in supplementary results.


# Experiment 1a

```{r loadingData_1a,echo=FALSE,results='hide'}

## record from the meta-data:
# One participant's ID changed from 26 to 261, because of duplication of subject id.
# participant No. 14 finished two sessions of the experiment, only the first session were included in the analysis
# # there are 4 foreign students, we didn't exclude them:
# foreignStdID <- c(24,29,30,33)

# data collected in Tsinghua U
df1a_1 <- read.csv(".\\exp1a\\rawdata_behav_exp1a_2014.csv", header = TRUE,
                   sep = ",", stringsAsFactors=FALSE, na.strings=c("","NA")) %>%
        dplyr::mutate(Site = "THU") 

# data collected in Wenzhou U
df1a_2 <- read.csv(".\\exp1a\\rawdata_behav_exp1a_2017.csv",header = TRUE,
                   sep = ",",stringsAsFactors=FALSE,na.strings=c("","NA")) %>%
        dplyr::mutate(Site = "WZU")

# combine data and clean
df1a   <- rbind(df1a_1,df1a_2) %>%
        dplyr::rename(ACC = Target.ACC,           # rename columns
                      RT  = Target.RT,
                      CRESP = Target.CRESP,
                      BlockNo = BlockList.Sample,
                      TrialNo = SubTrial,
                      RESP = Target.RESP,
                      Matchness = YesNoResp,
                      Valence = Shape) %>%
        dplyr::mutate(Valence = ifelse(Valence == "Normal", "Neutral", Valence),   # recode values
                      Matchness = ifelse(Matchness == "Yes", "Match", "Mismatch"),
                      Age = ifelse(Age == 0, NA, Age),
                      Subject = factor(Subject),
                      Site = factor(Site))  # if the min age is 0, that age is missing

rm(df1a_1,df1a_2)

df1a.T.basic     <- df1a %>%
  dplyr::select(Site, Subject, Age, Sex) %>%
  dplyr::distinct(Subject, .keep_all = TRUE) %>%
  dplyr::summarise(N = length(Subject),
                   N_thu = length(Site[Site == "THU"]),
                   N_wzu = length(Site[Site == "WZU"]),
                   Nf = length(Sex[Sex == "female"]),
                   Nm = length(Sex[Sex == "male"]),
                   Age_mean = round(mean(Age,na.rm=TRUE),2),
                   Age_sd = round(sd(Age,na.rm=TRUE),2))
  
# distinguish between practice and formal data
df1a.subj_P <- df1a %>%
  dplyr::filter(is.na(BlockNo)) %>%
  dplyr::distinct(Subject)

#[is.na(df1a$BlockList.Sample),]            # data from practice
df1a.subj_T <- df1a %>%
  dplyr::filter(complete.cases(BlockNo)) %>%
  dplyr::distinct(Subject)

#[complete.cases(df1a$BlockList.Sample),]   # data from test

# number of participant who didn't finished the experiment
nQuit <- length(df1a.subj_P) - length(df1a.subj_T)

#.T[df1a.T$RT <= 200 & df1a.T$ACC == 1,]
#df1a.excld.trial.r <- nrow(df1a.excld.trial)/nrow(df1a.T) # ratio of excluded trials in all triasl.

df1a.excld.sub <-  df1a %>%
  dplyr::group_by(Subject) %>%
  #dplyr::filter(RT > 200)  %>%                       # only use > 200 ms response (this standard will keep more participants)
  dplyr::mutate(ACC = ifelse(RT <= 200, 0, ACC)) %>%  # set less than 200 ms response as wrong
  dplyr::summarise(N = length(ACC),                   # caculate the overall accuracy for each subject
                   N_crrct = sum(ACC),
                   ACC = sum(ACC)/length(ACC)) %>%
  dplyr::filter(ACC < 0.6) %>%                        # exlucde the participants with less than 60% overall accuracy
  dplyr::select(Subject)


# The rate of excluded trials in valid data
df1a.invalid_trial_rate   <- df1a %>%
  dplyr::filter(complete.cases(BlockNo)) %>%
  dplyr::filter(!(Subject %in% df1a.excld.sub$Subject)) %>%   # exclude the invalid subjects
  dplyr::summarize(rate = length(RT[RT <= 200 & ACC == 1])/length(RT))

df1a.v   <- df1a %>%
  dplyr::filter(complete.cases(BlockNo)) %>%
  dplyr::filter(!(Subject %in% df1a.excld.sub$Subject)) %>%   # exclude the invalid subjects
  dplyr::filter(!(RT <= 200 & ACC == 1))                      # exclude < 200 trials

df1a.v.basic     <- df1a.v %>%
  dplyr::select(Site, Subject, Age, Sex) %>%
  dplyr::distinct(Subject, .keep_all = TRUE) %>%
  dplyr::summarise(N = length(Subject),
                   N_thu = length(Site[Site == "THU"]),
                   N_wzu = length(Site[Site == "WZU"]),
                   Nf = length(Sex[Sex == "female"]),
                   Nm = length(Sex[Sex == "male"]),
                   Age_mean = round(mean(Age,na.rm=TRUE),2),
                   Age_sd = round(sd(Age,na.rm=TRUE),2))

#df1a_dprime_long <- read.csv('.\\exp1a\\exp1a_dprime_long.csv') %>%
#  dplyr::rename(Valence = Morality) %>%
#  dplyr::mutate(Valence = factor(Valence, levels = c("Good", "Neutral", "Bad")))

#df1a_rt_acc_long <- read.csv('.\\exp1a\\exp1a_rt_acc_long.csv') %>%
#  dplyr::rename(Valence = Morality) %>%
#  dplyr::mutate(Valence = factor(Valence, levels = c("Good", "Neutral", "Bad"))) %>%
#  dplyr::rename(Matchness = Match) #%>%
  #dplyr::mutate(Match = ifelse(Match == 'Match', 'match','mismatch'))
```
## Methods
### Participants
`r df1a.T.basic$N` college students (`r df1a.T.basic$Nf` female, age = `r df1a.T.basic$Age_mean` $\pm$ `r df1a.T.basic$Age_sd` years) participated. `r df1a.T.basic$N_thu` of them were recruited from Tsinghua University community in 2014; `r df1a.T.basic$N_wzu` were recruited from Wenzhou University in 2017. All participants were right-handed except one, and all had normal or corrected-to-normal vision. Informed consent was obtained from all participants prior to the experiment according to procedures approved by the local ethics committees. `r length(df1a.excld.sub)` participant’s data were excluded from analysis because nearly random level of accuracy, leaving `r df1a.v.basic$N` participants (`r df1a.v.basic$Nf` female, age = `r df1a.v.basic$Age_mean` $\pm$ `r df1a.v.basic$Age_sd` years).

### Stimuli and Tasks
Three geometric shapes were used in this experiment: triangle, square, and circle. These shapes were paired with three labels (bad person, good person or neutral person). The pairs were counterbalanced across participants. 

### Procedure
As we describe in general method part, this experiment had two phases. First, there was a learning stage. Participants were asked to learn the relationship between geometric shapes (triangle, square, and circle) and different person (bad person, a good person, or a neutral person). For example, a participant was told, “bad person is a circle; good person is a triangle; and a neutral person is represented by a square.” After participant remember the associations (usually in a few minutes), participants started a practicing phase of matching task which has the exact task as in the experimental task. 
In the experimental task, participants judged whether shape–label pairs, which were subsequently presented, were correct. Each trial started with the presentation of a central fixation cross for 500 ms. Subsequently, a pairing of a shape and label (good person, bad person, and neutral person) was presented for 100 ms. The pair presented could confirm to the verbal instruction for each pairing given in the training stage, or it could be a recombination of a shape with a different label, with the shape–label pairings being generated at random. The next frame showed a blank for 1100ms. Participants were expected to judge whether the shape was correctly assigned to the person by pressing one of the two response buttons as quickly and accurately as possible within this timeframe (to encourage immediate responding). Feedback (correct or incorrect) was given on the screen for 500 ms at the end of each trial, if no response detected, “too slow” was presented to remind participants to accelerate. Participants were informed of their overall accuracy at the end of each block. The practice phase finished and the experimental task began after the overall performance of accuracy during practice phase achieved 60%. 
For pariticpants from the Tsinghua community, they completed 6 experimental blocks of 60 trials. Thus, there were 60 trials in each condition (bad-person matched, bad-person nonmatching, good-person matched, good-person nonmatching, neutral-person matched, and neutral-person nonmatching). For the participants from Wenzhou Univeristy, they finished 6 blocks of 120 trials, therefore, 120 trials for each condition.

### Questionnaires
After the experiment, part of the participants in Tsinghua University also finished psychological distance, trait social justice (Bai, 2013), cognitive reflection test (Frederick, 2005), and disgust senstivity (Tan, Cong, & Lu, 2007). The psychological distance measurement finished by indicating the the psychological distance between self, good person, bad person and neutral person, through two points on a horizontal line. This procedure is presented by Matlab. This method had been proven been an effective way to measure the psychological distance (Enock, Sui, Hewstone, & Humphreys, 2018). 
For all participants from Wenzhou University, they finished following questionnaires online immediately after the experiment: objective and subjective socioeconomic status (the objective SES measured by parents’ education and occupation (Shi & Shen, 2007), the subjective SES measured by ladder task (Ostrove, Adler, Kuppermann, & Washington, 2000)), psychological distance (Enock et al., 2018), sensitivity to justice (Wu et al., 2014), cognitive reflection test (Frederick, 2005), disgust senstivity scale (Tan et al., 2007), belief in just world (short) (Wu et al., 2011), a short version of big five personality (John & Srivastava, 1999), trait self-esteem (Rosenberg, 1965), locus of control (Levenson，1981), Free will and determinism plus (FAD+) (translated version) (Liu, Jian, Hu, & Peng, 2015; Paulhus & Carey, 2010), moral identity (Aquino & Reed II, 2002), and moral self image (translated version) (Jordan, Leliveld, & Tenbrunsel, 2015). Only the psychological distance data were analyized in the current study.  

### Data analysis
As we describe in the general method section.

## Results
### Analaysis of d prime.
We conducted a single factor (morlaity: good, neutral, bad) repeated measure ANOVA:
```{r 1a_dprime, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
# calculate d prime

df1a.v.dprime_l <- df1a.v %>%
  dplyr::mutate(sdt = mosaic::derivedFactor("hit" = (ACC ==1 & Matchness == "Match"),     # code as hit
                                    "CR" = (ACC ==1  & Matchness == "Mismatch"),  # code as correct reject
                                    "miss" = (ACC == 0 & Matchness == "Match"),   # code as miss
                                    "FA" = (ACC == 0 & Matchness == "Mismatch"),  # code as false alarm
                                    method ="first",  .default = NA)) %>% 
  dplyr::group_by(Site, Subject, Age, Sex, Valence, sdt) %>%
  dplyr::summarise(N = length(sdt)) %>%                                      # calculate the counts for each 
  dplyr::ungroup() %>%
  tidyr::spread(key = sdt, value = N,fill = 0) %>%                           # long-to-wide format
  dplyr::mutate(hitR = hit/(hit + miss),                                     # hit rate
                FAR  = FA/(FA+CR)) %>%                                       # fa rate
  dplyr::mutate(hitR = ifelse(hitR == 1, 1 - 1/(2*(hit + miss)), hitR),      # if hit rate is 1, standardize it
                FAR  = ifelse(FAR == 0, 1/(2*(hit + miss)), FAR)) %>%        # if FA rate is 0, standardize it
  dplyr::mutate(dprime = qnorm(hitR) - qnorm(FAR)) %>%
  dplyr::select(Site, Subject, Age, Sex, Valence, dprime) %>%                # select relevant columns
  dplyr::mutate(Valence = factor(Valence, levels = c("Good","Neutral","Bad")))

### Long to wide
df1a.v.dprime_w <- df1a.v.dprime_l %>%
  #tidyr::unite(col = "Cond",c("Valence"),sep = "_", remove = T) %>%  # combine two factors to condition
  tidyr::spread(key = Valence, value = dprime) %>%                                   # long to wide
  dplyr::rename_at(vars(-Site,-Subject,-Age,-Sex),function(x) paste0("d_",x))           # add prefix to certain conditions


# anova for d prime with 2*2 design
df1a_dprime_anova <- afex::aov_ez('Subject','dprime',df1a.v.dprime_l,  # using afex's function 
                                  within = c('Valence'))

# use LMM, random intercept for each participant
df1a_d_mixed <- afex::mixed(dprime ~ Valence +(1|Subject), 
                          df1a.v.dprime_l,
                          method = "S",
                          control = lmerControl(optCtrl = list(maxfun = 1e6)))

df1a_dprime_anova_apa <- df1a_dprime_anova$aov %>% papaja::apa_print()
#df4b_dprime_anova <- apa_print(df4b_dprime_anova)
```
We found the effect of Valence (`r df1a_dprime_anova_apa$full$Valence`).

```{r results='asis', echo = F}
#knitr::kable(nice(df4b_dprime_anova), caption = "ANOVA of d prime")
apa_table(df1a_dprime_anova_apa$table
  , caption = "A really beautiful ANOVA table."
  , note = "Note that the column names contain beautiful mathematical copy: This is because the table has variable labels."
)
```

We further examined the effect of valence. 

```{r results='asis', echo = F}
posthoc_1a_d <- emmeans::emmeans(df1a_dprime_anova, "Valence") # compare each valence for both self and other condition
#pairs(posthoc_1a_d)
```
The Good condition (2.23 $\pm$ 0.14) is great than Netural condition (2.05 $\pm$ 0.16, t(45) = 1.67, p = 0.226) and bad condition (1.87 $\pm$ 1.4, t(45) = 3.07, p = 0.01, Cohen'd = 0.36). This is no-significant difference between neutral and bad conidition, t(45) = 1.81, p = 1.77.

### Analaysis of reaction time.
We conducted 2 (Matchness: Match v. Mismatch) by 3 (Valence: good, neutral, bad) repeated measure ANOVA:
```{r 1a_RT, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
# anova for d prime with 2*2 design
df1a.v.rt_m <- df1a.v %>%
  dplyr::filter(ACC == 1) %>%
  dplyr::group_by(Site,Subject,Matchness, Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup()
df1a_RT_anova <- afex::aov_ez('Subject','RT_m',df1a.v.rt_m,     # using afex's function 
                                  within = c('Matchness','Valence'))
df1a_RT_anova_apa <- df1a_RT_anova %>% papaja::apa_print()

# use LMM, random intercept for each participant
df1a_RT_mixed <- afex::mixed(RT_m ~ Matchness*Valence + (1|Subject), 
                          df1a.v.rt_m,
                          method = "S",
                          control = lmerControl(optCtrl = list(maxfun = 1e6)))
```
We found the main effect of Matchness (`r df1a_RT_anova_apa$full$Matchness`), main effect of valence (`r df1a_RT_anova_apa$full$Valence`), and intercation between Matchness and Valence (`r df1a_RT_anova_apa$full$Matchness_Valence`)

```{r 1a_RT_match, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
df1a.v.rt_m1 <- df1a.v %>%
  dplyr::filter(ACC == 1 & Matchness == "Match") %>%
  dplyr::group_by(Site,Subject,Matchness, Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup() %>%
  dplyr::mutate(Valence = factor(Valence, levels = c("Good","Neutral","Bad")))

df1a_RT_anova_m <- afex::aov_ez('Subject','RT_m',df1a.v.rt_m1,     # using afex's function 
                                  within = c('Valence'))

df1a.v.rt_m2 <- df1a.v %>%
  dplyr::filter(ACC == 1 & Matchness == "Mismatch") %>%
  dplyr::group_by(Site,Subject,Matchness, Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup()

df1a_RT_anova_nm <- afex::aov_ez('Subject','RT_m',df1a.v.rt_m2,     # using afex's function 
                                  within = c('Valence'))

posthoc_1a_rt <- emmeans::emmeans(df1a_RT_anova_m, "Valence") # compare each valence for both self and other condition
# pairs(posthoc_1a_rt)

```

We carried out two separate ANOVA for both Match and mismatched trials. For matched trials, we found the effect of valence `r df1a_RT_anova_m$full$Valence`. For non-matched trials, there was no significant effect of Valence (`r df1a_RT_anova_nm$full$Valence`).

We further examined the effect of valence for both self and other for mached trials. We found that shapes associated with Good Person responded faster than Neutral (t(45) = -2.662, p = 0.0284) and Bad Person (t(45) = -4.793, p = 0.0001). Neutral condition is slightly faster than bad condition (t(45) = -2.33, p = 0.0618)

# Experiment 1b
In this study, we aimed at excluding the potential confouding factor of the familarity of words we used in experiment 1a, by matching the familiarity of the words.

## Method

```{r loadingData_1b,echo=FALSE,results='hide'}
# data collected in Tsinghua U
df1b_1 <- read.csv(".\\exp1b\\rawdata_behav_exp1b_2014.csv", header = TRUE,
                   sep = ",", stringsAsFactors=FALSE, na.strings=c("","NA")) %>%
        dplyr::mutate(Site = "THU") 

# data collected in Wenzhou U
df1b_2 <- read.csv(".\\exp1b\\rawdata_behav_exp1b_201705.csv",header = TRUE,
                   sep = ",",stringsAsFactors=FALSE,na.strings=c("","NA")) %>%
        dplyr::mutate(Site = "WZU")

# combine data and clean
df1b   <- rbind(df1b_1,df1b_2) %>%
        dplyr::rename(ACC = Target.ACC,           # rename columns
                      RT  = Target.RT,
                      CRESP = Target.CRESP,
                      BlockNo = BlockList.Sample,
                      TrialNo = SubTrial,
                      RESP = Target.RESP,
                      Matchness = YesNoResp,
                      Valence = Shape) %>%
        dplyr::mutate(Valence = ifelse(Valence == "Normal", "Neutral", Valence),   # recode values
                      Matchness = ifelse(Matchness == "Yes", "Match", "Mismatch"),
                      Age = ifelse(Age == 0, NA, Age),
                      Subject = factor(Subject),
                      Site = factor(Site))  # if the min age is 0, that age is missing

rm(df1b_1,df1b_2)

df1b.T.basic     <- df1b %>%
  dplyr::select(Site, Subject, Age, Sex) %>%
  dplyr::distinct(Subject, .keep_all = TRUE) %>%
  dplyr::summarise(N = length(Subject),
                   N_thu = length(Site[Site == "THU"]),
                   N_wzu = length(Site[Site == "WZU"]),
                   Nf = length(Sex[Sex == "female"]),
                   Nm = length(Sex[Sex == "male"]),
                   Age_mean = round(mean(Age,na.rm=TRUE),2),
                   Age_sd = round(sd(Age,na.rm=TRUE),2))
  
# distinguish between practice and formal data
df1b.subj_P <- df1b %>%
  dplyr::filter(is.na(BlockNo)) %>%
  dplyr::distinct(Subject)

#[is.na(df1a$BlockList.Sample),]            # data from practice
df1b.subj_T <- df1b %>%
  dplyr::filter(complete.cases(BlockNo)) %>%
  dplyr::distinct(Subject)

#[complete.cases(df1a$BlockList.Sample),]   # data from test

# number of participant who didn't finished the experiment
nQuit <- length(df1b.subj_P) - length(df1b.subj_T)

#.T[df1a.T$RT <= 200 & df1a.T$ACC == 1,]
#df1a.excld.trial.r <- nrow(df1a.excld.trial)/nrow(df1a.T) # ratio of excluded trials in all triasl.

df1b.excld.sub <-  df1b %>%
  dplyr::group_by(Subject) %>%
  #dplyr::filter(RT > 200)  %>%                       # only use > 200 ms response (this standard will keep more participants)
  dplyr::mutate(ACC = ifelse(RT <= 200, 0, ACC)) %>%  # set less than 200 ms response as wrong
  dplyr::summarise(N = length(ACC),                   # caculate the overall accuracy for each subject
                   N_crrct = sum(ACC),
                   ACC = sum(ACC)/length(ACC)) %>%
  dplyr::filter(ACC < 0.6) %>%                        # exlucde the participants with less than 60% overall accuracy
  dplyr::select(Subject)


# The rate of excluded trials in valid data
df1b.invalid_trial_rate   <- df1b %>%
  dplyr::filter(complete.cases(BlockNo)) %>%
  dplyr::filter(!(Subject %in% df1b.excld.sub$Subject)) %>%   # exclude the invalid subjects
  dplyr::summarize(rate = length(RT[RT <= 200 & ACC == 1])/length(RT))

df1b.v   <- df1b %>%
  dplyr::filter(complete.cases(BlockNo)) %>%
  dplyr::filter(!(Subject %in% df1b.excld.sub$Subject)) %>%   # exclude the invalid subjects
  dplyr::filter(!(RT <= 200 & ACC == 1))                      # exclude < 200 trials

df1b.v.basic     <- df1b.v %>%
  dplyr::select(Site, Subject, Age, Sex) %>%
  dplyr::distinct(Subject, .keep_all = TRUE) %>%
  dplyr::summarise(N = length(Subject),
                   N_thu = length(Site[Site == "THU"]),
                   N_wzu = length(Site[Site == "WZU"]),
                   Nf = length(Sex[Sex == "female"]),
                   Nm = length(Sex[Sex == "male"]),
                   Age_mean = round(mean(Age,na.rm=TRUE),2),
                   Age_sd = round(sd(Age,na.rm=TRUE),2))
```

### Participants
`r df1b.T.basic$N` college students (`r df1b.T.basic$Nf` female, age = `r df1b.T.basic$Age_mean` $\pm$ `r df1b.T.basic$Age_sd` years) participated. `r df1b.T.basic$N_thu` of them were recruited from Tsinghua University community in 2014; `r df1b.T.basic$N_wzu` were recruited from Wenzhou University in 2017. All participants were right-handed except one, and all had normal or corrected-to-normal vision. Informed consent was obtained from all participants prior to the experiment according to procedures approved by the local ethics committees. `r length(df1b.excld.sub)` participant’s data were excluded from analysis because nearly random level of accuracy, leaving `r df1b.v.basic$N` participants (`r df1b.v.basic$Nf` female, age = `r df1b.v.basic$Age_mean` $\pm$ `r df1b.v.basic$Age_sd` years).

### Stimuli and Tasks
Three geometric shapes (triangle, square, and circle, with 3.7º × 3.7º of visual angle) were presented above a white fixation cross subtending 0.8º × 0.8º of visual angle at the center of the screen. The three shapes were randomly assigned to three labels with different moral valence: a morally bad person (“恶人”, ERen), a morally good person (“善人”, ShanRen) or a morally neutral person (“常人”, ChangRen). The order of the associations between shapes and labels was counterbalanced across participants.
Three labels used in this experiment is selected based on the rating results from an independent survey, in which participants rated the familiarity, frequency, and concreteness of eight different words online. Of the eight words, three of them are morally positive (HaoRen, ShanRen, Junzi), two of them are morally neutral (ChangRen, FanRen), and three of them are morally negative (HuaiRen, ERen, LiuMang). An independent sample consist of 35 participants (22 females, age 20.6 ± 3.11) were recruited to rate these words. Based on the ratings (see Figure 1), we selected ShanRen, ChangRen, and ERen to represent morally positve, neutral, and negative person. 

Table 1b-1. Ratings of familarity, frequencies and concreteness for different labels that share similar meanings (n = 35).
Label	Familiarity	frequencies	concreteness
HaoRen	6.31 (1.01)	5.85 (1.24)	4.71 (1.83)
HuaiRen	6 (1.44)	4.68 (1.85)	4.51 (1.96)
ChangRen	5.49 (1.41)	4.4 (1.63)	4.28 (1.88)
ShanReng	4.89 (1.42)	2.8 (1.6)	4.57 (1.59)
Eren	5.08 (1.65)	2.69 (1.85)	4.6 (1.59)

### Procedure
For participants from both Tsinghua community and Wenzhou community, the procedure in the current study was exactly same as in experiment 1a. For participants in Tsinghua community, they finished a survey suite include personal distance, objective and subjective SES, belief in just world (Wu et al., 2011), disgust senstivity scale (谭永红 et al., 2007), trait justice (Wu et al., 2014), and cognitive reflection test (Frederick, 2005). For participants from Wenzhou community, they finished exactly the same questionnaires as the participants from Wenzhou University in experiment 1a.
## Analysis
Data was analyzed as in experiment 1a. 

## Results
### Analaysis of d prime.
We conducted a single factor (Valence: good, neutral, bad) repeated measure ANOVA:
```{r 1b_dprime, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
# calculate d prime
df1b.v.dprime_l <- df1b.v %>%
  dplyr::mutate(sdt = mosaic::derivedFactor("hit" = (ACC ==1 & Matchness == "Match"),     # code as hit
                                    "CR" = (ACC ==1  & Matchness == "Mismatch"),  # code as correct reject
                                    "miss" = (ACC == 0 & Matchness == "Match"),   # code as miss
                                    "FA" = (ACC == 0 & Matchness == "Mismatch"),  # code as false alarm
                                    method ="first",  .default = NA)) %>% 
  dplyr::group_by(Site, Subject, Age, Sex, Valence, sdt) %>%
  dplyr::summarise(N = length(sdt)) %>%                                      # calculate the counts for each 
  dplyr::ungroup() %>%
  tidyr::spread(key = sdt, value = N,fill = 0) %>%                           # long-to-wide format
  dplyr::mutate(hitR = hit/(hit + miss),                                     # hit rate
                FAR  = FA/(FA+CR)) %>%                                       # fa rate
  dplyr::mutate(hitR = ifelse(hitR == 1, 1 - 1/(2*(hit + miss)), hitR),      # if hit rate is 1, standardize it
                FAR  = ifelse(FAR == 0, 1/(2*(hit + miss)), FAR)) %>%        # if FA rate is 0, standardize it
  dplyr::mutate(dprime = qnorm(hitR) - qnorm(FAR)) %>%
  dplyr::select(Site, Subject, Age, Sex, Valence, dprime) %>%                # select relevant columns
  dplyr::mutate(Valence = factor(Valence, levels = c("Good","Neutral","Bad")))

### Long to wide
#df1b.v.dprime_w <- df1b.v.dprime_l %>%
#  tidyr::spread(key = Valence, value = dprime) %>%                                   # long to wide
#  dplyr::rename_at(vars(-Site,-Subject,-Age,-Sex),function(x) paste0("d_",x))           # add prefix to certain conditions


# anova for d prime with 2*2 design
df1b_dprime_anova <- afex::aov_ez('Subject','dprime',df1b.v.dprime_l,  # using afex's function 
                                  within = c('Valence'))

# use LMM, random intercept for each participant
df1b_d_mixed <- afex::mixed(dprime ~ Valence +(1|Subject), 
                          df1b.v.dprime_l,
                          method = "S",
                          control = lmerControl(optCtrl = list(maxfun = 1e6)))

df1b_dprime_anova_apa <- df1b_dprime_anova$aov %>% papaja::apa_print()
#df4b_dprime_anova <- apa_print(df4b_dprime_anova)
```
We found the effect of Valence (`r df1b_dprime_anova_apa$full$Valence`).


```{r results='asis', echo = F}
#knitr::kable(nice(df4b_dprime_anova), caption = "ANOVA of d prime")
#apa_table(df1b_dprime_anova_apa$table
#  , caption = "A really beautiful ANOVA table."
#  , note = "Note that the column names contain beautiful mathematical copy: This is because the table has variable labels."
#)
```

We further examined the effect of valence. 

```{r results='asis', echo = F}
posthoc_1b_d <- emmeans::emmeans(df1b_dprime_anova, "Valence") # compare each valence for both self and other condition
pairs(posthoc_1b_d)
```
The Good condition (1.9 $\pm$ 0.104) is great than Netural condition (1.49 $\pm$ 0.1, t(49) = 5.583, p < 0.001, Cohen's d = 0.415), Neutral and bad condition (1.71 $\pm$ 0.11, t(49) = -3.106, p = 0.008, Cohen'd = -0.229). This is no-significant difference between Good and bad conidition, t(49) = 2.05, p = 0.11.


# Experiment 4a

In study 1-3 participants made explicit judgements about moral associations. In Experiment 4, we examined whether the effects of moral valence occur even when the moral valence information might not be relevent to the task. In this study participants made perceptual match judgements to associations between self-referential labels and shapes (cf. Sui et al., 2012), but we presented labels of different moral valence levels in the shapes. 

```{r loadingData_4a,echo=FALSE,results='hide'}
df4a_dprime_long <- read.csv('.\\exp4a\\exp4a_dprime_long.csv') %>%
  dplyr::mutate(Morality = ifelse(Morality == "Moral", "Good",
                             ifelse(Morality == "Immoral","Bad", 'Neutral')))

df4a_rt_acc_long <- read.csv('.\\exp4a\\exp4a_rt_acc_long.csv') %>%
  dplyr::mutate(Morality = ifelse(Morality == "Moral", "Good",
                             ifelse(Morality == "Immoral","Bad", "Neutral"))) %>%
  dplyr::rename(Match = Matchness) %>%
  dplyr::mutate(Match = ifelse(Match == 'Match', 'match','mismatch'))
```
## Participants
64 participants (37 female, age = 19.7 $\pm$ 1.22) participated the current study, 32 of them were from Tsinghua Universtiy in 2015, the rest were from Wenzhou University parpticipated in 2017. All participants were right-handed, and all had normalneutral or corrected-to-normalneutral vision. Informed consent was obtained from all participants prior to the experiment according to procedures approved by a local ethics committee. The data of three participants from Tsinghua site and two participants from Wenzhou site were excluded from analysis because their accuracy was close to chance (< 0.6). The results for the remaining 59 participants (33 female, age = 19.78 $\pm$ 1.2) were analyzed and reported.

## Results
### Analaysis of d prime.
We conducted 2 (Idenity: self v. other) by 3 (morlaity: good, neutral, bad) repeated measure ANOVA:
```{r analyzing for d prime_4a, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
# anova for d prime with 2*2 design
df4a_dprime_anova <- afex::aov_ez('Subject','dprime',df4a_dprime_long,  # using afex's function 
                                  within = c('Identity','Morality'))

# use LMM, random intercept for each participant
df4a_d_mixed <- afex::mixed(dprime ~ Identity*Morality +(1|Subject), 
                          df4a_dprime_long,
                          method = "S",
                          control = lmerControl(optCtrl = list(maxfun = 1e6)))

df4a_dprime_anova_apa <- df4a_dprime_anova$aov %>% papaja::apa_print()
#df4b_dprime_anova <- apa_print(df4b_dprime_anova)
```
We found the effect of identity (`r df4a_dprime_anova_apa$full$Identity`) and its interaction with valence (the effect of gender differed by clinic, (`r df4a_dprime_anova_apa$full$Identity_Morality`). But the effect of valence was not found, `r df4a_dprime_anova_apa$full$Morality`.

```{r results='asis', echo = F}
#knitr::kable(nice(df4b_dprime_anova), caption = "ANOVA of d prime")
apa_table(df4a_dprime_anova_apa$table
  , caption = "A really beautiful ANOVA table."
  , note = "Note that the column names contain beautiful mathematical copy: This is because the table has variable labels."
)
```

We further examined the effect of valence for both self and other. 

```{r results='asis', echo = F}
m2 <- emmeans::emmeans(df4a_dprime_anova, "Morality", by = "Identity") # compare each valence for both self and other condition
#pairs(m2)
# summary(as.glht(pairs(m2)), test=adjusted("free"))
m3 <- emmeans(df4a_dprime_anova, "Identity", by = "Morality") # compare self vs. other for each valence condition
#pairs(m3)
```

### Analaysis of reaction time.
We conducted 2 (Matchness: match v. mismatch) by 2 (Idenity: self v. other) by 3 (morlaity: good, neutral, bad) repeated measure ANOVA:
```{r analyzing for RT_4a, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
# anova for d prime with 2*2 design
df4a_RT_anova <- afex::aov_ez('Subject','RT',df4a_rt_acc_long,  # using afex's function 
                                  within = c('Match','Identity','Morality'))
df4a_RT_anova_apa <- df4a_RT_anova %>% papaja::apa_print()

# use LMM, random intercept for each participant
df4a_RT_mixed <- afex::mixed(RT ~ Match*Identity*Morality +(1|Subject), 
                          df4a_rt_acc_long,
                          method = "S",
                          control = lmerControl(optCtrl = list(maxfun = 1e6)))


```
We found the main effect of Matchness (`r df4a_RT_anova_apa$full$Match`) and intercation between Matchness and Identity(`r df4a_RT_anova_apa$full$Match_Identity`)

We carried out two separate ANOVA for both Match and mismatched trials.

```{r analyzing for RT_4a_match, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
# anova for d prime with 2*2 design
df4a_rt_acc_long_m <- df4a_rt_acc_long %>% dplyr::filter(Match == 'match')
df4a_rt_acc_long_nm <- df4a_rt_acc_long %>% dplyr::filter(Match == 'mismatch')
df4a_RT_anova_m <- afex::aov_ez('Subject','RT',df4a_rt_acc_long_m,  # using afex's function 
                                  within = c('Identity','Morality'))
df4a_RT_anova_m_apa <- df4a_RT_anova_m %>% papaja::apa_print()

df4a_RT_anova_nm <- afex::aov_ez('Subject','RT',df4a_rt_acc_long_nm,  # using afex's function 
                                  within = c('Identity','Morality'))
df4a_RT_anova_nm_apa <- df4a_RT_anova_nm %>% papaja::apa_print()

```
For matched trials, we found the effect of identity `r df4a_RT_anova_m_apa$full$Identity`, and the interaction between morality and identity,`r df4a_RT_anova_m_apa$full$Identity_Morality`. However, there is no main effect of valence (`r df4a_RT_anova_m_apa$full$Morality`). 

For non-matched trials, there was no significant effect. Morality (`r df4a_RT_anova_nm_apa$full$Identity`), Identity(`r df4a_RT_anova_nm_apa$full$Morality`), interaction (`r df4a_RT_anova_nm_apa$full$Identity_Morality`).

```{r results='asis', echo = F}
#knitr::kable(nice(df4b_dprime_anova), caption = "ANOVA of d prime")
apa_table(df4a_RT_anova_m_apa$table
  , caption = "A really beautiful ANOVA table."
  , note = "Note that the column names contain beautiful mathematical copy: This is because the table has variable labels."
)
```

We further examined the effect of valence for both self and other for mached trials. 

```{r results='asis', echo = F}
m2 <- emmeans::emmeans(df4a_RT_anova_m, "Morality", by = "Identity") # compare each valence for both self and other condition
pairs(m2)
#summary(as.glht(pairs(m2)), test=adjusted("free"))
m3 <- emmeans(df4a_RT_anova_m, "Identity", by = "Morality") # compare self vs. other for each valence condition
pairs(m3)
```


# Experiment 4b:

```{r loadingData_4b,echo=FALSE,results='hide'}
df4b_dprime_long <- read.csv('.\\exp4b\\exp4b_dprime_long.csv') %>%
  dplyr::mutate(Morality = ifelse(Morality == "Moral", "Good",
                             ifelse(Morality == "Immoral","Bad", 'Neutral')))

df4b_rt_acc_long <- read.csv('.\\exp4b\\exp4b_rt_acc_long.csv') %>%
  dplyr::mutate(Morality = ifelse(Morality == "Moral", "Good",
                             ifelse(Morality == "Immoral","Bad", "Neutral"))) %>%
  dplyr::rename(Match = Matchness) %>%
  dplyr::mutate(Match = ifelse(Match == 'Match', 'match','mismatch'))
```
## Participants

## Results
### Analaysis of d prime.
We conducted 2 (Idenity: self v. other) by 3 (morlaity: good, neutral, bad) repeated measure ANOVA:
```{r analyzing for d prime_e5, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
# anova for d prime with 2*2 design
df4b_dprime_anova <- afex::aov_ez('Subject','dprime',df4b_dprime_long,  # using afex's function 
                                  within = c('Identity','Morality'))
df4b_dprime_anova_apa <- df4b_dprime_anova %>% papaja::apa_print()
#df4b_dprime_anova <- apa_print(df4b_dprime_anova)
```
Morality (`r df4b_dprime_anova_apa$full$Morality`) and Identity gender affected post-surgery quality of life, `r df4b_dprime_anova_apa$full$Identity`. However, the effect of gender differed by clinic, `r df4b_dprime_anova_apa$full$Identity_Morality`.

```{r results='asis', echo = TRUE}
#knitr::kable(nice(df4b_dprime_anova), caption = "ANOVA of d prime")
apa_table(df4b_dprime_anova_apa$table
  , caption = "A really beautiful ANOVA table."
  , note = "Note that the column names contain beautiful mathematical copy: This is because the table has variable labels."
)
```

We further examined the effect of valence for both self and other. 

```{r results='asis', echo = TRUE}
m2 <- emmeans::emmeans(df4b_dprime_anova, "Morality", by = "Identity") # compare each valence for both self and other condition
#pairs(m2)
summary(as.glht(pairs(m2)), test=adjusted("free"))

m3 <- emmeans(df4b_dprime_anova, "Identity", by = "Morality") # compare self vs. other for each valence condition
#pairs(m3)

```

# Results

# Discussion


\newpage

# References
```{r create_r-references}
r_refs(file = "r-references.bib")
```

\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

<div id = "refs"></div>
\endgroup
