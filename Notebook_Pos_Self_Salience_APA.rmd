---
title             : "Priorization of the morally good depends on self-relevance in perceptual matching"
shorttitle        : "Priorization of the morally good"

author: 
  - name          : "Hu Chuan-Peng"
    affiliation   : "1,2"
    corresponding : yes    # Define only one corresponding author
    address       : "School of Psychology, Nanjing Normal University, Ninghai Road 122, Gulou District, 210024 Nanjing, China"
    email         : "hcp4715@gmail.com"
  - name          : "Kaiping Peng"
    affiliation   : "2"
  - name          : "Jie Sui"
    affiliation   : "3"

affiliation:
  - id            : "1"
    institution   : "Nanjing Normal University, 210024 Nanjing, China"
  - id            : "2"
    institution   : "Tsinghua University, 100084 Beijing, China"
  - id            : "3"
    institution   : "University of Aberdeen, Aberdeen, Scotland"

authornote: |
  Hu Chuan-Peng, School of Psychology, Nanjing Normal University, 210024 Nanjing, China.
  Kaiping Peng, Department of Psychology, Tsinghua University, 100084 Beijing, China.
  Jie Sui, School of Psychology, University of Aberdeen, Aberdeen, Scotland.

  Authors contriubtion: HCP, JS, & KP design the study, HCP collected the data, HCP analyzed the data and drafted the manuscript. All authors read and agreed upon the current version of the manuscripts.

abstract: |
 To navigate in a complex social world, our cognitive system are evolved to be sensitive to social information. Among all these social informaiton, morality related information is of special interest. On the one hand, paying attention to other's moral character profitable for ourselves. On the other hand, we need to maitain a moral self-view that fit the soical norm. Though behavioral effects of moral character and moral self-enhancement had been extensively studied in psychology of morality, social perception, and identity, whether the moral character related information can impact low-level perceptual process is unknown. In a series of experiments, we examined the effect of immediately acquired moral character information on perceptual matching. Participants first learned the association between moral character and visual cues (shapes), then performed a perceptual matching task. The results showed that shapes associated with positive moral character were prioritized, as compared to neutral or negative bad moral characters. This pattern was robust after changing the words for moral charachter or using diagnostic behavioral as an proxy of mroal character. Also, this patterns were robust when changing simultaneous presentation to sequential presentation. We then examined two approximate explanations for this effect: value-based prioritization or social-categorization based prioritization. We manipulated the identity of different moral character explicitly and found that the good moral character effect was strong when for the self-referential conditions but weak or non-exist for other-referential condition. We further tested the good-self based social categorization by presenting the identity or moral character information as task-irrelevant stimuli, so that we can distinguish between the unique good-self hypothesis and a more general good-person based social categorization hypothesis. We found that ....., these results suggested that participants are more senstive to the moral valence of self when the valence were task-irrelevant, but less sensitive to the identity of the morally good when the identity were task-irrelvant. These results added new evidence for the social vision and suggested the advantage of moral good depends on the self-relevant in perceptual decision-making task, instead of perspective free.
  
 <!-- https://tinyurl.com/ybremelq -->
  
keywords          : "Perceptual decision-making, Self positivity bias, moral character"
wordcount         : "X"

bibliography      : 
  - r-references.bib
  - endnote.bib

floatsintext      : no
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : yes
mask              : no
draft             : no
figsintext        : no

documentclass     : "apa6"
classoption       : "man"
output            : 
  papaja::apa6_pdf:
    latex_engine  : xelatex

header-includes:
  - \usepackage{rotating}
  - \DeclareDelayedFloatFlavor{sidewaysfigure}{figure}
---
 <!-- This documents -->
 
```{r setup, include = FALSE}
#rm(list = ls())
source('Initial.r')

curDir = here::here()              # Get the current directory
figDir = here::here('figures')     # directory for figures.

# Seed for random number generation
set.seed(42)
options(tinytex.verbose = T) # debug the tex
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed)
```
 <!-- What is the theoretic meaning of the series study? -->

# Introduction

[sentences in bracket are key ideas]

social vision --> moral vision --> two competing explanations (value-based vs. true-self-based) --> true-self is not perspective free but self-centered.

Will not include experiment 5; stop exploring the correlations.

Our information processing system had been evolved in a way that top-down factor can modulate the low-level processes. There are debates on whether perception can be penetrated by top-down factors.

[Morality is the central of human social life]. People experience a substantial amount of moral events in everyday life [e.g., @hofmann_morality_2014]. When experiencing these events, it always involves judging "good" or "bad". By judging "right" or "wrong", people are implicitly judging the moral character of involved parties as "good" vs. "bad" [@uhlmann_person-centered_2015]. The central role of moral character also supported by the extensive studies from person perception and social evaluation, where morality is a basic dimension for social evaluation [@goodwin_moral_2014; @goodwin_moral_2015; @abele_navigating_2020; @willis_first_2006] and the most important aspect to evaluate the continuity of identity [@strohminger_true_2017]. 

Given the importance of moral character, to successfully navigate in a social world, a person needs to both evaluate others' moral character and behave in a way that she/he is perceived as a moral person, or at least not a morally bad person. Maintaining a moral self-view is as important as making judgments about others' moral character [@ellemers_psychology_2019]. Indeed, previous studies found that people maintain a positive moral self-view even after dishonest behavior [@monin_dynamic_2009] and that people evaluate themselves as morally superior to others [@klein_maybe_2016; @tappin_illusion_2017]. Recent theorists further integrated the moral judgment and moral self-view, proposed a person-centered account for moral psychology, which focused on the individuals in moral evaluation instead of acts [@uhlmann_person-centered_2015]. Under this framework, previous seemingly contradicting phenomenons can be explained. For example, whether people decide to expose an unethical behavior depends on how their relationship of the target [e.g., @waytz_whistleblowers_2013]. 

To date, however, as @freeman_dynamic_2011 put it, studies in the perception of moral character didn't try to explain the perceptual process, rather, they are trying to explain the higher-order social cognitive processes that come after. Essentially, these studies are perception of moral character without perceptual process. Without knowledge of perceptual processes, we can not have a full picture of how moral character is processed in our cognition. As an increasing attention is paid to perceptual process underlying social cognition, it's clear that perceptual processes are strongly influenced by social factors, such as group-categorization, stereotype [see @bagnis_toward_2019; @xiao_perceiving_2016;@stolier_functional_2016]. Given the importance of moral character and that moral character related information has strong influence on learning and memory [@stanley_moral_2019; @carlson_motivated_2020], one might expect that moral character related information could also play a role in perceptual process.

To explore the perceptual process of moral character and the underlying mechanism, we conducted a series of experiments to explore (1) whether we can detect the influence of moral character information on perceptual decision-making in a reliable way, and (2) potential explanations for the effect. In the first four experiments, we found a robust effect of good-person prioritization in perceptual decision-making. Then, we explore the potential explanations and tested value-based prioritization versus good-self-based prioritization (social-categorization [@turner_self_1994; @turner_rediscovering_1987]). These results suggested that people may categorize self and other based on moral character; in these categorizations, the core self, i.e., the good-self, is always prioritized.

## Perceptual process of moral character

[exp1a, b, c, and exp2]

[using associative learning task to study the moral character's influence on perception] Though it is theoretically possible that moral character related information may be prioritized in perceptual process, no empirical studies had directly explored this possibility. One difficulty of studying the perceptual process of moral character is that moral character is an inferred trait instead of observable feature. Usually, one needs more sensory input, e.g., behavior history, to infer moral character of a person. For example, @anderson_visual_2011 asked participant to first study the behavioral description of faces and then asked them to perform a perceptual detection task. They assumed that by learning the behavioral description of a person (represented by a face), participants can acquire the moral related information about faces, and the associations could then bias the perceptual processing of the faces (but see @stein_no_2017). One drawback of this approach is that participants may differ greatly when inferring the moral character of the person from behavioral descriptions, given that notion what is morality itself is varying across population [@henrich_weirdest_2010, @jones_which_2021] and those descriptions and faces may themselves are idiosyncratic, therefore, introduced additional variance to the targeted effect.

An alternative is to use abstract semantic concepts. Abstract concepts of moral character are used to describe and represent moral characters. These abstract concepts may be part of a dynamic network in which sensory cue, concrete behaviors and other information can activate/inhibit each other (e.g., aggressiveness) [@freeman_dynamic_2011; @amodio_social_2019]. If a concept of moral character (e.g., good person) is activated, it should be able to influence on the perceptual process of the visual cues through the dynamic network, especially when the perceptual decision-making is about the concept-cue association. In this case, abstract concepts of moral character may serve as signal of moral reputation (for others) or moral self-concept. Indeed, previous studies used the moral words and found that moral related information can be perceived faster [@gantman_moral_2014, but see, @firestone_enhanced_2015]. If moral character is an important in person perception, then, just as those other information such as races and stereotype [see @xiao_perceiving_2016], moral character related concepts also change the perceptual processes.

To investigate the above possibility, we used an associative learning paradigm to study how moral character concept change perceptual decision-making. In this paradigm, simple geometric shapes were paired with different words whose dominant meaning is describing the moral character of a person. Participants first learn the associations between shapes and words, e.g., triangle is a good-person. After formed direct associations between the labels of moral characters and visual cues, participants then perform a perceptual matching task to judge whether the shape-word pair presented on the screen match the association they learned. This paradigm has been used in studying the perceptual process of self-concept, but had also proven useful in studying other concepts like social group [e.g., @enock_overlap_2020]. By using simple and morally neutral shapes, we controlled the variations caused by visual cues.

Our first question is, whether the words used the in the associative paradigm is really related to the moral character? This assumption is consistent with previous theories, especially the interactive dynamic theory. To validate that moral character concepts activated moral character as a social cue, we used four experiments to explore and validate the paradigm. The first experiment directly adopted associative paradigm and changed labels from "self", "friend", and "stranger" to "good-person", "neutral-person", and "bad-person". We further tried semantic labels that have more explicit moral meaning ("kind-person", "neutral-person", and "evil-person"). In the third experiments, as in @anderson_visual_2011, we asked participant to learn the association between three different diagnostic behavior and three different names, and then use the names as moral labels for the associative learning. Finally, we also tested that simultaneously present shape-word pair and sequentially present word and shape didn't change the pattern. All of these four experiments showed a consistent pattern of effect, that is, the visual cues that associated with positive moral character were prioritized. 

## Morality as a social-categorization?

[possible explanations: person-based self-categorization vs. stimuli-based valence] The robust pattern from the first four experiments revealed a novel pattern that needs an explanation. It's novel because it's contradict with the "negative is stronger than positive" hypothesis in social psychology [@baumeister_bad_2001]. There are two major alternatives. One possible explanation is the value-based attention, which suggested that valuable stimuli is prioritized in our low-level cognitive processes. Because positive moral character is potentially rewarding, e.g., potential cooperators, it is valuable to individuals and therefore being prioritized. Most empirical evidence for value-based attention are from experiments used monetary reward. However, the monetary reward might be different greatly from the morality in social setting. So far, only a few empirical studies supported the value-based attention in social evaluation. XXX found that trustworthy faces attracted attention more than untrustworthy faces, probably because trustworthy faces are more likely to be the collaborative partners subsequent tasks, which will bring reward. Applying this explanation to the current setting need a further assumption that  participants automatically view the moral character related information as self-relevant objects. Only based on the objectified stimuli that we evaluate their value (rewarding or threatening) to us [@juechems_where_2019; @reicher_perception_2016]. 

Another possibility is that we will perceive those moral character not as objects but as person, and automatic categorize whether they are in-group or out-group, instead of calculating their value to us. This account assumed that moral character served as a way to categorize other. In the first four experiments' situation, the identity of the moral character is ambiguous, participants may automatically categorize morally good people as in-group and therefore preferentially processed these information. 

However, the above four experiments could not distinguish between these two possibilities, because the concept "good-person" can both be rewarding and be categorized as in-group member, and previous studies using associative learning paradigm revealed that both rewarding stimuli [e.g., @Sui_2012_JEPHPP] and in-group information [enock_overlap_2020] are prioritized.  

[Distinguish two explanations by make self salient, exp3a, 3b, 6b] Though both two frameworks can account for the positivity effect found in first four experiments (i.e., prioritization of "good-person", but not "neutral person" and "bad person"), they have different prediction if the experiment design include both identity and moral valence where the valence (good, bad, and neutral) conditions can describe both self and other. In this case the identity become salient and participants are less likely to spontaneously identify a good-other as the extension of self, but the value of good-person still exists. Actually, the rewarding value of good-other might be even stronger than good-self because the former indicate potential cooperation and material rewards, but the latter is more linked to personal belief. This means that the social categorization theory predicts participants prioritize good-self but not good-other, while reward-based attention theory predicts participants are both prioritized. Also, as in @Hu_2020_GoodSelf, people may also only identify with good-self instead of bad self. That is, people will show a unique pattern of self-identification: only good-self is identified as "self" while all the others categories were excluded.

In exp 3a, 3b, and 6b, we found that (1) good-self is always faster than neutral-self and bad-self, but good-other only have weak to null advantage to neutral-other and bad-other. which mean the social categorization is self-centered. (2) good-self's advantage over good other only occur when self- and other- were in the same task. i.e. the relative advantage is competition based instead of absolute. These three experiments suggest that people more like to view the moral character stimuli as person and categorize good-self as an unique category against all others. A mini-meta-analysis showed that there was no effect of valence when the identity is other. This results showed that value-based attention is not likely explained the pattern we observed in first four experiments. Why good-self is prioritized is less clear. Besides the social-categorization explanation, it's also possible that good self is so unique that it is prioritized in all possible situation and therefore is not social categorization *per se*. 

[what we care? valence of the self exp4a or identity of the good exp4b?] We go further to disentangle the good-self complex: is it because the special role of good-self or because of social categorization. We designed two complementary experiments. in experiment 4a, participants only learned the association between self and other, the words "good-person", "neutral person", and "bad person" were presented as task-irrelevant stimuli, while in experiment 4b, participants learned the associations between "good-person", "neutral-person", and "bad-person", and the "self" and "other" were presented as task-irrelevant stimuli. These two experiment can be used to distinguish the "good-self" as anchor account and the "good-self-based social categorization" account. If good-self as an anchor is true, then, in both experiment, good-self will show advantage over other stimuli. More specifically, in experiment 4a, in the self condition, there will be advantage for good as task-irrelevant condition than the other two self conditions; in experiment 4b, in the good condition, there will be an advantage for self as task-irrelevant condition over other as task-irrelevant condition. If good-self-based social categorization if true, then, the prioritization effect will depends on whether the stimuli can be categorized as the same group of good-self. More specifically, in experiment 4a, there will be good-as-task-irrelevant stimuli than other condition in self conditions, this prediction is the same as the "good-self as anchor" account; however, for experiment 4b, there will be no self-as-task-irrelevant stimuli than other-as-task-irrelevant condition.

[Good self in self-reported data] As an exploration, we also collected participants' self-reported psychological distance between self and good-person, bad-person, and neutral-person, moral identity, moral self-image, and self-esteem. All these data are available [see @Liu_2020_JOPD]. We explored the correlation between self-reported distance and these questionnaires as well as the questionnaires and behavioral data. However, given that the correlation between self-reported score and behavioral data has low correlation [@dang_why_2020], we didn't expect a high correlation between these self-reported measures and the behavioral data.

[whether categorize self as positive is not limited to morality] Finally, we explored the pattern is generalized to all positive traits or only to morality. We found that self-categorization is not limited to morality, but a special case of categorization in perpetual processing. 

Key concepts and discussing points:

**Self-categories** are cognitive groupings of self and some class of stimuli as identical or different from some other class. [Turner et al.]

**Personal identity** refers to self-categories that define the individual as a unique person in terms of his or her individual differences from other (in-group) persons.

**Social identity** refers to the shared social categorical self ("us" vs. "them").

**Variable self**: Who we are, how we see ourselves, how we define our relations to others (indeed whether they are construed as ‘other’ or as part of the extended 'we' self) is different in different settings. 

**Identification**: the degree to which an individual feels connected to an ingroup or includes the ingroup in his or her self-concept. (self is not bad; )

Morality as a way for social-categorization [@mchugh_moral_2019]? People are more likely to identify themselves with trustworthy faces [@verosky_differential_2010] (trustworthy faces has longer RTs).

What is the relation between morally good and self in a semantic network (attractor network) (Freeman & Ambady, 2011)? The psychological essentialism account proposed that the moral good self is perspective independent, i.e., there is a moral good self in all. This perspective free effect is not exist in our effect.

How to deal with the *variable self* (self-categorization theory) vs. *core/true/authentic self* vs. *self-enhancement*

**Limitations**:
The perceptual decision-making will show certain pattern under certain task demand. In our case, it's the forced, speed, two-option choice task.

in experiment 4a and 4b, we didn't have a baseline condition where there is no word inside the shape?

# Disclosures
We reported all the measurements, analyses, and results in all the experiments in the current study. Participants whose overall accuracy lower than 60% were excluded from analysis. Also, the accurate responses with less than 200ms reaction times were excluded from the analysis.  

All the experiments reported were not pre-registered. Most experiments (1a ~ 6b, except experiment 3b) reported in the current study were first finished between 2014 to 2016 in Tsinghua University, Beijing, China. Participants in these experiments were recruited in the local community. To increase the sample size of experiments to 50 or more [@Simmons_2013_life], we recruited additional participants in Wenzhou University, Wenzhou, China in 2017 for experiment 1a, 1b, 4a, and 4b. Experiment 3b was finished in Wenzhou University in 2017. To have a better estimation of the effect size, we included the data from two experiments (experiment 7a, 7b) that were reported in @Hu_2020_GoodSelf (See Table S1 for overview of these experiments). 

All participant received informed consent and compensated for their time. These experiments were approved by the ethic board in the Department of Tsinghua University. 

 <!-- 21-word solution (Simmons, Nelson & Simonsohn, 2012; retrieved from http://ssrn.com/abstract=2160588) -->

```{r loadingData,echo=FALSE,results='hide'}
load("AllData.RData")

### expclude the repeated subj from the raw data

# No repeating subj
df1a.v_meta <- df1a.v

# No repeating subj
df1b.v_meta <- df1b.v

# exclude participant from exp 1a
df1c.v_meta <- df1c.v %>% dplyr::filter(!Subject %in% c(1206, 1207, 1208, 1210))

# exclude participant from exp 1a
df2.v_meta <- df2.v %>% dplyr::filter(Subject > 2000)    

# exclude participants from ex1b, 1c, and 2
df3a.v_meta <- df3a.v %>% dplyr::filter(!Subject %in% c(3013, 3012, 3043, 3046)) 

# No repeating subj
df3b.v_meta <- df3b.v

# No repeating subj
df4a.v_meta <- df4a.v

# exclude participants from ex1b, 1c, and 2
df4b.v_meta <- df4b.v %>% dplyr::filter(!Subject %in% c(4210, 4202, 4201))   

# exclude participants from ex1b, 1c, and 2
df5.v_meta <- df5.v %>% dplyr::filter(!Subject %in% c(5201))   

# exclude participants from ex1b, 1c, and 2
df6a.v_meta <- df6a.v %>% dplyr::filter(!Subject %in% c(6118,6119,6122,6123,6131))   

# exclude participants from ex1b, 1c, and 2
df6b.v_meta <- df6b_d1.v %>% dplyr::filter(!Subject %in% c(6217))   

# exclude participants from ex1b, 1c, and 2
df7a.v_meta <- df7a_m.v %>% dplyr::filter(!Subject %in% c(7020))   

# No repeating subj
df7b.v_meta <- df7b_m.v

# remove all unnecessary variables
var_list <- c('df1a.v_meta', 'df1b.v_meta', 'df1c.v_meta', 'df2.v_meta', 'df3a.v_meta', 'df3b.v_meta',
              'df4a.v_meta', 'df4b.v_meta', 'df5.v_meta', 'df6a.v_meta', 'df6b.v_meta', 'df7a.v_meta', 'df7b.v_meta',
              'apatheme','exp_table', 'curDir', 'figDir')
rm(list=ls()[! ls() %in% var_list])

df1a.v_meta$ExpID <- 'Exp1a'
df1b.v_meta$ExpID <- 'Exp1b'
df1c.v_meta$ExpID <- 'Exp1c'
df2.v_meta$ExpID  <- 'Exp2'
df3a.v_meta$ExpID <- 'Exp3a'
df3b.v_meta$ExpID <- 'Exp3b'
df4a.v_meta$ExpID <- 'Exp4a'
df4b.v_meta$ExpID <- 'Exp4b'
df5.v_meta$ExpID  <- 'Exp5'
df6a.v_meta$ExpID <- 'Exp6a'
df6b.v_meta$ExpID <- 'Exp6b'
df7a.v_meta$ExpID <- 'Exp7a'
df7b.v_meta$ExpID <- 'Exp7b'
```

```{r define_funs, echo=FALSE, results='hide'}
# define a function to run the sdt GLMM for all exp with Matchness * Valence design
# for 1a, 1b, 1c, 2, 6a
fun_sdt_val <- function(exp_name) {
  df_name <- paste('df', exp_name, '.v', sep = '')
  m_name <- paste("glmmModels/exp", exp_name, "_sdt_m1_DummyCode", sep = '')
  df <- get(df_name)  # get the data by string
  
  m <- df %>%
  dplyr::filter(!is.na(RESP)) %>% # filter trials without response
  dplyr::mutate(ismatch = ifelse(Matchness == 'Match', 1, 0),
                saymatch = ifelse((Matchness == 'Match' & ACC == 1) | 
                                    (Matchness == 'Mismatch' & ACC == 0), 1, 0),
                Valence = factor(Valence, levels = c('Neutral', 'Bad', 'Good'))) %>%
  brms::brm(saymatch ~ 0 + Valence + ismatch:Valence + 
              (0 + Valence + ismatch:Valence | Subject),
            family = bernoulli(link="probit"),
            data = .,
            control = list(adapt_delta = .99),
            iter = 4000,
            thin = 2,
            cores = parallel::detectCores(),
            file = here::here(m_name))
  return(m)
}

fun_plot_sdt_val <- function(m_sdt) {
    # extract c
    tmp_c <- m_sdt %>% 
      tidybayes::gather_draws(b_ValenceBad, b_ValenceNeutral, b_ValenceGood) %>%
      dplyr::rename(Valence = .variable, sdt_c = .value) %>% dplyr::ungroup() %>%
      dplyr::mutate(Valence = gsub("b_", "", Valence)) %>%
      dplyr::mutate(Valence = ifelse(stringr::str_detect(Valence, 'Bad'), 'Bad',
                                     ifelse(stringr::str_detect(Valence, 'Good'), 'Good', 'Neutral')))
    
    # dprime
    tmp_d <- m_sdt %>% 
      tidybayes::gather_draws(`b_ValenceBad:ismatch`, `b_ValenceNeutral:ismatch`, 
                              `b_ValenceGood:ismatch`) %>%
      dplyr::rename(Valence = .variable, sdt_d = .value) %>% dplyr::ungroup() %>%
      dplyr::mutate(Valence = gsub("b_", "", Valence)) %>%
      dplyr::mutate(Valence = ifelse(stringr::str_detect(Valence, 'Bad'), 'Bad',
                                     ifelse(stringr::str_detect(Valence, 'Good'), 'Good', 'Neutral')))
    
    # plot summaries with densities
    p_sdt_d_sum <- tmp_d %>%
      dplyr::mutate(Valence = factor(Valence, levels = c('Bad', 'Neutral', 'Good'))) %>%
      ggplot2::ggplot(aes(x = sdt_d, y = Valence)) +
      tidybayes::stat_halfeyeh() + 
      labs(x = "sensitivity (d')", y = 'Posterior') +
      theme_classic()
    
    p_sdt_c_sum <- tmp_c %>%
      dplyr::mutate(Valence = factor(Valence, levels = c('Bad', 'Neutral', 'Good'))) %>%
      ggplot2::ggplot(aes(x = sdt_c, y = Valence)) +
      tidybayes::stat_halfeyeh() + 
      labs(x = "criteria (c)", y = 'Posterior') +
      theme_classic()
    
    # plot comparison
    p_sdt_d <- tmp_d %>%
      dplyr::mutate(Valence = factor(Valence, levels = c('Neutral', 'Bad', 'Good'))) %>%
      tidybayes::compare_levels(sdt_d, by = Valence) %>%
      ggplot2::ggplot(aes(x = sdt_d, y = Valence, fill = stat(x > 0))) +
      tidybayes::stat_halfeyeh() + 
      geom_vline(xintercept =0, linetype = "dashed") +
      scale_fill_manual(values = c("gray80", "skyblue")) +
      labs(x = "sensitivity (d')", y = 'Comparison') +
      theme_classic()
    
    p_sdt_c <- tmp_c %>%
      dplyr::mutate(Valence = factor(Valence, levels = c('Neutral', 'Bad', 'Good'))) %>%
      tidybayes::compare_levels(sdt_c, by = Valence) %>%
      ggplot2::ggplot(aes(x = sdt_c, y = Valence, fill = stat(x > 0))) +
      tidybayes::stat_halfeyeh() + 
      geom_vline(xintercept =0, linetype = "dashed") +
      scale_fill_manual(values = c("gray80", "skyblue")) +
      labs(x = "criteria (c)", y = 'Comparison') +
      theme_classic()
    
    return(list(p_sdt_d_sum, p_sdt_c_sum, p_sdt_d, p_sdt_c))
}

# define a function to run the RT GLMM for all exp with Matchness * Valence design
fun_rt_val <- function(exp_name) {
  df_name <- paste('df', exp_name, '.v', sep = '')
  m_name <- paste("glmmModels/exp", exp_name, "_rt_m1_DummyCode", sep = '')
  df <- get(df_name)  # get the data by string
  m <- df %>%
    dplyr::mutate(RT_sec = RT/1000) %>% # log RT in seconds
    dplyr::filter(ACC == 1) %>%
    dplyr::mutate(ismatch = ifelse(Matchness == 'Match', 1, 0),
                  Valence = factor(Valence, levels = c('Neutral', 'Bad', 'Good'))) %>%
    brms::brm(RT_sec ~ ismatch*Valence + (ismatch*Valence | Subject),
              family = shifted_lognormal(),
              data = ., control = list(adapt_delta = .99),
              iter = 4000,
              thin = 2,
              cores = parallel::detectCores(),
              file = here::here(m_name))
  return(m)
}

fun_plot_rt_val <- function(m_rt) {
    tmp_rt <- m_rt %>% 
      tidybayes::spread_draws(b_Intercept, b_ValenceBad, b_ValenceGood, 
                              b_ismatch,   `b_ValenceBad:ismatch`, `b_ValenceGood:ismatch`) %>%
      dplyr::mutate(Neut_MM = b_Intercept,
                    Bad_MM = Neut_MM + b_ValenceBad,
                    Good_MM = Neut_MM + b_ValenceGood,
                    Neut_M = Neut_MM + b_ismatch,
                    Bad_M = Neut_MM + b_ismatch + `b_ValenceBad:ismatch`,
                    Good_M = Neut_MM + b_ismatch + `b_ValenceGood:ismatch`) %>%
      dplyr::select(-contains('b_')) %>%
      tidyr::pivot_longer(cols = Neut_MM:Good_M,
                          names_to = 'cond',
                          values_to = 'logRT') %>%
      dplyr::mutate(RT = exp(logRT)*1000,
                    Matchness = dplyr::case_when(cond == 'Neut_MM' | cond == 'Bad_MM' | cond == 'Good_MM' ~ 'Mismatch',
                                                 cond == 'Neut_M'  | cond == 'Bad_M'  | cond == 'Good_M' ~ 'Match'),
                    Valence = dplyr::case_when(cond == 'Neut_MM' | cond == 'Neut_M' ~ 'Neutral',
                                               cond == 'Bad_MM'  | cond == 'Bad_M'  ~ 'Bad', 
                                               cond == 'Good_MM' | cond == 'Good_M' ~ 'Good'))
    p_exp1b_rt_m_sum <- tmp_rt %>% dplyr::mutate(Valence = factor(Valence, levels = c('Bad', 'Neutral', 'Good'))) %>%
      dplyr::filter(Matchness == 'Match') %>%
      ggplot2::ggplot(aes(x = RT, y = Valence)) +
      tidybayes::stat_halfeyeh() + 
      labs(x = "RTs (Matching, ms)", y = 'Posterior') +
      theme_classic()
    p_exp1b_rt_mm_sum <- tmp_rt %>% dplyr::mutate(Valence = factor(Valence, levels = c('Bad', 'Neutral', 'Good'))) %>%
      dplyr::filter(Matchness == 'Mismatch') %>%
      ggplot2::ggplot(aes(x = RT, y = Valence)) +
      tidybayes::stat_halfeyeh() + 
      labs(tag = 'D', x = "RTs (Mismatching, ms)", y = 'Posterior') +
      theme_classic()
    
    # plot comparison
    p_exp1b_rt_m <- tmp_rt %>% dplyr::mutate(Valence = factor(Valence, levels = c('Neutral', 'Bad', 'Good'))) %>%
      dplyr::filter(Matchness == 'Match') %>%
      tidybayes::compare_levels(RT, by = Valence) %>%
      ggplot2::ggplot(aes(x = RT, y = Valence, fill = stat(x < 0))) +
      tidybayes::stat_halfeyeh() + 
      geom_vline(xintercept =0, linetype = "dashed") +
      scale_fill_manual(values = c("gray80", "skyblue")) +
      labs(tag = 'C', x = "RTs (Matching, ms)", y = 'Comparison') +
      theme_classic()
    p_exp1b_rt_mm <- tmp_rt %>% dplyr::mutate(Valence = factor(Valence, levels = c('Neutral', 'Bad', 'Good'))) %>%
      dplyr::filter(Matchness == 'Mismatch') %>%
      tidybayes::compare_levels(RT, by = Valence) %>%
      ggplot2::ggplot(aes(x = RT, y = Valence, fill = stat(x < 0))) +
      tidybayes::stat_halfeyeh() + 
      geom_vline(xintercept =0, linetype = "dashed") +
      scale_fill_manual(values = c("gray80", "skyblue")) +
      labs(tag = 'D', x = "RTs (Mismatching, ms)", y = 'Comparison') +
      theme_classic()
    return(list(p_exp1b_rt_m_sum, p_exp1b_rt_mm_sum, p_exp1b_rt_m, p_exp1b_rt_mm))
}

fun_sdt_val_id <- function(exp_name) {
  df_name <- paste('df', exp_name, '.v', sep = '')
  m_name <- paste("glmmModels/exp", exp_name, "_sdt_m1_DummyCode", sep = '')
  df <- get(df_name)  # get the data by string
  
  m <- df %>%
  dplyr::filter(!is.na(RESP)) %>% # filter trials without response
  dplyr::mutate(ismatch = ifelse(Matchness == 'Match', 1, 0),
                saymatch = ifelse((Matchness == 'Match' & ACC == 1) | 
                                    (Matchness == 'Mismatch' & ACC == 0), 1, 0),
                Valence = factor(Valence, levels = c('Neutral', 'Bad', 'Good')),
                Identity = factor(Identity, levels = c('Self', 'Other'))) %>%
  brms::brm(saymatch ~ 0 + Identity:Valence + ismatch:Identity:Valence + 
              (0 + Identity:Valence + ismatch:Identity:Valence | Subject),
            family = bernoulli(link="probit"),
            data = .,
            control = list(adapt_delta = .99),
            iter = 4000,
            thin = 2,
            cores = parallel::detectCores(),
            file = here::here(m_name))
  return(m)
}

# define a function to run the RT GLMM for all exp with Matchness * Valence design
fun_rt_val_id <- function(exp_name) {
  df_name <- paste('df', exp_name, '.v', sep = '')
  m_name <- paste("glmmModels/exp", exp_name, "_rt_m1_DummyCode", sep = '')
  df <- get(df_name)  # get the data by string
  m <- df %>%
    dplyr::mutate(RT_sec = RT/1000) %>% # log RT in seconds
    dplyr::filter(ACC == 1) %>%
    dplyr::mutate(ismatch = ifelse(Matchness == 'Match', 1, 0),
                  Valence = factor(Valence, levels = c('Neutral', 'Bad', 'Good')),
                  Identity = factor(Identity, levels=c('Self', 'Other'))) %>%
    brms::brm(RT_sec ~ ismatch*Identity*Valence + (ismatch*Identity*Valence | Subject),
              family = shifted_lognormal(),
              data = ., control = list(adapt_delta = .99),
              iter = 4000,
              thin = 2,
              cores = parallel::detectCores(),
              file = here::here(m_name))
  return(m)
}

```

  <!-- A general method part describing experimental design and data analysis -->
```{r child = "general_method.rmd"}
```

# Part 1: Perceptual processing moral character related information
In this part, we report results from five experiments that tested whether an associative learning task. These five experiments revealed a robust effect of moral character on perceptual matching task.

```{r prepare data for first meta, echo=FALSE, results='hide', warning=FALSE}
### try meta-analysis 1a, 1b, 1c, 2, 5 and 6a
selected_columns <- c('ExpID', 'Site', 'Subject','Age', 'Sex', 'Matchness','Valence', 'RESP', 'ACC','RT')
df_moral <- dplyr::bind_rows(df1a.v_meta[selected_columns],
                             df1b.v_meta[selected_columns],
                             df1c.v_meta[selected_columns],
                             df2.v_meta[selected_columns],
                             df5.v_meta[selected_columns],
                             df6a.v_meta[selected_columns]) %>%
  dplyr::mutate(ExpID_new = paste(ExpID, Site, sep = "_")) %>%
  dplyr::mutate(Valence = factor(Valence, levels = c('Neutral', 'Bad', 'Good')))

df_moral_subj <- df_moral %>%
  dplyr::group_by(ExpID_new, Site) %>%
  dplyr::summarize(N = n_distinct(Subject),
                   N_trial = length(Subject),
                   Exp_conds = 6,
                   trial_per_cond = round((length(Subject)/6)/N, 0))

df_moral <- df_moral %>%
  dplyr::filter(!is.na(RESP)) %>% # filter trials without response
  dplyr::mutate(ismatch = ifelse(Matchness == 'Match', 1, 0),
                saymatch = ifelse((Matchness == 'Match' & ACC == 1) | 
                                    (Matchness == 'Mismatch' & ACC == 0), 1, 0)) %>%
  dplyr::select(ExpID_new, Subject, Valence, Matchness, RESP, ACC, RT, ismatch, saymatch) %>%
  dplyr::mutate(ismatch_num = ifelse(Matchness == 'Match', 0.5, -0.5))

# plot the nested structure of the data
with(df_moral, table(Subject, ExpID_new)) %>%
  image(
    col = grey.colors(80, start = 1, end = 0), 
    axes = TRUE, 
    xlab = "Subject", 
    ylab = "ExpID"
  )

```

```{r first meta sdt, echo=FALSE, results='hide', warning=FALSE}
# fit a three-level hierarchical model for SDT, didn't specify the prior; dummy coding
# about 20 hours to finish this sampling using ntel® Xeon(R) CPU E3-1505M v5 @ 2.80GHz × 8 machine.
# 87432.5 = 24.3 hours
sdt_val_m1 <- brms::brm(saymatch ~ 0 + Valence + Valence:ismatch + 
                         (0 + Valence + Valence:ismatch | ExpID_new) + 
                         (0 + Valence + Valence:ismatch  | ExpID_new:Subject),
                       family = bernoulli(link="probit"),
                       data = df_moral,
                       control = list(adapt_delta = .95),
                       cores = parallel::detectCores(),
                       backend = 'cmdstanr',  # with cmdstanr
                       file = here::here("glmmModels/sdt_val_DummyCode_3_level"))

summary(sdt_val_m1)
# stancode(sdt_val_m1)

# plot(hypothesis(sdt_val_m1, "ValenceBad:ismatch > ValenceNeutral:ismatch"))
# 
# plot(hypothesis(sdt_val_m1, "ValenceGood:ismatch > ValenceNeutral:ismatch"))

# combined with emmeans, no longer used
# sdt_val_m1_p <- sdt_val_m1 %>%
#   emmeans::emmeans( ~ ismatch | Valence) %>%
#   tidybayes::gather_emmeans_draws() %>%
#   dplyr::filter(ismatch == 'd prime') %>%
#   ggplot2::ggplot(aes(x = Valence, y = .value)) +
#   tidybayes::stat_halfeye() + # position=position_dodge(width = 0.1)
#   stat_summary(aes(group = NA), fun = mean, geom = "line") +
#   ylab(expression(paste("Sensitivity ",italic("d'"), sep = ' '))) +
#   facet_grid(cols = vars(ismatch), scales = "free_y") +
#   theme_classic() + 
#   theme(axis.title.x = element_blank())

# plot the population level parameter (d prime)
sdt_val_m1_p <- sdt_val_m1 %>%
  # get the traces of population level parameters
  tidybayes::gather_draws(b_ValenceBad, b_ValenceNeutral, b_ValenceGood,
                          `b_ValenceBad:ismatch`, `b_ValenceNeutral:ismatch`, 
                          `b_ValenceGood:ismatch`) %>%
  # create two columns for two independent factors.
  dplyr::mutate(Valence = dplyr::case_when((.variable == "b_ValenceBad") | (.variable == "b_ValenceBad:ismatch") ~ "Bad",
                                (.variable == "b_ValenceNeutral") | (.variable == "b_ValenceNeutral:ismatch") ~ "Neutral",
                                (.variable == "b_ValenceGood") | (.variable == "b_ValenceGood:ismatch")  ~ "Good"),
                params = dplyr::case_when(
                  (.variable == "b_ValenceBad") | (.variable == "b_ValenceNeutral") |  (.variable == "b_ValenceGood")  ~ "criterion",
                  (.variable=="b_ValenceBad:ismatch")|(.variable=="b_ValenceNeutral:ismatch")|(.variable=="b_ValenceGood:ismatch")~"d prime"),
                params = factor(params, levels = c('d prime', 'criterion')),
                Valence = factor(Valence, levels = c('Good', 'Neutral',  'Bad'))) %>%
  # select only d prime
  dplyr::filter(params == 'd prime') %>%
  ggplot2::ggplot(aes(x = Valence, y = .value)) +
  tidybayes::stat_halfeye() + # position=position_dodge(width = 0.1)
  stat_summary(aes(group = NA), fun = mean, geom = "line") +
  ylab(expression(paste("Sensitivity ", italic("d'"), sep = ' '))) +
  # xlab("Valence") +
  #facet_grid(cols = vars(params), scales = "free_y") +
  theme_classic() # + 
  # theme(axis.title.x = element_blank())

#### plot both overall parameters and experimental levels.
# # Get the variables in the model
# var_name_m1 <- tidybayes::get_variables(sdt_val_m1)

df_m1_post_sdt_exp <- sdt_val_m1 %>% 
  tidybayes::spread_draws(r_ExpID_new[condition, term]) %>%
  dplyr::rename(value = r_ExpID_new)

pop_mean <- sdt_val_m1 %>%
  tidybayes::gather_draws(b_ValenceBad, b_ValenceNeutral, b_ValenceGood,
                          `b_ValenceBad:ismatch`, `b_ValenceNeutral:ismatch`, 
                          `b_ValenceGood:ismatch`) %>%
  group_by(.variable) %>%       # this line not necessary (done automatically by spread_draws)
  tidybayes::mean_hdci(.value)  # get the high density continuous intervals

# extract the population level parameters
df_sdt_m1_pop <- sdt_val_m1 %>% 
  tidybayes::gather_draws(b_ValenceBad, b_ValenceNeutral, b_ValenceGood,
                          `b_ValenceBad:ismatch`, `b_ValenceNeutral:ismatch`, 
                          `b_ValenceGood:ismatch`) %>%
  dplyr::rename(term = .variable,
                pop_mean = .value) %>%
  #tidyr::separate(term, c(NA, 'term'), "_") 
  dplyr::ungroup() %>%
  dplyr::mutate(term = gsub("b_", "", term))

# Add the population mean to the experimental level and only keep the value after.
df_m1_post_sdt_exp_update <- merge(df_sdt_m1_pop, df_m1_post_sdt_exp, by = c('term','.chain','.iteration', '.draw'), all = T) %>%
  dplyr::mutate(mean_value = pop_mean + value) %>%  # add the population level value to each experiment
  dplyr::select(condition, term, `.chain`, `.iteration`, `.draw`, mean_value) %>% # select the added value
  dplyr::rename(value = mean_value)  # rename the value

# Plot the difference between conditions 
df_m1_plot_sdt <- df_sdt_m1_pop %>%
  dplyr::mutate(condition = 'Overall') %>%
  dplyr::rename(value = pop_mean) %>%
  dplyr::select(condition, term, `.chain`, `.iteration`, `.draw`, value) %>%
  dplyr::bind_rows(., df_m1_post_sdt_exp_update) %>%
  dplyr::mutate(condition = factor(condition, levels = c("Exp1a_THU", "Exp1a_WZU", "Exp1b_THU", 
                                                         "Exp1b_WZU", "Exp1c_THU", "Exp2_THU" , 
                                                         "Exp5_THU",  "Exp6a_THU","Overall")),
                condition = forcats::fct_rev(condition), # reverse the order because the plot function auto reverse.
                term = dplyr::case_when((term == "ValenceBad") ~ "c_Bad",
                                    (term == "ValenceNeutral") ~ "c_Neutral",
                                    (term == "ValenceGood") ~ "c_Good",
                                    (term == "ValenceBad:ismatch") ~ "dprime_Bad",
                                    (term == "ValenceNeutral:ismatch") ~ "dprime_Neutral",
                                    (term == "ValenceGood:ismatch") ~ "dprime_Good"),
                term = factor(term, levels = c("c_Bad", "c_Neutral", "c_Good",
                                               "dprime_Bad", "dprime_Neutral", "dprime_Good"))) 

df_m1_plot_sdt_diff <- df_m1_plot_sdt %>%
  tidyr::pivot_wider(names_from = c(term), values_from = value) %>%   # long to wide
  dplyr::mutate(diff_GB_c = c_Good - c_Bad,                           # calculate the differences between conditions
                diff_GN_c = c_Good - c_Neutral,
                diff_BN_c = c_Bad - c_Neutral,
                diff_GB_dprm = dprime_Good - dprime_Bad,
                diff_GN_dprm = dprime_Good - dprime_Neutral,
                diff_BN_dprm = dprime_Bad - dprime_Neutral) %>%
  dplyr::select(condition, `.chain`, `.iteration`, `.draw`,
               diff_GB_c,diff_GN_c, diff_BN_c,
               diff_GB_dprm, diff_GN_dprm, diff_BN_dprm) %>%
  tidyr::pivot_longer(cols = diff_GB_c:diff_BN_dprm, names_to = "term_diff", values_to =  "value") %>%  # wide to long
  dplyr::mutate(term_diff = factor(term_diff, levels = c('diff_GB_c','diff_GN_c', 'diff_BN_c',
                                                         'diff_GB_dprm', 'diff_GN_dprm', 'diff_BN_dprm')))

# plot the posterior of the d prime
# use the overall mean values as the vlines
vlines <- df_m1_plot_sdt %>% 
        tidyr::separate(term, c('params', 'Valence')) %>% 
        dplyr::mutate(Valence = factor(Valence, levels = c('Good', 'Neutral', 'Bad'))) %>%
        dplyr::filter(params == 'dprime') %>%
        dplyr::filter(condition == "Overall") %>%
        dplyr::group_by(Valence) %>% 
        dplyr::summarize(Mean = mean(value)) # %>%
        # dplyr::arrange(Mean)

# THIS is the one which the final plot will based on!!!
p_dprime1 <- df_m1_plot_sdt %>%
        tidyr::separate(term, c('params', 'Valence')) %>%
        dplyr::mutate(Valence = factor(Valence, levels = c('Good', 'Neutral', 'Bad'))) %>%
        dplyr::filter(params == 'dprime') %>%
        dplyr::rename(Experiments = condition) %>%
        # dplyr::mutate(Experiments = factor(Experiments, levels = c("Exp1b_WZU", "Exp5_THU", "Exp1a_THU", 
        #                                                            "Exp1b_THU", "Exp1c_THU", "Exp2_THU" , 
        #                                                            "Exp1a_WZU",  "Exp6a_THU","Overall")),
        #               Experiments = fct_rev(Experiments)) %>%
        ggplot2::ggplot(aes(y = Experiments, x = value, color = Valence)) +
        tidybayes::stat_halfeye(aes(fill = Valence), alpha = 0.7) +
        geom_vline(data = vlines, aes(xintercept = Mean,colour = Valence), linetype = "dashed") +
        labs(x=expression('Posteior distribution of '~italic(d)~' prime')) + 
        theme_apa()

# plot the posterior of the difference between d prime
p_dprime1_diff <- df_m1_plot_sdt_diff %>%
  dplyr::filter(str_detect(term_diff, '_dprm')) %>%
  dplyr::filter(!str_detect(term_diff, '_GB_')) %>%
  ggplot2::ggplot(aes(y = condition, x = value, fill = stat(x > 0))) +
  tidybayes::stat_halfeye() +
  geom_vline(xintercept = 0, linetype = "dashed") +
  scale_fill_manual(values = c('gray80', 'skyblue')) +
  xlab(expression(paste("Effect of valence on ", italic("d"), "prime", sep = ' '))) + 
  facet_wrap( ~ term_diff, # scales = "free_y",
               nrow = 1,
               labeller = label_parsed)

# # plot the posterior of difference between c, supplementary figure
# df_m1_plot_sdt_diff %>%
#   dplyr::filter(str_detect(term_diff, '_c')) %>%
#   dplyr::filter(!str_detect(term_diff, '_GB_')) %>%
#   ggplot2::ggplot(aes(y = condition, x = value, fill = stat(x > 0))) +
#   tidybayes::stat_halfeye() +
#   geom_vline(xintercept = 0, linetype = "dashed") +
#   scale_fill_manual(values = c('gray80', 'skyblue')) +
#   xlab("Valence effect on criterion in SDT") +
#   facet_wrap( ~ term_diff, # scales = "free_y",
#                nrow = 1,
#                labeller = label_parsed)

# posterior predictive check
#pp_check(sdt_val_m1)
#pp_sdt_val_m1 <- 
#  brms::pp_check(sdt_val_m1, nsamples = 1e2) + 
#  ggtitle("PPC sdt_val_m1") +
#  theme_bw (base_size = 10) + 
#  theme(legend.position = "none") +
#  xlim(-0.5, 1.5)
```

```{r first meta rt, echo=FALSE, results='hide', warning=FALSE}
# have a look at a few participants' data
set.seed(123)
random_sub <- sample(unique(df_moral$Subject), 10)
random_sub

# # plot the distribution of 10 randomly selected participants
# df_moral %>%
#   dplyr::mutate(RT_sec = RT/1000) %>%  # log RT in seconds
#   dplyr::filter(ACC == 1) %>%          # only correct trials
#   dplyr::filter(Subject %in% random_sub) %>%
#   dplyr::mutate(cond = paste(Matchness, Valence, sep = "_"),
#                 RT_log = log(RT_sec))%>%
#   ggplot2::ggplot(., aes(x=RT_log)) + 
#   geom_histogram(aes(fill=cond), alpha=0.5, bins=60) + 
#   facet_wrap(~Subject, nrow = 2) +  # One panel per id
#   coord_cartesian(xlim=c(-2, 1))

# fit a three-level hierarchical model for RT, didn't specify the prior, shifted_lognormal, effective coding
RT_val_m1 <- df_moral %>%
  dplyr::mutate(RT_sec = RT/1000) %>% # log RT in seconds
  dplyr::filter(ACC == 1) %>%         # only correct trials
  brms::brm(RT_sec ~ Valence*ismatch_num + 
              (Valence*ismatch_num | ExpID_new) +   
              (Valence*ismatch_num | ExpID_new:Subject),
            family=shifted_lognormal(),
            data = .,
            control = list(adapt_delta = .95),
            cores = parallel::detectCores(),
            backend = 'cmdstanr',  # with cmdstanr
            file = here::here("glmmModels/RT_val_EffectCode_3_level"))

# plot(RT_val_m1, "b_")
summary(RT_val_m1)  # ndt = 0 there fore, we used lognormal.
# pp_check(RT_val_m1)

# Will try dummy coding later, but the running time is long: Total execution time: 124845.8 seconds = 34.7 hours
# RT_val_m1 <- df_moral %>%
#   dplyr::mutate(RT_sec = RT/1000) %>% # log RT in seconds
#   dplyr::filter(ACC == 1) %>%         # only correct trials
#   brms::brm(RT_sec ~ Valence*ismatch +
#               (Valence*ismatch | ExpID_new) +
#               (Valence*ismatch  | ExpID_new:Subject),
#             family=lognormal(),
#             data = .,
#             control = list(adapt_delta = .95),
#             cores = parallel::detectCores(),
#             backend = 'cmdstanr',  # with cmdstanr
#             file = here::here("glmmModels/RT_val_DummyCode_3_level"))
# 
# summary(RT_val_m1)

#Population-Level Effects: 
#                        Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
#Intercept                  -0.40      0.06    -0.52    -0.27 1.01      837     1301  # baseline: mismatch:neutral
#ValenceBad                  0. 01      0.00     0.00     0.02 1.00     1752     2540  # mismatch:bad - mismatch:neutral = 0.01
#ValenceGood                -0.03      0.00    -0.04    -0.02 1.00     1237     2219  # mismatch:Good - mismatch:neutral = -0.03
#ismatch_num                -0.07      0.01    -0.09    -0.06 1.00     1638     1957  # match:neutral - mismatch:neutral = -0.07
#ValenceBad:ismatch_num      0.02      0.01     0.00     0.04 1.00     1597     2380  # match:bad - ValenceBad -ismatch_num = 0.02
#ValenceGood:ismatch_num    -0.05      0.01    -0.07    -0.03 1.00     1424     1775  # match:good - ValenceGood- ismatch_num = -0.05

# Mismatch:Neutral - Intercept = -0.4
# Mismatch:Bad     - Intercept  + ValenceBad = -0.4 + 0.01 = -0.39
# Mismatch:Good    - Intercept  + ValenceGood = -0.4 - 0.03 = -0.43
# Match: Neutral   - Intercept  + ismatch_num = -0.4 - 0.07 = -0.47
# Match: Bad       - Intercept  + ismatch_num + ValenceBad+ ValenceBad:ismatch_num = -0.4 + 0.01 + 0.02 =  -0.37 
# Match: Good      - Intercept  + ismatch_num + ValenceGood+ ValenceGood:ismatch_num = -0.4 + (-0.03) + (-0.05) = -0.48

# Get the variables in the model 1
# RT_var_name_m1 <- tidybayes::get_variables(RT_val_m1)

df_m1_post_rt_exp <- RT_val_m1 %>% 
  tidybayes::spread_draws(r_ExpID_new[condition, term]) %>%
  dplyr::rename(value = r_ExpID_new)

df_rt_m1_pop_mean <- RT_val_m1 %>%
  tidybayes::gather_draws(b_Intercept, b_ValenceBad, b_ValenceGood,
                          `b_ismatch_num`, `b_ValenceBad:ismatch_num`, 
                          `b_ValenceGood:ismatch_num`) %>%
  group_by(.variable) %>%       # this line not necessary (done automatically by spread_draws)
  tidybayes::mean_hdci(.value)  # get the high density continuous intervals

# extract the population level parameters
df_rt_m1_pop <- RT_val_m1 %>% 
  tidybayes::gather_draws(b_Intercept, b_ValenceBad, b_ValenceGood,
                          `b_ismatch_num`, `b_ValenceBad:ismatch_num`, 
                          `b_ValenceGood:ismatch_num`) %>%
  dplyr::rename(term = .variable,
                pop_mean = .value) %>%
  #tidyr::separate(term, c(NA, 'term'), "_") 
  dplyr::ungroup() %>%
  dplyr::mutate(term = gsub("b_", "", term))

# Add the population mean to the experimental level and only keep the value after.
df_m1_post_rt_exp_update <- merge(df_rt_m1_pop, df_m1_post_rt_exp, 
# rt_post_tmp <- merge(rt_pop_post, df_m1_post_rt_exp, 
                     by = c('term','.chain','.iteration', '.draw'), all = T) %>%
  dplyr::mutate(mean_value = pop_mean + value) %>%  # add the population leve value to each experiment
  dplyr::select(condition, term, `.chain`, `.iteration`, `.draw`, mean_value) %>% # select the added value
  dplyr::rename(value = mean_value)  # rename the value

# Plot the difference between conditions 
df_m1_plot_rt <- df_rt_m1_pop %>%
  dplyr::mutate(condition = 'Overall') %>%
  dplyr::rename(value = pop_mean) %>% # chagne the `pop_mean` as `value` for data frame merge
  dplyr::select(condition, term, `.chain`, `.iteration`, `.draw`, value) %>%
  dplyr::bind_rows(., df_m1_post_rt_exp_update) %>%
  dplyr::mutate(condition = factor(condition, levels = c("Exp1a_THU", "Exp1a_WZU", "Exp1b_THU", 
                                                         "Exp1b_WZU", "Exp1c_THU", "Exp2_THU" , 
                                                         "Exp5_THU",  "Exp6a_THU","Overall")),
                condition = forcats::fct_rev(condition)) %>%
  tidyr::pivot_wider(names_from = c(term), values_from = value) %>%   # long to wide
  dplyr::mutate(Neutral_NM = Intercept,               # calculate the differences between coditions
                Bad_NM = Intercept  + ValenceBad,
                Good_NM = Intercept  + ValenceGood ,
                Neutral_M = Intercept  + ismatch_num,
                Bad_M = Intercept  + ismatch_num + ValenceBad + `ValenceBad:ismatch_num`,
                Good_M = Intercept  + ismatch_num + ValenceGood+ `ValenceGood:ismatch_num`) %>%
  dplyr::select(condition, `.chain`, `.iteration`, `.draw`,
               Neutral_NM, Bad_NM, Good_NM,
               Neutral_M, Bad_M, Good_M) %>%
  tidyr::pivot_longer(cols = Neutral_NM:Good_M, names_to = "term", values_to =  "value") %>%  # wide to long
  dplyr::mutate(term = factor(term, levels = c('Good_NM', 'Neutral_NM', 'Bad_NM',
                                               'Good_M',  'Neutral_M',  'Bad_M')),
                value = exp(value),
                value = value * 1000) 

# plot the posterior of the d prime
# use the overall mean values as the vlines
vlines <- df_m1_plot_rt %>% 
        tidyr::separate(term, c('Valence', 'Match')) %>% 
        dplyr::mutate(Valence = factor(Valence, levels = c('Good', 'Neutral', 'Bad'))) %>%
        dplyr::filter(Match == 'M') %>%
        dplyr::filter(condition == "Overall") %>%
        dplyr::group_by(Valence) %>% 
        dplyr::summarize(Mean = mean(value)) # %>%
        # dplyr::arrange(Mean)

# THIS is the one which the final plot will based on!!!
p_rt1 <- df_m1_plot_rt %>%
        tidyr::separate(term, c('Valence', 'Match')) %>% 
        dplyr::mutate(Valence = factor(Valence, levels = c('Good', 'Neutral', 'Bad'))) %>%
        dplyr::filter(Match == 'M') %>%
        dplyr::rename(Experiments = condition) %>%
        # dplyr::mutate(Experiments = factor(Experiments, levels = c("Exp1b_WZU", "Exp5_THU", "Exp1a_THU", 
        #                                                            "Exp1b_THU", "Exp1c_THU", "Exp2_THU" , 
        #                                                            "Exp1a_WZU",  "Exp6a_THU","Overall")),
        #               Experiments = fct_rev(Experiments)) %>%
        ggplot2::ggplot(aes(y = Experiments, x = value, color = Valence)) +
        tidybayes::stat_halfeye(aes(fill = Valence), alpha = 0.7) +
        geom_vline(data = vlines, aes(xintercept = Mean,colour = Valence), linetype = "dashed") +
        labs(x=expression('Posteior distribution of reaction times')) + 
        theme_apa()


df_m1_plot_rt_diff <- df_m1_plot_rt %>%
  tidyr::pivot_wider(names_from = c(term), values_from = value) %>%   # long to wide
  dplyr::mutate(diff_GB_NM = Good_NM - Bad_NM,               # calculate the differences between coditions
                diff_GN_NM = Good_NM - Neutral_NM,
                diff_BN_NM = Bad_NM - Neutral_NM,
                diff_GB_M = Good_M - Bad_M, 
                diff_GN_M = Good_M - Neutral_M,
                diff_BN_M = Bad_M - Neutral_M,) %>%
  dplyr::select(condition, `.chain`, `.iteration`, `.draw`,
               diff_GB_NM,diff_GN_NM, diff_BN_NM,
               diff_GB_M, diff_GN_M, diff_BN_M) %>%
  tidyr::pivot_longer(cols = diff_GB_NM:diff_BN_M, names_to = "term_diff", values_to =  "value") %>%  # wide to long
  dplyr::mutate(term_diff = factor(term_diff, levels = c('diff_GB_NM','diff_GN_NM', 'diff_BN_NM',
                                                         'diff_GB_M', 'diff_GN_M', 'diff_BN_M')))
# 
# df_m1_rt_plot %>% 
#   dplyr::group_by(condition, term_diff, .chain) %>%
#   dplyr::tally()

# df_m1_rt_mean <- df_m1_rt_plot %>%
#   #tidybayes::gather_draws(b_Intercept, b_ValenceBad, b_ValenceGood,
#   #                        `b_ismatch_num`, `b_ValenceBad:ismatch_num`, 
#   #                        `b_ValenceGood:ismatch_num`) %>%
#   group_by(condition, term_diff) %>%       # this line not necessary (done automatically by spread_draws)
#   tidybayes::mean_hdci(value)  # get the high density continuous intervals

# plot the posterior of mismatch
# df_m1_plot_rt_diff  %>%
#   dplyr::filter(str_detect(term_diff, '_NM')) %>%
#   dplyr::filter(!str_detect(term_diff, '_GB_')) %>%
#   ggplot2::ggplot(aes(y = condition, x = value, fill = stat(x < 0))) +
#   tidybayes::stat_halfeye() +
#   geom_vline(xintercept = 0, linetype = "dashed") +
#   scale_fill_manual(values = c('gray80', 'skyblue')) + 
#   xlab("Effect (differences) of valence on RT (Mismatch trials)")+
#   facet_wrap( ~ term_diff, 
#               # scales = "free_y", 
#               nrow = 1,
#               labeller = label_parsed)

# plot the posterior of matching trials
p_rt1_diff <- df_m1_plot_rt_diff %>%
  dplyr::filter(str_detect(term_diff, '_M')) %>%
  dplyr::filter(!str_detect(term_diff, '_GB_')) %>%
  ggplot2::ggplot(aes(y = condition, x = value, fill = stat(x < 0))) +
  tidybayes::stat_halfeye() +
  geom_vline(xintercept = 0, linetype = "dashed") +
  scale_fill_manual(values = c('gray80', 'skyblue')) + 
  xlab("Effect of valence on RT (Match trials)") +
  facet_wrap( ~ term_diff,
              # scales = "free_y", 
              nrow = 1,
              labeller = label_parsed)
```

  <!-- plot all graphs form the first part together -->
  
```{r plot-bayes-meta-1, fig.cap="Effect of moral valence on RT and d'", fig.height=9, fig.width=15, warning=FALSE}
library(patchwork)
# (p_rt1 | p_dprime1)
p_rt1 + p_dprime1 +
        p_rt1_diff + p_dprime1_diff + plot_annotation(tag_levels = 'A')  + plot_layout(nrow = 2, byrow = TRUE)
```

See Figure \@ref(fig:plot-bayes-meta-1).

```{r model comp for rt, eval = FALSE, echo=FALSE, results='hide' }
#### model copmarison etc, will be in supplementary materials
# 
# log normal distribution, dummy coding
RT_val_m2 <- df_moral %>%
  dplyr::mutate(RT_sec = RT/1000) %>% # log RT in seconds
  dplyr::filter(ACC == 1) %>%
  brms::brm(RT_sec ~ Valence*ismatch + 
              (Valence*ismatch | ExpID_new) +   
              (Valence*ismatch | ExpID_new:Subject),
            family=lognormal(),
            data = .,
            control = list(adapt_delta = .98),
            cores = parallel::detectCores(),
            backend = 'cmdstanr',  # with cmdstanr
            file = here::here("glmmModels/RT_val_EffectCode_3_level_m2"))
summary(RT_val_m2)

# log normal distribution, with truncated distribution, , dummy coding
RT_val_m3_trunc <- df_moral %>%
  dplyr::mutate(RT_sec = RT/1000) %>% # log RT in seconds
  dplyr::filter(ACC == 1) %>%
  brms::brm(RT_sec|trunc(lb = 0.2, ub = 1.1) ~ Valence*ismatch + 
              (Valence*ismatch | ExpID_new) +   
              (Valence*ismatch | ExpID_new:Subject),
            family=lognormal(),
            data = .,
            control = list(adapt_delta = .98),
            cores = parallel::detectCores(),
            file = here::here("glmmModels/RT_val_EffectCode_3_level_m3_trunc"))
summary(RT_val_m3_trunc)
pp_check(RT_val_m3_trunc)
#plot(RT_val_m3_trunc, "b_")

# compare three models
loo(RT_val_m1, RT_val_m2, RT_val_m3_trunc) # takes about XX mins
bayes_factor(RT_val_m1,RT_val_m2)
# Monte Carlo SE of elpd_loo is 0.4.

#All Pareto k estimates are good (k < 0.5).
#See help('pareto-k-diagnostic') for details.

#Model comparisons:
#                elpd_diff se_diff
#RT_val_m1          0.0       0.0 
#RT_val_m2         -5.6       3.3 
#RT_val_m3_trunc -590.6      34.8 

# Get the variables in the model 3
RT_var_name_m3 <- tidybayes::get_variables(RT_val_m3_trunc)

df_m3_post_rt_exp <- RT_val_m3_trunc %>% 
  tidybayes::spread_draws(r_ExpID_new[condition, term]) %>%
  dplyr::rename(value = r_ExpID_new)

rt_pop_mean <- RT_val_m3_trunc %>%
  tidybayes::gather_draws(b_Intercept, b_ValenceBad, b_ValenceGood,
                          `b_ismatch`, `b_ValenceBad:ismatch`, 
                          `b_ValenceGood:ismatch`) %>%
  group_by(.variable) %>%       # this line not necessary (done automatically by spread_draws)
  tidybayes::mean_hdci(.value)  # get the high density continuous intervals

# extract the population level parameters
rt_pop_post <- RT_val_m3_trunc %>% 
  tidybayes::gather_draws(b_Intercept, b_ValenceBad, b_ValenceGood,
                          `b_ismatch`, `b_ValenceBad:ismatch`, 
                          `b_ValenceGood:ismatch`) %>%
  dplyr::rename(term = .variable,
                pop_mean = .value) %>%
  #tidyr::separate(term, c(NA, 'term'), "_") 
  dplyr::ungroup() %>%
  dplyr::mutate(term = gsub("b_", "", term))

# Add the population mean to the experimental level and only keep the value after.
rt_post_tmp <- merge(rt_pop_post, df_m3_post_rt_exp, 
                     by = c('term','.chain','.iteration', '.draw'), all = T) %>%
  dplyr::mutate(mean_value = pop_mean + value) %>%  # add the population leve value to each experiment
  dplyr::select(condition, term, `.chain`, `.iteration`, `.draw`, mean_value) %>% # select the added value
  dplyr::rename(value = mean_value)  # rename the value

# Plot the difference between conditions 
df_m3_rt_plot <- rt_pop_post %>%
  dplyr::mutate(condition = 'Overall') %>%
  dplyr::rename(value = pop_mean) %>%
  dplyr::select(condition, term, `.chain`, `.iteration`, `.draw`, value) %>%
  dplyr::bind_rows(., rt_post_tmp) %>%
  dplyr::mutate(condition = factor(condition, levels = c("Exp1a_THU", "Exp1a_WZU", "Exp1b_THU", 
                                                         "Exp1b_WZU", "Exp1c_THU", "Exp2_THU" , 
                                                         "Exp5_THU",  "Exp6a_THU","Overall")),
                condition = forcats::fct_rev(condition)#, # reverse the order b/c plot function auto reverse.
                ) %>%
  tidyr::pivot_wider(names_from = c(term), values_from = value) %>%   # long to wide
  dplyr::mutate(diff_GB_NM = ValenceGood - ValenceBad,               # calculate the differences between coditions
                diff_GN_NM = ValenceGood,
                diff_BN_NM = ValenceBad,
                diff_GN_M = ValenceGood + `ValenceGood:ismatch`,
                diff_BN_M = ValenceBad + `ValenceBad:ismatch`,
                diff_GB_M = diff_GN_M - diff_BN_M) %>%
  dplyr::select(condition, `.chain`, `.iteration`, `.draw`,
               diff_GB_NM,diff_GN_NM, diff_BN_NM,
               diff_GB_M, diff_GN_M, diff_BN_M) %>%
  tidyr::pivot_longer(cols = diff_GB_NM:diff_BN_M, names_to = "term_diff", values_to =  "value") %>%  # wide to long
  dplyr::mutate(term_diff = factor(term_diff, levels = c('diff_GB_NM','diff_GN_NM', 'diff_BN_NM',
                                                         'diff_GB_M', 'diff_GN_M', 'diff_BN_M')))

df_m3_rt_plot %>% 
  dplyr::group_by(condition, term_diff, .chain) %>%
  dplyr::tally()

df_m3_rt_mean <- df_m3_rt_plot %>%
  group_by(condition, term_diff) %>%       # this line not necessary (done automatically by spread_draws)
  tidybayes::mean_hdci(value)  # get the high density continuous intervals


# plot the posterior of mismatch
df_m3_rt_plot  %>%
  dplyr::filter(str_detect(term_diff, '_NM')) %>%
  ggplot2::ggplot(aes(y = condition, x = value, fill = stat(x < 0))) +
  tidybayes::stat_halfeyeh() +
  geom_vline(xintercept = 0, linetype = "dashed") +
  scale_fill_manual(values = c('gray80', 'skyblue')) + 
  facet_wrap( ~ term_diff,
               scales = "free_y", nrow = 1,
               labeller = label_parsed)

# plot the posterior of matching trials
df_m3_rt_plot %>%
  dplyr::filter(str_detect(term_diff, '_M')) %>%
  ggplot2::ggplot(aes(y = condition, x = value, fill = stat(x < 0))) +
  tidybayes::stat_halfeyeh() +
  geom_vline(xintercept = 0, linetype = "dashed") +
  scale_fill_manual(values = c('gray80', 'skyblue')) + 
  facet_wrap( ~ term_diff,
               scales = "free_y", nrow = 1,
               labeller = label_parsed)
```

# Part 2: interaction between valence and identity

In this part, we report three experiments (3a, 3b, and 6b) that aimed at testing whether the moral valence effect found in the previous experiments can be modulated by the self-referential processing. These analysis included 108 participants.

```{r prepare data for second meta, echo=FALSE, results='hide', warning=FALSE}
### try meta-analysis 1a, 1b, 1c, 2, 5 and 6a
selected_columns <- c('ExpID', 'Site', 'Subject','Age', 'Sex', 'Matchness', 'Identity', 'Valence', 'RESP', 'ACC','RT')
df_ms <- dplyr::bind_rows(df3a.v_meta[selected_columns],
                          df3b.v_meta[selected_columns],
                          df6b.v_meta[selected_columns]) %>%
  dplyr::mutate(ExpID_new = paste(ExpID, Site, sep = "_")) %>%
  dplyr::mutate(Valence = factor(Valence, levels = c('Neutral', 'Bad', 'Good')))

df_ms_subj <- df_ms %>%
  dplyr::group_by(ExpID_new, Site) %>%
  dplyr::summarize(N = n_distinct(Subject),
                   N_trial = length(Subject),
                   Exp_conds = 6,
                   trial_per_cond = round((length(Subject)/6)/N, 0))

df_ms <- df_ms %>%
  dplyr::filter(!is.na(RESP)) %>% # filter trials without response
  dplyr::mutate(ismatch = ifelse(Matchness == 'Match', 1, 0),
                saymatch = ifelse((Matchness == 'Match' & ACC == 1) | 
                                    (Matchness == 'Mismatch' & ACC == 0), 1, 0),
                Valence = factor(Valence, levels = c('Neutral', 'Bad', 'Good')),
                Identity = factor(Identity, levels = c('Self', 'Other'))) %>%
  dplyr::select(ExpID_new, Subject, Matchness, Identity,Valence, RESP, ACC, RT, ismatch, saymatch) %>%
  dplyr::mutate(ismatch_num = ifelse(Matchness == 'Match', 0.5, -0.5))

# plot the nested structure of the data
with(df_ms, table(Subject, ExpID_new)) %>%
  image(
    col = grey.colors(80, start = 1, end = 0), 
    axes = TRUE, 
    xlab = "Subject", 
    ylab = "ExpID"
  )
```

```{r second meta sdt, echo=FALSE, results='hide', warning=FALSE}
# fit a three-level hierarchical model for SDT of moral self, didn't specify the prior; dummy coding
# 
# Note: initialization failed for a few times for full model. need to re-consider the model
sdt_ms_m1 <- df_ms %>%
        dplyr::mutate(Subject = as.factor(Subject),
                      ExpID_new = as.factor(ExpID_new)) %>%
        brms::brm(saymatch ~ 0 + Identity:Valence + ismatch:Identity:Valence + 
                          (0 + Identity:Valence + ismatch:Identity:Valence | ExpID_new) + 
                          (0 + Identity:Valence + ismatch:Identity:Valence | ExpID_new:Subject),
                  family = bernoulli(link="probit"),
                  data = .,
                  chains = 6,
                  iter = 4000,
                  thin = 2,
                  control = list(adapt_delta = .90),
                  cores = parallel::detectCores(),
                  backend = 'cmdstanr',  # with cmdstanr
                  file = here::here("glmmModels/sdt_ms_DummyCode_3_level"))
# m <- df %>%
# dplyr::filter(!is.na(RESP)) %>% # filter trials without response
# dplyr::mutate(ismatch = ifelse(Matchness == 'Match', 1, 0),
#         saymatch = ifelse((Matchness == 'Match' & ACC == 1) | 
#                             (Matchness == 'Mismatch' & ACC == 0), 1, 0),
#         Valence = factor(Valence, levels = c('Neutral', 'Bad', 'Good')),
#         Identity = factor(Identity, levels = c('Self', 'Other'))) %>%
# brms::brm(saymatch ~ 0 + Identity:Valence + ismatch:Identity:Valence + 
#       (0 + Identity:Valence + ismatch:Identity:Valence | Subject),
#     family = bernoulli(link="probit"),
#     data = .,
#     control = list(adapt_delta = .99),
#     iter = 4000,
#     thin = 2,
#     cores = parallel::detectCores(),
#     file = here::here(m_name))
  
summary(sdt_ms_m1)

# # Get the variables in the model
var_name_m1 <- tidybayes::get_variables(sdt_ms_m1)

# # get the variable names start with 'b_', i.e., the population level parameters
pop_param_names <- grep('^b_.', var_name_m1, value = TRUE)

# plot the population level parameter (d prime)
sdt_ms_m1_p <- sdt_ms_m1 %>%
  # get the traces of population level parameters
  tidybayes::gather_draws(`b_.*`, regex = TRUE) %>%
  # create two columns for two independent factors.
  dplyr::mutate(Valence = dplyr::case_when(grepl("Neutral", .variable) ~ "Neutral",
                                           grepl("Bad", .variable) ~"Bad",
                                           grepl("Good", .variable) ~"Good"),
                Identity = dplyr::case_when(grepl("Self", .variable) ~ "Self",
                                           grepl("Other", .variable) ~"Other"),
                params = dplyr::case_when(grepl("ismatch", .variable) ~ "d prime",
                                           !grepl("ismatch", .variable) ~"criterion"),
                params = factor(params, levels = c('d prime', 'criterion')),
                Identity = factor(Identity, levels = c("Self", "Other")),
                Valence = factor(Valence, levels = c('Good', 'Neutral',  'Bad'))) %>%
  # select only d prime
  dplyr::filter(params == 'd prime') %>%
  ggplot2::ggplot(aes(x = Valence, y = .value)) +
  tidybayes::stat_halfeye(aes(fill = Identity, alpha = 0.7)) + # position=position_dodge(width = 0.1)
  geom_slabinterval(ymin = 0, ymax = 4) +
  stat_summary(aes(group = Identity, color = Identity), fun = mean, geom = "line") +
  ylab(expression(paste("Sensitivity ", italic("d'"), sep = ' '))) +
  # ylim(0, 4) +
  # xlab("Valence") +
  #facet_grid(cols = vars(Identity)) + # , scales = "free_y"
  theme_classic() # + 
  # theme(axis.title.x = element_blank())

#### plot both overall parameters and experimental levels.

df_ms_sdt_m1_post_exp <- sdt_ms_m1 %>% 
  tidybayes::spread_draws(r_ExpID_new[condition, term]) %>%
  dplyr::rename(value = r_ExpID_new)

df_ms_sdt_m1_pop_mean <- sdt_ms_m1 %>%
  tidybayes::gather_draws(`b_.*`, regex = TRUE) %>%
  group_by(.variable) %>%       # this line not necessary (done automatically by spread_draws)
  tidybayes::mean_hdci(.value)  # get the high density continuous intervals

# extract the population level parameters
df_ms_sdt_m1_pop <- sdt_ms_m1 %>% 
  tidybayes::gather_draws(`b_.*`, regex = TRUE) %>%
  dplyr::rename(term = .variable,
                pop_mean = .value) %>%
  #tidyr::separate(term, c(NA, 'term'), "_") 
  dplyr::ungroup() %>%
  dplyr::mutate(term = gsub("b_", "", term))

# Add the population mean to the experimental level and only keep the value after.
df_ms_sdt_m1_post_exp_update <- merge(df_ms_sdt_m1_pop, df_ms_sdt_m1_post_exp, by = c('term','.chain','.iteration', '.draw'), all = T) %>%
  dplyr::mutate(mean_value = pop_mean + value) %>%  # add the population level value to each experiment
  dplyr::select(condition, term, `.chain`, `.iteration`, `.draw`, mean_value) %>% # select the added value
  dplyr::rename(value = mean_value)  # rename the value

# Plot the difference between conditions 
df_ms_sdt_m1_plot <- df_ms_sdt_m1_pop %>%
  dplyr::mutate(condition = 'Overall') %>%
  dplyr::rename(value = pop_mean) %>%
  dplyr::select(condition, term, `.chain`, `.iteration`, `.draw`, value) %>%
  dplyr::bind_rows(., df_ms_sdt_m1_post_exp_update) %>%
  dplyr::mutate(condition = factor(condition, levels = c("Exp3a_THU", "Exp3b_WZU", "Exp6b_THU",
                                                         "Overall")),
                condition = forcats::fct_rev(condition), # reverse the order because the plot function auto reverse.
                Valence = dplyr::case_when(grepl("Neutral", term) ~ "Neutral",
                                           grepl("Bad", term) ~"Bad",
                                           grepl("Good", term) ~"Good"),
                Identity = dplyr::case_when(grepl("Self", term) ~ "Self",
                                           grepl("Other", term) ~"Other"),
                params = dplyr::case_when(grepl("ismatch", term) ~ "dprime",
                                           !grepl("ismatch", term) ~"c"),
                params = factor(params, levels = c('dprime', 'c')),
                Identity = factor(Identity, levels = c("Self", "Other")),
                Valence = factor(Valence, levels = c('Good', 'Neutral',  'Bad'))
                ) 

df_ms_sdt_m1_plot_diff <- df_ms_sdt_m1_plot %>%
  tidyr::unite(term, c('params', 'Valence')) %>%
  tidyr::pivot_wider(names_from = c(term), values_from = value) %>%   # long to wide
  dplyr::mutate(diff_GB_c = c_Good - c_Bad,                           # calculate the differences between conditions
                diff_GN_c = c_Good - c_Neutral,
                diff_BN_c = c_Bad - c_Neutral,
                diff_GB_dprm = dprime_Good - dprime_Bad,
                diff_GN_dprm = dprime_Good - dprime_Neutral,
                diff_BN_dprm = dprime_Bad - dprime_Neutral) %>%
  dplyr::select(condition, `.chain`, `.iteration`, `.draw`, Identity,
               diff_GB_c,diff_GN_c, diff_BN_c,
               diff_GB_dprm, diff_GN_dprm, diff_BN_dprm) %>%
  tidyr::pivot_longer(cols = diff_GB_c:diff_BN_dprm, names_to = "term_diff", values_to =  "value") %>%  # wide to long
  dplyr::mutate(term_diff = factor(term_diff, levels = c('diff_GB_c','diff_GN_c', 'diff_BN_c',
                                                         'diff_GB_dprm', 'diff_GN_dprm', 'diff_BN_dprm')))

# plot the posterior of the d prime
# use the overall mean values as the vlines
vlines <- df_ms_sdt_m1_plot %>% 
        #tidyr::separate(term, c('params', 'Identity', 'Valence')) %>% 
        dplyr::mutate(Valence = factor(Valence, levels = c('Good', 'Neutral', 'Bad'))) %>%
        dplyr::filter(params == 'dprime') %>%
        dplyr::filter(condition == "Overall") %>%
        dplyr::group_by(Identity, Valence) %>% 
        dplyr::summarize(Mean = mean(value)) # %>%
        # dplyr::arrange(Mean)

# THIS is the one which the final plot will based on!!!
p_ms_dprime1 <- df_ms_sdt_m1_plot %>%
        # tidyr::separate(term, c('params', 'Valence')) %>%
        dplyr::mutate(Valence = factor(Valence, levels = c('Good', 'Neutral', 'Bad')),
                      Identity = factor(Identity, levels = c("Self", "Other"))) %>%
        dplyr::filter(params == 'dprime') %>%
        dplyr::rename(Experiments = condition) %>%
        ggplot2::ggplot(aes(y = Experiments, x = value, color = Valence)) +
        tidybayes::stat_halfeye(aes(fill = Valence), alpha = 0.7) +
        facet_wrap(~Identity) + 
        geom_vline(data = vlines, aes(xintercept = Mean,colour = Valence), linetype = "dashed") +
        labs(x=expression('Posteior distribution of '~italic(d)~' prime')) + 
        theme_apa()

# plot the posterior of the difference between d prime
p_ms_dprime1_diff <- df_ms_sdt_m1_plot_diff %>%
  dplyr::filter(str_detect(term_diff, '_dprm')) %>%
  dplyr::filter(!str_detect(term_diff, '_GB_')) %>%
  tidyr::unite(term_diff, c('Identity', 'term_diff')) %>%
  ggplot2::ggplot(aes(y = condition, x = value, fill = stat(x > 0))) +
  tidybayes::stat_halfeye() +
  geom_vline(xintercept = 0, linetype = "dashed") +
  scale_fill_manual(values = c('gray80', 'skyblue')) +
  xlab(expression(paste("Valence effect on", italic("d"), "prime", sep = ' '))) + 
  facet_wrap( ~ term_diff, # scales = "free_y",
               nrow = 1,
               labeller = label_parsed)

# plot the posterior of difference between c, supplementary figure
df_ms_sdt_m1_plot_diff %>%
  dplyr::filter(str_detect(term_diff, '_c')) %>%
  dplyr::filter(!str_detect(term_diff, '_GB_')) %>%
  dplyr::filter(!str_detect(term_diff, '_GB_')) %>%
  tidyr::unite(term_diff, c('Identity', 'term_diff')) %>%
  ggplot2::ggplot(aes(y = condition, x = value, fill = stat(x > 0))) +
  tidybayes::stat_halfeye() +
  geom_vline(xintercept = 0, linetype = "dashed") +
  scale_fill_manual(values = c('gray80', 'skyblue')) +
  xlab(expression(paste("Valence effect on", italic("d"), "prime", sep = ' ')))+ 
  expand_limits(x = c(-3, 3)) + 
  facet_wrap( ~ term_diff, # scales = "free_y",
               nrow = 1,
               labeller = label_parsed) 
```

```{r second meta rt, echo=FALSE, results='hide', warning=FALSE}
# fit a three-level hierarchical model for RT, didn't specify the prior, shifted_lognormal, effective coding
RT_ms_m1 <- df_ms %>%
  dplyr::mutate(RT_sec = RT/1000) %>% # log RT in seconds
  dplyr::filter(ACC == 1) %>%         # only correct trials
  brms::brm(RT_sec ~ ismatch*Identity*Valence + 
              (ismatch*Identity*Valence | ExpID_new) +   
              (ismatch*Identity*Valence | ExpID_new:Subject),
            family=shifted_lognormal(),
            data = .,
            chains = 6,
            control = list(adapt_delta = .90),
            # iter = 4000,
            # thin = 2,
            cores = parallel::detectCores(),
            backend = 'cmdstanr',  # with cmdstanr
            file = here::here("glmmModels/RT_ms_DummyCode_3_level"))

summary(RT_ms_m1)  # ndt = 0 there fore, we used lognormal.
# pp_check(RT_val_m1)

# Population-Level Effects: 
#                                   Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
# Intercept                            -0.21      0.41    -0.97     0.80 1.02      118      307
# ismatch                              -0.08      0.06    -0.21     0.04 1.06       92      252
# IdentityOther                        -0.04      0.10    -0.29     0.13 1.07       84      134
# ValenceBad                            0.00      0.02    -0.05     0.05 1.05       87       29
# ValenceGood                          -0.04      0.17    -0.55     0.11 1.07       57       37
# ismatch:IdentityOther                -0.09      0.39    -0.95     0.73 1.07       88       28
# ismatch:ValenceBad                    0.01      0.08    -0.17     0.17 1.04      279      274
# ismatch:ValenceGood                  -0.07      0.03    -0.13     0.01 1.06       71       96
# IdentityOther:ValenceBad             -0.00      0.05    -0.09     0.13 1.10       48      140
# IdentityOther:ValenceGood             0.01      0.29    -0.64     0.79 1.14       80       55
# ismatch:IdentityOther:ValenceBad      0.03      0.06    -0.09     0.20 1.05      115       87
# ismatch:IdentityOther:ValenceGood     0.07      0.23    -0.47     0.46 1.03      237      189

# Mismatch:Neutral:Self  - Intercept = -0.21
# Mismatch:Bad:Self      - Intercept  + ValenceBad    = -0.21 + 0.00 = -0.21
# Mismatch:Good:Self     - Intercept  + ValenceGood   = -0.21 - 0.04 = -0.25
# Mismatch:Neutral:Other - Intercept  + IdentityOther = -0.21 - 0.04 = -0.25
# Mismatch:Bad:Other     - Intercept  + ValenceBad  + IdentityOther:ValenceBad  = -0.21 + 0.00 + 0.00 = -0.21
# Mismatch:Good:Other    - Intercept  + ValenceGood + IdentityOther:ValenceGood = -0.21 - 0.04 + 0.01 = -0.24
# Match: Neutral:Self    - Intercept  + ismatch = -0.19 - 0.08 = -0.27
# Match: Bad:Self        - Intercept  + ismatch + ismatch:ValenceBad    = -0.19 - 0.08 + 0.01 = -0.26 
# Match: Good:Self       - Intercept  + ismatch + ismatch:ValenceGood   = -0.19 - 0.08 - 0.07 = -0.34
# Match: Neutral:Other   - Intercept  + ismatch + ismatch:IdentityOther = -0.19 - 0.08 - 0.09 = -0.36
# Match: Bad:Other       - Intercept  + ismatch + ismatch:IdentityOther + ismatch:IdentityOther:ValenceBad  = -0.19 - 0.08 - 0.09 + 0.03 = -0.33 
# Match: Good:Other      - Intercept  + ismatch + ismatch:IdentityOther + ismatch:IdentityOther:ValenceGood = -0.19 - 0.08 - 0.09 + 0.07 = -0.29

# Get the variables in the model 1
# RT_var_name_m1 <- tidybayes::get_variables(RT_val_m1)

df_ms_m1_post_rt_exp <- RT_ms_m1 %>% 
  tidybayes::spread_draws(r_ExpID_new[condition, term]) %>%
  dplyr::rename(value = r_ExpID_new)

df_ms_m1_rt_pop_mean <- RT_ms_m1 %>%
  tidybayes::gather_draws(`b_.*`, regex = TRUE) %>%
  group_by(.variable) %>%       # this line not necessary (done automatically by spread_draws)
  tidybayes::mean_hdci(.value)  # get the high density continuous intervals

# extract the population level parameters
df_ms_m1_rt_pop <- RT_ms_m1 %>% 
  tidybayes::gather_draws(`b_.*`, regex = TRUE) %>%
  dplyr::rename(term = .variable,
                pop_mean = .value) %>%
  #tidyr::separate(term, c(NA, 'term'), "_") 
  dplyr::ungroup() %>%
  dplyr::mutate(term = gsub("b_", "", term))

# Add the population mean to the experimental level and only keep the value after.
df_ms_m1_rt_exp_update <- merge(df_ms_m1_rt_pop, df_ms_m1_post_rt_exp, 
# rt_post_tmp <- merge(rt_pop_post, df_m1_post_rt_exp, 
                     by = c('term','.chain','.iteration', '.draw'), all = T) %>%
  dplyr::mutate(mean_value = pop_mean + value) %>%  # add the population leve value to each experiment
  dplyr::select(condition, term, `.chain`, `.iteration`, `.draw`, mean_value) %>% # select the added value
  dplyr::rename(value = mean_value)  # rename the value

# Plot the difference between conditions 
df_ms_m1_plot_rt <- df_ms_m1_rt_pop %>%
        dplyr::mutate(condition = 'Overall') %>%
        dplyr::rename(value = pop_mean) %>% # chagne the `pop_mean` as `value` for data frame merge
        dplyr::select(condition, term, `.chain`, `.iteration`, `.draw`, value) %>%
        dplyr::bind_rows(., df_ms_m1_rt_exp_update) %>%
        dplyr::mutate(condition = factor(condition, levels = c("Exp3a_THU", "Exp3b_WZU", "Exp6b_THU",
                                                               "Overall")),
  # dplyr::mutate(condition = factor(condition, levels = c("Exp1a_THU", "Exp1a_WZU", "Exp1b_THU", 
  #                                                        "Exp1b_WZU", "Exp1c_THU", "Exp2_THU" , 
  #                                                        "Exp5_THU",  "Exp6a_THU","Overall")),
                      condition = forcats::fct_rev(condition)) %>%
        tidyr::pivot_wider(names_from = c(term), values_from = value) %>%   # long to wide
        dplyr::mutate(NM_Self_Neutral = Intercept,               # calculate the differences between conditions
                      NM_Self_Bad = Intercept  + ValenceBad,
                      NM_Self_Good = Intercept  + ValenceGood ,
                      NM_Other_Neutral = Intercept  + IdentityOther,               # calculate the differences between conditions
                      NM_Other_Bad = Intercept  + ValenceBad  + `IdentityOther:ValenceBad`,
                      NM_Other_Good = Intercept  + ValenceGood + `IdentityOther:ValenceGood`,
                      M_Self_Neutral = Intercept  + ismatch,
                      M_Self_Bad = Intercept  + ismatch + `ismatch:ValenceBad`,
                      M_Self_Good = Intercept  + ismatch + `ismatch:ValenceGood`,
                      M_Other_Neutral = Intercept  + ismatch + `ismatch:IdentityOther`,
                      M_Other_Bad = Intercept  + ismatch + `ismatch:IdentityOther` + `ismatch:IdentityOther:ValenceBad`,
                      M_Other_Good = Intercept  + ismatch + `ismatch:IdentityOther` + `ismatch:IdentityOther:ValenceGood`) %>%
        dplyr::select(condition, `.chain`, `.iteration`, `.draw`,
               contains('M_')) %>%
  tidyr::pivot_longer(cols = NM_Self_Neutral:M_Other_Good, names_to = "term", values_to =  "value") %>%  # wide to long
  dplyr::mutate(term = factor(term, levels = c('NM_Self_Neutral', 'NM_Self_Bad', 'NM_Self_Good',
                                               'NM_Other_Neutral', 'NM_Other_Bad', 'NM_Other_Good',
                                               'M_Self_Neutral', 'M_Self_Bad', 'M_Self_Good',
                                               'M_Other_Neutral', 'M_Other_Bad', 'M_Other_Good')),
                value = exp(value),
                value = value * 1000) 

# plot the posterior of the d prime
# use the overall mean values as the vlines
vlines <- df_ms_m1_plot_rt %>% 
        tidyr::separate(term, c('Match', 'Identity', 'Valence')) %>% 
        dplyr::mutate(Valence = factor(Valence, levels = c('Good', 'Neutral', 'Bad')),
                      Identity = factor(Identity, levels = c("Self", "Other"))) %>%
        dplyr::filter(Match == 'M') %>%
        dplyr::filter(condition == "Overall") %>%
        dplyr::group_by(Identity, Valence) %>% 
        dplyr::summarize(Mean = mean(value)) # %>%
        # dplyr::arrange(Mean)

# THIS is the one which the final plot will based on!!!
p_ms_rt1 <- df_ms_m1_plot_rt %>%
        tidyr::separate(term, c('Match', 'Identity', 'Valence')) %>% 
        dplyr::mutate(Valence = factor(Valence, levels = c('Good', 'Neutral', 'Bad')),
                      Identity = factor(Identity, levels = c("Self", "Other"))) %>%
        dplyr::filter(Match == 'M') %>%
        dplyr::rename(Experiments = condition) %>%
        ggplot2::ggplot(aes(y = Experiments, x = value, color = Valence)) +
        tidybayes::stat_halfeye(aes(fill = Valence), alpha = 0.7) +
        geom_vline(data = vlines, aes(xintercept = Mean,colour = Valence), linetype = "dashed") +
        labs(x=expression('Posteior distribution of reaction times')) + 
        facet_wrap(~Identity) + 
        geom_vline(data = vlines, aes(xintercept = Mean,colour = Valence), linetype = "dashed") +
        theme_apa()


df_m1_plot_rt_diff <- df_m1_plot_rt %>%
  tidyr::pivot_wider(names_from = c(term), values_from = value) %>%   # long to wide
  dplyr::mutate(diff_GB_NM = Good_NM - Bad_NM,               # calculate the differences between coditions
                diff_GN_NM = Good_NM - Neutral_NM,
                diff_BN_NM = Bad_NM - Neutral_NM,
                diff_GB_M = Good_M - Bad_M, 
                diff_GN_M = Good_M - Neutral_M,
                diff_BN_M = Bad_M - Neutral_M,) %>%
  dplyr::select(condition, `.chain`, `.iteration`, `.draw`,
               diff_GB_NM,diff_GN_NM, diff_BN_NM,
               diff_GB_M, diff_GN_M, diff_BN_M) %>%
  tidyr::pivot_longer(cols = diff_GB_NM:diff_BN_M, names_to = "term_diff", values_to =  "value") %>%  # wide to long
  dplyr::mutate(term_diff = factor(term_diff, levels = c('diff_GB_NM','diff_GN_NM', 'diff_BN_NM',
                                                         'diff_GB_M', 'diff_GN_M', 'diff_BN_M')))
# 
# df_m1_rt_plot %>% 
#   dplyr::group_by(condition, term_diff, .chain) %>%
#   dplyr::tally()

# df_m1_rt_mean <- df_m1_rt_plot %>%
#   #tidybayes::gather_draws(b_Intercept, b_ValenceBad, b_ValenceGood,
#   #                        `b_ismatch_num`, `b_ValenceBad:ismatch_num`, 
#   #                        `b_ValenceGood:ismatch_num`) %>%
#   group_by(condition, term_diff) %>%       # this line not necessary (done automatically by spread_draws)
#   tidybayes::mean_hdci(value)  # get the high density continuous intervals

# plot the posterior of mismatch
df_m1_plot_rt_diff  %>%
  dplyr::filter(str_detect(term_diff, '_NM')) %>%
  dplyr::filter(!str_detect(term_diff, '_GB_')) %>%
  ggplot2::ggplot(aes(y = condition, x = value, fill = stat(x < 0))) +
  tidybayes::stat_halfeye() +
  geom_vline(xintercept = 0, linetype = "dashed") +
  scale_fill_manual(values = c('gray80', 'skyblue')) + 
  xlab("Effect (differences) of valence on RT (Mismatch trials)")+
  facet_wrap( ~ term_diff, 
              # scales = "free_y", 
              nrow = 1,
              labeller = label_parsed)

# plot the posterior of matching trials
p_rt1_diff <- df_m1_plot_rt_diff %>%
  dplyr::filter(str_detect(term_diff, '_M')) %>%
  dplyr::filter(!str_detect(term_diff, '_GB_')) %>%
  ggplot2::ggplot(aes(y = condition, x = value, fill = stat(x < 0))) +
  tidybayes::stat_halfeye() +
  geom_vline(xintercept = 0, linetype = "dashed") +
  scale_fill_manual(values = c('gray80', 'skyblue')) + 
  xlab("Effect of valence on RT (Match trials)") +
  facet_wrap( ~ term_diff,
              # scales = "free_y", 
              nrow = 1,
              labeller = label_parsed)
```

# Part 3: Implicit binding between valence and identity

In this part, we reported two studies in which the moral valence or the self-referential processing is not task-relevant. We are interested in testing whether the task-relevance will eliminate the effect observed in previous experiment. 

```{r child = "exp4a.rmd", eval=FALSE}
```

```{r child = "exp4b.rmd", eval=FALSE}
```

```{r remove repeated subj Data, echo=FALSE, results='hide', eval=FALSE}
## exclude the repeating subjects
df1c.meta.d <- df1c.meta.d %>% dplyr::filter(!Subject %in% c(1206, 1207, 1208, 1210))
df1c.meta.rt <- df1c.meta.rt %>% dplyr::filter(!Subject %in% c(1206, 1207, 1208, 1210)) # exclude participants who participated exp1a or 1b

df2.meta.d <- df2.meta.d %>% dplyr::filter(Subject > 2000)    # exclude participant from exp 1a
df2.meta.rt <- df2.meta.rt %>% dplyr::filter(Subject > 2000)

df3a.meta.d <- df3a.meta.d %>% dplyr::filter(!Subject %in% c(3013, 3012, 3043, 3046)) # exclude participants from ex1b, 1c, and 2
df3a.meta.rt <- df3a.meta.rt %>% dplyr::filter(!Subject %in% c(3013, 3012, 3043, 3046)) # exclude participants from ex1b, 1c, and 2

df4b.meta.d <- df4b.meta.d %>% dplyr::filter(!Subject %in% c(4210, 4202, 4201))   # exclude participants from ex1b, 1c, and 2
df4b.meta.rt <- df4b.meta.rt %>% dplyr::filter(!Subject %in% c(4210, 4202, 4201)) # exclude participants from ex1b, 1c, and 2

df5.meta.d <- df5.meta.d %>% dplyr::filter(!Subject %in% c(5201))   # exclude participants from ex1b, 1c, and 2
df5.meta.rt <- df5.meta.rt %>% dplyr::filter(!Subject %in% c(5201)) # exclude participants from ex1b, 1c, and 2

df6a.meta.d <- df6a.meta.d %>% dplyr::filter(!Subject %in% c(6118,6119,6122,6123,6131))   # exclude participants from ex1b, 1c, and 2
df6a.meta.rt <- df6a.meta.rt %>% dplyr::filter(!Subject %in% c(6118,6119,6122,6123,6131)) # exclude participants from ex1b, 1c, and 2

df6b.meta.d <- df6b.meta.d %>% dplyr::filter(!Subject %in% c(6217))   # exclude participants from ex1b, 1c, and 2
df6b.meta.rt <- df6b.meta.rt %>% dplyr::filter(!Subject %in% c(6217)) # exclude participants from ex1b, 1c, and 2

df7a_m.meta.d <- df7a_m.meta.d %>% dplyr::filter(!Subject %in% c(7020))   # exclude participants from ex1b, 1c, and 2
df7a_m.meta.rt <- df7a_m.meta.rt %>% dplyr::filter(!Subject %in% c(7020)) # exclude participants from ex1b, 1c, and 2

```

# Results
```{r first meta,echo=FALSE, results='hide', eval=FALSE}
# Combine the data -----
df.meta_d_1 <- rbind(df1a.meta.d, df1b.meta.d, df1c.meta.d, df2.meta.d, df4b.meta.d , df5.meta.d, df6a.meta.d) 
df.meta_rt_1 <- rbind(df1a.meta.rt, df1b.meta.rt, df1c.meta.rt, df2.meta.rt, df4b.meta.rt,df5.meta.rt, df6a.meta.rt)

# Prepare the data for meta ----
# calculate the mean, sd, n, and r for estimating the effect size and SE of effect size.
effectList_1 <- c('Good_Bad','Good_Neut','Bad_Neut')

df.ES_1 <- data.frame(matrix(nrow=length(unique(df.meta_d_1$ExpID))*length(effectList_1)*2, ncol=0)) %>%
  dplyr::mutate(DVtype = rep(c('RT', 'dprime'), each = length(unique(df.meta_d_1$ExpID))*length(effectList_1)),
                ExpID  = rep(rep(unique(df.meta_d_1$ExpID), each = length(effectList_1)), 2),
                Effect = rep(effectList_1, length(unique(df.meta_d_1$ExpID))*2),
                #Group  = rep(groupList, length(unique(df.meta_d$ExpID))*2),
                M1 = NA, SD1 = NA, M2 = NA, SD2 = NA, N = NA, r = NA, ES = NA, ES.var = NA)

for (DVName in c('RT','dprime')){
  if (DVName == 'RT'){
    metaData <- df.meta_rt_1 %>% dplyr::filter(Matchness == "Match") %>% dplyr::rename(Value = RT)
  } else{
    metaData <- df.meta_d_1 %>% dplyr::rename(Value = dprime)
  }
  
  for (expName in unique(metaData$ExpID)){
    for (effectName in effectList_1){
      tmpdata <- metaData %>% dplyr::filter(ExpID == expName & Domain == 'Morality')
      
      if (effectName == 'Good_Bad'){
        #print(paste('processing Good_Bad of ', expName, sep = ''))
        dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good")
        dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Bad")
        }
      else if (effectName == 'Good_Neut'){
        #print(paste('processing Good_Neut of ', expName, sep = ''))
        #if ('Neutral' %in% tmpdata$Valence){
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good")
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Neutral")
        #  }
        #else{
          #print(paste('There is no Neutral condition in', expName, sepe=''))
        #  next
        #  }
        }
      else if (effectName == 'Bad_Neut'){
        #if ('Neutral' %in% tmpdata$Valence)
        #  {
            dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Bad")
            dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Neutral")  
        #  }
        #else{
            #print(paste('There is no Neutral condition in', expName, sepe=''))
        #    next
        #  }
        }
      #}
      M1  <- mean(dataCond1$Value) -> df.ES_1$M1[df.ES_1$DVtype == DVName & df.ES_1$ExpID == expName & df.ES_1$Effect == effectName]
      SD1 <- sd(dataCond1$Value)   -> df.ES_1$SD1[df.ES_1$DVtype == DVName & df.ES_1$ExpID == expName & df.ES_1$Effect == effectName] 
      M2  <- mean(dataCond2$Value) -> df.ES_1$M2[df.ES_1$DVtype == DVName & df.ES_1$ExpID == expName & df.ES_1$Effect == effectName]
      SD2 <- sd(dataCond2$Value)   -> df.ES_1$SD2[df.ES_1$DVtype == DVName & df.ES_1$ExpID == expName & df.ES_1$Effect == effectName]
      N   <- length(unique(dataCond2$Subject)) -> df.ES_1$N[df.ES_1$DVtype == DVName & df.ES_1$ExpID == expName & df.ES_1$Effect == effectName]
      r   <- cor(dataCond1$Value,dataCond2$Value) -> df.ES_1$r[df.ES_1$DVtype == DVName & df.ES_1$ExpID == expName & df.ES_1$Effect == effectName] 
      tmp2 <- d.sgpp(m.1 = M1, m.2 = M2, sd.1 = SD1, sd.2 = SD2,n = N, r = r)
      df.ES_1$ES[df.ES_1$DVtype == DVName & df.ES_1$ExpID == expName & df.ES_1$Effect == effectName] <- tmp2[1,1]
      df.ES_1$ES.var[df.ES_1$DVtype == DVName & df.ES_1$ExpID == expName & df.ES_1$Effect == effectName] <- tmp2[1,2]
    }
  }
}

# Do the meta-analysis in a for loop ----
df.ES_1_sum <- df.ES_1 %>% 
  dplyr::group_by(DVtype, Effect) %>% 
  tidyr::drop_na() %>% 
  dplyr::summarise(Nexp = length(unique(ExpID)), Nsubj = sum(N, na.rm = T))

df.res.meta_1 <- data.frame(matrix(nrow= 3*2, ncol=0)) %>%
  dplyr::mutate(DVtype = rep(c('RT', 'dprime'), each = 3),
                #Group  = rep(groupList_1, 2),
                Effect = rep(effectList_1, 2),
                #Group  = rep(groupList, length(unique(df.meta_d$ExpID))*2),
                N_exp = NA, Cohen_d = NA, se = NA, CI_low = NA, CI_upp = NA, pval = NA)

for (DVName in c('RT','dprime')){
  for (effectName in effectList_1){
    df.res.meta <- df.ES_1 %>%
      dplyr::filter(DVtype == DVName & Effect == effectName) %>%
      tidyr::drop_na()
    
    tmp.meta.res <- metafor::rma(yi = df.res.meta$ES,
                           vi = df.res.meta$ES.var,
                           slab = df.res.meta$ExpID)
    df.res.meta_1$N_exp[df.res.meta_1$DVtype == DVName & df.res.meta_1$Effect == effectName] <- tmp.meta.res$k
    df.res.meta_1$Cohen_d[df.res.meta_1$DVtype == DVName & df.res.meta_1$Effect == effectName] <- tmp.meta.res$beta
    df.res.meta_1$se[df.res.meta_1$DVtype == DVName & df.res.meta_1$Effect == effectName] <- tmp.meta.res$se
    df.res.meta_1$CI_low[df.res.meta_1$DVtype == DVName & df.res.meta_1$Effect == effectName] <- tmp.meta.res$ci.lb
    df.res.meta_1$CI_upp[df.res.meta_1$DVtype == DVName & df.res.meta_1$Effect == effectName] <- tmp.meta.res$ci.ub
    df.res.meta_1$pval[df.res.meta_1$DVtype == DVName & df.res.meta_1$Effect == effectName] <- tmp.meta.res$pval
  }
}

# Prepare data for plotting the effect size ----
df.res.meta_1 <- df.res.meta_1 %>%
  dplyr::mutate(Identity = "No-Ref.",
                EffectType = Effect) 
```

```{r second meta,echo=FALSE, results='hide', eval=FALSE}
# Results part 2: with self-referential, included experiments: 3a, 3b, 6b, 7a, 7b

# Combine the data  ----
df.meta_d_2 <- rbind(df3a.meta.d, df3b.meta.d, df6b.meta.d, df7a_m.meta.d, df7b_m.meta.d) 
df.meta_rt_2 <- rbind(df3a.meta.rt, df3b.meta.rt, df6b.meta.rt, df7a_m.meta.rt, df7b_m.meta.rt)

# Calculate the mean, sd, n, and r ----
# for estimating the effect size and SE of effect size.
effectList_2 <- c('Good_Bad_S','Good_Neut_S','Bad_Neut_S',
                'Good_Bad_O','Good_Neut_O','Bad_Neut_O')

df.ES_2 <- data.frame(matrix(nrow=length(unique(df.meta_d_2$ExpID))*length(effectList_2)*2, ncol=0)) %>%
  dplyr::mutate(DVtype = rep(c('RT', 'dprime'), each = length(unique(df.meta_d_2$ExpID))*length(effectList_2)),
                ExpID  = rep(rep(unique(df.meta_d_2$ExpID), each = length(effectList_2)), 2),
                Effect = rep(effectList_2, length(unique(df.meta_d_2$ExpID))*2),
                M1 = NA, SD1 = NA, M2 = NA, SD2 = NA, N = NA, r = NA, ES = NA, ES.var = NA)

for (DVName in c('RT','dprime')){
  if (DVName == 'RT'){
    metaData <- df.meta_rt_2 %>% dplyr::filter(Matchness == "Match") %>% dplyr::rename(Value = RT)
  } else{
    metaData <- df.meta_d_2 %>% dplyr::rename(Value = dprime)
  }
  
  for (expName in unique(metaData$ExpID)){
    for (effectName in effectList_2){
      tmpdata <- metaData %>% dplyr::filter(ExpID == expName & Domain == 'Morality')
      
      if (effectName == 'Good_Bad_S'){
        
        if (!all(is.na(tmpdata$Identity))){
          #print(paste('processing Good_Bad_S of ', expName, sep = ''))
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good" & Identity == 'Self')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Bad" & Identity == 'Self')  
          }
        else{
            #print(paste('Skip Good_Bad_S of ', expName, sep = ''))
          next
          }
        }
      else if (effectName == 'Good_Neut_S'){
        if (!all(is.na(tmpdata$Identity)) & 'Neutral' %in% tmpdata$Valence ){
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good" & Identity == 'Self')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Neutral" & Identity == 'Self')  
          }
        else{
          next
          }
        }  
      else if (effectName == 'Bad_Neut_S'){
        if (!all(is.na(tmpdata$Identity)) & 'Neutral' %in% tmpdata$Valence ){
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Bad" & Identity == 'Self')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Neutral" & Identity == 'Self')  
          }
        else{
          next
          }
        }
      else if (effectName == 'Good_Bad_O'){
        if (!all(is.na(tmpdata$Identity))){
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good" & Identity == 'Other')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Bad" & Identity == 'Other')  
          }
        else{
          next
          }
        }
      else if (effectName == 'Good_Neut_O'){
        if (!all(is.na(tmpdata$Identity)) & 'Neutral' %in% tmpdata$Valence )
          {
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good" & Identity == 'Other')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Neutral" & Identity == 'Other')  
          }
        else{
          next
          }
        }
      else if (effectName == 'Bad_Neut_O'){
        if (!all(is.na(tmpdata$Identity)) & 'Neutral' %in% tmpdata$Valence){
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Bad" & Identity == 'Other')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Neutral" & Identity == 'Other')  
          }
        else{
          next
          }
      }
      
      M1  <- mean(dataCond1$Value) -> df.ES_2$M1[df.ES_2$DVtype == DVName & df.ES_2$ExpID == expName & df.ES_2$Effect == effectName]
      SD1 <- sd(dataCond1$Value)   -> df.ES_2$SD1[df.ES_2$DVtype == DVName & df.ES_2$ExpID == expName & df.ES_2$Effect == effectName] 
      M2  <- mean(dataCond2$Value) -> df.ES_2$M2[df.ES_2$DVtype == DVName & df.ES_2$ExpID == expName & df.ES_2$Effect == effectName]
      SD2 <- sd(dataCond2$Value)   -> df.ES_2$SD2[df.ES_2$DVtype == DVName & df.ES_2$ExpID == expName & df.ES_2$Effect == effectName]
      N   <- length(unique(dataCond2$Subject)) -> df.ES_2$N[df.ES_2$DVtype == DVName & df.ES_2$ExpID == expName & df.ES_2$Effect == effectName]
      r   <- cor(dataCond1$Value,dataCond2$Value) -> df.ES_2$r[df.ES_2$DVtype == DVName & df.ES_2$ExpID == expName & df.ES_2$Effect == effectName] 
      tmp2 <- d.sgpp(m.1 = M1, m.2 = M2, sd.1 = SD1, sd.2 = SD2,n = N, r = r)
      df.ES_2$ES[df.ES_2$DVtype == DVName & df.ES_2$ExpID == expName & df.ES_2$Effect == effectName] <- tmp2[1,1]
      df.ES_2$ES.var[df.ES_2$DVtype == DVName & df.ES_2$ExpID == expName & df.ES_2$Effect == effectName] <- tmp2[1,2]
    }
  }
}

# Do the meta ----
# info about participants
df.ES_2_sum <- df.ES_2 %>% 
  dplyr::group_by(DVtype, Effect) %>% 
  tidyr::drop_na() %>% 
  dplyr::summarise(Nexp = length(unique(ExpID)), Nsubj = sum(N, na.rm = T))

df.res.meta_2 <- data.frame(matrix(nrow= (2*3)*2, ncol=0)) %>%
  dplyr::mutate(DVtype = rep(c('RT', 'dprime'), each = (2*3)),
                Effect = rep(effectList_2, 2),
                N_exp = NA, Cohen_d = NA, se = NA, CI_low = NA, CI_upp = NA, pval = NA)

# meta -analysis
for (DVName in c('RT','dprime')){
  for (effectName in effectList_2){
    df.res.meta <- df.ES_2 %>%
      dplyr::filter(DVtype == DVName & Effect == effectName) %>%
      tidyr::drop_na()
  
    tmp.meta.res <- metafor::rma(yi = df.res.meta$ES,
                           vi = df.res.meta$ES.var,
                           slab = df.res.meta$ExpID)
    df.res.meta_2$N_exp[df.res.meta_2$DVtype == DVName & df.res.meta_2$Effect == effectName] <- tmp.meta.res$k
    df.res.meta_2$Cohen_d[df.res.meta_2$DVtype == DVName & df.res.meta_2$Effect == effectName] <- tmp.meta.res$beta
    df.res.meta_2$se[df.res.meta_2$DVtype == DVName & df.res.meta_2$Effect == effectName] <- tmp.meta.res$se
    df.res.meta_2$CI_low[df.res.meta_2$DVtype == DVName & df.res.meta_2$Effect == effectName] <- tmp.meta.res$ci.lb
    df.res.meta_2$CI_upp[df.res.meta_2$DVtype == DVName & df.res.meta_2$Effect == effectName] <- tmp.meta.res$ci.ub
    df.res.meta_2$pval[df.res.meta_2$DVtype == DVName & df.res.meta_2$Effect == effectName] <- tmp.meta.res$pval
  }
}

# plot the effect size  ----
df.res.meta_2 <- df.res.meta_2 %>%
  dplyr::mutate(Identity = ifelse(Effect == "Good_Bad_S" | Effect == "Good_Neut_S" | Effect == "Bad_Neut_S",
                                  "Self-Ref.", "Other-Ref."),
                EffectType = ifelse(Effect == "Good_Bad_S" | Effect == "Good_Bad_O", "Good_Bad",
                                    ifelse(Effect == "Good_Neut_S" | Effect == "Good_Neut_O", "Good_Neut", "Bad_Neut")))

df.res_meta_pdata <- rbind(df.res.meta_1, df.res.meta_2) %>%
  dplyr::mutate(Identity = factor(Identity, levels = c("No-Ref.", "Self-Ref.", "Other-Ref.")),
                EffectType = factor(EffectType, levels = c("Good_Bad", "Good_Neut", "Bad_Neut" )))

```

## Effect of moral valence

```{r plot-all-effect, fig.cap="Effect size (Cohen's *d*) of Valence.", warning=FALSE, eval=FALSE}
# fig.width=8, 
df.res_meta_pdata %>%
  dplyr::filter(EffectType != 'Good_Bad') %>%
  ggplot2::ggplot(., aes(x = EffectType, y=Cohen_d, color=EffectType, fill=EffectType )) + # 
  geom_pointrange(aes(ymin=Cohen_d - 1.96*se, ymax = Cohen_d + 1.96*se), 
                  position = position_dodge(width = 0.5),
                  shape=18, size=0.8) +
  geom_hline(yintercept=0, size=1, color='grey', linetype = 'dashed') +
  coord_cartesian(ylim=c(-1.5, 1.5))+
  scale_color_brewer(palette = "Dark2")+
  scale_fill_brewer(palette = "Dark2")+
  ylab(expression(paste("Effect size: Cohen's ",italic("d"), sep = ' '))) +
  xlab('Contrasts between different valence') +
  apatheme_x +
  facet_grid(  DVtype ~ Identity)
```



## Interaction between valence and self-reference
In this part, we combined the experiments that explicitly manipulated the self-reference and valence, which includes 3a, 3b, 6b, 7a, and 7b. For the positive versus negative contrast, data were from five experiments with 178 participants; for positive versus neutral and neutral versus negative contrasts, data were from three experiments ( 3a, 3b, and 6b) with 108 participants.

In most of these experiments, the interaction between self-reference and valence was significant (see results of each experiment in supplementary materials). In the mini-meta-analysis, we analyzed the valence effect for self-referential condition and other-referential condition separately.



## Generalizibility of the valence effect
In this part, we reported the results from experiment 4 in which either moral valence or self-reference were manipulated as task-irrelevant stimuli. 

```{r analyzing exp4a, echo=FALSE, results='hide', warning=FALSE, message=FALSE, eval=FALSE}
df.ES_4a <- data.frame(matrix(nrow=length(unique(df4a.meta.d$ExpID))*length(effectList_2)*2, ncol=0)) %>%
  dplyr::mutate(DVtype = rep(c('RT', 'dprime'), each = length(unique(df4a.meta.d$ExpID))*length(effectList_2)),
                ExpID  = rep(rep(unique(df4a.meta.d$ExpID), each = length(effectList_2)), 2),
                Effect = rep(effectList_2, length(unique(df4a.meta.d$ExpID))*2),
                M1 = NA, SD1 = NA, M2 = NA, SD2 = NA, N = NA, r = NA, ES = NA, ES.var = NA)

for (DVName in c('RT','dprime')){
  if (DVName == 'RT'){
    metaData <- df4a.meta.rt %>% dplyr::filter(Matchness == "Match") %>% dplyr::rename(Value = RT)
  } else{
    metaData <- df4a.meta.d %>% dplyr::rename(Value = dprime)
  }
  
  for (expName in unique(metaData$ExpID)){
    for (effectName in effectList_2){
      tmpdata <- metaData %>% dplyr::filter(ExpID == expName & Domain == 'Morality')
      
      if (effectName == 'Good_Bad_S'){
        
        if (!all(is.na(tmpdata$Identity))){
          #print(paste('processing Good_Bad_S of ', expName, sep = ''))
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good" & Identity == 'Self')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Bad" & Identity == 'Self')  
          }
        else{
            #print(paste('Skip Good_Bad_S of ', expName, sep = ''))
          next
          }
        }
      else if (effectName == 'Good_Neut_S'){
        if (!all(is.na(tmpdata$Identity)) & 'Neutral' %in% tmpdata$Valence ){
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good" & Identity == 'Self')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Neutral" & Identity == 'Self')  
          }
        else{
          next
          }
        }  
      else if (effectName == 'Bad_Neut_S'){
        if (!all(is.na(tmpdata$Identity)) & 'Neutral' %in% tmpdata$Valence ){
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Bad" & Identity == 'Self')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Neutral" & Identity == 'Self')  
          }
        else{
          next
          }
        }
      else if (effectName == 'Good_Bad_O'){
        if (!all(is.na(tmpdata$Identity))){
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good" & Identity == 'Other')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Bad" & Identity == 'Other')  
          }
        else{
          next
          }
        }
      else if (effectName == 'Good_Neut_O'){
        if (!all(is.na(tmpdata$Identity)) & 'Neutral' %in% tmpdata$Valence )
          {
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good" & Identity == 'Other')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Neutral" & Identity == 'Other')  
          }
        else{
          next
          }
        }
      else if (effectName == 'Bad_Neut_O'){
        if (!all(is.na(tmpdata$Identity)) & 'Neutral' %in% tmpdata$Valence){
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Bad" & Identity == 'Other')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Neutral" & Identity == 'Other')  
          }
        else{
          next
          }
      }
      
      M1  <- mean(dataCond1$Value) -> df.ES_4a$M1[df.ES_4a$DVtype == DVName & df.ES_4a$ExpID == expName & df.ES_4a$Effect == effectName]
      SD1 <- sd(dataCond1$Value)   -> df.ES_4a$SD1[df.ES_4a$DVtype == DVName & df.ES_4a$ExpID == expName & df.ES_4a$Effect == effectName] 
      M2  <- mean(dataCond2$Value) -> df.ES_4a$M2[df.ES_4a$DVtype == DVName & df.ES_4a$ExpID == expName & df.ES_4a$Effect == effectName]
      SD2 <- sd(dataCond2$Value)   -> df.ES_4a$SD2[df.ES_4a$DVtype == DVName & df.ES_4a$ExpID == expName & df.ES_4a$Effect == effectName]
      N   <- length(unique(dataCond2$Subject)) -> df.ES_4a$N[df.ES_4a$DVtype == DVName & df.ES_4a$ExpID == expName & df.ES_4a$Effect == effectName]
      r   <- cor(dataCond1$Value,dataCond2$Value) -> df.ES_4a$r[df.ES_4a$DVtype == DVName & df.ES_4a$ExpID == expName & df.ES_4a$Effect == effectName] 
      tmp2 <- d.sgpp(m.1 = M1, m.2 = M2, sd.1 = SD1, sd.2 = SD2,n = N, r = r)
      df.ES_4a$ES[df.ES_4a$DVtype == DVName & df.ES_4a$ExpID == expName & df.ES_4a$Effect == effectName] <- tmp2[1,1]
      df.ES_4a$ES.var[df.ES_4a$DVtype == DVName & df.ES_4a$ExpID == expName & df.ES_4a$Effect == effectName] <- tmp2[1,2]
    }
  }
}

df.ES_4a <- df.ES_4a %>%
  dplyr::mutate(Identity = ifelse(Effect == "Good_Bad_S" | Effect == "Good_Neut_S" | Effect == "Bad_Neut_S",
                                  "Self-ref.", "Other-ref."),
                EffectType = ifelse(Effect == "Good_Bad_S" | Effect == "Good_Bad_O", "Good_Bad",
                                    ifelse(Effect == "Good_Neut_S" | Effect == "Good_Neut_O", "Good_Neut", "Bad_Neut")),
                Identity = factor(Identity, levels = c("Self-ref.", "Other-ref.")),
                EffectType = factor(EffectType, levels = c("Good_Bad", "Good_Neut", "Bad_Neut")))
```

```{r 'plot-exp4a-effect', fig.cap="Effect size (Cohen's *d*) of Valence in Exp4a.", warning=FALSE, eval=FALSE}
df.ES_4a %>%
  dplyr::filter(EffectType != "Good_Bad") %>%
  ggplot(., aes(x=EffectType, y=ES, color=EffectType, fill=EffectType)) + 
  geom_pointrange(aes(ymin=ES - 1.96*sqrt(ES.var), ymax = ES + 1.96*sqrt(ES.var)), 
                  position = position_dodge(width = 0.5),
                  shape=18, size=0.8) +
  geom_hline(yintercept=0, size=1, color='grey', linetype = 'dashed') +
  # ggtitle('A: Valence effect') +
  coord_cartesian(ylim=c(-1.1, 1.1))+
  scale_color_brewer(palette = "Dark2")+
  scale_fill_brewer(palette = "Dark2")+
  ylab(expression(paste("Effect size: Cohen's ",italic("d"), sep = ' ')))+
  xlab('Contrasts between different valence')+
  apatheme_x +
  facet_grid(DVtype ~ Identity)
```


```{r analyzing exp4b, echo=FALSE, results='hide', warning=FALSE, message=FALSE, eval=FALSE}
#### Approach 1: compared between self and other
effectList_3 <- c('Self_Other_G','Self_Other_N', 'Self_Other_B')

df.ES_4b <- data.frame(matrix(nrow=length(unique(df4b.meta.d$ExpID))*length(effectList_3)*2, ncol=0)) %>%
  dplyr::mutate(DVtype = rep(c('RT', 'dprime'), each = length(unique(df4b.meta.d$ExpID))*length(effectList_3)),
                ExpID  = rep(rep(unique(df4b.meta.d$ExpID), each = length(effectList_3)), 2),
                Effect = rep(effectList_3, length(unique(df4b.meta.d$ExpID))*2),
                M1 = NA, SD1 = NA, M2 = NA, SD2 = NA, N = NA, r = NA, ES = NA, ES.var = NA)

for (DVName in c('RT','dprime')){
  if (DVName == 'RT'){
    metaData <- df4b.meta.rt %>% dplyr::filter(Matchness == "Match") %>% dplyr::rename(Value = RT)
  } else{
    metaData <- df4b.meta.d %>% dplyr::rename(Value = dprime)
  }
  for (expName in unique(metaData$ExpID)){
    for (effectName in effectList_3){
      tmpdata <- metaData %>% dplyr::filter(ExpID == expName & Domain == 'Morality')

      if (effectName == 'Self_Other_G'){

        if (!all(is.na(tmpdata$Identity))){
          #print(paste('processing Good_Bad_S of ', expName, sep = ''))
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good" & Identity == 'Self')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Good" & Identity == 'Other')
          }
        else{
            #print(paste('Skip Good_Bad_S of ', expName, sep = ''))
          next
          }
        }
      else if (effectName == 'Self_Other_N'){
        if (!all(is.na(tmpdata$Identity)) & 'Neutral' %in% tmpdata$Valence ){
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Neutral" & Identity == 'Self')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Neutral" & Identity == 'Other')
          }
        else{
          next
          }
        }
      else if (effectName == 'Self_Other_B'){
        if (!all(is.na(tmpdata$Identity)) & 'Bad' %in% tmpdata$Valence ){
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Bad" & Identity == 'Self')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Bad" & Identity == 'Other')
          }
        else{
          next
          }
        }

      M1  <- mean(dataCond1$Value) -> df.ES_4b$M1[df.ES_4b$DVtype == DVName & df.ES_4b$ExpID == expName & df.ES_4b$Effect == effectName]
      SD1 <- sd(dataCond1$Value)   -> df.ES_4b$SD1[df.ES_4b$DVtype == DVName & df.ES_4b$ExpID == expName & df.ES_4b$Effect == effectName]
      M2  <- mean(dataCond2$Value) -> df.ES_4b$M2[df.ES_4b$DVtype == DVName & df.ES_4b$ExpID == expName & df.ES_4b$Effect == effectName]
      SD2 <- sd(dataCond2$Value)   -> df.ES_4b$SD2[df.ES_4b$DVtype == DVName & df.ES_4b$ExpID == expName & df.ES_4b$Effect == effectName]
      N   <- length(unique(dataCond2$Subject)) -> df.ES_4b$N[df.ES_4b$DVtype == DVName & df.ES_4b$ExpID == expName & df.ES_4b$Effect == effectName]
      r   <- cor(dataCond1$Value,dataCond2$Value) -> df.ES_4b$r[df.ES_4b$DVtype == DVName & df.ES_4b$ExpID == expName & df.ES_4b$Effect == effectName]
      tmp2 <- d.sgpp(m.1 = M1, m.2 = M2, sd.1 = SD1, sd.2 = SD2,n = N, r = r)
      df.ES_4b$ES[df.ES_4b$DVtype == DVName & df.ES_4b$ExpID == expName & df.ES_4b$Effect == effectName] <- tmp2[1,1]
      df.ES_4b$ES.var[df.ES_4b$DVtype == DVName & df.ES_4b$ExpID == expName & df.ES_4b$Effect == effectName] <- tmp2[1,2]
    }
  }
}

df.ES_4b <- df.ES_4b %>%
  dplyr::mutate(Val = ifelse(Effect == "Self_Other_G", "Good",
                                  ifelse(Effect == "Self_Other_N", 'Neutral', 'Bad')),
                EffectType = 'Self_Other',
                Val = factor(Val, levels = c("Good", "Neutral", "Bad")))

#### Approach 2: compared between self and other
# Added the interaction in the effect size calculation directly
df.ES_4b_2 <- data.frame(matrix(nrow= (length(unique(df4b.meta.d$ExpID))*length(effectList_2) +3)*2 , ncol=0)) %>%
  dplyr::mutate(DVtype = rep(c('RT', 'dprime'), each = length(unique(df4b.meta.d$ExpID))*length(effectList_2) + 3),
                ExpID  = rep(rep(unique(df4b.meta.d$ExpID), each = length(effectList_2) + 3), 2),
                Effect = rep(c(effectList_2, c('Good_Bad_SO', 'Good_Neut_SO', 'Bad_Neut_SO')), length(unique(df4b.meta.d$ExpID))*2),
                M1 = NA, SD1 = NA, M2 = NA, SD2 = NA, N = NA, r = NA, ES = NA, ES.var = NA)

for (DVName in c('RT','dprime')){
  if (DVName == 'RT'){
    metaData <- df4b.meta.rt %>% dplyr::filter(Matchness == "Match") %>% dplyr::rename(Value = RT)
  } else{
    metaData <- df4b.meta.d %>% dplyr::rename(Value = dprime)
  }

  for (expName in unique(metaData$ExpID)){
    for (effectName in c(effectList_2, c('Good_Bad_SO', 'Good_Neut_SO', 'Bad_Neut_SO'))){
      tmpdata <- metaData %>% dplyr::filter(ExpID == expName & Domain == 'Morality')

      if (effectName == 'Good_Bad_S'){

        if (!all(is.na(tmpdata$Identity))){
          #print(paste('processing Good_Bad_S of ', expName, sep = ''))
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good" & Identity == 'Self')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Bad" & Identity == 'Self')
          }
        else{
            #print(paste('Skip Good_Bad_S of ', expName, sep = ''))
          next
          }
        }
      else if (effectName == 'Good_Neut_S'){
        if (!all(is.na(tmpdata$Identity)) & 'Neutral' %in% tmpdata$Valence ){
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good" & Identity == 'Self')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Neutral" & Identity == 'Self')
          }
        else{
          next
          }
        }
      else if (effectName == 'Bad_Neut_S'){
        if (!all(is.na(tmpdata$Identity)) & 'Neutral' %in% tmpdata$Valence ){
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Bad" & Identity == 'Self')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Neutral" & Identity == 'Self')
          }
        else{
          next
          }
        }
      else if (effectName == 'Good_Bad_O'){
        if (!all(is.na(tmpdata$Identity))){
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good" & Identity == 'Other')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Bad" & Identity == 'Other')
          }
        else{
          next
          }
        }
      else if (effectName == 'Good_Neut_O'){
        if (!all(is.na(tmpdata$Identity)) & 'Neutral' %in% tmpdata$Valence )
          {
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good" & Identity == 'Other')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Neutral" & Identity == 'Other')
          }
        else{
          next
          }
        }
      else if (effectName == 'Bad_Neut_O'){
        if (!all(is.na(tmpdata$Identity)) & 'Neutral' %in% tmpdata$Valence){
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Bad" & Identity == 'Other')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Neutral" & Identity == 'Other')
          }
        else{
          next
          }
      }
      else if (effectName == 'Good_Bad_SO'){
        if (!all(is.na(tmpdata$Identity))){
          dataCond01 <- tmpdata %>% dplyr::filter(Valence == "Good" & Identity == 'Self')
          dataCond02 <- tmpdata %>% dplyr::filter(Valence == "Bad" & Identity == 'Self')
          dataCond03 <- tmpdata %>% dplyr::filter(Valence == "Good" & Identity == 'Other')
          dataCond04 <- tmpdata %>% dplyr::filter(Valence == "Bad" & Identity == 'Other') 
          
          dataCond1 <- dataCond01 %>% dplyr::mutate(Value = Value - dataCond02$Value)  # good-self - bad-self 
          dataCond2 <- dataCond03 %>% dplyr::mutate(Value = Value - dataCond04$Value)   # good-other - bad-other
          }
        else{
          next
          }
        }
      else if (effectName == 'Good_Neut_SO'){
        if (!all(is.na(tmpdata$Identity)) & 'Neutral' %in% tmpdata$Valence )
          {
          dataCond01 <- tmpdata %>% dplyr::filter(Valence == "Good" & Identity == 'Self') 
          dataCond02 <- tmpdata %>% dplyr::filter(Valence == "Neutral" & Identity == 'Self')
          dataCond03 <- tmpdata %>% dplyr::filter(Valence == "Good" & Identity == 'Other')
          dataCond04 <- tmpdata %>% dplyr::filter(Valence == "Neutral" & Identity == 'Other')
          
          dataCond1 <- dataCond01 %>% dplyr::mutate(Value = Value - dataCond02$Value)   # good-self - neutral-self 
          dataCond2 <- dataCond03 %>% dplyr::mutate(Value = Value - dataCond04$Value)   # good-other - neutral-other
          }
        else{
          next
          }
        }
      else if (effectName == 'Bad_Neut_SO'){
        if (!all(is.na(tmpdata$Identity)) & 'Neutral' %in% tmpdata$Valence){
          dataCond01 <- tmpdata %>% dplyr::filter(Valence == "Bad" & Identity == 'Self')
          dataCond02 <- tmpdata %>% dplyr::filter(Valence == "Neutral" & Identity == 'Self')
          dataCond03 <- tmpdata %>% dplyr::filter(Valence == "Bad" & Identity == 'Other')
          dataCond04 <- tmpdata %>% dplyr::filter(Valence == "Neutral" & Identity == 'Other')
          
          dataCond1 <- dataCond01 %>% dplyr::mutate(Value = Value - dataCond02$Value) # bad-self - neutral-self
          dataCond2 <- dataCond03 %>% dplyr::mutate(Value = Value - dataCond04$Value) # bad-other - neutral-other
          }
        else{
          next
          }
      }
      M1  <- mean(dataCond1$Value) -> df.ES_4b_2$M1[df.ES_4b_2$DVtype == DVName & df.ES_4b_2$ExpID == expName & df.ES_4b_2$Effect == effectName]
      SD1 <- sd(dataCond1$Value)   -> df.ES_4b_2$SD1[df.ES_4b_2$DVtype == DVName & df.ES_4b_2$ExpID == expName & df.ES_4b_2$Effect == effectName]
      M2  <- mean(dataCond2$Value) -> df.ES_4b_2$M2[df.ES_4b_2$DVtype == DVName & df.ES_4b_2$ExpID == expName & df.ES_4b_2$Effect == effectName]
      SD2 <- sd(dataCond2$Value)   -> df.ES_4b_2$SD2[df.ES_4b_2$DVtype == DVName & df.ES_4b_2$ExpID == expName & df.ES_4b_2$Effect == effectName]
      N   <- length(unique(dataCond2$Subject)) -> df.ES_4b_2$N[df.ES_4b_2$DVtype == DVName & df.ES_4b_2$ExpID == expName & df.ES_4b_2$Effect == effectName]
      r   <- cor(dataCond1$Value,dataCond2$Value) -> df.ES_4b_2$r[df.ES_4b_2$DVtype == DVName & df.ES_4b_2$ExpID == expName & df.ES_4b_2$Effect == effectName]
      tmp2 <- d.sgpp(m.1 = M1, m.2 = M2, sd.1 = SD1, sd.2 = SD2,n = N, r = r)
      df.ES_4b_2$ES[df.ES_4b_2$DVtype == DVName & df.ES_4b_2$ExpID == expName & df.ES_4b_2$Effect == effectName] <- tmp2[1,1]
      df.ES_4b_2$ES.var[df.ES_4b_2$DVtype == DVName & df.ES_4b_2$ExpID == expName & df.ES_4b_2$Effect == effectName] <- tmp2[1,2]
    }
  }
}

df.ES_4b_2 <- df.ES_4b_2 %>%
  dplyr::mutate(Identity = ifelse(Effect == "Good_Bad_S" | Effect == "Good_Neut_S" | Effect == "Bad_Neut_S",
                                  "Self-ref.", 
                                  ifelse(Effect == "Good_Bad_O" | Effect == "Good_Neut_O" | Effect == "Bad_Neut_O", 
                                         "Other-ref.", 'Interaction')),
                EffectType = ifelse(Effect == "Good_Bad_S" | Effect == "Good_Bad_O"  | Effect == "Good_Bad_SO", "Good_Bad",
                                    ifelse(Effect == "Good_Neut_S" | Effect == "Good_Neut_O"  | Effect == "Good_Neut_SO", "Good_Neut", "Bad_Neut")),
                Identity = factor(Identity, levels = c("Self-ref.", "Other-ref.", 'Interaction')),
                EffectType = factor(EffectType, levels = c("Good_Bad", "Good_Neut", "Bad_Neut")))
```

```{r 'plot-exp4b-effect-1', fig.cap="Effect size (Cohen's *d*) of Valence in Exp4b.", warning=FALSE, eval=FALSE}
df.ES_4b %>%
  #dplyr::filter(Identity == "Self") %>%
  ggplot(., aes(x=EffectType, y=ES, color=Val, fill=Val)) + # , color=Val, fill=Val
  geom_pointrange(aes(ymin=ES - 1.96*sqrt(ES.var), ymax = ES + 1.96*sqrt(ES.var)),
                  position = position_dodge(width = 0.5),
                  shape=18, size=0.8) +
  geom_hline(yintercept=0, size=0.5, color='grey', linetype = 'dashed') +
  # ggtitle('Self-reference effect') +
  coord_cartesian(ylim=c(-1.1, 1.1))+
  scale_color_brewer(palette = "Dark2")+
  scale_fill_brewer(palette = "Dark2")+
  ylab(expression(paste("Cohen's ",italic("d"), sep = ' '))) +
  xlab('Self-reference effect') + 
  apatheme_x +
  facet_grid(DVtype ~ .)
```

```{r 'plot-exp4b-effect-2', fig.cap="Effect size (Cohen's *d*) of Valence in Exp4b.", warning=FALSE, eval=FALSE}
df.ES_4b_2 %>%
  dplyr::filter(Effect %in% effectList_2) %>%
  dplyr::filter(EffectType != "Good_Bad") %>%
  ggplot(., aes(x=EffectType, y=ES, color=EffectType, fill=EffectType)) +
  geom_pointrange(aes(ymin=ES - 1.96*sqrt(ES.var), ymax = ES + 1.96*sqrt(ES.var)),
                  position = position_dodge(width = 0.5),
                  shape=18, size=1) +
  geom_hline(yintercept=0, size=1, color='grey', linetype = 'dashed') +
  # ggtitle('A: Valence effect') +
  coord_cartesian(ylim=c(-1.1, 1.1))+
  scale_color_brewer(palette = "Dark2")+
  scale_fill_brewer(palette = "Dark2")+
  ylab(expression(paste("Effect size: Cohen's ",italic("d"), sep = ' ')))+
  xlab('Valence effect')+
  apatheme_x +
  facet_grid(DVtype ~ Identity)
```

```{r 'plot-exp4b-diff-diff', fig.cap="Effect size (Cohen's *d*) of Valence in Exp4b.", warning=FALSE, eval=FALSE}
df.ES_4b_2 %>%
  #dplyr::filter(Effect %in% c('Good_Bad_SO', 'Good_Neut_SO', 'Bad_Neut_SO')) %>%
  dplyr::filter(Effect %in% c('Good_Neut_SO', 'Bad_Neut_SO')) %>%
  ggplot(., aes(x=EffectType, y=ES, color=EffectType, fill=EffectType)) + 
  geom_pointrange(aes(ymin=ES - 1.96*sqrt(ES.var), ymax = ES + 1.96*sqrt(ES.var)), 
                  position = position_dodge(width = 0.5),
                  shape=18, size=0.8) +
  geom_hline(yintercept=0, size=0.5, color='grey', linetype = 'dashed') +
  # ggtitle('Differences in valence effect (self-other)') +
  coord_cartesian(ylim=c(-1.1, 1.1))+
  scale_color_brewer(palette = "Dark2")+
  scale_fill_brewer(palette = "Dark2")+
  ylab(expression(paste("Effect size: Cohen's ",italic("d"), sep = ' ')))+
  xlab('Diff of valence effect between self vs. other condition')+
  apatheme_x +
  facet_grid(DVtype ~ .)
  # facet_wrap(~ DVtype, strip.position="right")
```

For experiment 4b, when valence was the target and the identity was task-irrelevant, we found a strong valence effect (see supplementary results and Figure \@ref(fig:plot-exp4b-effect-1), Figure \@ref(fig:plot-exp4b-effect-2)). 

## Self-reported personal distance

```{r personal distance, echo=FALSE, results='hide', warning=FALSE, message=FALSE, eval=FALSE}
# prepare questionnaire data
df.scales <- read.csv(here::here("Scale_data", "FADGS_dataset4ID_clean.csv"), header = TRUE, sep = ",",
                 stringsAsFactors=FALSE,na.strings=c("","NA")) %>%
  dplyr::mutate(expID = dplyr::case_when(
                                    (expID == "exp1.0") ~ "Exp1a",
                                    (expID == "exp1.1") ~ "Exp1b",
                                    (expID == "exp3")   ~ "Exp3a",
                                    (expID == "exp3.1") ~ "Exp3b",
                                    (expID == "exp4.1") ~ "Exp4a",
                                    (expID == "exp4.2") ~ "Exp4b",
                                    (expID == "exp5.2") ~ "Exp5",
                                    (expID == "exp6.2") ~ "Exp6b",
                                    (expID == "exp7.1") ~ "Exp7a",
                                    (expID == "exp7r")  ~ "Exp7b",
                                    (expID == "exp6")   ~ "Exp_dpr"))

## get the questionnaire names
# Self-esteem
SlfEstNames <- c("SES1","SES2","SES3","SES4","SES5","SES6","SES7","SES8","SES9","SES10")
SlfEstNames_r <- c("SES1","SES2","SES3_r","SES4","SES5_r","SES6","SES7","SES8","SES9_r","SES10_r")

# moral identity
mrlIdNames <- c("morId_1","morId_2","morId_3","morId_4", "morId_5","morId_6",
                "morId_7","morId_8","morId_9","morId_10","morId_11","morId_12",
                "morId_13","morId_14","morId_15","morId_16")

mrlIdIntNames <- c("morId_1","morId_2","morId_5","morId_8", "morId_10","morId_11",
                   "morId_12","morId_13","morId_14")
mrlIdIntNames_r <- c("morId_1","morId_2","morId_5_r","morId_8", "morId_10","morId_11",
                   "morId_12","morId_13","morId_14")
mrlIdExtNames <- c("morId_3","morId_4", "morId_6", "morId_7", "morId_9",
                   "morId_15", "morId_16")

# moral self images
mrlslfImgNames <- c("morSlfImg_1","morSlfImg_2","morSlfImg_3","morSlfImg_4",
                    "morSlfImg_5","morSlfImg_6","morSlfImg_7","morSlfImg_8","morSlfImg_9")

# personal distance
perDistNames <- c("SelfSelf", 
                  "SelfGood_1", "SelfGood_2", "SelfGood_3", "SelfGood_4",
                  "SelfNeut_1", "SelfNeut_2", "SelfNeut_3", "SelfNeut_4",
                  "SelfBad_1",  "SelfBad_2",  "SelfBad_3",  "SelfBad_4",
                  "SelfStra_1", "SelfStra_2", "SelfStra_3", "SelfStra_4",
                  "GoodNeut_1", "GoodNeut_2", "GoodNeut_3", "GoodNeut_4", 
                  "GoodBad_1",  "GoodBad_2",  "GoodBad_3",  "GoodBad_4",
                  "NeutBad_1",  "NeutBad_2",  "NeutBad_3",  "NeutBad_4")

perDistNames2 <- c("SelfGood_1", "SelfGood_2", "SelfGood_3", "SelfGood_4",
                  "SelfNeut_1", "SelfNeut_2", "SelfNeut_3", "SelfNeut_4",
                  "SelfBad_1",  "SelfBad_2",  "SelfBad_3",  "SelfBad_4",
                  "GoodNeut_1", "GoodNeut_2", "GoodNeut_3", "GoodNeut_4", 
                  "GoodBad_1",  "GoodBad_2",  "GoodBad_3",  "GoodBad_4",
                  "NeutBad_1",  "NeutBad_2",  "NeutBad_3",  "NeutBad_4")

# Normalize the person distance by dividing the maximum value for each data point
df.perdist <- df.scales %>%
  dplyr::select(c(expID, subjID),perDistNames) %>%
  dplyr::mutate(sd_raw = matrixStats::rowSds(as.matrix(.[perDistNames]))) %>%
  dplyr::filter(sd_raw >=10) %>%                                # remove data with small variance
  dplyr::mutate(maxDist = pmax(!!!rlang::syms(perDistNames)))   # find the maximum value of the row

df.perdist[,3:31] <- df.perdist[,3:31]/df.perdist$maxDist       # dividing the maximum

# Get the mean value of each distance
df.perdist <- df.perdist %>%        
    dplyr::mutate(# sumRaw = rowMeans(.[3:31], na.rm = T),
                SelfGood = rowMeans(.[grep("SelfGood", names(.))], na.rm = T),
                SelfNeut = rowMeans(.[grep("SelfNeut", names(.))], na.rm = T),
                SelfBad  = rowMeans(.[grep("SelfBad", names(.))], na.rm = T),
                GoodNeut = rowMeans(.[grep("GoodNeut", names(.))], na.rm = T),
                GoodBad  = rowMeans(.[grep("GoodBad", names(.))], na.rm = T),
                NeutBad  = rowMeans(.[grep("NeutBad", names(.))], na.rm = T)) %>%
    dplyr::select(expID, subjID,
                SelfGood, SelfNeut, SelfBad, GoodNeut, GoodBad, NeutBad) %>%
  tidyr::drop_na()

# calculate the factor score for moral identity, moral self image, self-esteem, and personal distance.

df.scales <- df.scales %>%
  dplyr::mutate(morId_5_r = 0 - morId_5, # reverse the items that need to be reversed.
                SES3_r = 5 - SES3,
                SES5_r = 5 - SES5,
                SES9_r = 5 - SES9,
                SES10_r = 5 - SES10) %>%
  dplyr::mutate(SlfEst_sum = rowSums(.[SlfEstNames_r]),
                mrlIdInt_sum = rowSums(.[mrlIdIntNames_r]),
                mrlIdExt_sum = rowSums(.[mrlIdExtNames]),
                mrlSlfImg_sum = rowSums(.[mrlslfImgNames]))

df.scale.fs <- df.scales %>% dplyr::select(expID, subjID, SlfEst_sum, mrlIdInt_sum, mrlIdExt_sum, mrlSlfImg_sum)

# export data try to model individual predictor using exp1b's data
df1b.scale.fs <- df.scale.fs %>%
  dplyr::filter(expID == 'Exp1b') %>%
  dplyr::full_join(df1b.v, ., by =c ('Subject' = 'subjID' )) %>%
  dplyr::filter(!is.na(RESP)) %>%                       # exclude trials without response or with wrong keys
  dplyr::mutate(RT = RT/1000,
                stim = ifelse(Matchness == "Match", 1, 0), 
                response = ifelse((Matchness == "Match" & ACC ==1) | (Matchness == "Mismatch" & ACC ==0), 1, 0)) %>%
  dplyr::select(Subject, Matchness, Valence, stim, response, RT, SlfEst_sum, mrlIdInt_sum, mrlIdExt_sum, mrlSlfImg_sum) %>%   # select columns
  dplyr::rename(subj_idx = Subject, match = Matchness, val = Valence, rt = RT) %>%  # rename columns
  dplyr::filter(!is.na(mrlIdInt_sum))

write.csv(df1b.scale.fs, file = paste(curDir,'/HDDM/', 'df1bv.hddm_stim.reg.csv', sep = ''), row.names = F)

FS.m.id1 <- 'mrlIdInt =~ morId_1 + morId_2 + morId_5_r + morId_8 + morId_10 + morId_11 + morId_12 + morId_13 + morId_14
             
             mrlIdExt =~ morId_3 + morId_4 + morId_6 + morId_7 + morId_9 + morId_15 + morId_16 '

FS.m.id1.fit <- lavaan::cfa(FS.m.id1, data = df.scales, estimator = "MLR")

idx <- lavInspect(FS.m.id1.fit, "case.idx")
fscores <- lavPredict(FS.m.id1.fit)
for (fs in colnames(fscores)) {
  df.scale.fs[idx, fs] <- fscores[ , fs]
}

FS.m.id2 <- ' morSlfImg =~ morSlfImg_1 + morSlfImg_2 + morSlfImg_3 + morSlfImg_4 + morSlfImg_5 + morSlfImg_6 + morSlfImg_7 + 
                          morSlfImg_8 + morSlfImg_9 '

FS.m.id2.fit <- lavaan::cfa(FS.m.id2, data = df.scales, estimator = "MLR")

idx <- lavInspect(FS.m.id2.fit, "case.idx")
fscores <- lavPredict(FS.m.id2.fit)
for (fs in colnames(fscores)) {
  df.scale.fs[idx, fs] <- fscores[ , fs]
}

FS.m.id3 <- ' SlfEst =~ SES1 + SES2 + SES3_r + SES4 + SES5_r + SES6 + SES7 + SES8 + SES9_r + SES10_r '

FS.m.id3.fit <- lavaan::cfa(FS.m.id3, data = df.scales, estimator = "MLR")

# summary(FS.m.id3.fit, standardize = TRUE, fit.measures=TRUE)
# semPlot::semPaths(FS.m.id3.fit, "std", edge.label.cex = 0.5, curvePivot = TRUE, intercepts = FALSE)

idx <- lavInspect(FS.m.id3.fit, "case.idx")
fscores <- lavPredict(FS.m.id3.fit)
for (fs in colnames(fscores)) {
  df.scale.fs[idx, fs] <- fscores[ , fs]
}

df.scale.fs <- df.scale.fs %>%
  dplyr::left_join(., df.perdist)

```


```{r plot-person-dist, fig.cap="Self-rated personal distance", fig.width=8, warning=FALSE, eval=FALSE}
# Boxplot
p_dist_1 <- df.perdist %>% 
  tidyr::pivot_longer(., cols = SelfGood:NeutBad,
                      names_to = 'PerDist',
                      values_to = 'value') %>%
  dplyr::mutate(PerDist=factor(PerDist, levels = c('SelfNeut', 'SelfGood', 'GoodNeut', 'NeutBad', 'GoodBad', 'SelfBad'))) %>%
  ggplot2::ggplot(.,aes(x=PerDist, y=value)) +
  ggplot2::geom_boxplot() +
  ggplot2::geom_point(position = position_jitter(),size = 1, shape = 20, alpha = 0.15) + 
  scale_fill_brewer(palette = "Dark2") +
    theme_bw() +
    theme(panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          panel.background = element_blank(),
          panel.border = element_blank(),
          text=element_text(family='Times'),
          legend.title=element_blank(),
          legend.text = element_text(size =12),
          plot.title = element_text(lineheight=.8, face="bold", size = 16, margin=margin(0,0,20,0)),
          axis.text = element_text (size = 12, color = 'black'),
          axis.title = element_text (size = 12),
          axis.title.x = element_blank(),
          axis.title.y = element_blank(),
          axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1),
          axis.line.x = element_line(color='black', size = 1),    # increase the size of font
          axis.line.y = element_line(color='black', size = 1),    # increase the size of font
          strip.text = element_text (size = 12, color = 'black'), # size of text in strips, face = "bold"
          panel.spacing = unit(3, "lines")) 

dist.cor <- df.perdist %>%
  dplyr::select(-c(subjID, expID)) %>%
  as.matrix() %>%
  Hmisc::rcorr(., type = 'spearman')

p_dist_2 <- ggcorrplot::ggcorrplot(dist.cor$r, hc.order = TRUE, type = "lower",
     outline.col = "white", colors = c('red', 'white', 'blue'),
     lab = TRUE, p.mat = dist.cor$P) +
  #theme_bw() +
  scale_y_discrete(position='right') +
  theme(panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          panel.background = element_blank(),
          panel.border = element_blank(),
          text=element_text(family='Times'),
          legend.title=element_blank(),
          legend.text = element_text(size =12),
          plot.title = element_text(lineheight=.8, face="bold", size = 16, margin=margin(0,0,20,0)),
          axis.text = element_text (size = 12, color = 'black'),
          axis.title = element_text (size = 12),
          axis.title.x = element_blank(),
          axis.title.y = element_blank(),
          axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1),
          #axis.line.x = element_line(color='black', size = 1),    # increase the size of font
          #axis.line.y = element_line(color='black', size = 1),    # increase the size of font
          strip.text = element_text (size = 12, color = 'black'), # size of text in strips, face = "bold"
          panel.spacing = unit(0, "lines")) 

# correlation bewteen self-reported measures
dist.cor2 <- df.scale.fs %>%
  dplyr::select(mrlIdInt:NeutBad) %>%
  as.matrix() %>%
  Hmisc::rcorr(., type = 'spearman')

p_dist_3 <- ggcorrplot::ggcorrplot(dist.cor2$r, hc.order = TRUE, type = "lower",
     outline.col = "white", colors = c('red', 'white', 'blue'),  insig = "blank",
     lab = TRUE, p.mat = dist.cor2$P) +
  #theme_bw() +
  scale_y_discrete(position='right') +
  theme(panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          panel.background = element_blank(),
          panel.border = element_blank(),
          text=element_text(family='Times'),
          legend.title=element_blank(),
          legend.text = element_text(size =12),
          plot.title = element_text(lineheight=.8, face="bold", size = 16, margin=margin(0,0,20,0)),
          axis.text = element_text (size = 12, color = 'black'),
          axis.title = element_text (size = 12),
          axis.title.x = element_blank(),
          axis.title.y = element_blank(),
          axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1),
          #axis.line.x = element_line(color='black', size = 1),    # increase the size of font
          #axis.line.y = element_line(color='black', size = 1),    # increase the size of font
          strip.text = element_text (size = 12, color = 'black'), # size of text in strips, face = "bold"
          panel.spacing = unit(0, "lines")) 
# 
# corrplot(dist.cor$r, type = "upper", order = "hclust", 
#          tl.col = "black", tl.srt = 45,
#          p.mat = dist.cor$P, sig.level = 0.01, insig = "blank")

# col <- colorRampPalette(c( "red", "white", "blue"))(20)
# p_dist_2 <- heatmap(x = dist.cor$r, col = col, symm = TRUE)
# 
# corrplot(dist.cor$r, type="upper", order="hclust", col=col)
# legend(x="bottomright", legend=c("min", "ave", "max"), 
#      fill=colorRampPalette(c( "red", "white", "blue"))(20))
  
library(patchwork)
p_dist_1 + p_dist_2 + plot_annotation(tag_levels = 'A')  + plot_layout(nrow = 1, byrow = FALSE)

```

See Figure \@ref(fig:plot-person-dist).

## Correlation analyses
The reliability of questionnaires can be found in [@Liu_2020_JOPD]. We calculated the correlation between the data from behavioral task and the questionnaire data. First, we calculated the score for each scale based on their structure and factor loading, instead of sum score [@mcneish_thinking_2020]. Then, we used SEM to estimate the correlation because it can include measurement model and statistical model in a unified framework. 

To make sure that what we found were not false positive, we used two method to ensure the robustness of our analysis. first, we split the data into two half: the data with self and without, then, we used the conditional random forest to find the robust correlation in the exploratory data (with self reference) that can be replicated in the confirmatory data (without the self reference). The robust correlation were then analyzed using SEM


```{r correlation analysis, echo=FALSE, results='hide', warning=FALSE, message=FALSE, eval=FALSE}
### failed attempt:
# We tried to first correlate the DDM parameters and the questionnaire separately for self-referential and other-referential, and then validation the correlation using data of experiment without self/other-referential. But the sample size for the correlation between questionnaires and behavioral results from experiment without identity are too small n = 16. Therefore, we give up this exploration-validation approach.

# Step 1: Get the parameter values
params.list <- list.files(here::here('HDDM'), pattern = '*_hddm_params.csv')

df_hddm_ls_1 <- params.list[c(1:4, 9:10)]
df_hddm_ls_2 <- params.list[c(5, 6, 11:13)]

for (indx in 1:6){
  if ((indx ==1) && exists('df_hddm_param_1')){   # if the variable already exist before the for loop start
    rm(df_hddm_param_1)
  }
  if (indx == 5 ){
    hddm_params_tmp <- read.csv(here::here("HDDM", df_hddm_ls_1[indx]), header = TRUE, sep = ",",
                   stringsAsFactors=FALSE,na.strings=c("","NA")) %>%
      dplyr::filter(domain == "Morality") %>%
      dplyr::rename(Subject = subj_idx, Matchness = match, Valence = val) %>%
      dplyr::select(Subject, Matchness, Valence, knode_name, mean) %>%
      tidyr::drop_na() %>%
      tidyr::separate(knode_name, into = paste('v', 1:2, sep= '')) %>%
      dplyr::rename(param = v1)  %>% dplyr::filter(Matchness=='Match') %>% dplyr::select(- c(v2, Matchness)) %>%
      tidyr::pivot_wider(., names_from = c('Valence', 'param'), values_from = 'mean')  
    
  } else {
    hddm_params_tmp <- read.csv(here::here("HDDM", df_hddm_ls_1[indx]), header = TRUE, sep = ",",
                   stringsAsFactors=FALSE,na.strings=c("","NA")) %>%
      dplyr::rename(Subject = subj_idx, Matchness = match, Valence = val) %>%
      dplyr::select(Subject, Matchness, Valence, knode_name, mean) %>%
      tidyr::drop_na() %>%
      tidyr::separate(knode_name, into = paste('v', 1:2, sep= '')) %>%
      dplyr::rename(param = v1)  %>% dplyr::filter(Matchness=='Match') %>% dplyr::select(- c(v2, Matchness)) %>%
      tidyr::pivot_wider(., names_from = c('Valence', 'param'), values_from = 'mean')   # %>%
      #dplyr::mutate(ExpID = 'Exp1a')
  }
  if (exists('df_hddm_param_1')) {
    df_hddm_param_1 <- rbind(df_hddm_param_1, hddm_params_tmp) 
  } else {
    df_hddm_param_1 <- hddm_params_tmp
  }
}

for (indx in 1:5){
  if ((indx ==1) && exists('df_hddm_param_2')){   # in case the variable exist in the env.
    rm(df_hddm_param_2)
  }
  hddm_params_tmp <- read.csv(paste(here::here("HDDM", df_hddm_ls_2[indx])), header = TRUE, sep = ",",
                 stringsAsFactors=FALSE,na.strings=c("","NA")) %>%
    dplyr::rename(Subject = subj_idx, Matchness = match, Valence = val, Identity = id) %>%
    dplyr::select(Subject, Matchness, Identity, Valence, knode_name, mean) %>%
    tidyr::drop_na() %>%
    tidyr::separate(knode_name, into = paste('v', 1:2, sep= '')) %>%
    dplyr::rename(param = v1)  %>% 
    dplyr::filter(Matchness=='Match') %>% 
    dplyr::select(- c(v2, Matchness)) %>%
    tidyr::unite(conds, c(Valence, param)) %>%
    #tidyr::unite(conds, c(Identity, Valence, param)) %>%
    tidyr::pivot_wider(., names_from = c('conds'), values_from = 'mean')   # %>%
    #dplyr::mutate(ExpID = 'Exp1a')
  if (indx == 4 | indx == 5){
    hddm_params_tmp <- hddm_params_tmp %>%
      dplyr::mutate(Neutral_v = NA,
                    Neutral_a = NA,
                    #Other_Neutral_v = NA,
                    #Other_Neutral_a = NA,
                    #Other_Neutral_t = NA,
                    Neutral_t = NA) # %>%
      #dplyr::select(Subject, Identity, Bad_a, Good_a, Neutral_a, Bad_v, Good_v, Neutral_v, Bad_t, Good_t,
      #              Neutral_t)
  }
  
  if (exists('df_hddm_param_2')) {
    df_hddm_param_2 <- rbind(df_hddm_param_2, hddm_params_tmp) 
  } else {
    df_hddm_param_2 <- hddm_params_tmp
  }
}

df_hddm_param_1 <- df_hddm_param_1 %>%
  dplyr::mutate(Identity = NA) %>%
  dplyr::select(colnames(df_hddm_param_2))

df_hddm_param_all <- df_hddm_param_2 %>%
  dplyr::filter(Identity == "Self") %>%
  rbind(df_hddm_param_1, .)

# intersection between participant from behavioral task and scales and get the data
subj.common <- intersect(df.scale.fs$subjID, unique(df_hddm_param_all$Subject))  # 260

df.q_scores.v <- df.scale.fs %>% dplyr::filter(subjID %in% subj.common) %>%
  dplyr::select_if(~sum(!is.na(.)) > 0) # remove columns that only have NA.

# temp data for SEM
# tmp <- merge(df.scales.v, df_hddm_param_all, by.x = 'subjID', by.y = 'Subject')

## calculate correlation ----
df.corr <- merge(df.q_scores.v, df_hddm_param_all, by.x = 'subjID', by.y = 'Subject') %>%
  dplyr::select(-c(expID, Identity)) %>%
  dplyr::select(-contains('_sum')) # %>%
  
# library(corrr)
res.cor_all <-df.corr %>%
  dplyr::select(-c(subjID)) %>%
  as.matrix() %>%
  Hmisc::rcorr(., type = 'spearman')

#heatmap(x = res.cor_all$r, col = col, symm = TRUE)

p.mat <- res.cor_all$P %>%
  tidyr::replace_na(1)

# plat the corr matrix
#ggcorrplot::ggcorrplot(res.cor_all$r, hc.order = TRUE, p.mat = p.mat, insig = "blank", # type = "lower",
#                       outline.col = "black", colors = c('red', 'white', 'blue'), lab = T)

#res.cor_all <-df.corr %>%
#  dplyr::select(-c(subjID)) %>%
#  correlation::correlation(., method="spearman", p_adjust = "holm")

param1_names <- colnames(df.scale.fs)[7:length(df.scale.fs)]
param2_names <- colnames(df_hddm_param_all[3:11])

cor_pairs_all <- data.frame(matrix(ncol = 4, nrow = 0))
x <- c("Parameter1", "Parameter2", "r", 'p')
colnames(cor_pairs_all) <- x
i = 0
for (param1 in param1_names) {
  # print(param1)
  for (param2 in param2_names) {
    tmp_r <- res.cor_all$r[param1, param2]
    tmp_p <- res.cor_all$P[param1, param2]
    if (tmp_p <= 0.05) {
      i = i + 1
      cor_pairs_all[i, "Parameter1"] <- param1
      cor_pairs_all[i, "Parameter2"] <- param2
      cor_pairs_all[i, "r"] <- tmp_r
      cor_pairs_all[i, "p"] <- tmp_p
    }
  }
}

```

Instead of use the exploratory correlation analysis, we used a more principled way to explore the correlation between parameter of HDDM (*v*, *t*, and *a*) and scale scores and person distance. 

```{r get plots of correlation, echo=FALSE, results='hide', warning=FALSE, message=FALSE, eval=FALSE}
# Permutation
set.seed(12345)
permutation <- function(df) {
  v1 <- df[, 1] %>% base::sample(.)
  v2 <- df[, 2] %>% base::sample(.)
  tmp_cor <- cor(v1, v2, method = "pearson")
  tmp_cor
}

# plot for all
boot_plot_list <- list()
corr_plot_list <- list()
for (row_id in 1:nrow(cor_pairs_all)){
  
  # select variables
  var1 <- df.corr %>% dplyr::select(cor_pairs_all$Parameter1[row_id])
  var2 <- df.corr %>% dplyr::select(cor_pairs_all$Parameter2[row_id])
  var_tmp <- data.frame(var1, var2) %>%
    tidyr::drop_na()
  
  # boot
  boot_var <- var_tmp %>%
    bootES::bootES(., R = 5000, effect.type = 'r')
  
  cor_pairs_all$BootES_cor[row_id] <- boot_var$t0[1]
  cor_pairs_all$BootES_lb[row_id] <- boot_var$bounds[[1]]
  cor_pairs_all$BootES_ub[row_id] <- boot_var$bounds[[2]]
  
  # permutation
  per_cor <- rep(NA, 5000)
  for (i in 1:length(per_cor)){
    per_cor[i] <- permutation(var_tmp)
  }
  
  # plot scatter plot
  corr_plot_list[[row_id]] <- data.frame(var1, var2) %>%
    ggplot(., aes_string(x = cor_pairs_all$Parameter1[row_id], y = cor_pairs_all$Parameter2[row_id])) + 
    geom_point() + 
    geom_smooth(method=lm) +
    labs(title=paste(cor_pairs_all$Parameter1[row_id], '&', cor_pairs_all$Parameter2[row_id], sep = ' '), 
       x = cor_pairs_all$Parameter1[row_id], 
       y = cor_pairs_all$Parameter2[row_id]) +
    apatheme_s
  
  # plot permutation and boot 
  boot_cor <- boot_var$t %>%
    as.data.frame(.) %>%
    dplyr::arrange(V1) %>%
    dplyr::rename(corcoef = V1) %>%
    dplyr::mutate(Method = 'bootstrap')
    # dplyr::pull(V1)
  per_cor <- data.frame(per_cor) %>%
    dplyr::rename(corcoef = per_cor) %>%
    dplyr::mutate(Method = 'permutation')
  
  probs <- c(0.025, 0.975)
  quantiles <- quantile(per_cor$corcoef, prob=probs)
  
  # p_dist_df <- rbind(boot_cor, per_cor)
  
  xd <- data.frame(density(per_cor$corcoef)[c("x", "y")]) %>% dplyr::mutate(Method = 'permutation')
  yd <- data.frame(density(boot_cor$corcoef)[c("x", "y")]) %>% dplyr::mutate(Method = 'bootstrap')
  zd <- rbind(xd, yd)
  
  label_r <- paste("r = ", round(cor_pairs_all$r[row_id], 3), sep = '')
  
  boot_plot_list[[row_id]] <- ggplot(zd, aes(x, y, group=Method, colour = Method)) + 
      geom_area(data = subset(xd, x > quantiles[1] & x < quantiles[2]), fill = "grey") + # plot the 95 % area of zero
      geom_line() + 
      geom_vline(xintercept = cor_pairs_all$r[row_id], colour = 'blue') +
      geom_vline(xintercept = quantiles[1], colour = 'grey', linetype="dashed") + 
      geom_vline(xintercept = quantiles[2], colour = 'grey', linetype="dashed") + 
      geom_vline(xintercept = 0, colour = 'grey', linetype="dashed") + 
      # geom_text(aes(x = cor_pairs_all$r[row_id]*2, y = 6, label = label_r), colour = 'blue') +
      scale_color_grey() +
      apatheme_s
}

```
We didn't find the correlation between scale scores and the parameters of HDDM, but found weak correlation between personal distance and the parameter estimated from Good and neutral conditions. 

First, boundary separation (*a*) of moral good condition was correlated with both Self-Bad distance ($r = 0.198$, 95% CI [], $p = 0.0063$) and Neutral-Bad distance ($r = 0.1571$, 95% CI [], $p = 0.031$). At the same time, the non-decision time is negatively correlated with Self-Bad distance ($r = 0.169$, 95% CI [], $p = 0.0197$). See Figure \@ref(fig:plot-corr-1).

```{r plot-corr-1, fig.cap="Correlation between moral identity and boundary separation of good condition; moral self-image and drift rate of good condition", fig.width=8, warning=FALSE, eval=FALSE}
library(patchwork)
corr_plot_list[[3]] + corr_plot_list[[6]] + corr_plot_list[[5]]  + 
           boot_plot_list[[3]] + boot_plot_list[[6]] + boot_plot_list[[5]]+ plot_layout(ncol = 3)
```

Second, we found the boundary separation of neutral condition is positively correlated with the personal distance between self and good distance ($r = 0.189$, 95% CI [], $p = 0.036$), but negatively correlated with self-neutral distance($r = -0.183$, 95% CI [], $p = 0.042$). Also, the drift rate of the neutral condition is positively correlated with the Self-Bad distance ($r = 0.177$, 95% CI [], $p = 0.048$).a. See figure \@ref(fig:plot-corr-2)

```{r plot-corr-2, fig.cap="Correlation between personal distance and boundary separation of neutral condition", fig.width=8, warning=FALSE, eval=FALSE}
library(patchwork)
corr_plot_list[[1]] + corr_plot_list[[2]]  + corr_plot_list[[4]] + 
           boot_plot_list[[1]] + boot_plot_list[[2]] + boot_plot_list[[4]] + plot_layout(ncol = 3)
```

We also explored the correlation between behavioral data and questionnaire scores separately for experiments with and without self-referential, however, the sample size is very low for some conditions.

# Discussion

# References
```{r create_r-references, echo=FALSE,results='hide'}
#r_refs(file = "r-references.bib"))
```

\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

<div id = "refs"></div>
\endgroup
