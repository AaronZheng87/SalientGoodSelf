---
title             : "Open notebook of perpecptual salience of positive self"
shorttitle        : "Salient Positive Self"

author: 
  - name          : "Chuan-Peng Hu"
    affiliation   : "1,2"
    corresponding : yes    # Define only one corresponding author
    address       : "55131"
    email         : "hcp4715@email.com"
  - name          : "Jie Sui"
    affiliation   : "3"
  - name          : "Kaiping Peng"
    affiliation   : "1"

affiliation:
  - id            : "1"
    institution   : "Tsinghua University, 100084 Beijing, China"
  - id            : "2"
    institution   : "German Resilience Center, 55131 Mainz, Germany"
  - id            : "3"
    institution   : "University of Bath, Bath, UK"

authornote: |
  Add complete departmental affiliations for each author here. Each new line herein must be indented, like this line.

  Enter author note here.

abstract: |
  One or two sentences providing a **basic introduction** to the field,  comprehensible to a scientist in any discipline.
  
  Two to three sentences of **more detailed background**, comprehensible  to scientists in related disciplines.
  
  One sentence clearly stating the **general problem** being addressed by  this particular study.
  
  One sentence summarizing the main result (with the words "**here we show**" or their equivalent).
  
  Two or three sentences explaining what the **main result** reveals in direct comparison to what was thought to be the case previously, or how the  main result adds to previous knowledge.
  
  One or two sentences to put the results into a more **general context**.
  
  Two or three sentences to provide a **broader perspective**, readily comprehensible to a scientist in any discipline.
  
  <!-- https://tinyurl.com/ybremelq -->
  
keywords          : "Perceptual decision-making, Self"
wordcount         : "X"

bibliography      : ["r-references.bib"]

floatsintext      : no
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : yes
mask              : no
draft             : no

documentclass     : "apa6"
classoption       : "man"
output            : 
  papaja::apa6_pdf:
#    latex_engine  : xelatex

---

```{r setup, include = FALSE}
#library("papaja")
source('Initial.r')

# using afex and emmeans to do the ANOVA and emmeans for post-hoc comparison
afex_options(emmeans_model = "multivariate")
```

```{r, include=FALSE}
options(tinytex.verbose = F) # debug the tex
```

```{r analysis-preferences}
# Seed for random number generation
set.seed(42)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed)
```

# General Methods
## Participants.
The experiments (except experiment 3b) reported in the current study were first conducted between 2014 to 2016 in Tsinghua University, Beijing, participants of these experiments were recruited in Tsinghua University community. To increase the power by adding collecting more data so that each experiment has 50 or more valid data (Simmons, Nelson, & Simonsohn, 2013) , we recruited additional participants in Wenzhou University, Wenzhou, China in 2017. However, duo to the limited time and resources, additional data were not collected for experiment 2, 3, and 4b. 

 <!-- 21-word solution (Simmons, Nelson & Simonsohn, 2012; retrieved from http://ssrn.com/abstract=2160588) -->

## Material and Procedure
In the current study, we used the social associative learning paradigm (Sui, He, & Humphreys, 2012), in which participants first learn the associations between geometric shapes and labels of person with different moral valence (e.g., in first three studies, the triangle, square, and circle and good person, neutral person, and bad person, respectively). The associations of the shapes and label were counterbalanced across participants. After learning phase, participants finish a practice phase to familiar with the task, in which they viewed one of the shapes upon the fixation while one of the labels below the fixation and judged whether the shape and the label were matched. When participants can get 60% or higher accuracy at the end of the practicing session, they can start the experimental task which is the same as in the practice phase.

If not noted, E-prime 2.0 was used in all experiments. For participants recruited in Tsinghua University, they finished the experiment individually in a dim-lighted chamber, stimuli were presented on 22-inch CRT monitors, with a chin-rest brace. The visual angle of geometric shapes was about 3.7º × 3.7º, the finxation cross is of (0.8º × 0.8º of visual angle) at the center of the screen. The words were of 3.6º × 1.6º visual angle. The distance between the center of the shape or the word and the fixation cross was 3.5º of visual angle. Participant fixed their head on a chin-fixation, about 60 cm from the screen. 

For participants recruited in Wenzhou University, they finished the experiment in a group consist of 3 ~ 12 participants in a dim-lighted testing room. Participants were required to finished the whole experiment independently. Also, they were instructed to start the experiment at the same time, so that the distraction between participants were minimized. The stimuli were presented on 19-inch CRT monitor. The visual angles are could not be exactly controlled because participants’s chin were not fixed.


## Data analysis
We reported all the measurements, analysis and results in all the experiments in the current study. All data were first pre-processed using R `r cite_r("r-references.bib")`. The clean data were analyzed using JASP (0.8.6.0, www.jasp-stats.org, (Love et al., 2019)). Participants whose overall accuracy lower than 60% were excluded from analysis. Also, the accurate responses with less than 200ms reaction times were excluded from the analysis.

We analyzed accuracy performance using a signal detection approach, as in Sui et al. (2012). The performance in each match condition was combined with that in the nonmatching condition with the same shape to form a measure of d’. Trials without response were coded either as “miss” (matched trials) or “false alarm” (mismatched trials). The d’ were then analyzed using repeated measures analyses of variance (repeated measures ANOVA). 

The reaction times of accurate trials were also analyzed using repeated measures ANOVA. To control the false positive when conducting the post-hoc comparisons, we used Bonferroni correction. Please note that in the first two experiment (experiment 1a and 1b), we included the variable matchness (matched vs. mismatched) in our ANOVA of reaction times and then examine matched trials and mismatched trials separately when the interaction between matchness and other variables are significant. In both experiments, we found significant interaction between matchness and valence. Then, as previous study, we focused on the matched trial for the rest of the experiment (Sui et al., 2012). 

We reported the effect size of repeated measures ANOVA (omega squared) (Bakeman, 2005; Lakens, 2013). Also, we reported Cohen’s d and its 95% confidence intervals for the post-hoc comparisons. To provide more information about the results, we also reported the Bayes Factor using JASP (Hu, Kong, Wagenmakers, Ly, & Peng, 2018; Wagenmakers et al., 2018). The Bayes factor is the ratio of the probability of the current data pattern under alternative hypothesis (H1) and the probability of the current data pattern under null hypothesis (H0), which index the relative evidence for these two hypotheses from the current data. The BF10 represents the evidence for alternative hypothesis (H1) vs. evidence for null hypothesis (H0); in contrast, BF01 represents that evidence for null hypothesis over the evidence for althernative hypothesis. We used the default prior in JASP for all the Bayes Factor analyses, and used Jeffreys (1961)’s convention for the strength of evidence: the BF10 > 3 means there are some evidence for H1 as compared with H0,  BF10 great or equal to 10 means strong evidence for H1.

To assess the individual difference, we explored correlation between self-reported psychological distance and more objective responses bias (i.e., reaction times and d prime). To do this, we first normalized the personal distance by taking the percentage of the mean distance between each two persons in the sum of all 6 distances (self-good, self-normal, self-bad, good-normal, good-bad, normal-bad), and then calculated the bias score (indexed by the differences between good-normal, good-bad). Also, as exploratory analysis, we analyzed the correlation between behavioral response and moral identity, self-esteem, if data are available. As recent study showed that small size leads to unstable correlation estimates (Schönbrodt & Perugini, 2013), we only reported the correlation based on data pooled from all experiments, while the results of each experiment were reported in supplementary results.


# Experiment 1a

```{r loadingData_1a,echo=FALSE,results='hide'}

## record from the meta-data:
# One participant's ID changed from 26 to 261, because of duplication of subject id.
# participant No. 14 finished two sessions of the experiment, only the first session were included in the analysis
# # there are 4 foreign students, we didn't exclude them:
# foreignStdID <- c(24,29,30,33)

# data collected in Tsinghua U
df1a_1 <- read.csv(".\\exp1a\\rawdata_behav_exp1a_2014.csv", header = TRUE,
                   sep = ",", stringsAsFactors=FALSE, na.strings=c("","NA")) %>%
        dplyr::mutate(Site = "THU") 

# data collected in Wenzhou U
df1a_2 <- read.csv(".\\exp1a\\rawdata_behav_exp1a_2017.csv",header = TRUE,
                   sep = ",",stringsAsFactors=FALSE,na.strings=c("","NA")) %>%
        dplyr::mutate(Site = "WZU")

# combine data and clean
df1a   <- rbind(df1a_1,df1a_2) %>%
        dplyr::rename(ACC = Target.ACC,           # rename columns
                      RT  = Target.RT,
                      CRESP = Target.CRESP,
                      BlockNo = BlockList.Sample,
                      TrialNo = SubTrial,
                      RESP = Target.RESP,
                      Matchness = YesNoResp,
                      Valence = Shape) %>%
        dplyr::mutate(Valence = ifelse(Valence == "Normal", "Neutral", Valence),   # recode values
                      Matchness = ifelse(Matchness == "Yes", "Match", "Mismatch"),
                      Age = ifelse(Age == 0, NA, Age),
                      Subject = factor(Subject),
                      Site = factor(Site))  # if the min age is 0, that age is missing

rm(df1a_1,df1a_2)

df1a.T.basic     <- df1a %>%
  dplyr::select(Site, Subject, Age, Sex) %>%
  dplyr::distinct(Subject, .keep_all = TRUE) %>%
  dplyr::summarise(N = length(Subject),
                   N_thu = length(Site[Site == "THU"]),
                   N_wzu = length(Site[Site == "WZU"]),
                   Nf = length(Sex[Sex == "female"]),
                   Nm = length(Sex[Sex == "male"]),
                   Age_mean = round(mean(Age,na.rm=TRUE),2),
                   Age_sd = round(sd(Age,na.rm=TRUE),2))
  
# distinguish between practice and formal data
df1a.subj_P <- df1a %>%
  dplyr::filter(is.na(BlockNo)) %>%
  dplyr::distinct(Subject)

#[is.na(df1a$BlockList.Sample),]            # data from practice
df1a.subj_T <- df1a %>%
  dplyr::filter(complete.cases(BlockNo)) %>%
  dplyr::distinct(Subject)

#[complete.cases(df1a$BlockList.Sample),]   # data from test

# number of participant who didn't finished the experiment
nQuit <- length(df1a.subj_P) - length(df1a.subj_T)

#.T[df1a.T$RT <= 200 & df1a.T$ACC == 1,]
#df1a.excld.trial.r <- nrow(df1a.excld.trial)/nrow(df1a.T) # ratio of excluded trials in all triasl.

df1a.excld.sub <-  df1a %>%
  dplyr::group_by(Subject) %>%
  #dplyr::filter(RT > 200)  %>%                       # only use > 200 ms response (this standard will keep more participants)
  dplyr::mutate(ACC = ifelse(RT <= 200, 0, ACC)) %>%  # set less than 200 ms response as wrong
  dplyr::summarise(N = length(ACC),                   # caculate the overall accuracy for each subject
                   N_crrct = sum(ACC),
                   ACC = sum(ACC)/length(ACC)) %>%
  dplyr::filter(ACC < 0.6) %>%                        # exlucde the participants with less than 60% overall accuracy
  dplyr::select(Subject)


# The rate of excluded trials in valid data
df1a.invalid_trial_rate   <- df1a %>%
  dplyr::filter(complete.cases(BlockNo)) %>%
  dplyr::filter(!(Subject %in% df1a.excld.sub$Subject)) %>%   # exclude the invalid subjects
  dplyr::summarize(rate = length(RT[RT <= 200 & ACC == 1])/length(RT))

df1a.v   <- df1a %>%
  dplyr::filter(complete.cases(BlockNo)) %>%
  dplyr::filter(!(Subject %in% df1a.excld.sub$Subject)) %>%   # exclude the invalid subjects
  dplyr::filter(!(RT <= 200 & ACC == 1))                      # exclude < 200 trials

df1a.v.basic     <- df1a.v %>%
  dplyr::select(Site, Subject, Age, Sex) %>%
  dplyr::distinct(Subject, .keep_all = TRUE) %>%
  dplyr::summarise(N = length(Subject),
                   N_thu = length(Site[Site == "THU"]),
                   N_wzu = length(Site[Site == "WZU"]),
                   Nf = length(Sex[Sex == "female"]),
                   Nm = length(Sex[Sex == "male"]),
                   Age_mean = round(mean(Age,na.rm=TRUE),2),
                   Age_sd = round(sd(Age,na.rm=TRUE),2))

#df1a_dprime_long <- read.csv('.\\exp1a\\exp1a_dprime_long.csv') %>%
#  dplyr::rename(Valence = Morality) %>%
#  dplyr::mutate(Valence = factor(Valence, levels = c("Good", "Neutral", "Bad")))

#df1a_rt_acc_long <- read.csv('.\\exp1a\\exp1a_rt_acc_long.csv') %>%
#  dplyr::rename(Valence = Morality) %>%
#  dplyr::mutate(Valence = factor(Valence, levels = c("Good", "Neutral", "Bad"))) %>%
#  dplyr::rename(Matchness = Match) #%>%
  #dplyr::mutate(Match = ifelse(Match == 'Match', 'match','mismatch'))
```
## Participants
`r df1a.T.basic$N` college students (`r df1a.T.basic$Nf` female, age = `r df1a.T.basic$Age_mean` $\pm$ `r df1a.T.basic$Age_sd` years) participated. `r df1a.T.basic$N_thu` of them were recruited from Tsinghua University community in 2014; `r df1a.T.basic$N_wzu` were recruited from Wenzhou University in 2017. All participants were right-handed except one, and all had normal or corrected-to-normal vision. Informed consent was obtained from all participants prior to the experiment according to procedures approved by the local ethics committees. 6 participant’s data were excluded from analysis because nearly random level of accuracy (4 participants from the Tsinghua sample and 2 from the Wenzhou sample), leaving `r df1a.v.basic$N` participants (`r df1a.v.basic$Nf` female, age = `r df1a.v.basic$Age_mean` $\pm$ `r df1a.v.basic$Age_sd` years).

## Results
### Analaysis of d prime.
We conducted 2 (Idenity: self v. other) by 3 (morlaity: good, neutral, bad) repeated measure ANOVA:
```{r 1a_dprime, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
# calculate d prime

df1a.v.dprime_l <- df1a.v %>%
  dplyr::mutate(sdt = mosaic::derivedFactor("hit" = (ACC ==1 & Matchness == "Match"),     # code as hit
                                    "CR" = (ACC ==1  & Matchness == "Mismatch"),  # code as correct reject
                                    "miss" = (ACC == 0 & Matchness == "Match"),   # code as miss
                                    "FA" = (ACC == 0 & Matchness == "Mismatch"),  # code as false alarm
                                    method ="first",  .default = NA)) %>% 
  dplyr::group_by(Site, Subject, Age, Sex, Valence, sdt) %>%
  dplyr::summarise(N = length(sdt)) %>%                                      # calculate the counts for each 
  dplyr::ungroup() %>%
  tidyr::spread(key = sdt, value = N,fill = 0) %>%                           # long-to-wide format
  dplyr::mutate(hitR = hit/(hit + miss),                                     # hit rate
                FAR  = FA/(FA+CR)) %>%                                       # fa rate
  dplyr::mutate(hitR = ifelse(hitR == 1, 1 - 1/(2*(hit + miss)), hitR),      # if hit rate is 1, standardize it
                FAR  = ifelse(FAR == 0, 1/(2*(hit + miss)), FAR)) %>%        # if FA rate is 0, standardize it
  dplyr::mutate(dprime = qnorm(hitR) - qnorm(FAR)) %>%
  dplyr::select(Site, Subject, Age, Sex, Valence, dprime) %>%                # select relevant columns
  dplyr::mutate(Valence = factor(Valence, levels = c("Good","Neutral","Bad")))

### Long to wide
df1a.v.dprime_w <- df1a.v.dprime_l %>%
  #tidyr::unite(col = "Cond",c("Valence"),sep = "_", remove = T) %>%  # combine two factors to condition
  tidyr::spread(key = Valence, value = dprime) %>%                                   # long to wide
  dplyr::rename_at(vars(-Site,-Subject,-Age,-Sex),function(x) paste0("d_",x))           # add prefix to certain conditions


# anova for d prime with 2*2 design
df1a_dprime_anova <- afex::aov_ez('Subject','dprime',df1a.v.dprime_l,  # using afex's function 
                                  within = c('Valence'))

# use LMM, random intercept for each participant
df1a_d_mixed <- afex::mixed(dprime ~ Valence +(1|Subject), 
                          df1a.v.dprime_l,
                          method = "S",
                          control = lmerControl(optCtrl = list(maxfun = 1e6)))

df1a_dprime_anova_apa <- df1a_dprime_anova$aov %>% papaja::apa_print()
#df4b_dprime_anova <- apa_print(df4b_dprime_anova)
```
We found the effect of Valence (`r df1a_dprime_anova_apa$full$Valence`).

```{r results='asis', echo = F}
#knitr::kable(nice(df4b_dprime_anova), caption = "ANOVA of d prime")
apa_table(df1a_dprime_anova_apa$table
  , caption = "A really beautiful ANOVA table."
  , note = "Note that the column names contain beautiful mathematical copy: This is because the table has variable labels."
)
```

We further examined the effect of valence. 

```{r results='asis', echo = F}
posthoc_1a_d <- emmeans::emmeans(df1a_dprime_anova, "Valence") # compare each valence for both self and other condition
pairs(posthoc_1a_d)
```
The Good condition (2.23 $\pm$ 0.14) is great than Netural condition (2.05 $\pm$ 0.16, t(45) = 1.67, p = 0.226) and bad condition (1.87 $\pm$ 1.4, t(45) = 3.07, p = 0.01, Cohen'd = 0.36). This is no-significant difference between neutral and bad conidition, t(45) = 1.81, p = 1.77.


### Analaysis of reaction time.
We conducted 2 (Matchness: Match v. Mismatch) by 3 (Valence: good, neutral, bad) repeated measure ANOVA:
```{r 1a_RT, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
# anova for d prime with 2*2 design
df1a.v.rt_m <- df1a.v %>%
  dplyr::filter(ACC == 1) %>%
  dplyr::group_by(Site,Subject,Matchness, Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup()
df1a_RT_anova <- afex::aov_ez('Subject','RT_m',df1a.v.rt_m,     # using afex's function 
                                  within = c('Matchness','Valence'))
df1a_RT_anova_apa <- df1a_RT_anova %>% papaja::apa_print()

# use LMM, random intercept for each participant
df1a_RT_mixed <- afex::mixed(RT_m ~ Matchness*Valence + (1|Subject), 
                          df1a.v.rt_m,
                          method = "S",
                          control = lmerControl(optCtrl = list(maxfun = 1e6)))


```
We found the main effect of Matchness (`r df1a_RT_anova_apa$full$Matchness`) and intercation between Matchness and Valence (`r df1a_RT_anova_apa$full$Matchness_Valence`)

We carried out two separate ANOVA for both Match and mismatched trials.

```{r 1a_RT_match, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
# anova for d prime with 2*2 design
df1a_rt_acc_long_m  <- df1a_rt_acc_long %>% dplyr::filter(Matchness == 'Match')
df1a_rt_acc_long_nm <- df1a_rt_acc_long %>% dplyr::filter(Matchness == 'Mismatch')

df1a_RT_anova_m     <- afex::aov_ez('Subject','RT',df1a_rt_acc_long_m,  # using afex's function 
                                  within = c('Valence'))
df1a_RT_anova_m_apa <- df1a_RT_anova_m %>% papaja::apa_print()

df1a_RT_anova_nm <- afex::aov_ez('Subject','RT',df1a_rt_acc_long_nm,  # using afex's function 
                                  within = c('Valence'))
df1a_RT_anova_nm_apa <- df1a_RT_anova_nm %>% papaja::apa_print()

```
For matched trials, we found the effect of valence `r df1a_RT_anova_m_apa$full$Valence`. 

For non-matched trials, there was no significant effect of Valence (`r df1a_RT_anova_nm_apa$full$Valence`).

```{r results='asis', echo = F}
#knitr::kable(nice(df4b_dprime_anova), caption = "ANOVA of d prime")
apa_table(df1a_RT_anova_m_apa$table
  , caption = "A really beautiful ANOVA table."
  , note = "Note that the column names contain beautiful mathematical copy: This is because the table has variable labels."
)
```

We further examined the effect of valence for both self and other for mached trials. 

```{r results='asis', echo = F}
posthoc_1a_rt <- emmeans::emmeans(df1a_RT_anova_m, "Valence") # compare each valence for both self and other condition
pairs(posthoc_1a_rt)
```


# Experiment 4a

In study 1-3 participants made explicit judgements about moral associations. In Experiment 4, we examined whether the effects of moral valence occur even when the moral valence information might not be relevent to the task. In this study participants made perceptual match judgements to associations between self-referential labels and shapes (cf. Sui et al., 2012), but we presented labels of different moral valence levels in the shapes. 

```{r loadingData_4a,echo=FALSE,results='hide'}
df4a_dprime_long <- read.csv('.\\exp4a\\exp4a_dprime_long.csv') %>%
  dplyr::mutate(Morality = ifelse(Morality == "Moral", "Good",
                             ifelse(Morality == "Immoral","Bad", 'Neutral')))

df4a_rt_acc_long <- read.csv('.\\exp4a\\exp4a_rt_acc_long.csv') %>%
  dplyr::mutate(Morality = ifelse(Morality == "Moral", "Good",
                             ifelse(Morality == "Immoral","Bad", "Neutral"))) %>%
  dplyr::rename(Match = Matchness) %>%
  dplyr::mutate(Match = ifelse(Match == 'Match', 'match','mismatch'))
```
## Participants
64 participants (37 female, age = 19.7 $\pm$ 1.22) participated the current study, 32 of them were from Tsinghua Universtiy in 2015, the rest were from Wenzhou University parpticipated in 2017. All participants were right-handed, and all had normalneutral or corrected-to-normalneutral vision. Informed consent was obtained from all participants prior to the experiment according to procedures approved by a local ethics committee. The data of three participants from Tsinghua site and two participants from Wenzhou site were excluded from analysis because their accuracy was close to chance (< 0.6). The results for the remaining 59 participants (33 female, age = 19.78 $\pm$ 1.2) were analyzed and reported.

## Results
### Analaysis of d prime.
We conducted 2 (Idenity: self v. other) by 3 (morlaity: good, neutral, bad) repeated measure ANOVA:
```{r analyzing for d prime_4a, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
# anova for d prime with 2*2 design
df4a_dprime_anova <- afex::aov_ez('Subject','dprime',df4a_dprime_long,  # using afex's function 
                                  within = c('Identity','Morality'))

# use LMM, random intercept for each participant
df4a_d_mixed <- afex::mixed(dprime ~ Identity*Morality +(1|Subject), 
                          df4a_dprime_long,
                          method = "S",
                          control = lmerControl(optCtrl = list(maxfun = 1e6)))

df4a_dprime_anova_apa <- df4a_dprime_anova$aov %>% papaja::apa_print()
#df4b_dprime_anova <- apa_print(df4b_dprime_anova)
```
We found the effect of identity (`r df4a_dprime_anova_apa$full$Identity`) and its interaction with valence (the effect of gender differed by clinic, (`r df4a_dprime_anova_apa$full$Identity_Morality`). But the effect of valence was not found, `r df4a_dprime_anova_apa$full$Morality`.

```{r results='asis', echo = F}
#knitr::kable(nice(df4b_dprime_anova), caption = "ANOVA of d prime")
apa_table(df4a_dprime_anova_apa$table
  , caption = "A really beautiful ANOVA table."
  , note = "Note that the column names contain beautiful mathematical copy: This is because the table has variable labels."
)
```

We further examined the effect of valence for both self and other. 

```{r results='asis', echo = F}
m2 <- emmeans::emmeans(df4a_dprime_anova, "Morality", by = "Identity") # compare each valence for both self and other condition
#pairs(m2)
# summary(as.glht(pairs(m2)), test=adjusted("free"))
m3 <- emmeans(df4a_dprime_anova, "Identity", by = "Morality") # compare self vs. other for each valence condition
#pairs(m3)
```

### Analaysis of reaction time.
We conducted 2 (Matchness: match v. mismatch) by 2 (Idenity: self v. other) by 3 (morlaity: good, neutral, bad) repeated measure ANOVA:
```{r analyzing for RT_4a, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
# anova for d prime with 2*2 design
df4a_RT_anova <- afex::aov_ez('Subject','RT',df4a_rt_acc_long,  # using afex's function 
                                  within = c('Match','Identity','Morality'))
df4a_RT_anova_apa <- df4a_RT_anova %>% papaja::apa_print()

# use LMM, random intercept for each participant
df4a_RT_mixed <- afex::mixed(RT ~ Match*Identity*Morality +(1|Subject), 
                          df4a_rt_acc_long,
                          method = "S",
                          control = lmerControl(optCtrl = list(maxfun = 1e6)))


```
We found the main effect of Matchness (`r df4a_RT_anova_apa$full$Match`) and intercation between Matchness and Identity(`r df4a_RT_anova_apa$full$Match_Identity`)

We carried out two separate ANOVA for both Match and mismatched trials.

```{r analyzing for RT_4a_match, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
# anova for d prime with 2*2 design
df4a_rt_acc_long_m <- df4a_rt_acc_long %>% dplyr::filter(Match == 'match')
df4a_rt_acc_long_nm <- df4a_rt_acc_long %>% dplyr::filter(Match == 'mismatch')
df4a_RT_anova_m <- afex::aov_ez('Subject','RT',df4a_rt_acc_long_m,  # using afex's function 
                                  within = c('Identity','Morality'))
df4a_RT_anova_m_apa <- df4a_RT_anova_m %>% papaja::apa_print()

df4a_RT_anova_nm <- afex::aov_ez('Subject','RT',df4a_rt_acc_long_nm,  # using afex's function 
                                  within = c('Identity','Morality'))
df4a_RT_anova_nm_apa <- df4a_RT_anova_nm %>% papaja::apa_print()

```
For matched trials, we found the effect of identity `r df4a_RT_anova_m_apa$full$Identity`, and the interaction between morality and identity,`r df4a_RT_anova_m_apa$full$Identity_Morality`. However, there is no main effect of valence (`r df4a_RT_anova_m_apa$full$Morality`). 

For non-matched trials, there was no significant effect. Morality (`r df4a_RT_anova_nm_apa$full$Identity`), Identity(`r df4a_RT_anova_nm_apa$full$Morality`), interaction (`r df4a_RT_anova_nm_apa$full$Identity_Morality`).

```{r results='asis', echo = F}
#knitr::kable(nice(df4b_dprime_anova), caption = "ANOVA of d prime")
apa_table(df4a_RT_anova_m_apa$table
  , caption = "A really beautiful ANOVA table."
  , note = "Note that the column names contain beautiful mathematical copy: This is because the table has variable labels."
)
```

We further examined the effect of valence for both self and other for mached trials. 

```{r results='asis', echo = F}
m2 <- emmeans::emmeans(df4a_RT_anova_m, "Morality", by = "Identity") # compare each valence for both self and other condition
pairs(m2)
#summary(as.glht(pairs(m2)), test=adjusted("free"))
m3 <- emmeans(df4a_RT_anova_m, "Identity", by = "Morality") # compare self vs. other for each valence condition
pairs(m3)
```


# Experiment 4b:

```{r loadingData_4b,echo=FALSE,results='hide'}
df4b_dprime_long <- read.csv('.\\exp4b\\exp4b_dprime_long.csv') %>%
  dplyr::mutate(Morality = ifelse(Morality == "Moral", "Good",
                             ifelse(Morality == "Immoral","Bad", 'Neutral')))

df4b_rt_acc_long <- read.csv('.\\exp4b\\exp4b_rt_acc_long.csv') %>%
  dplyr::mutate(Morality = ifelse(Morality == "Moral", "Good",
                             ifelse(Morality == "Immoral","Bad", "Neutral"))) %>%
  dplyr::rename(Match = Matchness) %>%
  dplyr::mutate(Match = ifelse(Match == 'Match', 'match','mismatch'))
```
## Participants

## Results
### Analaysis of d prime.
We conducted 2 (Idenity: self v. other) by 3 (morlaity: good, neutral, bad) repeated measure ANOVA:
```{r analyzing for d prime_e5, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
# anova for d prime with 2*2 design
df4b_dprime_anova <- afex::aov_ez('Subject','dprime',df4b_dprime_long,  # using afex's function 
                                  within = c('Identity','Morality'))
df4b_dprime_anova_apa <- df4b_dprime_anova %>% papaja::apa_print()
#df4b_dprime_anova <- apa_print(df4b_dprime_anova)
```
Morality (`r df4b_dprime_anova_apa$full$Morality`) and Identity gender affected post-surgery quality of life, `r df4b_dprime_anova_apa$full$Identity`. However, the effect of gender differed by clinic, `r df4b_dprime_anova_apa$full$Identity_Morality`.

```{r results='asis', echo = TRUE}
#knitr::kable(nice(df4b_dprime_anova), caption = "ANOVA of d prime")
apa_table(df4b_dprime_anova_apa$table
  , caption = "A really beautiful ANOVA table."
  , note = "Note that the column names contain beautiful mathematical copy: This is because the table has variable labels."
)
```

We further examined the effect of valence for both self and other. 

```{r results='asis', echo = TRUE}
m2 <- emmeans::emmeans(df4b_dprime_anova, "Morality", by = "Identity") # compare each valence for both self and other condition
#pairs(m2)
summary(as.glht(pairs(m2)), test=adjusted("free"))

m3 <- emmeans(df4b_dprime_anova, "Identity", by = "Morality") # compare self vs. other for each valence condition
#pairs(m3)

```

# Results

# Discussion


\newpage

# References
```{r create_r-references}
r_refs(file = "r-references.bib")
```

\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

<div id = "refs"></div>
\endgroup
