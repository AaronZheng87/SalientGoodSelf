---
title             : "The good person is me: Spontaneous self-referential process explains the prioritization of moral character"
shorttitle        : "Priorization of moral character"

author: 
  - name          : "Hu Chuan-Peng"
    affiliation   : "1, 2"
    corresponding : yes    # Define only one corresponding author
    address       : "School of Psychology, Nanjing Normal University, Ninghai Road 122, Gulou District, 210024 Nanjing, China"
    email         : "hcp4715@hotmail.com"
  - name          : "Kaiping Peng"
    affiliation   : "2"
  - name          : "Jie Sui"
    affiliation   : "3"

affiliation:
  - id            : "1"
    institution   : "Nanjing Normal University, 210024 Nanjing, China"
  - id            : "2"
    institution   : "Tsinghua University, 100084 Beijing, China"
  - id            : "3"
    institution   : "University of Aberdeen, Aberdeen, Scotland"

authornote: |
  Hu Chuan-Peng, School of Psychology, Nanjing Normal University, 210024 Nanjing, China.
  Kaiping Peng, Department of Psychology, Tsinghua University, 100084 Beijing, China.
  Jie Sui, School of Psychology, University of Aberdeen, Aberdeen, Scotland.
  Authors contriubtion: HCP, JS, & KP design the study, HCP collected the data, HCP analyzed the data and drafted the manuscript. All authors read and agreed upon the current version of the manuscripts.

abstract: |
 Morality is central to social perception and moral psychology, previous studies found that information related to moral character is prioritized information processing and explained the effect in terms of valence, i.e., either as a negativity or positivity effect. In this study, we report 9 experiments (N = 4XX, trials = XXX) where we find (1) there is a robust good character prioritization effect in perceptual matching task, i.e., when neutral geometric shapes were associated with good character, they were prioritized as compared to shapes associated with neutral or bad characters; (2) the prioritization of good character was robust only when the good character is referred to the self but weak or non-exist when it referred to a non-self label; (3) the binding between good character and self exist even when either the self or the moral character information was task-irrelevant. Together, these results provided evidence for spontaneous self-referential processing as a novel mechanism of the prioritization effect of good character.
  
 <!-- https://tinyurl.com/ybremelq -->
  
keywords          : "Perceptual decision-making, Self positivity bias, moral character"
wordcount         : "X"

bibliography      : 
  - r-references.bib
  - endnote.bib

floatsintext      : no
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : yes
mask              : no
draft             : no
figsintext        : no

documentclass     : "apa6"
classoption       : "man"
output            : 
  papaja::apa6_pdf:
    latex_engine  : xelatex

header-includes:
  - \usepackage{rotating}
  - \DeclareDelayedFloatFlavor{sidewaysfigure}{figure}
---
 <!-- This documents -->
 
```{r setup, include = FALSE}
#rm(list = ls())
source('Initial.r')

curDir = here::here()              # Get the current directory
figDir = here::here('figures')     # directory for figures.

# Seed for random number generation
set.seed(42)
options(tinytex.verbose = T) # debug the tex
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed)
```
 <!-- What is the theoretic meaning of the series study? -->

Alternative title: Self-relevance modulates the priorization of the good character in perceptual matching

# Introduction

 <!--[sentences in bracket are key ideas] -->

[quotes about moral character]

<!-- 
Ideas: 
little value in relying on people's self-reported moral principles or moral ideals to predict their real life behaviors, "paradox of morality" (Ellemers, 2019);
moral associative learning as an stronger predictor??
-->
[Morality is central to social life, moral character is the central of morality] **People experience a substantial amount of moral events in everyday life [e.g., @hofmann_morality_2014] and judging the moral character of people is indispensable part of these events**. Whether we are the agent, target, or a third party of a moral event, we always judge moral behaviors as "right" or "wrong", and by doing so, we judge people as "good" or "bad" [@uhlmann_person-centered_2015]. Moral character is so important in social life that it is a basic dimension in our social evaluation [@goodwin_moral_2014; @goodwin_moral_2015] and that a substantial part of people's conversation are gossiping others' moral character (or, reputation) [e.g., @dunbar_gossip_2004]. These moral character information may help us to evaluate our in-group members and distinguish out-group members [@ellemers_morality_2018]. 

[Two possibilities about moral character]
Given the importance of moral character and limited cognitive resources to process all the information in a social world, will people prioritize information with certain moral character? Focus on the valence of moral character, previous studies explore both negativity effect and positivity effect. The negativity effect, i.e., 'bad' character are prioritized, is consistent with early studies in impression formation which found that negative traits are weighted more in overall impression [@anderson_averaging_1965; @fiske_attention_1980; @skowronski_social_1987]. This idea also seemed to consistent with the more general idea that "bad is stronger than good" [@baumeister_bad_2001; @pratto_automatic_1991]. A few studies provided evidence for this possibility. For example, @anderson_visual_2011 asked participants to associate faces with different behaviors (e.g., negative and neutral behaviors from both social and nonsocial domains) and then perform a binocular rivalry task, where a face and a building were presented to each eye. Participants were required report the content of their visual awareness by pressing buttons. The results revealed that faces associated negative social behaviors dominated participants' visual awareness longer than faces associated with other types of behaviors [but see @stein_no_2017]. Similarly, @eiserbeck_visual_2020 combined  associative learning with attention blink paradigm, where neutral faces were associated with sentences about neutral or negative trust behaviors. They also found that neutral faces associated with negative behavior were processed preferentially. 

The positivity effect, i.e., good moral characters are prioritized, is also plausible [see recent reviews, @pool_attentional_2016; @unkelbach_chapter_2020]. @unkelbach_chapter_2020 pointed out that bad is not necessarily stronger than good in all aspects of information processing. Sometimes, good is stronger than bad. For example, when participants are asked to classify words as good or bad, positive trait words are classified faster than negative words [@bargh_generality_1992]. Similarly, in a lexical decision task, participants judge positive words faster than negative words [@unkelbach_good_2010]. Also, @anisfeld_when_1966 found that positive words are easier to associate with nonsense word-like strings, and this advantage in associative potential also appeared in implicit association test (IAT) [@anselmi_positive_2011]. Direct evidence for positivity effect of moral character also exist: @shore_social_2013 found that faces with positive interaction in a trust game were prioritized in pre-attentive process.

These two possibilities, however, ignore the agency of participants who is perceiving the information and making perceptual decisions. The external stimuli only contain subjective value if they are relevant to the self of the decision-maker []. When it comes to moral character, there are long-history of studies showing that moral character is central for people's self-concept and identity. A positive moral character is viewed as the core feature of identity [e.g., @strohminger_true_2017]. A lot of studies revealed that people distort their perception, memory, and change their actions to maintain a positive view of their moral self-view. Given this strong motivation, it is possible that participant has spontaneous self-referential for the perception tasks where no self-referential process were not explicitly excluded [citation related to spontaneous self-referential].

Here, we report nine experiments where we found (1) there is a robust good character prioritization effect in social associative learning task, i.e., when neutral geometric shapes were associated with good character, they were prioritized as compared to shapes associated with neutral or bad characters; (2) prioritization of good character was robust only when it is relevant to the self but weak or non-exist when it referred to a non-self label; (3) the binding between good character and self exist even when one of the label became task-irrelevant. Together, these results provided evidence for spontaneous self-referential processing as a novel mechanism of the prioritization effect of good character. In all experiments, a social associative learning task in which th effect of physical features are minimized — participants performed a perceptual matching task after associated different moral characters (good, neutral, and bad) with different geometric shapes. 

<!-- 
we attempted to distinguish these two possibilities by a social associative learning task in which physical features had minimal influences — participants performed a perceptual matching task after associated different moral characters (good, neutral, and bad) with different geometric shapes. If there is a positivity effect, there should be an advantage for shapes associated with good character over shapes associated with neutral or bad shapes. If there is a negativity effect, the advantage should be occur on shapes associated with bad characters. The first four experiments and two additional follow-up experiments provided strong evidence for good character effect in the current paradigm.

The positivity effect consistent with previous studies where positivity effect of social trait words were found [@anselmi_positive_2011; @bargh_generality_1992; @unkelbach_good_2010]. However, the effect could not be explained by the similarity hypothesis [@unkelbach_chapter_2020] because we only used three stimuli. There are two possibility explanations. The first one is the value-based attention account, which suggests that stimuli that are valuable to us are prioritized [@anderson_neurobiology_2019]. In our experiments, the good character label "good person" may represent an indirect but valuable stimuli because, in social life, a good other is usually more valuable than an bad other [@abele_agency_2007]. Another possibility is derived from social categorization theory, which suggested that we automatically categorize others as in-group or out-group [@turner_rediscovering_1987]. Moral character is an important criterion for social categorization [@mchugh_moral_2019; @descioli_side_taking_2016]. However, the above four experiments could not distinguish between these two possibilities, because "good person" could both be rewarding and be categorized as in-group member. Given that both rewarding stimuli [e.g., @Sui_2012_JEPHPP] and in-group information [@enock_overlap_2020] are prioritized when using social associative learning paradigm, we further tested these two possibilities in new experiments.

To distinguish the value-based account and the social categorization explanations, we introduced the identity (self- vs. other-referential) of moral character as an addition independent variable in exp 3a, 3b, and 6b. Now moral valence is orthogonal to the identity. In this case, the identity of moral character information become salient and participants are less likely to spontaneously categorize a good-other as an extension of self, but the value of good-person still exists. If the positivity effect was driven by social categorization theory, then participants prioritize good-self but not good-other. If the value-based attention theory is true, then, both good-self and good-other are prioritized, or maybe good-other are even more prioritized. 

Although the introduction of self- and other-referential processing provided evident that value-based account can not explain the good-character effect, it might introduce the good-self effect, i.e., the good-self is prioritized over all the other stimuli. This effect, if true, may suggest underlying mechanisms other than social-categorization. For example, the moral true self account. Moral true self view suggested that moral self if the true self [@strohminger_true_2017]. Therefore, even good-self can be viewed as categorized to in-group, it can also be viewed as the core of the self and it is the anchor of all the other effects.

To test the moral true self view and the social-categorization account, we designed two complementary experiments. In experiment 4a, participants only learned the association between self and other, the words "good-person", "neutral person", and "bad person" were presented as task-irrelevant stimuli, while in experiment 4b, participants learned the associations between "good-person", "neutral-person", and "bad-person", and the "self" and "other" were presented as task-irrelevant stimuli. These two experiments can be used to distinguish the moral-self view and social categorization" account. If moral-self view is true, then, in both experiments, good-self will show advantage over all other stimuli, and there will be no other effects. More specifically, in experiment 4a, where only the self-referential processing is task-relevant, there will be advantage for good as task-irrelevant condition than when bad or neutral character as task-irrelevant for the self conditions, while there is no other effects; in experiment 4b, in the good condition, there will be an advantage for self as task-irrelevant condition over other as task-irrelevant condition, and no other effects. If social categorization is true, then, the prioritization effect will depends on whether the stimuli can be categorized as the same group of good-self. More specifically, in experiment 4a, there will be good effect in self conditions, this prediction is the same as the moral self-view; it predicts a reverse good effect in other condition because good and other a conflict in terms of social-categorization, this prediction is different from the "good-self" anchor account; however, for experiment 4b, it predicts no identity effect in the good-person condition because both self and other are in the good group.


[Good self in self-reported data] 
As an exploration, we also collected participants' self-reported psychological distance between self and good-person, bad-person, and neutral-person, moral identity, moral self-image, and self-esteem. All these data are available [see @Liu_2020_JOPD]. We explored the correlation between self-reported distance and these questionnaires as well as the questionnaires and behavioral data. However, given that the correlation between self-reported score and behavioral data has low correlation [@dang_why_2020], we didn't expect a high correlation between these self-reported measures and the behavioral data.
-->

 <!-- 
Key concepts and discussing points:

**Self-categories** are cognitive groupings of self and some class of stimuli as identical or different from some other class. [Turner et al.]

**Personal identity** refers to self-categories that define the individual as a unique person in terms of his or her individual differences from other (in-group) persons.

**Social identity** refers to the shared social categorical self ("us" vs. "them").

**Variable self**: Who we are, how we see ourselves, how we define our relations to others (indeed whether they are construed as ‘other’ or as part of the extended 'we' self) is different in different settings. 

**Identification**: the degree to which an individual feels connected to an ingroup or includes the ingroup in his or her self-concept. (self is not bad; )

Morality as a way for social-categorization [@mchugh_moral_2019]? People are more likely to identify themselves with trustworthy faces [@verosky_differential_2010] (trustworthy faces has longer RTs).

What is the relation between morally good and self in a semantic network (attractor network) (Freeman & Ambady, 2011)? The psychological essentialism account proposed that the moral good self is perspective independent, i.e., there is a moral good self in all. This perspective free effect is not exist in our effect.

How to deal with the *variable self* (self-categorization theory) vs. *core/true/authentic self* vs. *self-enhancement*

**Limitations**:
The perceptual decision-making will show certain pattern under certain task demand. In our case, it's the forced, speed, two-option choice task.

in experiment 4a and 4b, we didn't have a baseline condition where there is no word inside the shape? -->

# Disclosures
We reported all the measurements, analyses, and results in all the experiments in the current study. Participants whose overall accuracy lower than 60% were excluded from analysis. Also, the accurate responses with less than 200ms reaction times were excluded from the analysis. These excluded data can be found in the shared raw data files.

All the experiments reported were not pre-registered. Most experiments (1a ~ 4b, except experiment 3b) reported in the current study were first finished between 2013 to 2016 in Tsinghua University, Beijing, China. Participants in these experiments were recruited in the local community. To increase the sample size of experiments to 50 or more [@Simmons_2013_life], we recruited additional participants in Wenzhou University, Wenzhou, China in 2017 for experiment 1a, 1b, 4a, and 4b. Experiment 3b was finished in Wenzhou University in 2017 (See Table S1 for overview of these experiments). 

All participant received informed consent and compensated for their time. These experiments were approved by the ethic board in the Department of Psychology, Tsinghua University. 

 <!-- 21-word solution (Simmons, Nelson & Simonsohn, 2012; retrieved from http://ssrn.com/abstract=2160588) -->

```{r loadingData,echo=FALSE,results='hide'}
load("AllData.RData")

### expclude the repeated subj from the raw data

# No repeating subj
df1a.v_meta <- df1a.v

# No repeating subj
df1b.v_meta <- df1b.v

# exclude participant from exp 1a
df1c.v_meta <- df1c.v %>% dplyr::filter(!Subject %in% c(1206, 1207, 1208, 1210))

# exclude participant from exp 1a
df2.v_meta <- df2.v %>% dplyr::filter(Subject > 2000)    

# exclude participants from ex1b, 1c, and 2
df3a.v_meta <- df3a.v %>% dplyr::filter(!Subject %in% c(3013, 3012, 3043, 3046)) 

# No repeating subj
df3b.v_meta <- df3b.v

# No repeating subj
df4a.v_meta <- df4a.v

# exclude participants from ex1b, 1c, and 2
df4b.v_meta <- df4b.v %>% dplyr::filter(!Subject %in% c(4210, 4202, 4201))   

# exclude participants from ex1b, 1c, and 2
df5.v_meta <- df5.v %>% dplyr::filter(!Subject %in% c(5201))   

# exclude participants from ex1b, 1c, and 2
df6a.v_meta <- df6a.v %>% dplyr::filter(!Subject %in% c(6118,6119,6122,6123,6131))   

# exclude participants from ex1b, 1c, and 2
df6b.v_meta <- df6b_d1.v %>% dplyr::filter(!Subject %in% c(6217))   

# exclude participants from ex1b, 1c, and 2
df7a.v_meta <- df7a_m.v %>% dplyr::filter(!Subject %in% c(7020))   

# No repeating subj
df7b.v_meta <- df7b_m.v


df1a.v_meta$ExpID <- 'Exp1a'
df1b.v_meta$ExpID <- 'Exp1b'
df1c.v_meta$ExpID <- 'Exp1c'
df2.v_meta$ExpID  <- 'Exp2'
df3a.v_meta$ExpID <- 'Exp3a'
df3b.v_meta$ExpID <- 'Exp3b'
df4a.v_meta$ExpID <- 'Exp4a'
df4b.v_meta$ExpID <- 'Exp4b'
df5.v_meta$ExpID  <- 'Exp5'
df6a.v_meta$ExpID <- 'Exp6a'
df6b.v_meta$ExpID <- 'Exp6b'
df7a.v_meta$ExpID <- 'Exp7a'
df7b.v_meta$ExpID <- 'Exp7b'
```

```{r define_funs, echo=FALSE, results='hide'}
# define a function to run the sdt GLMM for all exp with Matchness * Valence design
# for 1a, 1b, 1c, 2, 6a
fun_sdt_val <- function(exp_name) {
  df_name <- paste('df', exp_name, '.v', sep = '')
  m_name <- paste("glmmModels/exp", exp_name, "_sdt_m1_DummyCode", sep = '')
  df <- get(df_name)  # get the data by string
  
  m <- df %>%
  dplyr::filter(!is.na(RESP)) %>% # filter trials without response
  dplyr::mutate(ismatch = ifelse(Matchness == 'Match', 1, 0),
                saymatch = ifelse((Matchness == 'Match' & ACC == 1) | 
                                    (Matchness == 'Mismatch' & ACC == 0), 1, 0),
                Valence = factor(Valence, levels = c('Neutral', 'Bad', 'Good'))) %>%
  brms::brm(saymatch ~ 0 + Valence + ismatch:Valence + 
              (0 + Valence + ismatch:Valence | Subject),
            family = bernoulli(link="probit"),
            data = .,
            control = list(adapt_delta = .99),
            iter = 4000,
            thin = 2,
            cores = parallel::detectCores(),
            file = here::here(m_name))
  return(m)
}

fun_plot_sdt_val <- function(m_sdt) {
    # extract c
    tmp_c <- m_sdt %>% 
      tidybayes::gather_draws(b_ValenceBad, b_ValenceNeutral, b_ValenceGood) %>%
      dplyr::rename(Valence = .variable, sdt_c = .value) %>% dplyr::ungroup() %>%
      dplyr::mutate(Valence = gsub("b_", "", Valence)) %>%
      dplyr::mutate(Valence = ifelse(stringr::str_detect(Valence, 'Bad'), 'Bad',
                                     ifelse(stringr::str_detect(Valence, 'Good'), 'Good', 'Neutral')))
    
    # dprime
    tmp_d <- m_sdt %>% 
      tidybayes::gather_draws(`b_ValenceBad:ismatch`, `b_ValenceNeutral:ismatch`, 
                              `b_ValenceGood:ismatch`) %>%
      dplyr::rename(Valence = .variable, sdt_d = .value) %>% dplyr::ungroup() %>%
      dplyr::mutate(Valence = gsub("b_", "", Valence)) %>%
      dplyr::mutate(Valence = ifelse(stringr::str_detect(Valence, 'Bad'), 'Bad',
                                     ifelse(stringr::str_detect(Valence, 'Good'), 'Good', 'Neutral')))
    
    # plot summaries with densities
    p_sdt_d_sum <- tmp_d %>%
      dplyr::mutate(Valence = factor(Valence, levels = c('Bad', 'Neutral', 'Good'))) %>%
      ggplot2::ggplot(aes(x = sdt_d, y = Valence)) +
      tidybayes::stat_halfeyeh() + 
      labs(x = "sensitivity (d')", y = 'Posterior') +
      theme_classic()
    
    p_sdt_c_sum <- tmp_c %>%
      dplyr::mutate(Valence = factor(Valence, levels = c('Bad', 'Neutral', 'Good'))) %>%
      ggplot2::ggplot(aes(x = sdt_c, y = Valence)) +
      tidybayes::stat_halfeyeh() + 
      labs(x = "criteria (c)", y = 'Posterior') +
      theme_classic()
    
    # plot comparison
    p_sdt_d <- tmp_d %>%
      dplyr::mutate(Valence = factor(Valence, levels = c('Neutral', 'Bad', 'Good'))) %>%
      tidybayes::compare_levels(sdt_d, by = Valence) %>%
      ggplot2::ggplot(aes(x = sdt_d, y = Valence, fill = after_stat(x > 0))) +
      tidybayes::stat_halfeyeh() + 
      geom_vline(xintercept =0, linetype = "dashed") +
      scale_fill_manual(values = c("gray80", "skyblue")) +
      labs(x = "sensitivity (d')", y = 'Comparison') +
      theme_classic()
    
    p_sdt_c <- tmp_c %>%
      dplyr::mutate(Valence = factor(Valence, levels = c('Neutral', 'Bad', 'Good'))) %>%
      tidybayes::compare_levels(sdt_c, by = Valence) %>%
      ggplot2::ggplot(aes(x = sdt_c, y = Valence, fill = after_stat(x > 0))) +
      tidybayes::stat_halfeyeh() + 
      geom_vline(xintercept =0, linetype = "dashed") +
      scale_fill_manual(values = c("gray80", "skyblue")) +
      labs(x = "criteria (c)", y = 'Comparison') +
      theme_classic()
    
    return(list(p_sdt_d_sum, p_sdt_c_sum, p_sdt_d, p_sdt_c))
}

# define a function to run the RT GLMM for all exp with Matchness * Valence design
fun_rt_val <- function(exp_name) {
  df_name <- paste('df', exp_name, '.v', sep = '')
  m_name <- paste("glmmModels/exp", exp_name, "_rt_m1_DummyCode", sep = '')
  df <- get(df_name)  # get the data by string
  m <- df %>%
    dplyr::mutate(RT_sec = RT/1000) %>% # log RT in seconds
    dplyr::filter(ACC == 1) %>%
    dplyr::mutate(ismatch = ifelse(Matchness == 'Match', 1, 0),
                  Valence = factor(Valence, levels = c('Neutral', 'Bad', 'Good'))) %>%
    brms::brm(RT_sec ~ ismatch*Valence + (ismatch*Valence | Subject),
              family = shifted_lognormal(),
              data = ., control = list(adapt_delta = .99),
              iter = 4000,
              thin = 2,
              cores = parallel::detectCores(),
              file = here::here(m_name))
  return(m)
}

fun_plot_rt_val <- function(m_rt) {
    tmp_rt <- m_rt %>% 
      tidybayes::spread_draws(b_Intercept, b_ValenceBad, b_ValenceGood, 
                              b_ismatch,   `b_ValenceBad:ismatch`, `b_ValenceGood:ismatch`) %>%
      dplyr::mutate(Neut_MM = b_Intercept,
                    Bad_MM = Neut_MM + b_ValenceBad,
                    Good_MM = Neut_MM + b_ValenceGood,
                    Neut_M = Neut_MM + b_ismatch,
                    Bad_M = Neut_MM + b_ismatch + `b_ValenceBad:ismatch`,
                    Good_M = Neut_MM + b_ismatch + `b_ValenceGood:ismatch`) %>%
      dplyr::select(-contains('b_')) %>%
      tidyr::pivot_longer(cols = Neut_MM:Good_M,
                          names_to = 'cond',
                          values_to = 'logRT') %>%
      dplyr::mutate(RT = exp(logRT)*1000,
                    Matchness = dplyr::case_when(grepl("_MM$", cond) ~ "Mismatch",
                                                 grepl("_M$", .variable) ~ "Match"),
                    Valence = dplyr::case_when(grepl("Neut", cond) ~ "Neutral",
                                               grepl("Bad", cond) ~ "Bad",
                                               grepl("Good", cond) ~ "Good")
                    # Matchness = dplyr::case_when(cond == 'Neut_MM' | cond == 'Bad_MM' | cond == 'Good_MM' ~ 'Mismatch',
                    #                              cond == 'Neut_M'  | cond == 'Bad_M'  | cond == 'Good_M' ~ 'Match'),
                    # Valence = dplyr::case_when(cond == 'Neut_MM' | cond == 'Neut_M' ~ 'Neutral',
                    #                            cond == 'Bad_MM'  | cond == 'Bad_M'  ~ 'Bad', 
                    #                            cond == 'Good_MM' | cond == 'Good_M' ~ 'Good')
                    )
    p_exp1b_rt_m_sum <- tmp_rt %>% dplyr::mutate(Valence = factor(Valence, levels = c('Bad', 'Neutral', 'Good'))) %>%
      dplyr::filter(Matchness == 'Match') %>%
      ggplot2::ggplot(aes(x = RT, y = Valence)) +
      tidybayes::stat_halfeyeh() + 
      labs(x = "RTs (Matching, ms)", y = 'Posterior') +
      theme_classic()
    p_exp1b_rt_mm_sum <- tmp_rt %>% dplyr::mutate(Valence = factor(Valence, levels = c('Bad', 'Neutral', 'Good'))) %>%
      dplyr::filter(Matchness == 'Mismatch') %>%
      ggplot2::ggplot(aes(x = RT, y = Valence)) +
      tidybayes::stat_halfeyeh() + 
      labs(tag = 'D', x = "RTs (Mismatching, ms)", y = 'Posterior') +
      theme_classic()
    
    # plot comparison
    p_exp1b_rt_m <- tmp_rt %>% dplyr::mutate(Valence = factor(Valence, levels = c('Neutral', 'Bad', 'Good'))) %>%
      dplyr::filter(Matchness == 'Match') %>%
      tidybayes::compare_levels(RT, by = Valence) %>%
      ggplot2::ggplot(aes(x = RT, y = Valence, fill = after_stat(x < 0))) +
      tidybayes::stat_halfeyeh() + 
      geom_vline(xintercept =0, linetype = "dashed") +
      scale_fill_manual(values = c("gray80", "skyblue")) +
      labs(tag = 'C', x = "RTs (Matching, ms)", y = 'Comparison') +
      theme_classic()
    p_exp1b_rt_mm <- tmp_rt %>% dplyr::mutate(Valence = factor(Valence, levels = c('Neutral', 'Bad', 'Good'))) %>%
      dplyr::filter(Matchness == 'Mismatch') %>%
      tidybayes::compare_levels(RT, by = Valence) %>%
      ggplot2::ggplot(aes(x = RT, y = Valence, fill = after_stat(x < 0))) +
      tidybayes::stat_halfeyeh() + 
      geom_vline(xintercept =0, linetype = "dashed") +
      scale_fill_manual(values = c("gray80", "skyblue")) +
      labs(tag = 'D', x = "RTs (Mismatching, ms)", y = 'Comparison') +
      theme_classic()
    return(list(p_exp1b_rt_m_sum, p_exp1b_rt_mm_sum, p_exp1b_rt_m, p_exp1b_rt_mm))
}

fun_sdt_val_id <- function(exp_name) {
  df_name <- paste('df', exp_name, '.v', sep = '')
  m_name <- paste("glmmModels/exp", exp_name, "_sdt_m1_DummyCode", sep = '')
  df <- get(df_name)  # get the data by string
  
  m <- df %>%
  dplyr::filter(!is.na(RESP)) %>% # filter trials without response
  dplyr::mutate(ismatch = ifelse(Matchness == 'Match', 1, 0),
                saymatch = ifelse((Matchness == 'Match' & ACC == 1) | 
                                    (Matchness == 'Mismatch' & ACC == 0), 1, 0),
                Valence = factor(Valence, levels = c('Neutral', 'Bad', 'Good')),
                Identity = factor(Identity, levels = c('Self', 'Other'))) %>%
  brms::brm(saymatch ~ 0 + Identity:Valence + ismatch:Identity:Valence + 
              (0 + Identity:Valence + ismatch:Identity:Valence | Subject),
            family = bernoulli(link="probit"),
            data = .,
            control = list(adapt_delta = .99),
            iter = 4000,
            thin = 2,
            cores = parallel::detectCores(),
            file = here::here(m_name))
  return(m)
}

# define a function to run the RT GLMM for all exp with Matchness * Valence design
fun_rt_val_id <- function(exp_name) {
  df_name <- paste('df', exp_name, '.v', sep = '')
  m_name <- paste("glmmModels/exp", exp_name, "_rt_m1_DummyCode", sep = '')
  df <- get(df_name)  # get the data by string
  m <- df %>%
    dplyr::mutate(RT_sec = RT/1000) %>% # log RT in seconds
    dplyr::filter(ACC == 1) %>%
    dplyr::mutate(ismatch = ifelse(Matchness == 'Match', 1, 0),
                  Valence = factor(Valence, levels = c('Neutral', 'Bad', 'Good')),
                  Identity = factor(Identity, levels=c('Self', 'Other'))) %>%
    brms::brm(RT_sec ~ ismatch*Identity*Valence + (ismatch*Identity*Valence | Subject),
              family = shifted_lognormal(),
              data = ., control = list(adapt_delta = .99),
              iter = 4000,
              thin = 2,
              cores = parallel::detectCores(),
              file = here::here(m_name))
  return(m)
}

```

  <!-- A general method part describing experimental design and data analysis -->
```{r child = "general_method.rmd"}
```

# Results
## Prioritization of good character related information
In this part, we report results from five experiments that tested whether an associative learning task, including 192 participants. Note that for both experiment 1a and 1b, there were two independent samples with different equipment, trials numbers and testing situations. Therefore, we modeled them as independent samples. These five experiments revealed a robust effect of moral character on perceptual matching task. 

```{r remove non-meta data, eval = FALSE, echo=FALSE, results='hide', warning=FALSE}
# remove all unnecessary variables
var_list <- c('df1a.v_meta', 'df1b.v_meta', 'df1c.v_meta', 'df2.v_meta', 'df3a.v_meta', 'df3b.v_meta',
              'df4a.v_meta', 'df4b.v_meta', 'df5.v_meta', 'df6a.v_meta', 'df6b.v_meta', 'df7a.v_meta', 'df7b.v_meta',
              'apatheme','exp_table', 'curDir', 'figDir')
rm(list=ls()[! ls() %in% var_list])
```

```{r prepare data for first meta, echo=FALSE, results='hide', warning=FALSE}
### try meta-analysis 1a, 1b, 1c, 2, 5 and 6a
selected_columns <- c('ExpID', 'Site', 'Subject','Age', 'Sex', 'Matchness','Valence', 'RESP', 'ACC','RT')
df_moral <- dplyr::bind_rows(df1a.v_meta[selected_columns],
                             df1b.v_meta[selected_columns],
                             df1c.v_meta[selected_columns],
                             df2.v_meta[selected_columns],
                             df5.v_meta[selected_columns],
                             df6a.v_meta[selected_columns]) %>%
  dplyr::mutate(ExpID_new = paste(ExpID, Site, sep = "_")) %>%
  dplyr::mutate(Valence = factor(Valence, levels = c('Neutral', 'Bad', 'Good')))

df_moral_subj <- df_moral %>%
  dplyr::group_by(ExpID_new, Site) %>%
  dplyr::summarize(N = n_distinct(Subject),
                   N_trial = length(Subject),
                   Exp_conds = 6,
                   trial_per_cond = round((length(Subject)/6)/N, 0))

df_moral <- df_moral %>%
  dplyr::filter(!is.na(RESP)) %>% # filter trials without response
  dplyr::mutate(ismatch = ifelse(Matchness == 'Match', 1, 0),
                saymatch = ifelse((Matchness == 'Match' & ACC == 1) | 
                                    (Matchness == 'Mismatch' & ACC == 0), 1, 0)) %>%
  dplyr::select(ExpID_new, Subject, Valence, Matchness, RESP, ACC, RT, ismatch, saymatch) %>%
  dplyr::mutate(ismatch_num = ifelse(Matchness == 'Match', 0.5, -0.5))

# # plot the nested structure of the data
# with(df_moral, table(Subject, ExpID_new)) %>%
#   image(
#     col = grey.colors(80, start = 1, end = 0), 
#     axes = TRUE, 
#     xlab = "Subject", 
#     ylab = "ExpID"
#   )

```

```{r first meta sdt, echo=FALSE, results='hide', warning=FALSE}
# fit a three-level hierarchical model for SDT, didn't specify the prior; dummy coding
# about 20 hours to finish this sampling using ntel® Xeon(R) CPU E3-1505M v5 @ 2.80GHz × 8 machine.
# 87432.5 = 24.3 hours
sdt_val_m1 <- brms::brm(saymatch ~ 0 + Valence + Valence:ismatch + 
                         (0 + Valence + Valence:ismatch | ExpID_new) + 
                         (0 + Valence + Valence:ismatch  | ExpID_new:Subject),
                       family = bernoulli(link="probit"),
                       data = df_moral,
                       control = list(adapt_delta = .95),
                       cores = parallel::detectCores(),
                       backend = 'cmdstanr',  # with cmdstanr
                       file = here::here("glmmModels/sdt_val_DummyCode_3_level"))

# summary(sdt_val_m1)
# stancode(sdt_val_m1)

# plot(hypothesis(sdt_val_m1, "ValenceBad:ismatch > ValenceNeutral:ismatch"))
# 
# plot(hypothesis(sdt_val_m1, "ValenceGood:ismatch > ValenceNeutral:ismatch"))

# combined with emmeans, no longer used
# sdt_val_m1_p <- sdt_val_m1 %>%
#   emmeans::emmeans( ~ ismatch | Valence) %>%
#   tidybayes::gather_emmeans_draws() %>%
#   dplyr::filter(ismatch == 'd prime') %>%
#   ggplot2::ggplot(aes(x = Valence, y = .value)) +
#   tidybayes::stat_halfeye() + # position=position_dodge(width = 0.1)
#   stat_summary(aes(group = NA), fun = mean, geom = "line") +
#   ylab(expression(paste("Sensitivity ",italic("d'"), sep = ' '))) +
#   facet_grid(cols = vars(ismatch), scales = "free_y") +
#   theme_classic() + 
#   theme(axis.title.x = element_blank())

# plot the population level parameter (d prime)
# sdt_val_m1_p <- sdt_val_m1 %>%
#         # get the traces of population level parameters
#         tidybayes::gather_draws(`b_.*`, regex = TRUE) %>%
#         # create two columns for two independent factors.
#         dplyr::mutate(Valence = dplyr::case_when(
#                 grepl("ValenceBad", .variable) ~ "Bad",
#                 grepl("ValenceNeutral", .variable) ~ "Neutral",
#                 grepl("ValenceGood", .variable) ~ "Good"),
#                 params = dplyr::case_when(grepl("ismatch", .variable) ~ "d prime",
#                                            !grepl("ismatch", .variable) ~"criterion"),
#                 params = factor(params, levels = c('d prime', 'criterion')),
#                 Valence = factor(Valence, levels = c('Good', 'Neutral',  'Bad'))
#           ) %>%
#   # select only d prime
#   dplyr::filter(params == 'd prime') %>%
#   ggplot2::ggplot(aes(x = Valence, y = .value)) +
#   tidybayes::stat_halfeye() + # position=position_dodge(width = 0.1)
#   stat_summary(aes(group = NA), fun = mean, geom = "line") +
#   ylab(expression(paste("Sensitivity ", italic("d'"), sep = ' '))) +
#   # xlab("Valence") +
#   #facet_grid(cols = vars(params), scales = "free_y") +
#   theme_classic() # + 
  # theme(axis.title.x = element_blank())

df_m1_std_fixed_effect <- bayestestR::describe_posterior(
  sdt_val_m1,
  effects = "fixed",
  component = "all",
  ci = 0.95,
  ci_method = 'hdi',
  test = c("p_direction", "p_significance"),
  centrality = "all") %>%
        dplyr::mutate(Valence = dplyr::case_when(
                grepl("ValenceBad", Parameter) ~ "Bad",
                grepl("ValenceNeutral", Parameter) ~ "Neutral",
                grepl("ValenceGood", Parameter) ~ "Good"),
                params = dplyr::case_when(grepl("ismatch", Parameter) ~ "d prime",
                                           !grepl("ismatch", Parameter) ~"criterion"),
                params = factor(params, levels = c('d prime', 'criterion')),
                Valence = factor(Valence, levels = c('Good', 'Neutral',  'Bad'))) 
#### plot both overall parameters and experimental levels.
# # Get the variables in the model
# var_name_m1 <- tidybayes::get_variables(sdt_val_m1)

df_m1_post_sdt_exp <- sdt_val_m1 %>% 
  tidybayes::spread_draws(r_ExpID_new[condition, term]) %>%
  dplyr::rename(value = r_ExpID_new)

pop_mean <- sdt_val_m1 %>%
  tidybayes::gather_draws(`b_.*`, regex = TRUE) %>%
  group_by(.variable) %>%       # this line not necessary (done automatically by spread_draws)
  tidybayes::mean_hdci(.value)  # get the high density continuous intervals

# extract the population level parameters
df_sdt_m1_pop <- sdt_val_m1 %>% 
  tidybayes::gather_draws(`b_.*`, regex = TRUE) %>%
  dplyr::rename(term = .variable,
                pop_mean = .value) %>%
  #tidyr::separate(term, c(NA, 'term'), "_") 
  dplyr::ungroup() %>%
  dplyr::mutate(term = gsub("b_", "", term))

# Add the population mean to the experimental level and only keep the value after.
df_m1_post_sdt_exp_update <- merge(df_sdt_m1_pop, df_m1_post_sdt_exp, by = c('term','.chain','.iteration', '.draw'), all = T) %>%
  dplyr::mutate(mean_value = pop_mean + value) %>%  # add the population level value to each experiment
  dplyr::select(condition, term, `.chain`, `.iteration`, `.draw`, mean_value) %>% # select the added value
  dplyr::rename(value = mean_value)  # rename the value

# Plot the difference between conditions 
df_m1_plot_sdt <- df_sdt_m1_pop %>%
  dplyr::mutate(condition = 'Overall') %>%
  dplyr::rename(value = pop_mean) %>%
  dplyr::select(condition, term, `.chain`, `.iteration`, `.draw`, value) %>%
  dplyr::bind_rows(., df_m1_post_sdt_exp_update) %>%
  dplyr::mutate(condition = factor(condition, levels = c("Exp1a_THU", "Exp1a_WZU", "Exp1b_THU", 
                                                         "Exp1b_WZU", "Exp1c_THU", "Exp2_THU" , 
                                                         "Exp5_THU",  "Exp6a_THU","Overall")),
                condition = forcats::fct_rev(condition), # reverse the order because the plot function auto reverse.
                term = dplyr::case_when((term == "ValenceBad") ~ "c_Bad",
                                    (term == "ValenceNeutral") ~ "c_Neutral",
                                    (term == "ValenceGood") ~ "c_Good",
                                    (term == "ValenceBad:ismatch") ~ "dprime_Bad",
                                    (term == "ValenceNeutral:ismatch") ~ "dprime_Neutral",
                                    (term == "ValenceGood:ismatch") ~ "dprime_Good"),
                term = factor(term, levels = c("c_Bad", "c_Neutral", "c_Good",
                                               "dprime_Bad", "dprime_Neutral", "dprime_Good"))) 

df_m1_plot_sdt_diff <- df_m1_plot_sdt %>%
  tidyr::pivot_wider(names_from = c(term), values_from = value) %>%   # long to wide
  dplyr::mutate(diff_GB_c = c_Good - c_Bad,                           # calculate the differences between conditions
                diff_GN_c = c_Good - c_Neutral,
                diff_BN_c = c_Bad - c_Neutral,
                diff_GB_dprm = dprime_Good - dprime_Bad,
                diff_GN_dprm = dprime_Good - dprime_Neutral,
                diff_BN_dprm = dprime_Bad - dprime_Neutral) %>%
  dplyr::select(condition, `.chain`, `.iteration`, `.draw`,
               diff_GB_c,diff_GN_c, diff_BN_c,
               diff_GB_dprm, diff_GN_dprm, diff_BN_dprm) %>%
  tidyr::pivot_longer(cols = diff_GB_c:diff_BN_dprm, names_to = "term_diff", values_to =  "value") %>%  # wide to long
  dplyr::mutate(term_diff = factor(term_diff, levels = c('diff_GB_c','diff_GN_c', 'diff_BN_c',
                                                         'diff_GB_dprm', 'diff_GN_dprm', 'diff_BN_dprm')))

# plot the posterior of the d prime
# use the overall mean values as the vlines
vlines_df_m1_sdt <- df_m1_plot_sdt %>% 
        tidyr::separate(term, c('params', 'Valence')) %>% 
        dplyr::mutate(Valence = factor(Valence, levels = c('Good', 'Neutral', 'Bad'))) %>%
        dplyr::filter(params == 'dprime') %>%
        dplyr::filter(condition == "Overall") %>%
        dplyr::group_by(Valence) %>% 
        dplyr::summarize(Mean = mean(value)) # %>%
        # dplyr::arrange(Mean)

# THIS is the one which the final plot will based on!!!
p_dprime1 <- df_m1_plot_sdt %>%
        tidyr::separate(term, c('params', 'Valence')) %>%
        dplyr::mutate(Valence = factor(Valence, levels = c('Good', 'Neutral', 'Bad'))) %>%
        dplyr::filter(params == 'dprime') %>%
        dplyr::rename(Experiments = condition) %>%
        # dplyr::mutate(Experiments = factor(Experiments, levels = c("Exp1b_WZU", "Exp5_THU", "Exp1a_THU", 
        #                                                            "Exp1b_THU", "Exp1c_THU", "Exp2_THU" , 
        #                                                            "Exp1a_WZU",  "Exp6a_THU","Overall")),
        #               Experiments = fct_rev(Experiments)) %>%
        ggplot2::ggplot(aes(y = Experiments, x = value, color = Valence)) +
        tidybayes::stat_halfeye(aes(fill = Valence), alpha = 0.7) +
        geom_vline(data = vlines_df_m1_sdt, aes(xintercept = Mean,colour = Valence), linetype = "dashed") +
        labs(x=expression('Posteior distribution of '~italic(d)~' prime')) + 
        scale_colour_brewer(palette = "Dark2") +
        scale_fill_brewer(palette = "Dark2") +
        theme_apa()

# plot the posterior of the difference between d prime
p_dprime1_diff <- df_m1_plot_sdt_diff %>%
        dplyr::filter(str_detect(term_diff, '_dprm')) %>%
        dplyr::filter(!str_detect(term_diff, '_GB_')) %>%
        ggplot2::ggplot(aes(y = condition, x = value, fill = after_stat(x > 0))) +
        tidybayes::stat_halfeye() +
        geom_vline(xintercept = 0, linetype = "dashed") +
        # scale_fill_manual(values = c('gray80', 'skyblue')) +
        scale_fill_manual(values = c('skyblue', 'gray80'),
                    breaks = c(TRUE, FALSE),
                    name = "Effect" , labels = c("Yes", "No")) + 
        xlab(expression(paste("Effect of valence on ", italic("d"), " prime", sep = ' '))) + 
        facet_wrap( ~ term_diff, # scales = "free_y",
                    nrow = 1,
                    labeller = label_parsed)

df_dprime1_diff_hdi <- df_m1_plot_sdt_diff %>%
        dplyr::filter(str_detect(term_diff, '_dprm')) %>%
        # dplyr::filter(!str_detect(term_diff, '_GB_')) %>%
        dplyr::filter(condition == "Overall") %>%
        tidyr::pivot_wider(.,
                           id_cols = c('.chain', '.iteration', '.draw'),
                           names_from = term_diff) %>% 
        dplyr::select(-c('.chain', '.iteration', '.draw')) %>%
        bayestestR::describe_posterior(.,
                                       ci = 0.95,
                                       ci_method = 'hdi',
                                       test = c("p_direction", "p_significance"),
                                       centrality = "median") # %>%
        # tidyr::separate(Parameter, c('Valence', 'Match')) %>% 
        # dplyr::mutate(Valence = factor(Valence, levels = c('Good', 'Neutral', 'Bad')))
```

```{r first meta rt, echo=FALSE, results='hide', warning=FALSE}
# have a look at a few participants' data
# set.seed(123)
# random_sub <- sample(unique(df_moral$Subject), 10)
# random_sub

# # plot the distribution of 10 randomly selected participants
# df_moral %>%
#   dplyr::mutate(RT_sec = RT/1000) %>%  # log RT in seconds
#   dplyr::filter(ACC == 1) %>%          # only correct trials
#   dplyr::filter(Subject %in% random_sub) %>%
#   dplyr::mutate(cond = paste(Matchness, Valence, sep = "_"),
#                 RT_log = log(RT_sec))%>%
#   ggplot2::ggplot(., aes(x=RT_log)) + 
#   geom_histogram(aes(fill=cond), alpha=0.5, bins=60) + 
#   facet_wrap(~Subject, nrow = 2) +  # One panel per id
#   coord_cartesian(xlim=c(-2, 1))

# fit a three-level hierarchical model for RT, didn't specify the prior, shifted_lognormal, effective coding
RT_val_m1 <- df_moral %>%
  dplyr::mutate(RT_sec = RT/1000) %>% # log RT in seconds
  dplyr::filter(ACC == 1) %>%         # only correct trials
  brms::brm(RT_sec ~ Valence*ismatch_num + 
              (Valence*ismatch_num | ExpID_new) +   
              (Valence*ismatch_num | ExpID_new:Subject),
            family=shifted_lognormal(),
            data = .,
            control = list(adapt_delta = .95),
            cores = parallel::detectCores(),
            backend = 'cmdstanr',  # with cmdstanr
            file = here::here("glmmModels/RT_val_EffectCode_3_level"))

# plot(RT_val_m1, "b_")

# summary(RT_val_m1)  # ndt = 0 there fore, we used lognormal.
# pp_check(RT_val_m1)

# Will try dummy coding later, but the running time is long: Total execution time: 124845.8 seconds = 34.7 hours
# RT_val_m1 <- df_moral %>%
#   dplyr::mutate(RT_sec = RT/1000) %>% # log RT in seconds
#   dplyr::filter(ACC == 1) %>%         # only correct trials
#   brms::brm(RT_sec ~ Valence*ismatch +
#               (Valence*ismatch | ExpID_new) +
#               (Valence*ismatch  | ExpID_new:Subject),
#             family=lognormal(),
#             data = .,
#             control = list(adapt_delta = .95),
#             cores = parallel::detectCores(),
#             backend = 'cmdstanr',  # with cmdstanr
#             file = here::here("glmmModels/RT_val_DummyCode_3_level"))
# 
# summary(RT_val_m1)

#Population-Level Effects: 
#                        Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
#Intercept                  -0.40      0.06    -0.52    -0.27 1.01      837     1301  # baseline: mismatch:neutral
#ValenceBad                  0. 01      0.00     0.00     0.02 1.00     1752     2540  # mismatch:bad - mismatch:neutral = 0.01
#ValenceGood                -0.03      0.00    -0.04    -0.02 1.00     1237     2219  # mismatch:Good - mismatch:neutral = -0.03
#ismatch_num                -0.07      0.01    -0.09    -0.06 1.00     1638     1957  # match:neutral - mismatch:neutral = -0.07
#ValenceBad:ismatch_num      0.02      0.01     0.00     0.04 1.00     1597     2380  # match:bad - ValenceBad -ismatch_num = 0.02
#ValenceGood:ismatch_num    -0.05      0.01    -0.07    -0.03 1.00     1424     1775  # match:good - ValenceGood- ismatch_num = -0.05

# Mismatch:Neutral - Intercept = -0.4
# Mismatch:Bad     - Intercept  + ValenceBad = -0.4 + 0.01 = -0.39
# Mismatch:Good    - Intercept  + ValenceGood = -0.4 - 0.03 = -0.43
# Match: Neutral   - Intercept  + ismatch_num = -0.4 - 0.07 = -0.47
# Match: Bad       - Intercept  + ismatch_num + ValenceBad+ ValenceBad:ismatch_num = -0.4 + 0.01 + 0.02 =  -0.37 
# Match: Good      - Intercept  + ismatch_num + ValenceGood+ ValenceGood:ismatch_num = -0.4 + (-0.03) + (-0.05) = -0.48

# Get the variables in the model 1
# RT_var_name_m1 <- tidybayes::get_variables(RT_val_m1)

df_m1_post_rt_exp <- RT_val_m1 %>% 
  tidybayes::spread_draws(r_ExpID_new[condition, term]) %>%
  dplyr::rename(value = r_ExpID_new)

df_rt_m1_pop_mean <- RT_val_m1 %>%
  tidybayes::gather_draws(`b_.*`, regex = TRUE) %>%
  group_by(.variable) %>%       # this line not necessary (done automatically by spread_draws)
  tidybayes::mean_hdci(.value)  # get the high density continuous intervals

# extract the population level parameters
df_rt_m1_pop <- RT_val_m1 %>% 
  tidybayes::gather_draws(`b_.*`, regex = TRUE) %>%
  dplyr::rename(term = .variable,
                pop_mean = .value) %>%
  #tidyr::separate(term, c(NA, 'term'), "_") 
  dplyr::ungroup() %>%
  dplyr::mutate(term = gsub("b_", "", term))

# Add the population mean to the experimental level and only keep the value after.
df_m1_post_rt_exp_update <- merge(df_rt_m1_pop, df_m1_post_rt_exp, 
# rt_post_tmp <- merge(rt_pop_post, df_m1_post_rt_exp, 
                     by = c('term','.chain','.iteration', '.draw'), all = T) %>%
  dplyr::mutate(mean_value = pop_mean + value) %>%  # add the population leve value to each experiment
  dplyr::select(condition, term, `.chain`, `.iteration`, `.draw`, mean_value) %>% # select the added value
  dplyr::rename(value = mean_value)  # rename the value

# Plot the difference between conditions 
df_m1_plot_rt <- df_rt_m1_pop %>%
  dplyr::mutate(condition = 'Overall') %>%
  dplyr::rename(value = pop_mean) %>% # chagne the `pop_mean` as `value` for data frame merge
  dplyr::select(condition, term, `.chain`, `.iteration`, `.draw`, value) %>%
  dplyr::bind_rows(., df_m1_post_rt_exp_update) %>%
  dplyr::mutate(condition = factor(condition, levels = c("Exp1a_THU", "Exp1a_WZU", "Exp1b_THU", 
                                                         "Exp1b_WZU", "Exp1c_THU", "Exp2_THU" , 
                                                         "Exp5_THU",  "Exp6a_THU","Overall")),
                condition = forcats::fct_rev(condition)) %>%
  tidyr::pivot_wider(names_from = c(term), values_from = value) %>%   # long to wide
  dplyr::mutate(Neutral_NM = Intercept,               # calculate the differences between coditions
                Bad_NM = Intercept  + ValenceBad,
                Good_NM = Intercept  + ValenceGood ,
                Neutral_M = Intercept  + ismatch_num,
                Bad_M = Intercept  + ismatch_num + ValenceBad + `ValenceBad:ismatch_num`,
                Good_M = Intercept  + ismatch_num + ValenceGood+ `ValenceGood:ismatch_num`) %>%
  dplyr::select(condition, `.chain`, `.iteration`, `.draw`,
               Neutral_NM, Bad_NM, Good_NM,
               Neutral_M, Bad_M, Good_M) %>%
  tidyr::pivot_longer(cols = Neutral_NM:Good_M, names_to = "term", values_to =  "value") %>%  # wide to long
  dplyr::mutate(term = factor(term, levels = c('Good_NM', 'Neutral_NM', 'Bad_NM',
                                               'Good_M',  'Neutral_M',  'Bad_M')),
                value = exp(value),
                value = value * 1000) 

# plot the posterior of the d prime
# use the overall mean values as the vlines
vlines <- df_m1_plot_rt %>% 
        tidyr::separate(term, c('Valence', 'Match')) %>% 
        dplyr::mutate(Valence = factor(Valence, levels = c('Good', 'Neutral', 'Bad'))) %>%
        dplyr::filter(Match == 'M') %>%
        dplyr::filter(condition == "Overall") %>%
        dplyr::group_by(Valence) %>% 
        dplyr::summarize(Mean = mean(value)) # %>%
        # dplyr::arrange(Mean)

df_m1_rt_fixed_effect <- df_m1_plot_rt %>%
        dplyr::filter(condition == "Overall") %>%
        tidyr::pivot_wider(.,
                           id_cols = c('.chain', '.iteration', '.draw'),
                           names_from = term ) %>% 
        dplyr::select(-c('.chain', '.iteration', '.draw')) %>%
        bayestestR::describe_posterior(.,
                                       ci = 0.95,
                                       ci_method = 'hdi',
                                       test = c("p_direction", "p_significance"),
                                       centrality = "median") %>%
        tidyr::separate(Parameter, c('Valence', 'Match')) %>% 
        dplyr::mutate(Valence = factor(Valence, levels = c('Good', 'Neutral', 'Bad')))

# THIS is the one which the final plot will based on!!!
p_rt1 <- df_m1_plot_rt %>%
        tidyr::separate(term, c('Valence', 'Match')) %>% 
        dplyr::mutate(Valence = factor(Valence, levels = c('Good', 'Neutral', 'Bad'))) %>%
        dplyr::filter(Match == 'M') %>%
        dplyr::rename(Experiments = condition) %>%
        # dplyr::mutate(Experiments = factor(Experiments, levels = c("Exp1b_WZU", "Exp5_THU", "Exp1a_THU", 
        #                                                            "Exp1b_THU", "Exp1c_THU", "Exp2_THU" , 
        #                                                            "Exp1a_WZU",  "Exp6a_THU","Overall")),
        #               Experiments = fct_rev(Experiments)) %>%
        ggplot2::ggplot(aes(y = Experiments, x = value, color = Valence)) +
        tidybayes::stat_halfeye(aes(fill = Valence), alpha = 0.7) +
        geom_vline(data = vlines, aes(xintercept = Mean,colour = Valence), linetype = "dashed") +
        labs(x=expression('Posteior distribution of reaction times')) + 
        scale_colour_brewer(palette = "Dark2") +
        scale_fill_brewer(palette = "Dark2") +
        theme_apa()


df_m1_plot_rt_diff <- df_m1_plot_rt %>%
  tidyr::pivot_wider(names_from = c(term), values_from = value) %>%   # long to wide
  dplyr::mutate(diff_GB_NM = Good_NM - Bad_NM,               # calculate the differences between conditions
                diff_GN_NM = Good_NM - Neutral_NM,
                diff_BN_NM = Bad_NM - Neutral_NM,
                diff_GB_M = Good_M - Bad_M, 
                diff_GN_M = Good_M - Neutral_M,
                diff_BN_M = Bad_M - Neutral_M,) %>%
  dplyr::select(condition, `.chain`, `.iteration`, `.draw`,
               diff_GB_NM,diff_GN_NM, diff_BN_NM,
               diff_GB_M, diff_GN_M, diff_BN_M) %>%
  tidyr::pivot_longer(cols = diff_GB_NM:diff_BN_M, names_to = "term_diff", values_to =  "value") %>%  # wide to long
  dplyr::mutate(term_diff = factor(term_diff, levels = c('diff_GB_NM','diff_GN_NM', 'diff_BN_NM',
                                                         'diff_GB_M', 'diff_GN_M', 'diff_BN_M')))
# 
# df_m1_rt_plot %>% 
#   dplyr::group_by(condition, term_diff, .chain) %>%
#   dplyr::tally()

# df_m1_rt_mean <- df_m1_rt_plot %>%
#   #tidybayes::gather_draws(b_Intercept, b_ValenceBad, b_ValenceGood,
#   #                        `b_ismatch_num`, `b_ValenceBad:ismatch_num`, 
#   #                        `b_ValenceGood:ismatch_num`) %>%
#   group_by(condition, term_diff) %>%       # this line not necessary (done automatically by spread_draws)
#   tidybayes::mean_hdci(value)  # get the high density continuous intervals

# plot the posterior of mismatch
# df_m1_plot_rt_diff  %>%
#   dplyr::filter(str_detect(term_diff, '_NM')) %>%
#   dplyr::filter(!str_detect(term_diff, '_GB_')) %>%
#   ggplot2::ggplot(aes(y = condition, x = value, fill = after_stat(x < 0))) +
#   tidybayes::stat_halfeye() +
#   geom_vline(xintercept = 0, linetype = "dashed") +
#   scale_fill_manual(values = c('gray80', 'skyblue')) + 
#   xlab("Effect (differences) of valence on RT (Mismatch trials)")+
#   facet_wrap( ~ term_diff, 
#               # scales = "free_y", 
#               nrow = 1,
#               labeller = label_parsed)

# plot the posterior of matching trials
p_rt1_diff <- df_m1_plot_rt_diff %>%
  dplyr::filter(str_detect(term_diff, '_M')) %>%
  dplyr::filter(!str_detect(term_diff, '_GB_')) %>%
  ggplot2::ggplot(aes(y = condition, x = value, fill = stat(x < 0))) +
  tidybayes::stat_halfeye() +
  geom_vline(xintercept = 0, linetype = "dashed") +
  # scale_fill_manual(values = c('gray80', 'skyblue')) +
  scale_fill_manual(values = c('skyblue', 'gray80'),
                    breaks = c(TRUE, FALSE),
                    name = "Effect" , labels = c("Yes", "No")) + 
  xlab("Effect of valence on RT (Match trials)") +
  facet_wrap( ~ term_diff,
              # scales = "free_y", 
              nrow = 1,
              labeller = label_parsed)

df_rt1_diff_hdi <- df_m1_plot_rt_diff %>%
        # dplyr::filter(str_detect(term_diff, '_M')) %>%
        dplyr::filter(condition == "Overall") %>%
        tidyr::pivot_wider(.,
                           id_cols = c('.chain', '.iteration', '.draw'),
                           names_from = term_diff) %>%
        dplyr::select(-c('.chain', '.iteration', '.draw')) %>%
        bayestestR::describe_posterior(.,
                                       ci = 0.95,
                                       ci_method = 'hdi',
                                       test = c("p_direction", "p_significance"),
                                       centrality = "median")
```

  <!-- plot all graphs form the first part together -->
  
```{r plot-bayes-meta-1, fig.cap="Effect of moral valence on RT and d'", fig.height=9, fig.width=15, warning=FALSE}
library(patchwork)
p_rt1 + p_dprime1 +
        p_rt1_diff + p_dprime1_diff + plot_annotation(tag_levels = 'A')  + plot_layout(nrow = 2, byrow = TRUE, guides = 'collect')

# p <- p_rt1 + p_dprime1 + plot_annotation(tag_levels = 'A') + plot_layout(guides = "collect") 

#  ggsave('part1_plot_posterior.png', p, width = 15, height = 7.5)
```

For the *d* prime, we found robust effect of moral character. Shapes associated with good character ("good person", "kind person" or a name associated with morally good behavioral history) has higher sensitivity (median = `r df_m1_std_fixed_effect$Median[df_m1_std_fixed_effect$Valence == 'Good' & df_m1_std_fixed_effect$params == 'd prime']`, 95% HDI = [`r df_m1_std_fixed_effect$CI_low[df_m1_std_fixed_effect$Valence == 'Good' & df_m1_std_fixed_effect$params == 'd prime']` `r df_m1_std_fixed_effect$CI_high[df_m1_std_fixed_effect$Valence == 'Good' & df_m1_std_fixed_effect$params == 'd prime']`]) than shapes associated with neutral character (median = `r df_m1_std_fixed_effect$Median[df_m1_std_fixed_effect$Valence == 'Neutral' & df_m1_std_fixed_effect$params == 'd prime']`, 95% HDI = [`r df_m1_std_fixed_effect$CI_low[df_m1_std_fixed_effect$Valence == 'Neutral' & df_m1_std_fixed_effect$params == 'd prime']` `r df_m1_std_fixed_effect$CI_high[df_m1_std_fixed_effect$Valence == 'Neutral' & df_m1_std_fixed_effect$params == 'd prime']`]), $median_{diff}$ = `r df_dprime1_diff_hdi$Median[df_dprime1_diff_hdi$Parameter == 'diff_GN_dprm']`, 95% HDI [`r df_dprime1_diff_hdi$CI_low[df_dprime1_diff_hdi$Parameter == 'diff_GN_dprm']` `r df_dprime1_diff_hdi$CI_high[df_dprime1_diff_hdi$Parameter == 'diff_GN_dprm']`] , but we did not find differences between shapes associated with bad character (median = `r df_m1_std_fixed_effect$Median[df_m1_std_fixed_effect$Valence == 'Bad' & df_m1_std_fixed_effect$params == 'd prime']`, 95% HDI = [`r df_m1_std_fixed_effect$CI_low[df_m1_std_fixed_effect$Valence == 'Bad' & df_m1_std_fixed_effect$params == 'd prime']` `r df_m1_std_fixed_effect$CI_high[df_m1_std_fixed_effect$Valence == 'Bad' & df_m1_std_fixed_effect$params == 'd prime']`]) and neutral character, $median_{diff}$ = `r df_dprime1_diff_hdi$Median[df_dprime1_diff_hdi$Parameter == 'diff_BN_dprm']`, 95% HDI [`r df_dprime1_diff_hdi$CI_low[df_dprime1_diff_hdi$Parameter == 'diff_BN_dprm']` `r df_dprime1_diff_hdi$CI_high[df_dprime1_diff_hdi$Parameter == 'diff_BN_dprm']`].

For the reaction times, we also found robust effect of moral character for both match trials (see figure \@ref(fig:plot-bayes-meta-1) C) and nonmatch trials (**see supplementary materials**). For match trials, shapes associated with good character has faster responses (median = `r df_m1_rt_fixed_effect$Median[df_m1_rt_fixed_effect$Valence == 'Good' & df_m1_rt_fixed_effect$Match == 'M']` ms, 95% HDI = [`r df_m1_rt_fixed_effect$CI_low[df_m1_std_fixed_effect$Valence == 'Good' & df_m1_rt_fixed_effect$Match == 'M']` `r df_m1_rt_fixed_effect$CI_high[df_m1_rt_fixed_effect$Valence == 'Good' & df_m1_rt_fixed_effect$Match == 'M']`]) than shapes associated with neutral character (median = `r df_m1_rt_fixed_effect$Median[df_m1_rt_fixed_effect$Valence == 'Neutral' & df_m1_rt_fixed_effect$Match == 'M']` ms, 95% HDI = [`r df_m1_rt_fixed_effect$CI_low[df_m1_std_fixed_effect$Valence == 'Neutral' & df_m1_rt_fixed_effect$Match == 'M']` `r df_m1_rt_fixed_effect$CI_high[df_m1_rt_fixed_effect$Valence == 'Neutral' & df_m1_rt_fixed_effect$Match == 'M']`]), $median_{diff}$ = `r df_rt1_diff_hdi$Median[df_rt1_diff_hdi$Parameter == 'diff_GN_M']`, 95% HDI [`r df_rt1_diff_hdi$CI_low[df_rt1_diff_hdi$Parameter == 'diff_GN_M']` `r df_rt1_diff_hdi$CI_high[df_rt1_diff_hdi$Parameter == 'diff_GN_M']`]. We also found that the responses to shapes associated with bad character (median = `r df_m1_rt_fixed_effect$Median[df_m1_rt_fixed_effect$Valence == 'Bad' & df_m1_rt_fixed_effect$Match == 'M']` ms, 95% HDI = [`r df_m1_rt_fixed_effect$CI_low[df_m1_std_fixed_effect$Valence == 'Bad' & df_m1_rt_fixed_effect$Match == 'M']` `r df_m1_rt_fixed_effect$CI_high[df_m1_rt_fixed_effect$Valence == 'Bad' & df_m1_rt_fixed_effect$Match == 'M']`]) were slower as compared to the neutral character, $median_{diff}$ = `r df_rt1_diff_hdi$Median[df_rt1_diff_hdi$Parameter == 'diff_BN_M']`, 95% HDI [`r df_rt1_diff_hdi$CI_low[df_rt1_diff_hdi$Parameter == 'diff_BN_M']` `r df_rt1_diff_hdi$CI_high[df_rt1_diff_hdi$Parameter == 'diff_BN_M']`]. See Figure \@ref(fig:plot-bayes-meta-1).

For the nonmatch trials, we also found the advantage of good character: Shapes associated with good character (median = `r df_m1_rt_fixed_effect$Median[df_m1_rt_fixed_effect$Valence == 'Good' & df_m1_rt_fixed_effect$Match == 'NM']` ms, 95% HDI = [`r df_m1_rt_fixed_effect$CI_low[df_m1_std_fixed_effect$Valence == 'Good' & df_m1_rt_fixed_effect$Match == 'NM']` `r df_m1_rt_fixed_effect$CI_high[df_m1_rt_fixed_effect$Valence == 'Good' & df_m1_rt_fixed_effect$Match == 'NM']`]) are faster than shapes associated with neutral (median = `r df_m1_rt_fixed_effect$Median[df_m1_rt_fixed_effect$Valence == 'Neutral' & df_m1_rt_fixed_effect$Match == 'NM']` ms, 95% HDI = [`r df_m1_rt_fixed_effect$CI_low[df_m1_std_fixed_effect$Valence == 'Neutral' & df_m1_rt_fixed_effect$Match == 'NM']` `r df_m1_rt_fixed_effect$CI_high[df_m1_rt_fixed_effect$Valence == 'Neutral' & df_m1_rt_fixed_effect$Match == 'NM']`]), $median_{diff}$ = `r df_rt1_diff_hdi$Median[df_rt1_diff_hdi$Parameter == 'diff_GN_NM']` ms, 95% HDI [`r df_rt1_diff_hdi$CI_low[df_rt1_diff_hdi$Parameter == 'diff_GN_NM']` `r df_rt1_diff_hdi$CI_high[df_rt1_diff_hdi$Parameter == 'diff_GN_NM']`]. Similarly, the shapes associated with bad character (median = `r df_m1_rt_fixed_effect$Median[df_m1_rt_fixed_effect$Valence == 'Bad' & df_m1_rt_fixed_effect$Match == 'NM']` ms, 95% HDI = [`r df_m1_rt_fixed_effect$CI_low[df_m1_std_fixed_effect$Valence == 'Bad' & df_m1_rt_fixed_effect$Match == 'NM']` `r df_m1_rt_fixed_effect$CI_high[df_m1_rt_fixed_effect$Valence == 'Bad' & df_m1_rt_fixed_effect$Match == 'NM']`]) was responded slower than shapes associated with neutral character, $median_{diff}$ = `r df_rt1_diff_hdi$Median[df_rt1_diff_hdi$Parameter == 'diff_BN_M']` ms, 95% HDI [`r df_rt1_diff_hdi$CI_low[df_rt1_diff_hdi$Parameter == 'diff_BN_M']` `r df_rt1_diff_hdi$CI_high[df_rt1_diff_hdi$Parameter == 'diff_BN_M']`], but the effect size was smaller, (**see supplementary materials**).

```{r model comp for rt, eval = FALSE, echo=FALSE, results='hide' }
#### model copmarison etc, will be in supplementary materials
# 
# log normal distribution, dummy coding
RT_val_m2 <- df_moral %>%
  dplyr::mutate(RT_sec = RT/1000) %>% # log RT in seconds
  dplyr::filter(ACC == 1) %>%
  brms::brm(RT_sec ~ Valence*ismatch + 
              (Valence*ismatch | ExpID_new) +   
              (Valence*ismatch | ExpID_new:Subject),
            family=lognormal(),
            data = .,
            control = list(adapt_delta = .98),
            cores = parallel::detectCores(),
            backend = 'cmdstanr',  # with cmdstanr
            file = here::here("glmmModels/RT_val_EffectCode_3_level_m2"))
summary(RT_val_m2)

# log normal distribution, with truncated distribution, , dummy coding
RT_val_m3_trunc <- df_moral %>%
  dplyr::mutate(RT_sec = RT/1000) %>% # log RT in seconds
  dplyr::filter(ACC == 1) %>%
  brms::brm(RT_sec|trunc(lb = 0.2, ub = 1.1) ~ Valence*ismatch + 
              (Valence*ismatch | ExpID_new) +   
              (Valence*ismatch | ExpID_new:Subject),
            family=lognormal(),
            data = .,
            control = list(adapt_delta = .98),
            cores = parallel::detectCores(),
            file = here::here("glmmModels/RT_val_EffectCode_3_level_m3_trunc"))
summary(RT_val_m3_trunc)
pp_check(RT_val_m3_trunc)
#plot(RT_val_m3_trunc, "b_")

# compare three models
loo(RT_val_m1, RT_val_m2, RT_val_m3_trunc) # takes about XX mins
bayes_factor(RT_val_m1,RT_val_m2)
# Monte Carlo SE of elpd_loo is 0.4.

#All Pareto k estimates are good (k < 0.5).
#See help('pareto-k-diagnostic') for details.

#Model comparisons:
#                elpd_diff se_diff
#RT_val_m1          0.0       0.0 
#RT_val_m2         -5.6       3.3 
#RT_val_m3_trunc -590.6      34.8 

# Get the variables in the model 3
RT_var_name_m3 <- tidybayes::get_variables(RT_val_m3_trunc)

df_m3_post_rt_exp <- RT_val_m3_trunc %>% 
  tidybayes::spread_draws(r_ExpID_new[condition, term]) %>%
  dplyr::rename(value = r_ExpID_new)

rt_pop_mean <- RT_val_m3_trunc %>%
  tidybayes::gather_draws(b_Intercept, b_ValenceBad, b_ValenceGood,
                          `b_ismatch`, `b_ValenceBad:ismatch`, 
                          `b_ValenceGood:ismatch`) %>%
  group_by(.variable) %>%       # this line not necessary (done automatically by spread_draws)
  tidybayes::mean_hdci(.value)  # get the high density continuous intervals

# extract the population level parameters
rt_pop_post <- RT_val_m3_trunc %>% 
  tidybayes::gather_draws(b_Intercept, b_ValenceBad, b_ValenceGood,
                          `b_ismatch`, `b_ValenceBad:ismatch`, 
                          `b_ValenceGood:ismatch`) %>%
  dplyr::rename(term = .variable,
                pop_mean = .value) %>%
  #tidyr::separate(term, c(NA, 'term'), "_") 
  dplyr::ungroup() %>%
  dplyr::mutate(term = gsub("b_", "", term))

# Add the population mean to the experimental level and only keep the value after.
rt_post_tmp <- merge(rt_pop_post, df_m3_post_rt_exp, 
                     by = c('term','.chain','.iteration', '.draw'), all = T) %>%
  dplyr::mutate(mean_value = pop_mean + value) %>%  # add the population leve value to each experiment
  dplyr::select(condition, term, `.chain`, `.iteration`, `.draw`, mean_value) %>% # select the added value
  dplyr::rename(value = mean_value)  # rename the value

# Plot the difference between conditions 
df_m3_rt_plot <- rt_pop_post %>%
  dplyr::mutate(condition = 'Overall') %>%
  dplyr::rename(value = pop_mean) %>%
  dplyr::select(condition, term, `.chain`, `.iteration`, `.draw`, value) %>%
  dplyr::bind_rows(., rt_post_tmp) %>%
  dplyr::mutate(condition = factor(condition, levels = c("Exp1a_THU", "Exp1a_WZU", "Exp1b_THU", 
                                                         "Exp1b_WZU", "Exp1c_THU", "Exp2_THU" , 
                                                         "Exp5_THU",  "Exp6a_THU","Overall")),
                condition = forcats::fct_rev(condition)#, # reverse the order b/c plot function auto reverse.
                ) %>%
  tidyr::pivot_wider(names_from = c(term), values_from = value) %>%   # long to wide
  dplyr::mutate(diff_GB_NM = ValenceGood - ValenceBad,               # calculate the differences between coditions
                diff_GN_NM = ValenceGood,
                diff_BN_NM = ValenceBad,
                diff_GN_M = ValenceGood + `ValenceGood:ismatch`,
                diff_BN_M = ValenceBad + `ValenceBad:ismatch`,
                diff_GB_M = diff_GN_M - diff_BN_M) %>%
  dplyr::select(condition, `.chain`, `.iteration`, `.draw`,
               diff_GB_NM,diff_GN_NM, diff_BN_NM,
               diff_GB_M, diff_GN_M, diff_BN_M) %>%
  tidyr::pivot_longer(cols = diff_GB_NM:diff_BN_M, names_to = "term_diff", values_to =  "value") %>%  # wide to long
  dplyr::mutate(term_diff = factor(term_diff, levels = c('diff_GB_NM','diff_GN_NM', 'diff_BN_NM',
                                                         'diff_GB_M', 'diff_GN_M', 'diff_BN_M')))

df_m3_rt_plot %>% 
  dplyr::group_by(condition, term_diff, .chain) %>%
  dplyr::tally()

df_m3_rt_mean <- df_m3_rt_plot %>%
  group_by(condition, term_diff) %>%       # this line not necessary (done automatically by spread_draws)
  tidybayes::mean_hdci(value)  # get the high density continuous intervals


# plot the posterior of mismatch
df_m3_rt_plot  %>%
  dplyr::filter(str_detect(term_diff, '_NM')) %>%
  ggplot2::ggplot(aes(y = condition, x = value, fill = after_stat(x < 0))) +
  tidybayes::stat_halfeyeh() +
  geom_vline(xintercept = 0, linetype = "dashed") +
  scale_fill_manual(values = c('gray80', 'skyblue')) + 
  facet_wrap( ~ term_diff,
               scales = "free_y", nrow = 1,
               labeller = label_parsed)

# plot the posterior of matching trials
df_m3_rt_plot %>%
  dplyr::filter(str_detect(term_diff, '_M')) %>%
  ggplot2::ggplot(aes(y = condition, x = value, fill = after_stat(x < 0))) +
  tidybayes::stat_halfeyeh() +
  geom_vline(xintercept = 0, linetype = "dashed") +
  scale_fill_manual(values = c('gray80', 'skyblue')) + 
  facet_wrap( ~ term_diff,
               scales = "free_y", nrow = 1,
               labeller = label_parsed)
```

## Self-referential process modulates prioritization of good character

In this part, we report results from three experiments (3a, 3b, and 6b) that aimed at testing whether the moral valence effect found in the previous experiments is modulated by self-referential processes. These three experiments included  data from 108 participants. 

Because we have found that a facilitation effect of good character and slow-down effect of bad character in the first part, in this part, we will focus on the whether such effect interact with self-referential factor. In others words, we not only reported differences between good/bad character with neutral character for self-referential and other-referential separately, but also compare the differences between the difference. For details of individual studies, please see supplementary materials.

```{r prepare data for second meta, echo=FALSE, results='hide', warning=FALSE}
### try meta-analysis 1a, 1b, 1c, 2, 5 and 6a
selected_columns <- c('ExpID', 'Site', 'Subject','Age', 'Sex', 'Matchness', 'Identity', 'Valence', 'RESP', 'ACC','RT')
df_ms <- dplyr::bind_rows(df3a.v_meta[selected_columns],
                          df3b.v_meta[selected_columns],
                          df6b.v_meta[selected_columns]) %>%
  dplyr::mutate(ExpID_new = paste(ExpID, Site, sep = "_")) %>%
  dplyr::mutate(Valence = factor(Valence, levels = c('Neutral', 'Bad', 'Good')))

df_ms_subj <- df_ms %>%
  dplyr::group_by(ExpID_new, Site) %>%
  dplyr::summarize(N = n_distinct(Subject),
                   N_trial = length(Subject),
                   Exp_conds = 6,
                   trial_per_cond = round((length(Subject)/6)/N, 0))

df_ms <- df_ms %>%
  dplyr::filter(!is.na(RESP)) %>% # filter trials without response
  dplyr::mutate(ismatch = ifelse(Matchness == 'Match', 1, 0),
                saymatch = ifelse((Matchness == 'Match' & ACC == 1) | 
                                    (Matchness == 'Mismatch' & ACC == 0), 1, 0),
                Valence = factor(Valence, levels = c('Neutral', 'Bad', 'Good')),
                Identity = factor(Identity, levels = c('Self', 'Other'))) %>%
  dplyr::select(ExpID_new, Subject, Matchness, Identity,Valence, RESP, ACC, RT, ismatch, saymatch) %>%
  dplyr::mutate(ismatch_num = ifelse(Matchness == 'Match', 0.5, -0.5))

# plot the nested structure of the data
# with(df_ms, table(Subject, ExpID_new)) %>%
#   image(
#     col = grey.colors(80, start = 1, end = 0), 
#     axes = TRUE, 
#     xlab = "Subject", 
#     ylab = "ExpID"
#   )
```

```{r second meta sdt, echo=FALSE, results='hide', warning=FALSE}
# fit a three-level hierarchical model for SDT of moral self, didn't specify the prior; dummy coding
# 
# Note: initialization failed for a few times for full model. need to re-consider the model
sdt_ms_m1 <- df_ms %>%
        dplyr::mutate(Subject = as.factor(Subject),
                      ExpID_new = as.factor(ExpID_new)) %>%
        brms::brm(saymatch ~ 0 + Identity:Valence + ismatch:Identity:Valence + 
                          (0 + Identity:Valence + ismatch:Identity:Valence | ExpID_new) + 
                          (0 + Identity:Valence + ismatch:Identity:Valence | ExpID_new:Subject),
                  family = bernoulli(link="probit"),
                  data = .,
                  chains = 6,
                  iter = 4000,
                  thin = 2,
                  control = list(adapt_delta = .90),
                  cores = parallel::detectCores(),
                  backend = 'cmdstanr',  # with cmdstanr
                  file = here::here("glmmModels/sdt_ms_DummyCode_3_level"))

# summary(sdt_ms_m1)

# # Get the variables in the model
var_name_m1 <- tidybayes::get_variables(sdt_ms_m1)

# # get the variable names start with 'b_', i.e., the population level parameters
pop_param_names <- grep('^b_.', var_name_m1, value = TRUE)

# plot the population level parameter (d prime)
sdt_ms_m1_p <- sdt_ms_m1 %>%
  # get the traces of population level parameters
  tidybayes::gather_draws(`b_.*`, regex = TRUE) %>%
  # create two columns for two independent factors.
  dplyr::mutate(Valence = dplyr::case_when(grepl("Neutral", .variable) ~ "Neutral",
                                           grepl("Bad", .variable) ~"Bad",
                                           grepl("Good", .variable) ~"Good"),
                Identity = dplyr::case_when(grepl("Self", .variable) ~ "Self",
                                           grepl("Other", .variable) ~"Other"),
                params = dplyr::case_when(grepl("ismatch", .variable) ~ "d prime",
                                           !grepl("ismatch", .variable) ~"criterion"),
                params = factor(params, levels = c('d prime', 'criterion')),
                Identity = factor(Identity, levels = c("Self", "Other")),
                Valence = factor(Valence, levels = c('Good', 'Neutral',  'Bad'))) %>%
  # select only d prime
  dplyr::filter(params == 'd prime') %>%
  ggplot2::ggplot(aes(x = Valence, y = .value)) +
  tidybayes::stat_halfeye(aes(fill = Identity), alpha = 0.7) + # position=position_dodge(width = 0.1)
  geom_slabinterval(ymin = 0, ymax = 4) +
  stat_summary(aes(group = Identity, color = Identity), fun = mean, geom = "line") +
  ylab(expression(paste("Sensitivity ", italic("d'"), sep = ' '))) +
  # ylim(0, 4) +
  # xlab("Valence") +
  #facet_grid(cols = vars(Identity)) + # , scales = "free_y"
  theme_classic() # + 
  # theme(axis.title.x = element_blank())

#### plot both overall parameters and experimental levels.

df_ms_sdt_m1_post_exp <- sdt_ms_m1 %>% 
  tidybayes::spread_draws(r_ExpID_new[condition, term]) %>%
  dplyr::rename(value = r_ExpID_new)

df_ms_sdt_m1_pop_mean <- sdt_ms_m1 %>%
  tidybayes::gather_draws(`b_.*`, regex = TRUE) %>%
  group_by(.variable) %>%       # this line not necessary (done automatically by spread_draws)
  tidybayes::mean_hdci(.value)  # get the high density continuous intervals

# extract the population level parameters
df_ms_sdt_m1_pop <- sdt_ms_m1 %>% 
  tidybayes::gather_draws(`b_.*`, regex = TRUE) %>%
  dplyr::rename(term = .variable,
                pop_mean = .value) %>%
  #tidyr::separate(term, c(NA, 'term'), "_") 
  dplyr::ungroup() %>%
  dplyr::mutate(term = gsub("b_", "", term))

# Add the population mean to the experimental level and only keep the value after.
df_ms_sdt_m1_post_exp_update <- merge(df_ms_sdt_m1_pop, df_ms_sdt_m1_post_exp, by = c('term','.chain','.iteration', '.draw'), all = T) %>%
  dplyr::mutate(mean_value = pop_mean + value) %>%  # add the population level value to each experiment
  dplyr::select(condition, term, `.chain`, `.iteration`, `.draw`, mean_value) %>% # select the added value
  dplyr::rename(value = mean_value)  # rename the value

# Plot the difference between conditions 
df_ms_sdt_m1_plot <- df_ms_sdt_m1_pop %>%
  dplyr::mutate(condition = 'Overall') %>%
  dplyr::rename(value = pop_mean) %>%
  dplyr::select(condition, term, `.chain`, `.iteration`, `.draw`, value) %>%
  dplyr::bind_rows(., df_ms_sdt_m1_post_exp_update) %>%
  dplyr::mutate(condition = factor(condition, levels = c("Exp3a_THU", "Exp3b_WZU", "Exp6b_THU",
                                                         "Overall")),
                condition = forcats::fct_rev(condition), # reverse the order because the plot function auto reverse.
                Valence = dplyr::case_when(grepl("Neutral", term) ~ "Neutral",
                                           grepl("Bad", term) ~"Bad",
                                           grepl("Good", term) ~"Good"),
                Identity = dplyr::case_when(grepl("Self", term) ~ "Self",
                                           grepl("Other", term) ~"Other"),
                params = dplyr::case_when(grepl("ismatch", term) ~ "dprime",
                                           !grepl("ismatch", term) ~"c"),
                params = factor(params, levels = c('dprime', 'c')),
                Identity = factor(Identity, levels = c("Self", "Other")),
                Valence = factor(Valence, levels = c('Good', 'Neutral',  'Bad'))
                ) 

# plot the posterior of the d prime
# use the overall mean values as the vlines
p_ms_sdt_vlines <- df_ms_sdt_m1_plot %>% 
        #tidyr::separate(term, c('params', 'Identity', 'Valence')) %>% 
        dplyr::mutate(Valence = factor(Valence, levels = c('Good', 'Neutral', 'Bad'))) %>%
        dplyr::filter(params == 'dprime') %>%
        dplyr::filter(condition == "Overall") %>%
        dplyr::group_by(Identity, Valence) %>% 
        dplyr::summarize(Mean = mean(value)) # %>%
        # dplyr::arrange(Mean)

# THIS is the one which the final plot will based on!!!
p_ms_dprime1 <- df_ms_sdt_m1_plot %>%
        # tidyr::separate(term, c('params', 'Valence')) %>%
        dplyr::mutate(Valence = factor(Valence, levels = c('Good', 'Neutral', 'Bad')),
                      Identity = factor(Identity, levels = c("Self", "Other"))) %>%
        dplyr::filter(params == 'dprime') %>%
        dplyr::rename(Experiments = condition) %>%
        dplyr::filter((value >= 0) & (value <= 4)) %>%  # limit the x-axis's value
        ggplot2::ggplot(aes(y = Experiments, x = value, color = Valence)) +
        tidybayes::stat_halfeye(aes(fill = Valence), alpha = 0.7) +
        facet_wrap(~Identity) + 
        geom_vline(data = p_ms_sdt_vlines, aes(xintercept = Mean,colour = Valence), linetype = "dashed") +
        labs(x=expression('Posteior distribution of '~italic(d)~' prime')) + 
        theme_apa()

# plot the posterior of the difference between d prime
df_ms_sdt_m1_plot_diff <- df_ms_sdt_m1_plot %>%
        tidyr::unite(term, c('params', 'Identity', 'Valence')) %>%
        tidyr::pivot_wider(names_from = c(term), values_from = value) %>%   # long to wide
        dplyr::mutate(
                # diff_GN_c_S = c_Self_Good - c_Self_Neutral,
                # diff_BN_c_S = c_Self_Bad - c_Self_Neutral,
                # diff_GN_c_O = c_Other_Good - c_Other_Neutral,
                # diff_BN_c_O = c_Other_Bad - c_Other_Neutral,
                diff_GN_dprm_S = dprime_Self_Good - dprime_Self_Neutral,
                diff_BN_dprm_S = dprime_Self_Bad - dprime_Self_Neutral,
                diff_GN_dprm_O = dprime_Other_Good - dprime_Other_Neutral,
                diff_BN_dprm_O = dprime_Other_Bad - dprime_Other_Neutral,
                diff_SO_dprm_G = dprime_Self_Good - dprime_Other_Good,
                diff_SO_dprm_N =  dprime_Self_Neutral - dprime_Other_Neutral,
                diff_SO_dprm_B =  dprime_Self_Bad - dprime_Other_Bad,
                diff_diff_GN = diff_GN_dprm_S - diff_GN_dprm_O,
                diff_diff_BN = diff_BN_dprm_S - diff_BN_dprm_O
                ) %>%
  dplyr::select(condition, `.chain`, `.iteration`, `.draw`,
               diff_GN_dprm_S, diff_BN_dprm_S, diff_GN_dprm_O, diff_BN_dprm_O,
               diff_SO_dprm_G, diff_SO_dprm_N, diff_SO_dprm_B, diff_diff_GN, diff_diff_BN) 

df_ms_dprm1_diff_diff <- df_ms_sdt_m1_plot_diff %>%
        tidyr::pivot_longer(cols = diff_GN_dprm_S:diff_diff_BN, names_to = "term_diff", values_to =  "value") %>%  # wide to long
        dplyr::filter(str_detect(term_diff, 'diff_diff')) %>%
        dplyr::mutate(term_diff = factor(term_diff, levels = c('diff_diff_GN', 'diff_diff_BN'))) %>% 
        dplyr::filter(condition == "Overall") %>%
        tidyr::pivot_wider(.,
                           id_cols = c('.chain', '.iteration', '.draw'),
                           names_from = term_diff) %>%
        dplyr::select(-c('.chain', '.iteration', '.draw')) %>%
        bayestestR::describe_posterior(.,
                                       ci = 0.95,
                                       ci_method = 'hdi',
                                       test = c("p_direction", "p_significance"),
                                       centrality = "median")

p_ms_dprime1_diff_val <- df_ms_sdt_m1_plot_diff %>%
        tidyr::pivot_longer(cols = diff_GN_dprm_S:diff_diff_BN, names_to = "term_diff", values_to =  "value") %>%  # wide to long
        dplyr::filter(str_detect(term_diff, '_dprm_S|_dprm_O')) %>%
        dplyr::mutate(term_diff = factor(term_diff, levels = c('diff_GN_dprm_S', 'diff_BN_dprm_S', 
                                                               'diff_GN_dprm_O', 'diff_BN_dprm_O'))) %>%
        dplyr::filter((value >= -1.5) & (value <= 1.5)) %>%
        dplyr::rename(Experiments = condition) %>%
        ggplot2::ggplot(aes(y = Experiments, x = value, fill = after_stat(x > 0))) +
        tidybayes::stat_halfeye() +
        geom_vline(xintercept = 0, linetype = "dashed") +
        scale_fill_manual(values = c('skyblue', 'gray80'),
                    breaks = c(TRUE, FALSE),
                    name = "Effect" , labels = c("Yes", "No")) + 
        # scale_fill_manual(values = c('gray80', 'skyblue')) +
        xlab(expression(paste("Valence effect on ", italic("d"), " prime", sep = ' '))) + 
        facet_wrap( ~ term_diff, # scales = "free_y",
               nrow = 1,
               labeller = label_parsed)

df_ms_dprm1_diff_val <- df_ms_sdt_m1_plot_diff %>%
        tidyr::pivot_longer(cols = diff_GN_dprm_S:diff_diff_BN, names_to = "term_diff", values_to =  "value") %>%  # wide to long
        dplyr::filter(str_detect(term_diff, '_dprm_S|_dprm_O')) %>%
        dplyr::filter(condition == "Overall") %>%
        tidyr::pivot_wider(.,
                           id_cols = c('.chain', '.iteration', '.draw'),
                           names_from = term_diff) %>%
        dplyr::select(-c('.chain', '.iteration', '.draw')) %>%
        bayestestR::describe_posterior(.,
                                       ci = 0.95,
                                       ci_method = 'hdi',
                                       test = c("p_direction", "p_significance"),
                                       centrality = "median")

p_ms_dprime1_diff_id <- df_ms_sdt_m1_plot_diff %>%
        tidyr::pivot_longer(cols = diff_GN_dprm_S:diff_diff_BN, names_to = "term_diff", values_to =  "value") %>%  # wide to long
        dplyr::filter(str_detect(term_diff, '_SO_')) %>%
        dplyr::mutate(term_diff = factor(term_diff, levels = c('diff_SO_dprm_G', 'diff_SO_dprm_N', 'diff_SO_dprm_B'))) %>%
        #dplyr::filter(!str_detect(term_diff, '_GB_')) %>%
        # tidyr::unite(term_diff, c('Identity', 'term_diff')) %>%
        dplyr::filter((value >= -1.5) & (value <= 1.5)) %>%
        dplyr::rename(Experiments = condition) %>%
        ggplot2::ggplot(aes(y = Experiments, x = value, fill = after_stat(x > 0))) +
        tidybayes::stat_halfeye() +
        geom_vline(xintercept = 0, linetype = "dashed") +
        scale_fill_manual(values = c('skyblue', 'gray80'),
                    breaks = c(TRUE, FALSE),
                    name = "Effect" , labels = c("Yes", "No")) + 
        # scale_fill_manual(values = c('gray80', 'skyblue')) +
        xlab(expression(paste("Self-referential effect on ", italic("d"), " prime", sep = ' '))) + 
        facet_wrap( ~ term_diff, # scales = "free_y",
               nrow = 1,
               labeller = label_parsed)

df_ms_dprm1_diff_id <- df_ms_sdt_m1_plot_diff %>%
        tidyr::pivot_longer(cols = diff_GN_dprm_S:diff_diff_BN, names_to = "term_diff", values_to =  "value") %>%  # wide to long
        dplyr::filter(str_detect(term_diff, '_SO_')) %>%
#        dplyr::filter(str_detect(term_diff, '_dprm_S|_dprm_O')) %>%
        dplyr::filter(condition == "Overall") %>%
        tidyr::pivot_wider(.,
                           id_cols = c('.chain', '.iteration', '.draw'),
                           names_from = term_diff) %>%
        dplyr::select(-c('.chain', '.iteration', '.draw')) %>%
        bayestestR::describe_posterior(.,
                                       ci = 0.95,
                                       ci_method = 'hdi',
                                       test = c("p_direction", "p_significance"),
                                       centrality = "median")
# plot the posterior of difference between c, supplementary figure
# df_ms_sdt_m1_plot_diff %>%
#   dplyr::filter(str_detect(term_diff, '_c')) %>%
#   dplyr::filter(!str_detect(term_diff, '_GB_')) %>%
#   dplyr::filter(!str_detect(term_diff, '_GB_')) %>%
#   tidyr::unite(term_diff, c('Identity', 'term_diff')) %>%
#   dplyr::filter((value >= -1.5) & (value <= 1.5)) %>%
#   ggplot2::ggplot(aes(y = condition, x = value, fill = after_stat(x > 0))) +
#   tidybayes::stat_halfeye() +
#   geom_vline(xintercept = 0, linetype = "dashed") +
#   scale_fill_manual(values = c('gray80', 'skyblue')) +
#   xlab(expression(paste("Valence effect on", italic("d"), "prime", sep = ' ')))+ 
#   expand_limits(x = c(-3, 3)) + 
#   facet_wrap( ~ term_diff, # scales = "free_y",
#                nrow = 1,
#                labeller = label_parsed) 
```

```{r second meta rt, echo=FALSE, results='hide', warning=FALSE}
# fit a three-level hierarchical model for RT, didn't specify the prior, shifted_lognormal, effective coding
RT_ms_m1 <- df_ms %>%
  dplyr::mutate(RT_sec = RT/1000) %>% # log RT in seconds
  dplyr::filter(ACC == 1) %>%         # only correct trials
  brms::brm(RT_sec ~ ismatch*Identity*Valence + 
              (ismatch*Identity*Valence | ExpID_new) +   
              (ismatch*Identity*Valence | ExpID_new:Subject),
            family=shifted_lognormal(),
            data = .,
            chains = 6,
            control = list(adapt_delta = .90),
            # iter = 4000,
            # thin = 2,
            cores = parallel::detectCores(),
            backend = 'cmdstanr',  # with cmdstanr
            file = here::here("glmmModels/RT_ms_DummyCode_3_level"))

# summary(RT_ms_m1)  # ndt = 0 there fore, we used lognormal.
# pp_check(RT_val_m1)

# Population-Level Effects: 
#                                   Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
# Intercept                            -0.21      0.41    -0.97     0.80 1.02      118      307
# ismatch                              -0.08      0.06    -0.21     0.04 1.06       92      252
# IdentityOther                        -0.04      0.10    -0.29     0.13 1.07       84      134
# ValenceBad                            0.00      0.02    -0.05     0.05 1.05       87       29
# ValenceGood                          -0.04      0.17    -0.55     0.11 1.07       57       37
# ismatch:IdentityOther                -0.09      0.39    -0.95     0.73 1.07       88       28
# ismatch:ValenceBad                    0.01      0.08    -0.17     0.17 1.04      279      274
# ismatch:ValenceGood                  -0.07      0.03    -0.13     0.01 1.06       71       96
# IdentityOther:ValenceBad             -0.00      0.05    -0.09     0.13 1.10       48      140
# IdentityOther:ValenceGood             0.01      0.29    -0.64     0.79 1.14       80       55
# ismatch:IdentityOther:ValenceBad      0.03      0.06    -0.09     0.20 1.05      115       87
# ismatch:IdentityOther:ValenceGood     0.07      0.23    -0.47     0.46 1.03      237      189

# Mismatch:Neutral:Self  - Intercept = -0.21
# Mismatch:Bad:Self      - Intercept  + ValenceBad    = -0.21 + 0.00 = -0.21
# Mismatch:Good:Self     - Intercept  + ValenceGood   = -0.21 - 0.04 = -0.25
# Mismatch:Neutral:Other - Intercept  + IdentityOther = -0.21 - 0.04 = -0.25
# Mismatch:Bad:Other     - Intercept  + ValenceBad  + IdentityOther:ValenceBad  = -0.21 + 0.00 + 0.00 = -0.21
# Mismatch:Good:Other    - Intercept  + ValenceGood + IdentityOther:ValenceGood = -0.21 - 0.04 + 0.01 = -0.24
# Match: Neutral:Self    - Intercept  + ismatch = -0.19 - 0.08 = -0.27
# Match: Bad:Self        - Intercept  + ismatch + ismatch:ValenceBad    = -0.19 - 0.08 + 0.01 = -0.26 
# Match: Good:Self       - Intercept  + ismatch + ismatch:ValenceGood   = -0.19 - 0.08 - 0.07 = -0.34
# Match: Neutral:Other   - Intercept  + ismatch + ismatch:IdentityOther = -0.19 - 0.08 - 0.09 = -0.36
# Match: Bad:Other       - Intercept  + ismatch + ismatch:IdentityOther + ismatch:IdentityOther:ValenceBad  = -0.19 - 0.08 - 0.09 + 0.03 = -0.33 
# Match: Good:Other      - Intercept  + ismatch + ismatch:IdentityOther + ismatch:IdentityOther:ValenceGood = -0.19 - 0.08 - 0.09 + 0.07 = -0.29

# Get the variables in the model 1
# RT_var_name_m1 <- tidybayes::get_variables(RT_val_m1)

df_ms_m1_post_rt_exp <- RT_ms_m1 %>% 
  tidybayes::spread_draws(r_ExpID_new[condition, term]) %>%
  dplyr::rename(value = r_ExpID_new)

df_ms_m1_rt_pop_mean <- RT_ms_m1 %>%
  tidybayes::gather_draws(`b_.*`, regex = TRUE) %>%
  group_by(.variable) %>%       # this line not necessary (done automatically by spread_draws)
  tidybayes::mean_hdci(.value)  # get the high density continuous intervals

# extract the population level parameters
df_ms_m1_rt_pop <- RT_ms_m1 %>% 
  tidybayes::gather_draws(`b_.*`, regex = TRUE) %>%
  dplyr::rename(term = .variable,
                pop_mean = .value) %>%
  #tidyr::separate(term, c(NA, 'term'), "_") 
  dplyr::ungroup() %>%
  dplyr::mutate(term = gsub("b_", "", term))

# Add the population mean to the experimental level and only keep the value after.
df_ms_m1_rt_exp_update <- merge(df_ms_m1_rt_pop, df_ms_m1_post_rt_exp, 
# rt_post_tmp <- merge(rt_pop_post, df_m1_post_rt_exp, 
                     by = c('term','.chain','.iteration', '.draw'), all = T) %>%
  dplyr::mutate(mean_value = pop_mean + value) %>%  # add the population leve value to each experiment
  dplyr::select(condition, term, `.chain`, `.iteration`, `.draw`, mean_value) %>% # select the added value
  dplyr::rename(value = mean_value)  # rename the value

# Plot the difference between conditions 
df_ms_m1_plot_rt <- df_ms_m1_rt_pop %>%
        dplyr::mutate(condition = 'Overall') %>%
        dplyr::rename(value = pop_mean) %>% # chagne the `pop_mean` as `value` for data frame merge
        dplyr::select(condition, term, `.chain`, `.iteration`, `.draw`, value) %>%
        dplyr::bind_rows(., df_ms_m1_rt_exp_update) %>%
        dplyr::mutate(condition = factor(condition, levels = c("Exp3a_THU", "Exp3b_WZU", "Exp6b_THU",
                                                               "Overall")),
  # dplyr::mutate(condition = factor(condition, levels = c("Exp1a_THU", "Exp1a_WZU", "Exp1b_THU", 
  #                                                        "Exp1b_WZU", "Exp1c_THU", "Exp2_THU" , 
  #                                                        "Exp5_THU",  "Exp6a_THU","Overall")),
                      condition = forcats::fct_rev(condition)) %>%
        tidyr::pivot_wider(names_from = c(term), values_from = value) %>%   # long to wide
        dplyr::mutate(NM_Self_Neutral = Intercept,               # calculate the differences between conditions
                      NM_Self_Bad = Intercept  + ValenceBad,
                      NM_Self_Good = Intercept  + ValenceGood ,
                      NM_Other_Neutral = Intercept  + IdentityOther,               # calculate the differences between conditions
                      NM_Other_Bad = Intercept  + ValenceBad  + `IdentityOther:ValenceBad`,
                      NM_Other_Good = Intercept  + ValenceGood + `IdentityOther:ValenceGood`,
                      M_Self_Neutral = Intercept  + ismatch,
                      M_Self_Bad = Intercept  + ismatch + `ismatch:ValenceBad`,
                      M_Self_Good = Intercept  + ismatch + `ismatch:ValenceGood`,
                      M_Other_Neutral = Intercept  + ismatch + `ismatch:IdentityOther`,
                      M_Other_Bad = Intercept  + ismatch + `ismatch:IdentityOther` + `ismatch:IdentityOther:ValenceBad`,
                      M_Other_Good = Intercept  + ismatch + `ismatch:IdentityOther` + `ismatch:IdentityOther:ValenceGood`) %>%
        dplyr::select(condition, `.chain`, `.iteration`, `.draw`,
               contains('M_')) %>%
  tidyr::pivot_longer(cols = NM_Self_Neutral:M_Other_Good, names_to = "term", values_to =  "value") %>%  # wide to long
  dplyr::mutate(term = factor(term, levels = c('NM_Self_Neutral', 'NM_Self_Bad', 'NM_Self_Good',
                                               'NM_Other_Neutral', 'NM_Other_Bad', 'NM_Other_Good',
                                               'M_Self_Neutral', 'M_Self_Bad', 'M_Self_Good',
                                               'M_Other_Neutral', 'M_Other_Bad', 'M_Other_Good')),
                value = exp(value),
                value = value * 1000) 

# plot the posterior of the d prime
# use the overall mean values as the vlines
p_ms_rt1_vlines <- df_ms_m1_plot_rt %>% 
        tidyr::separate(term, c('Match', 'Identity', 'Valence')) %>% 
        dplyr::mutate(Valence = factor(Valence, levels = c('Good', 'Neutral', 'Bad')),
                      Identity = factor(Identity, levels = c("Self", "Other"))) %>%
        dplyr::filter(Match == 'M') %>%
        dplyr::filter(condition == "Overall") %>%
        dplyr::filter((value >=200) & (value <=1200)) %>%
        dplyr::group_by(Identity, Valence) %>% 
        tidybayes::median_hdci(value)
        #dplyr::summarize(Mean = mean(value)) # %>%
        # dplyr::arrange(Mean)

# THIS is the one which the final plot will based on!!!
p_ms_rt1 <- df_ms_m1_plot_rt %>%
        tidyr::separate(term, c('Match', 'Identity', 'Valence')) %>% 
        dplyr::mutate(Valence = factor(Valence, levels = c('Good', 'Neutral', 'Bad')),
                      Identity = factor(Identity, levels = c("Self", "Other"))) %>%
        dplyr::filter(Match == 'M') %>%
        dplyr::rename(Experiments = condition) %>%
        dplyr::filter((value >=200) & (value <=1200)) %>%
        ggplot2::ggplot(aes(y = Experiments, x = value, color = Valence)) +
        tidybayes::stat_halfeye(aes(fill = Valence), alpha = 0.7) +
        geom_vline(data = p_ms_rt1_vlines, aes(xintercept = value, colour = Valence), linetype = "dashed") +
        labs(x=expression('Posteior distribution of RTs')) + 
        facet_wrap(~Identity) + 
        theme_apa()

df_ms_m1_plot_rt_diff <- df_ms_m1_plot_rt %>%
        tidyr::pivot_wider(names_from = c(term), values_from = value) %>%   # long to wide
        # calculate the difference between conditions, matched trials only
        dplyr::mutate(diff_GN_M_S = M_Self_Good - M_Self_Neutral,               # calculate the differences between conditions
                      diff_BN_M_S = M_Self_Bad - M_Self_Neutral,
                      diff_GN_M_O = M_Other_Good - M_Other_Neutral,  
                      diff_BN_M_O = M_Other_Bad - M_Other_Neutral,
                      diff_SO_G   = M_Self_Good - M_Other_Good, 
                      diff_SO_N   = M_Self_Neutral - M_Other_Neutral,
                      diff_SO_B   = M_Self_Bad - M_Other_Bad,
                      diff_diff_GN = diff_GN_M_S - diff_GN_M_O,
                      diff_diff_BN = diff_BN_M_S - diff_BN_M_O) %>%
        dplyr::select(condition, `.chain`, `.iteration`, `.draw`,
                      diff_GN_M_S, diff_BN_M_S, diff_GN_M_O,
                      diff_BN_M_O, diff_SO_G, diff_SO_N, diff_SO_B,
                      diff_diff_GN, diff_diff_BN) #  %>%

df_ms_rt1_diff_diff <- df_ms_m1_plot_rt_diff %>%
        tidyr::pivot_longer(cols = diff_GN_M_S:diff_diff_BN, names_to = "term_diff", values_to =  "value") %>%  # wide to long
        dplyr::filter(str_detect(term_diff, 'diff_diff')) %>%
        dplyr::mutate(term_diff = factor(term_diff, levels = c('diff_diff_GN', 'diff_diff_BN'))) %>% 
        dplyr::filter(condition == "Overall") %>%
        tidyr::pivot_wider(.,
                           id_cols = c('.chain', '.iteration', '.draw'),
                           names_from = term_diff) %>%
        dplyr::select(-c('.chain', '.iteration', '.draw')) %>%
        bayestestR::describe_posterior(.,
                                       ci = 0.95,
                                       ci_method = 'hdi',
                                       test = c("p_direction", "p_significance"),
                                       centrality = "median")

# plot the posterior of matching trials of valence
p_ms_rt1_diff_val <- df_ms_m1_plot_rt_diff %>%
        tidyr::pivot_longer(cols = diff_GN_M_S:diff_SO_B, names_to = "term_diff", values_to =  "value")  %>%  # wide to long
        dplyr::filter(str_detect(term_diff, '_M_')) %>%
        dplyr::mutate(term_diff = factor(term_diff, levels = c('diff_GN_M_S','diff_BN_M_S', 
                                                               'diff_GN_M_O', 'diff_BN_M_O'))) %>%
        dplyr::filter((value >= -200) & (value <= 200)) %>%
        dplyr::rename(Experiments = condition) %>%
        ggplot2::ggplot(aes(y = Experiments, x = value, fill = after_stat(x < 0))) +
        tidybayes::stat_halfeye() +
        geom_vline(xintercept = 0, linetype = "dashed") +
        scale_fill_manual(values = c('skyblue', 'gray80'),
                    breaks = c(TRUE, FALSE),
                    name = "Effect" , labels = c("Yes", "No")) + 
        # scale_fill_manual(values = c('gray80', 'skyblue')) + 
        xlab("Valence effect on RTs (Match trials)") +
        facet_wrap( ~ term_diff,
              # scales = "free_y", 
              nrow = 1,
              labeller = label_parsed)

df_ms_rt1_diff_val <- df_ms_m1_plot_rt_diff %>%
        tidyr::pivot_longer(cols = diff_GN_M_S:diff_SO_B, names_to = "term_diff", values_to =  "value")  %>%  # wide to long
        dplyr::filter(str_detect(term_diff, '_M_')) %>%
        dplyr::filter(condition == "Overall") %>%
        tidyr::pivot_wider(.,
                           id_cols = c('.chain', '.iteration', '.draw'),
                           names_from = term_diff) %>%
        dplyr::select(-c('.chain', '.iteration', '.draw')) %>%
        bayestestR::describe_posterior(.,
                                       ci = 0.95,
                                       ci_method = 'hdi',
                                       test = c("p_direction", "p_significance"),
                                       centrality = "median")

# plot the posterior of matching trials, diff between self and other
p_ms_rt1_diff_id <- df_ms_m1_plot_rt_diff %>%
        tidyr::pivot_longer(cols = diff_GN_M_S:diff_SO_B, names_to = "term_diff", values_to =  "value")  %>%  # wide to long
        dplyr::filter(str_detect(term_diff, '_SO_')) %>%
        dplyr::mutate(term_diff = factor(term_diff, levels = c('diff_SO_G', 'diff_SO_N', 'diff_SO_B'))) %>%
        dplyr::filter((value >= -200) & (value <= 200)) %>%
        dplyr::rename(Experiments = condition) %>%
        ggplot2::ggplot(aes(y = Experiments, x = value, fill = after_stat(x < 0))) +
        tidybayes::stat_halfeye() +
        geom_vline(xintercept = 0, linetype = "dashed") +
        scale_fill_manual(values = c('skyblue', 'gray80'),
                    breaks = c(TRUE, FALSE),
                    name = "Effect" , labels = c("Yes", "No")) + 
        # scale_fill_manual(values = c('gray80', 'skyblue')) + 
        xlab("Self-referential effect on RTs (Match trials)") +
        facet_wrap( ~ term_diff,
              # scales = "free_y", 
              nrow = 1,
              labeller = label_parsed)

df_ms_rt1_diff_id <- df_ms_m1_plot_rt_diff %>%
        tidyr::pivot_longer(cols = diff_GN_M_S:diff_SO_B, names_to = "term_diff", values_to =  "value")  %>%  # wide to long
        dplyr::filter(str_detect(term_diff, '_SO_')) %>%
        dplyr::mutate(term_diff = factor(term_diff, levels = c('diff_SO_G', 'diff_SO_N', 'diff_SO_B'))) %>%
        dplyr::filter(condition == "Overall") %>%
        tidyr::pivot_wider(.,
                           id_cols = c('.chain', '.iteration', '.draw'),
                           names_from = term_diff) %>%
        dplyr::select(-c('.chain', '.iteration', '.draw')) %>%
        bayestestR::describe_posterior(.,
                                       ci = 0.95,
                                       ci_method = 'hdi',
                                       test = c("p_direction", "p_significance"),
                                       centrality = "median")
```

```{r plot-bayes2, fig.cap="Interaction between moral valence and self-referential", fig.height=12, fig.width=15, warning=FALSE}
library(patchwork)
# (p_rt1 | p_dprime1)
p_ms_rt1 + p_ms_dprime1 +
        p_ms_rt1_diff_val + p_ms_dprime1_diff_val + 
        p_ms_rt1_diff_id + p_ms_dprime1_diff_id + plot_annotation(tag_levels = 'A')  + plot_layout(nrow = 3, byrow = TRUE, guides = "collect")
```

For the *d* prime, we found that an interaction between moral character effect and self-referential, the self- and other-referential difference was greater than zero for good vs. neutral character differences ($median_{diff}$ = `r df_ms_dprm1_diff_diff$Median[df_ms_dprm1_diff_diff$Parameter == 'diff_diff_GN']`; 95% HDI = [`r df_ms_dprm1_diff_diff$CI_low[df_ms_dprm1_diff_diff$Parameter == 'diff_diff_GN']` `r df_ms_dprm1_diff_diff$CI_high[df_ms_dprm1_diff_diff$Parameter == 'diff_diff_GN']`]) but not for bad vs. neutral differences ($median_{diff}$ = `r df_ms_dprm1_diff_diff$Median[df_ms_dprm1_diff_diff$Parameter == 'diff_diff_BN']`; 95% HDI = [`r df_ms_dprm1_diff_diff$CI_low[df_ms_dprm1_diff_diff$Parameter == 'diff_diff_BN']` `r df_ms_dprm1_diff_diff$CI_high[df_ms_dprm1_diff_diff$Parameter == 'diff_diff_BN']`]). Further analyses revealed that the good vs. neutral character effect only appeared for self-referential conditions but not other-referential conditions. The estimated *d* prime for good-self was greater than neutral-self ($median_{diff}$ = `r df_ms_dprm1_diff_val$Median[df_ms_dprm1_diff_val$Parameter == 'diff_GN_dprm_S']`; 95% HDI = [`r df_ms_dprm1_diff_val$CI_low[df_ms_dprm1_diff_val$Parameter == 'diff_GN_dprm_S']` `r df_ms_dprm1_diff_val$CI_high[df_ms_dprm1_diff_val$Parameter == 'diff_GN_dprm_S']`]), *d* prime for good-self was also greater than good-other condition ($median_{diff}$ = `r df_ms_dprm1_diff_id$Median[df_ms_dprm1_diff_val$Parameter == 'diff_SO_dprm_G']`; 95% HDI = [`r df_ms_dprm1_diff_val$CI_low[df_ms_dprm1_diff_val$Parameter == 'diff_SO_dprm_G']` `r df_ms_dprm1_diff_val$CI_high[df_ms_dprm1_diff_val$Parameter == 'diff_SO_dprm_G']`]). The differences between bad-self and neutral-self, good-other and neutral-other, bad-other and neutral-other are all centered around zero (see Figure \@ref(fig:plot-bayes2), B, D). 

For the RTs part, we also found the interaction between moral character and self-referential, the self- and other-referential differences was below zero for the good vs. neutral differences ($median_{diff}$ = `r df_ms_rt1_diff_diff$Median[df_ms_rt1_diff_diff$Parameter == 'diff_diff_GN']`; 95% HDI = [`r df_ms_rt1_diff_diff$CI_low[df_ms_rt1_diff_diff$Parameter == 'diff_diff_GN']` `r df_ms_rt1_diff_diff$CI_high[df_ms_rt1_diff_diff$Parameter == 'diff_diff_GN']`]) but not for the bad vs. neutral differences ($median_{diff}$ = `r df_ms_rt1_diff_diff$Median[df_ms_rt1_diff_diff$Parameter == 'diff_diff_BN']`; 95% HDI = [`r df_ms_rt1_diff_diff$CI_low[df_ms_rt1_diff_diff$Parameter == 'diff_diff_BN']` `r df_ms_rt1_diff_diff$CI_high[df_ms_rt1_diff_diff$Parameter == 'diff_diff_BN']`]). Further analyses revealed a robust good-self prioritization effect as compared to neutral-self ($median_{diff}$ = `r df_ms_rt1_diff_val$Median[df_ms_rt1_diff_val$Parameter == 'diff_GN_M_S']`; 95% HDI = [`r df_ms_rt1_diff_val$CI_low[df_ms_rt1_diff_val$Parameter == 'diff_GN_M_S']` `r df_ms_rt1_diff_val$CI_high[df_ms_rt1_diff_val$Parameter == 'diff_GN_M_S']`]) and good-other ($median_{diff}$ = `r df_ms_rt1_diff_id$Median[df_ms_rt1_diff_id$Parameter == 'diff_SO_G']`; 95% HDI = [`r df_ms_rt1_diff_id$CI_low[df_ms_rt1_diff_id$Parameter == 'diff_SO_G']` `r df_ms_rt1_diff_id$CI_high[df_ms_rt1_diff_id$Parameter == 'diff_SO_G']`]) conditions. Also, we found that both good character and bad character were responded slower than neutral character when it was other-referential. See Figure \@ref(fig:plot-bayes2).

## Spontaneous binding between the good character and the self

In this part, we reported two studies in which the moral valence or the self-referential processing is not task-relevant. We are interested in testing whether the task-relevance modulated the effect observed in previous experiment. 

```{r 4a_BGLMM_sdt, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
exp_name <- '4a'
exp4a_sdt_m1 <- fun_sdt_val_id(exp_name)

#summary(exp4a_sdt_m1)    # check summary

# check fixed and varying effect using bayestestR
# bayestestR::describe_posterior(
#   exp4a_sdt_m1,
#   effects = "all",
#   component = "all",
#   test = c("p_direction", "p_significance"),
#   centrality = "all"
# )
#pp_check(exp4a_sdt_m1)   # posterior predictive check

# d-prime
hypothesis(exp4a_sdt_m1, "IdentitySelf:ValenceGood:ismatch > IdentitySelf:ValenceNeutral:ismatch")      # .82
hypothesis(exp4a_sdt_m1, "IdentitySelf:ValenceGood:ismatch > IdentitySelf:ValenceBad:ismatch")          # .75
hypothesis(exp4a_sdt_m1, "IdentitySelf:ValenceNeutral:ismatch > IdentitySelf:ValenceBad:ismatch")       # .44
hypothesis(exp4a_sdt_m1, "IdentityOther:ValenceGood:ismatch > IdentityOther:ValenceNeutral:ismatch")    # .11
hypothesis(exp4a_sdt_m1, "IdentityOther:ValenceGood:ismatch > IdentityOther:ValenceBad:ismatch")        # .07
hypothesis(exp4a_sdt_m1, "IdentityOther:ValenceNeutral:ismatch > IdentityOther:ValenceBad:ismatch")     # .39

hypothesis(exp4a_sdt_m1, "IdentitySelf:ValenceGood:ismatch > IdentityOther:ValenceGood:ismatch")        # 1
hypothesis(exp4a_sdt_m1, "IdentitySelf:ValenceNeutral:ismatch > IdentityOther:ValenceNeutral:ismatch")  # 1
hypothesis(exp4a_sdt_m1, "IdentitySelf:ValenceBad:ismatch > IdentityOther:ValenceBad:ismatch")          # 1

# hypothesis(exp4a_sdt_m1, "IdentitySelf:ValenceGood > IdentitySelf:ValenceNeutral")  # .73
# hypothesis(exp4a_sdt_m1, "IdentitySelf:ValenceGood > IdentitySelf:ValenceBad")  # .9
# hypothesis(exp4a_sdt_m1, "IdentitySelf:ValenceNeutral > IdentitySelf:ValenceBad")  # .49
# hypothesis(exp4a_sdt_m1, "IdentityOther:ValenceGood > IdentityOther:ValenceNeutral")  # .68
# hypothesis(exp4a_sdt_m1, "IdentityOther:ValenceGood > IdentityOther:ValenceBad")  # .92
# hypothesis(exp4a_sdt_m1, "IdentityOther:ValenceNeutral> IdentityOther:ValenceBad")  # .8
# 
# hypothesis(exp4a_sdt_m1, "IdentitySelf:ValenceGood > IdentityOther:ValenceGood")  # .92
# hypothesis(exp4a_sdt_m1, "IdentitySelf:ValenceNeutral > IdentityOther:ValenceNeutral")  # .76
# hypothesis(exp4a_sdt_m1, "IdentitySelf:ValenceBad > IdentityOther:ValenceBad")  # .96

# extract the population level parameters
# criteria

df_exp4a_sdt_m1_plot <- exp4a_sdt_m1 %>%
  tidybayes::gather_draws(`b_.*`, regex = TRUE) %>% # get the traces of population level parameters
  # create two columns for two independent factors.
  dplyr::mutate(Valence = dplyr::case_when(grepl("Neutral", .variable) ~ "Neutral",
                                           grepl("Bad", .variable) ~"Bad",
                                           grepl("Good", .variable) ~"Good"),
                Identity = dplyr::case_when(grepl("Self", .variable) ~ "Self",
                                           grepl("Other", .variable) ~"Other"),
                params = dplyr::case_when(grepl("ismatch", .variable) ~ "dprime",
                                           !grepl("ismatch", .variable) ~"criterion"),
                params = factor(params, levels = c('dprime', 'criterion')),
                Identity = factor(Identity, levels = c("Self", "Other")),
                Valence = factor(Valence, levels = c('Good', 'Neutral',  'Bad'))) 

exp4a_sdt_p <- df_exp4a_sdt_m1_plot %>%
  dplyr::filter(params == 'dprime') %>%  # select only d prime
  ggplot2::ggplot(aes(x = Identity, y = .value, color = Valence)) +
  tidybayes::stat_halfeye(aes(fill = Valence), alpha = 0.7) + # position=position_dodge(width = 0.1)
  # geom_slabinterval(ymin = 0, ymax = 4) +
  stat_summary(aes(group = Valence, color = Valence), fun = mean, geom = "line") +
  labs(x = expression("Self-Referential"), 
      y = expression(paste("Posteior of sensitivity ", italic("d'"), sep = ' '))) +
  scale_colour_brewer(palette = "Dark2") +
  scale_fill_brewer(palette = "Dark2") +
  # facet_grid(~ params , scales = "free_y") +
  theme_classic() 

df_exp4a_sdt_hdi <- df_exp4a_sdt_m1_plot %>%
        dplyr::ungroup() %>%
        dplyr::filter(params == 'dprime') %>%
        dplyr::select(-c('.variable', 'params')) %>%
        # dplyr::mutate(term_diff = stringr::str_sub(.$term_diff, end = -8)) %>%
        tidyr::pivot_wider(.,
                           id_cols = c('.chain', '.iteration', '.draw'),
                           values_from = '.value',
                           names_from = c('Valence', 'Identity')) %>%
        dplyr::select(-c('.chain', '.iteration', '.draw')) %>%
        bayestestR::describe_posterior(.,
                                       ci = 0.95,
                                       ci_method = 'hdi',
                                       test = c("p_direction", "p_significance"),
                                       BF = 1,
                                       centrality = "median")

# exp4a_sdt_p <- exp4a_sdt_m1 %>%
#   emmeans::emmeans( ~ ismatch | Identity| Valence) %>%
#   tidybayes::gather_emmeans_draws() %>%
#   dplyr::mutate(ismatch = ifelse(ismatch == 0, 'criterion', 'd prime'),
#                 ismatch = factor(ismatch, levels = c('d prime', 'criterion')),
#                 Valence = factor(Valence, levels = c('Good', 'Neutral',  'Bad')),
#                 Identity = factor(Identity, levels = c('Self', 'Other'))) %>%
#   ggplot2::ggplot(aes(x = Valence, y = .value, group = Identity, color = Identity)) +
#   #ggplot2::ggplot(aes(x = Valence, y = .value, group = .draw)) +
#   #geom_line(alpha = .01) +
#   scale_colour_brewer(palette = "Dark2") +
#   scale_fill_brewer(palette = "Dark2") +
#   tidybayes::stat_halfeye() + # position=position_dodge(width = 0.1)
#   stat_summary(aes(group = Identity, color = Identity), fun.y = mean, geom = "line"
#                #,position=position_dodge(width = 0.1)
#                ) +
#   #scale_fill_brewer() +
#   facet_grid(~ ismatch) +
#   theme_classic()

df_exp4a_sdt_m1_plot_diff <- df_exp4a_sdt_m1_plot %>%
        tidyr::unite(term, c('params', 'Identity', 'Valence')) %>%
        dplyr::ungroup() %>%
        dplyr::select(term, `.chain`, `.iteration`, `.draw`, `.value`) %>%
        tidyr::pivot_wider(names_from = c(term), values_from = .value) %>%   # long to wide
        dplyr::mutate(
                # diff_GN_c_S = c_Self_Good - c_Self_Neutral,
                # diff_BN_c_S = c_Self_Bad - c_Self_Neutral,
                # diff_GN_c_O = c_Other_Good - c_Other_Neutral,
                # diff_BN_c_O = c_Other_Bad - c_Other_Neutral,
                diff_GN_dprm_S = dprime_Self_Good - dprime_Self_Neutral,
                diff_BN_dprm_S = dprime_Self_Bad - dprime_Self_Neutral,
                diff_GB_dprm_S = dprime_Self_Good - dprime_Self_Bad,
                diff_GN_dprm_O = dprime_Other_Good - dprime_Other_Neutral,
                diff_BN_dprm_O = dprime_Other_Bad - dprime_Other_Neutral,
                diff_GB_dprm_O = dprime_Other_Good - dprime_Other_Bad,
                diff_SO_dprm_G = dprime_Self_Good - dprime_Other_Good,
                diff_SO_dprm_N =  dprime_Self_Neutral - dprime_Other_Neutral,
                diff_SO_dprm_B =  dprime_Self_Bad - dprime_Other_Bad,
                diff_diff_GN_SO = diff_GN_dprm_S - diff_GN_dprm_O,
                diff_diff_GB_SO = diff_GB_dprm_S - diff_GB_dprm_O,
                diff_diff_BN_SO = diff_BN_dprm_S - diff_BN_dprm_O
                ) %>%
  dplyr::select(`.chain`, `.iteration`, `.draw`,
               diff_GN_dprm_S:diff_diff_BN_SO) %>%
  tidyr::pivot_longer(cols = diff_GN_dprm_S:diff_diff_BN_SO, names_to = "term_diff", values_to =  "value") %>%  # wide to long
  dplyr::mutate(term_diff = factor(term_diff, levels = c('diff_GB_dprm_S', 'diff_GN_dprm_S', 'diff_BN_dprm_S', 
                                                         'diff_GB_dprm_O', 'diff_GN_dprm_O', 'diff_BN_dprm_O', 
                                                         'diff_SO_dprm_G', 'diff_SO_dprm_N', 'diff_SO_dprm_B',
                                                         'diff_diff_GN_SO', 'diff_diff_GB_SO', 'diff_diff_BN_SO')))
p_exp4a_dprime1_diff_val <- df_exp4a_sdt_m1_plot_diff %>%
        dplyr::filter(str_detect(term_diff, '_dprm_S|_dprm_O')) %>%
        dplyr::mutate(Identity = dplyr::case_when(grepl("_S", term_diff) ~ "Self",
                                           grepl("_O", term_diff) ~"Other"),
                      Identity = factor(Identity, levels = c("Self", "Other"))) %>%
        dplyr::filter(!str_detect(term_diff, '_GB_')) %>%
        dplyr::mutate(term_diff = stringr::str_sub(.$term_diff, end = -8)) %>%
        dplyr::mutate(term_diff = dplyr::case_when(grepl("_GB", term_diff) ~ "Good vs. Bad",
                                                   grepl("_GN", term_diff) ~"Good vs. Neutral",
                                                   grepl("_BN", term_diff) ~ "Bad vs. Neutral"),
                      term_diff = factor(term_diff, levels = c("Good vs. Bad", "Good vs. Neutral", "Bad vs. Neutral"))) %>%
        # dplyr::filter(str_detect(term_diff, '_SO_')) %>%
        # tidyr::unite(term_diff, c('Identity', 'term_diff')) %>%
        dplyr::filter((value >= -1.5) & (value <= 1.5)) %>%
        dplyr::rename(conditions = term_diff) %>%
        ggplot2::ggplot(aes(x = value, y = fct_rev(conditions), fill = after_stat(x > 0))) +
        tidybayes::stat_halfeye() +
        geom_vline(xintercept = 0, linetype = "dashed") +
        scale_fill_manual(values = c('skyblue', 'gray80'),
                    breaks = c(TRUE, FALSE),
                    name = "Effect" , labels = c("Yes", "No")) + 
        # scale_fill_manual(values = c('gray80', 'skyblue')) +
        labs(x = expression(paste("Valence effect on ", italic("d"), " prime", sep = ' ')),
             y = expression("Contrasts")) + 
        facet_wrap( ~ Identity, nrow = 1)

df_exp4a_dprime1_diff_val <- df_exp4a_sdt_m1_plot_diff %>%
        dplyr::filter(str_detect(term_diff, '_dprm_S|_dprm_O')) %>%
        dplyr::mutate(Identity = dplyr::case_when(grepl("_S", term_diff) ~ "Self",
                                           grepl("_O", term_diff) ~"Other"),
                      Identity = factor(Identity, levels = c("Self", "Other"))) %>%
        dplyr::filter(!str_detect(term_diff, '_GB_')) %>%
        dplyr::mutate(term_diff = stringr::str_sub(.$term_diff, end = -8)) %>%
        tidyr::pivot_wider(.,
                           id_cols = c('.chain', '.iteration', '.draw'),
                           names_from = c('term_diff', 'Identity')) %>%
        dplyr::select(-c('.chain', '.iteration', '.draw')) %>%
        bayestestR::describe_posterior(.,
                                       ci = 0.95,
                                       ci_method = 'hdi',
                                       test = c("p_direction", "p_significance"),
                                       BF = 1,
                                       centrality = "median")

p_exp4a_dprime1_diff_id <- df_exp4a_sdt_m1_plot_diff %>%
        dplyr::filter(str_detect(term_diff, '_SO_')) %>%
        dplyr::mutate(term_diff = dplyr::case_when(grepl("_B", term_diff) ~ "Bad",
                                                   grepl("_N", term_diff) ~"Neutral",
                                                   grepl("_G", term_diff) ~ "Good"),
                      term_diff = factor(term_diff, levels = c("Good", "Neutral", "Bad"))) %>%
        #dplyr::filter(!str_detect(term_diff, '_GB_')) %>%
        # tidyr::unite(term_diff, c('Identity', 'term_diff')) %>%
        dplyr::filter((value >= -1.5) & (value <= 1.5)) %>%
        dplyr::rename(conditions = term_diff) %>%
        ggplot2::ggplot(aes(x = value, y = fct_rev(conditions), fill = after_stat(x > 0))) +
        tidybayes::stat_halfeye() +
        geom_vline(xintercept = 0, linetype = "dashed") +
        scale_fill_manual(values = c('skyblue', 'gray80'),
                    breaks = c(TRUE, FALSE),
                    name = "Effect" , labels = c("Yes", "No")) +
        # scale_fill_manual(values = c('skyblue')) +   # note: only one value here, used blue here
        labs(x = expression(paste("Self-referential effect on ", italic("d"), " prime", sep = ' ')),
             y = expression("Contrasts (Self vs. Other)"))

p_exp4a_dprime1_diff_diff <- df_exp4a_sdt_m1_plot_diff %>%
        dplyr::filter(str_detect(term_diff, '_diff_')) %>%
        # dplyr::filter(!str_detect(term_diff, 'GB')) %>%
        dplyr::mutate(term_diff = dplyr::case_when(grepl("_GB", term_diff) ~ "GB",
                                                   grepl("_GN", term_diff) ~"GN",
                                                   grepl("_BN", term_diff) ~ "BN"),
                      term_diff = factor(term_diff, levels = c("GN", "GB", "BN"))) %>%
        #dplyr::filter(!str_detect(term_diff, '_GB_')) %>%
        # tidyr::unite(term_diff, c('Identity', 'term_diff')) %>%
        dplyr::filter((value >= -1.5) & (value <= 1.5)) %>%
        dplyr::rename(conditions = term_diff) %>%
        ggplot2::ggplot(aes(x = value, y = fct_rev(conditions), fill = after_stat(x > 0))) +
        tidybayes::stat_halfeye() +
        geom_vline(xintercept = 0, linetype = "dashed") +
        scale_fill_manual(values = c('skyblue', 'gray80'),
                    breaks = c(TRUE, FALSE),
                    name = "Effect" , labels = c("Yes", "No")) +
        # scale_fill_manual(values = c('skyblue')) +   # note: only one value here, used blue here
        labs(x = expression(paste("Self-referential effect on ", italic("d"), " prime", sep = ' ')),
             y = expression("Difference (Self vs. Other) of difference (Valence)"))

df_exp4a_dprime1_diff_diff <- df_exp4a_sdt_m1_plot_diff %>%  # difference between differences
        dplyr::filter(str_detect(term_diff, '_diff_')) %>%
        # dplyr::filter(!str_detect(term_diff, 'GB')) %>%
        dplyr::mutate(term_diff = dplyr::case_when(grepl("_GB", term_diff) ~ "GB",
                                                   grepl("_GN", term_diff) ~"GN",
                                                   grepl("_BN", term_diff) ~ "BN"),
                      term_diff = factor(term_diff, levels = c("GN", "GB", "BN"))) %>%
        tidyr::pivot_wider(.,
                           id_cols = c('.chain', '.iteration', '.draw'),
                           names_from = term_diff) %>%
        dplyr::select(-c('.chain', '.iteration', '.draw')) %>%
        bayestestR::describe_posterior(.,
                                       ci = 0.95,
                                       ci_method = 'hdi',
                                       test = c("p_direction", "p_significance"),
                                       centrality = "median")
```

```{r 4a_BGLMM_rt, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
exp_name <- '4a'
exp4a_rt_m1 <- fun_rt_val_id(exp_name)

# summary(exp4a_rt_m1)  # n
# 
# bayestestR::describe_posterior(
#   exp4a_rt_m1,
#   effects = "fixed",
#   component = "all",
#   test = c("p_direction", "p_significance"),
#   centrality = "all"
# )

#pp_check(exp4a_rt_m1)
# rg <- emmeans::ref_grid(exp4a_rt_m1)
# em <- emmeans::emmeans(rg, 'ismatch')
# summary(em, point.est = median)
# emmeans::joint_tests(exp4a_rt_m1)

df_exp4a_m1_plot_rt <- exp4a_rt_m1 %>%
        tidybayes::gather_draws(`b_.*`, regex = TRUE)  %>%
        dplyr::mutate(.variable = gsub("b_", "", .variable)) %>%
        tidyr::pivot_wider(names_from = c(.variable), values_from = .value) %>%
        dplyr::mutate(NM_Self_Neutral = Intercept,               # calculate the differences between conditions
                      NM_Self_Bad = Intercept  + ValenceBad,
                      NM_Self_Good = Intercept  + ValenceGood ,
                      NM_Other_Neutral = Intercept  + IdentityOther,               # calculate the differences between conditions
                      NM_Other_Bad = Intercept  + ValenceBad  + `ValenceBad:IdentityOther`,
                      NM_Other_Good = Intercept  + ValenceGood + `ValenceGood:IdentityOther`,
                      M_Self_Neutral = Intercept  + ismatch,
                      M_Self_Bad = Intercept  + ismatch + `ismatch:ValenceBad`,
                      M_Self_Good = Intercept  + ismatch + `ismatch:ValenceGood`,
                      M_Other_Neutral = Intercept  + ismatch + `ismatch:IdentityOther`,
                      M_Other_Bad = Intercept  + ismatch + `ismatch:IdentityOther` + `ismatch:ValenceBad:IdentityOther`,
                      M_Other_Good = Intercept  + ismatch + `ismatch:IdentityOther` + `ismatch:ValenceGood:IdentityOther`) %>%
        dplyr::select(`.chain`, `.iteration`, `.draw`, contains('M_')) %>%
        tidyr::pivot_longer(cols = NM_Self_Neutral:M_Other_Good, names_to = "term", values_to =  "value") %>%  # wide to long
  dplyr::mutate(term = factor(term, levels = c('NM_Self_Neutral', 'NM_Self_Bad', 'NM_Self_Good',
                                               'NM_Other_Neutral', 'NM_Other_Bad', 'NM_Other_Good',
                                               'M_Self_Neutral', 'M_Self_Bad', 'M_Self_Good',
                                               'M_Other_Neutral', 'M_Other_Bad', 'M_Other_Good')),
                value = exp(value),
                value = value * 1000) 

p_exp4a_rt1 <- df_exp4a_m1_plot_rt %>%
        tidyr::separate(term, c('Match', 'Identity', 'Valence')) %>% 
        dplyr::mutate(Valence = factor(Valence, levels = c('Good', 'Neutral', 'Bad')),
                      Identity = factor(Identity, levels = c("Self", "Other"))) %>%
        dplyr::filter(Match == 'M') %>%
        # dplyr::rename(Experiments = condition) %>%
        dplyr::filter((value >=200) & (value <=1200)) %>%
        ggplot2::ggplot(aes(y = value, x = Identity, color = Valence)) +
        tidybayes::stat_halfeye(aes(fill = Valence), alpha = 0.7) +
        stat_summary(aes(group = Valence, color = Valence), fun = mean, geom = "line") +
        # geom_vline(data = p_ms_rt1_vlines, aes(xintercept = value, colour = Valence), linetype = "dashed") +
        labs(x = expression("Self-Referential"), 
             y = expression('Posteior of reaction times')) +
        scale_colour_brewer(palette = "Dark2") +
        scale_fill_brewer(palette = "Dark2") +
        # facet_grid(~ params , scales = "free_y") +
        theme_classic()
        # facet_wrap(~Identity) + 
        #theme_apa()

df_exp4a_rt1_hdi <- df_exp4a_m1_plot_rt %>%
        tidyr::separate(term, c('Match', 'Identity', 'Valence')) %>% 
        dplyr::mutate(Valence = factor(Valence, levels = c('Good', 'Neutral', 'Bad')),
                      Identity = factor(Identity, levels = c("Self", "Other"))) %>%
        dplyr::filter(Match == 'M') %>%
        dplyr::select(-c('Match')) %>%
        # dplyr::mutate(term_diff = stringr::str_sub(.$term_diff, end = -8)) %>%
        tidyr::pivot_wider(.,
                           id_cols = c('.chain', '.iteration', '.draw'),
                           values_from = 'value',
                           names_from = c('Valence', 'Identity')) %>%
        dplyr::select(-c('.chain', '.iteration', '.draw')) %>%
        bayestestR::describe_posterior(.,
                                       ci = 0.95,
                                       ci_method = 'hdi',
                                       test = c("p_direction", "p_significance"),
                                       BF = 1,
                                       centrality = "median")
# 
# emm1 <- emmeans::emmeans(exp4a_rt_m1, specs = pairwise ~ Identity | Valence | ismatch)
# emm1$contrasts %>% summary(infer = TRUE, point.est = mean)
# 
# emm2 <- emmeans::emmeans(exp4a_rt_m1, specs = pairwise ~ Valence | Identity | ismatch)
# emm2$contrasts %>% summary(infer = TRUE, point.est = mean)

df_exp4a_m1_plot_rt_diff <- df_exp4a_m1_plot_rt %>%
        # tidyr::unite(term, c('params', 'Identity', 'Valence')) %>%
        dplyr::ungroup() %>%
        dplyr::select(term, `.chain`, `.iteration`, `.draw`, `value`) %>%
        tidyr::pivot_wider(names_from = c(term), values_from = value) %>%   # long to wide
        dplyr::mutate(
                diff_GN_S_RT_M = M_Self_Good - M_Self_Neutral,
                diff_BN_S_RT_M = M_Self_Bad - M_Self_Neutral,
                diff_GB_S_RT_M = M_Self_Good - M_Self_Bad,
                diff_GN_O_RT_M = M_Other_Good - M_Other_Neutral,
                diff_BN_O_RT_M = M_Other_Bad - M_Other_Neutral,
                diff_GB_O_RT_M = M_Other_Good - M_Other_Bad,
                diff_SO_G_RT_M = M_Self_Good - M_Other_Good,
                diff_SO_N_RT_M = M_Self_Neutral - M_Other_Neutral,
                diff_SO_B_RT_M = M_Self_Bad - M_Other_Bad,
                diff_diff_GN_SO = diff_GN_S_RT_M - diff_GN_O_RT_M,
                diff_diff_GB_SO = diff_GB_S_RT_M - diff_GB_O_RT_M,
                diff_diff_BN_SO = diff_BN_S_RT_M - diff_BN_O_RT_M
                ) %>%
  dplyr::select(`.chain`, `.iteration`, `.draw`,
               diff_GN_S_RT_M:diff_diff_BN_SO) %>%
  tidyr::pivot_longer(cols = diff_GN_S_RT_M:diff_diff_BN_SO, names_to = "term_diff", values_to =  "value") %>%  # wide to long
  dplyr::mutate(term_diff = factor(term_diff, levels = c('diff_GN_S_RT_M', 'diff_BN_S_RT_M', 'diff_GB_S_RT_M', 
                                                         'diff_GN_O_RT_M', 'diff_BN_O_RT_M', 'diff_GB_O_RT_M', 
                                                         'diff_SO_G_RT_M', 'diff_SO_N_RT_M', 'diff_SO_B_RT_M',
                                                         'diff_diff_GN_SO', 'diff_diff_GB_SO', 'diff_diff_BN_SO')))
p_exp4a_rt_diff_val <- df_exp4a_m1_plot_rt_diff %>%
        dplyr::filter(str_detect(term_diff, '_S_RT_M|_O_RT_M')) %>%
        dplyr::mutate(Identity = dplyr::case_when(grepl("_S", term_diff) ~ "Self",
                                                  grepl("_O", term_diff) ~"Other"),
                      Identity = factor(Identity, levels = c("Self", "Other"))) %>%
        dplyr::filter(!str_detect(term_diff, '_GB_')) %>%
        dplyr::mutate(term_diff = stringr::str_sub(.$term_diff, end = -8)) %>%
        dplyr::mutate(term_diff = dplyr::case_when(grepl("_GB", term_diff) ~ "Good vs. Bad",
                                                   grepl("_GN", term_diff) ~"Good vs. Neutral",
                                                   grepl("_BN", term_diff) ~ "Bad vs. Neutral"),
                      term_diff = factor(term_diff, levels = c("Good vs. Bad", "Good vs. Neutral", "Bad vs. Neutral"))) %>%
        # dplyr::filter(str_detect(term_diff, '_SO_')) %>%
        #dplyr::filter(!str_detect(term_diff, '_GB_')) %>%
        # tidyr::unite(term_diff, c('Identity', 'term_diff')) %>%
        # dplyr::filter((value >= -1.5) & (value <= 1.5)) %>%
        dplyr::rename(conditions = term_diff) %>%
        ggplot2::ggplot(aes(x = value, y = fct_rev(conditions), fill = after_stat(x < 0))) +
        tidybayes::stat_halfeye() +
        geom_vline(xintercept = 0, linetype = "dashed") +
        scale_fill_manual(values = c('skyblue', 'gray80'),
                    breaks = c(TRUE, FALSE),
                    name = "Effect" , labels = c("Yes", "No")) + 
        # scale_fill_manual(values = c('gray80', 'skyblue')) +
        labs(x = expression("Valence effect on RTs "),
             y = expression("Contrasts")) + 
        facet_wrap( ~ Identity, nrow = 1)

p_exp4a_rt_diff_id <- df_exp4a_m1_plot_rt_diff %>%
        dplyr::filter(str_detect(term_diff, '_SO_')) %>%
        dplyr::mutate(term_diff = dplyr::case_when(grepl("_B", term_diff) ~ "Bad",
                                                   grepl("_N", term_diff) ~"Neutral",
                                                   grepl("_G", term_diff) ~ "Good"),
                      term_diff = factor(term_diff, levels = c("Good", "Neutral", "Bad"))) %>%
        # dplyr::filter(!str_detect(term_diff, '_GB_')) %>%
        # tidyr::unite(term_diff, c('Identity', 'term_diff')) %>%
        # dplyr::filter((value >= -1.5) & (value <= 1.5)) %>%
        dplyr::rename(conditions = term_diff) %>%
        ggplot2::ggplot(aes(x = value, y = fct_rev(conditions), fill = after_stat(x < 0))) +
        tidybayes::stat_halfeye() +
        geom_vline(xintercept = 0, linetype = "dashed") +
        scale_fill_manual(values = c('skyblue', 'gray80'),
                    breaks = c(TRUE, FALSE),
                    name = "Effect" , labels = c("Yes", "No")) + 
        # scale_fill_manual(values = c('skyblue')) +   # note: only one value here, used blue here
        labs(x = expression("Self-referential effect on RTs "),
             y = expression("Contrasts (Self vs. Other)"))

p_exp4a_rt1_diff_diff <- df_exp4a_m1_plot_rt_diff %>%
        dplyr::filter(str_detect(term_diff, '_diff_')) %>%
        dplyr::mutate(term_diff = dplyr::case_when(grepl("_GB", term_diff) ~ "GB",
                                                   grepl("_GN", term_diff) ~"GN",
                                                   grepl("_BN", term_diff) ~ "BN"),
                      term_diff = factor(term_diff, levels = c("GN", "GB", "BN"))) %>%
        #dplyr::filter(!str_detect(term_diff, '_GB_')) %>%
        # tidyr::unite(term_diff, c('Identity', 'term_diff')) %>%
        # dplyr::filter((value >= -1.5) & (value <= 1.5)) %>%
        dplyr::rename(conditions = term_diff) %>%
        ggplot2::ggplot(aes(x = value, y = fct_rev(conditions), fill = after_stat(x > 0))) +
        tidybayes::stat_halfeye() +
        geom_vline(xintercept = 0, linetype = "dashed") +
        scale_fill_manual(values = c('skyblue', 'gray80'),
                    breaks = c(TRUE, FALSE),
                    name = "Effect" , labels = c("Yes", "No")) +
        # scale_fill_manual(values = c('skyblue')) +   # note: only one value here, used blue here
        labs(x = expression("Interaction effect on RT"),
             y = expression("Difference (Self vs. Other) of difference (Valence)"))
```

```{r plot-exp4a-BGLM, fig.cap="exp4a: Results of Bayesian GLM analysis.",  fig.height=9, fig.width=12, warning=FALSE}
library(patchwork)
p1 <- (p_exp4a_rt1 + exp4a_sdt_p) #+ plot_layout(nrow = 1, guides = "collect") 
p2 <- (p_exp4a_rt_diff_val + p_exp4a_dprime1_diff_val) + plot_layout(nrow = 1, byrow = FALSE, guides = "collect") 
# p3 <- p_exp4a_rt_diff_id + p_exp4a_dprime1_diff_id + plot_layout(nrow = 1, byrow = FALSE, guides = "collect") 
#p1/ 
#        p2  +  plot_layout(nrow = 2)  
        # p3 +  plot_layout(nrow = 3) 
```

In experiment 4a, where self- and other-referential were task-relevant and moral character are task-irrelevant. We found self-related conditions were performed better than other-related conditions, on both *d* prime and reaction times. This pattern is consistent with previous studies (e.g., @Sui_2012_JEPHPP).

More importantly, we found evidence, albeit weak, that task-irrelevant moral character also played an role. For shapes associated with self, *d'* was greater when shapes had a good character inside the shape (median = 2.83, 95% HDI [2.63 3.01]) than shapes that have neutral character (median = 2.74, 95% HDI [2.58 2.95], BF = 4.4) or bad character (median = 2.76, 95% HDI [2.56 2.95], 3.1), but we did not found difference between shapes with bad character and neutral character inside for the self-referential shapes. For shapes associated with other, the results of *d'* revealed a reversed pattern to the self-referential condition: *d* prime was smaller when shapes had a good character inside (median = 1.87, 95% HDI [1.71 2.04]) than had neutral (median = 1.96, 95% HDI [1.80 2.14]) or bad character (median = 1.98, 95% HDI [1.79 2.17]) inside. See Figure \@ref(fig:plot-exp4-all). 

The same pattern was found for RTs. For self-referential condition, when good character was presented as a task-irrelevant stimuli, the responds (median = 641, 95% HDI [623 662]) were faster than when neutral character (median = 649, 95% HDI [631 668]) or bad character (median = 648, 95% HDI [628 667]) were inside. This effect was reversed for other-referential condition: shapes associated with other with good character inside (median = 733, 95% HDI [711 754]) were slower than with neutral character (median = 721, 95% HDI [702 741]) or bad character (median = 718, 95% HDI [696 740]) inside.

```{r 4b_BGLMM_sdt, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
exp_name <- '4b'
exp4b_sdt_m1 <- fun_sdt_val_id(exp_name)

# d-prime
# hypothesis(exp4b_sdt_m1, "IdentitySelf:ValenceGood:ismatch > IdentitySelf:ValenceNeutral:ismatch")     # .98
# hypothesis(exp4b_sdt_m1, "IdentitySelf:ValenceGood:ismatch > IdentitySelf:ValenceBad:ismatch")         # 1
# hypothesis(exp4b_sdt_m1, "IdentitySelf:ValenceNeutral:ismatch > IdentitySelf:ValenceBad:ismatch")      # .86
# hypothesis(exp4b_sdt_m1, "IdentityOther:ValenceGood:ismatch > IdentityOther:ValenceNeutral:ismatch")   # .91
# hypothesis(exp4b_sdt_m1, "IdentityOther:ValenceGood:ismatch > IdentityOther:ValenceBad:ismatch")       # .91
# hypothesis(exp4b_sdt_m1, "IdentityOther:ValenceNeutral:ismatch > IdentityOther:ValenceBad:ismatch")    # .65

hypothesis(exp4b_sdt_m1, "IdentitySelf:ValenceGood:ismatch > IdentityOther:ValenceGood:ismatch")        # .92
hypothesis(exp4b_sdt_m1, "IdentitySelf:ValenceNeutral:ismatch > IdentityOther:ValenceNeutral:ismatch")  # .67
hypothesis(exp4b_sdt_m1, "IdentitySelf:ValenceBad:ismatch > IdentityOther:ValenceBad:ismatch")          # .29

# extract the population level parameters
# criteria

df_exp4b_sdt_m1_plot <- exp4b_sdt_m1 %>%
  tidybayes::gather_draws(`b_.*`, regex = TRUE) %>% # get the traces of population level parameters
  # create two columns for two independent factors.
  dplyr::mutate(Valence = dplyr::case_when(grepl("Neutral", .variable) ~ "Neutral",
                                           grepl("Bad", .variable) ~"Bad",
                                           grepl("Good", .variable) ~"Good"),
                Identity = dplyr::case_when(grepl("Self", .variable) ~ "Self",
                                           grepl("Other", .variable) ~"Other"),
                params = dplyr::case_when(grepl("ismatch", .variable) ~ "dprime",
                                           !grepl("ismatch", .variable) ~"criterion"),
                params = factor(params, levels = c('dprime', 'criterion')),
                Identity = factor(Identity, levels = c("Self", "Other")),
                Valence = factor(Valence, levels = c('Good', 'Neutral',  'Bad'))) 

exp4b_sdt_p <- df_exp4b_sdt_m1_plot %>%
  dplyr::filter(params == 'dprime') %>%  # select only d prime
  ggplot2::ggplot(aes(x = Valence, y = .value, color = Identity)) +
  tidybayes::stat_halfeye(aes(fill = Identity), alpha = 0.7) + # position=position_dodge(width = 0.1)
  stat_summary(aes(group = Identity, color = Identity), fun = mean, geom = "line") +
  labs(x = expression("Valence"), 
      y = expression(paste("Posteior of sensitivity ", italic("d'"), sep = ' '))) +
  #scale_colour_brewer(palette = "Dark2") +
  #scale_fill_brewer(palette = "Dark2") +
  theme_classic() 

df_exp4b_sdt_m1_plot_diff <- df_exp4b_sdt_m1_plot %>%
        tidyr::unite(term, c('params', 'Identity', 'Valence')) %>%
        dplyr::ungroup() %>%
        dplyr::select(term, `.chain`, `.iteration`, `.draw`, `.value`) %>%
        tidyr::pivot_wider(names_from = c(term), values_from = .value) %>%   # long to wide
        dplyr::mutate(
                diff_GN_dprm_S = dprime_Self_Good - dprime_Self_Neutral,
                diff_BN_dprm_S = dprime_Self_Bad - dprime_Self_Neutral,
                diff_GB_dprm_S = dprime_Self_Good - dprime_Self_Bad,
                diff_GN_dprm_O = dprime_Other_Good - dprime_Other_Neutral,
                diff_BN_dprm_O = dprime_Other_Bad - dprime_Other_Neutral,
                diff_GB_dprm_O = dprime_Other_Good - dprime_Other_Bad,
                diff_SO_dprm_G = dprime_Self_Good - dprime_Other_Good,
                diff_SO_dprm_N =  dprime_Self_Neutral - dprime_Other_Neutral,
                diff_SO_dprm_B =  dprime_Self_Bad - dprime_Other_Bad
                ) %>%
  dplyr::select(`.chain`, `.iteration`, `.draw`,
               diff_GN_dprm_S, diff_BN_dprm_S, diff_GB_dprm_S,
               diff_GN_dprm_O, diff_BN_dprm_O, diff_GB_dprm_O, 
               diff_SO_dprm_G, diff_SO_dprm_N, diff_SO_dprm_B) %>%
  tidyr::pivot_longer(cols = diff_GN_dprm_S:diff_SO_dprm_B, names_to = "term_diff", values_to =  "value") %>%  # wide to long
  dplyr::mutate(term_diff = factor(term_diff, levels = c('diff_GB_dprm_S', 'diff_GN_dprm_S', 'diff_BN_dprm_S', 
                                                         'diff_GB_dprm_O', 'diff_GN_dprm_O', 'diff_BN_dprm_O', 
                                                         'diff_SO_dprm_G', 'diff_SO_dprm_N', 'diff_SO_dprm_B')))
p_exp4b_dprime1_diff_val <- df_exp4b_sdt_m1_plot_diff %>%
        dplyr::filter(str_detect(term_diff, '_dprm_S|_dprm_O')) %>%
        dplyr::mutate(Identity = dplyr::case_when(grepl("_S", term_diff) ~ "Self",
                                           grepl("_O", term_diff) ~"Other"),
                      Identity = factor(Identity, levels = c("Self", "Other"))) %>%
        dplyr::mutate(term_diff = stringr::str_sub(.$term_diff, end = -8)) %>%
        dplyr::mutate(term_diff = dplyr::case_when(grepl("_GB", term_diff) ~ "Good vs. Bad",
                                                   grepl("_GN", term_diff) ~"Good vs. Neutral",
                                                   grepl("_BN", term_diff) ~ "Bad vs. Neutral"),
                      term_diff = factor(term_diff, levels = c("Good vs. Bad", "Good vs. Neutral", "Bad vs. Neutral"))) %>%
        #dplyr::filter((value >= -1.5) & (value <= 1.5)) %>%
        dplyr::rename(conditions = term_diff) %>%
        ggplot2::ggplot(aes(x = value, y = fct_rev(conditions), fill = after_stat(x > 0))) +
        tidybayes::stat_halfeye() +
        geom_vline(xintercept = 0, linetype = "dashed") +
        scale_fill_manual(values = c('skyblue', 'gray80'),
                    breaks = c(TRUE, FALSE),
                    name = "Effect" , labels = c("Yes", "No")) + 
        # scale_fill_manual(values = c('gray80', 'skyblue')) +
        labs(x = expression(paste("Valence effect on ", italic("d"), " prime", sep = ' ')),
             y = expression("Contrasts")) + 
        facet_wrap( ~ Identity, nrow = 1)

p_exp4b_dprime1_diff_id <- df_exp4b_sdt_m1_plot_diff %>%
        dplyr::filter(str_detect(term_diff, '_SO_')) %>%
        dplyr::mutate(term_diff = dplyr::case_when(grepl("_B", term_diff) ~ "Bad",
                                                   grepl("_N", term_diff) ~"Neutral",
                                                   grepl("_G", term_diff) ~ "Good"),
                      term_diff = factor(term_diff, levels = c("Good", "Neutral", "Bad"))) %>%
        #dplyr::filter(!str_detect(term_diff, '_GB_')) %>%
        # tidyr::unite(term_diff, c('Identity', 'term_diff')) %>%
        dplyr::filter((value >= -1.5) & (value <= 1.5)) %>%
        dplyr::rename(conditions = term_diff) %>%
        ggplot2::ggplot(aes(x = value, fill = after_stat(x > 0))) + #y = fct_rev(conditions), 
        tidybayes::stat_halfeye() +
        geom_vline(xintercept = 0, linetype = "dashed") +
        scale_fill_manual(values = c('skyblue', 'gray80'),
                    breaks = c(TRUE, FALSE),
                    name = "Effect" , labels = c("Yes", "No")) +
        # scale_fill_manual(values = c('skyblue')) +   # note: only one value here, used blue here
        labs(x = expression(paste("Self-referential effect on ", italic("d"), " prime", sep = ' ')),
             y = expression("Contrasts (Self vs. Other)"))+ 
        facet_wrap( ~ conditions, nrow = 1)
```

```{r 4b_BGLMM_rt, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
exp_name <- '4b'
exp4b_rt_m1 <- fun_rt_val_id(exp_name)

df_exp4b_m1_plot_rt <- exp4b_rt_m1 %>%
        tidybayes::gather_draws(`b_.*`, regex = TRUE)  %>%
        dplyr::mutate(.variable = gsub("b_", "", .variable)) %>%
        tidyr::pivot_wider(names_from = c(.variable), values_from = .value) %>%
        dplyr::mutate(NM_Self_Neutral = Intercept,               # calculate the differences between conditions
                      NM_Self_Bad = Intercept  + ValenceBad,
                      NM_Self_Good = Intercept  + ValenceGood ,
                      NM_Other_Neutral = Intercept  + IdentityOther,               # calculate the differences between conditions
                      NM_Other_Bad = Intercept  + ValenceBad  + `IdentityOther:ValenceBad`,
                      NM_Other_Good = Intercept  + ValenceGood + `IdentityOther:ValenceGood`,
                      M_Self_Neutral = Intercept  + ismatch,
                      M_Self_Bad = Intercept  + ismatch + `ismatch:ValenceBad`,
                      M_Self_Good = Intercept  + ismatch + `ismatch:ValenceGood`,
                      M_Other_Neutral = Intercept  + ismatch + `ismatch:IdentityOther`,
                      M_Other_Bad = Intercept  + ismatch + `ismatch:IdentityOther` + `ismatch:IdentityOther:ValenceBad`,
                      M_Other_Good = Intercept  + ismatch + `ismatch:IdentityOther` + `ismatch:IdentityOther:ValenceGood`) %>%
        dplyr::select(`.chain`, `.iteration`, `.draw`, contains('M_')) %>%
        tidyr::pivot_longer(cols = NM_Self_Neutral:M_Other_Good, names_to = "term", values_to =  "value") %>%  # wide to long
  dplyr::mutate(term = factor(term, levels = c('NM_Self_Neutral', 'NM_Self_Bad', 'NM_Self_Good',
                                               'NM_Other_Neutral', 'NM_Other_Bad', 'NM_Other_Good',
                                               'M_Self_Neutral', 'M_Self_Bad', 'M_Self_Good',
                                               'M_Other_Neutral', 'M_Other_Bad', 'M_Other_Good')),
                value = exp(value),
                value = value * 1000) 

p_exp4b_rt1 <- df_exp4b_m1_plot_rt %>%
        tidyr::separate(term, c('Match', 'Identity', 'Valence')) %>% 
        dplyr::mutate(Valence = factor(Valence, levels = c('Good', 'Neutral', 'Bad')),
                      Identity = factor(Identity, levels = c("Self", "Other"))) %>%
        dplyr::filter(Match == 'M') %>%
        # dplyr::rename(Experiments = condition) %>%
        dplyr::filter((value >=200) & (value <=1200)) %>%
        ggplot2::ggplot(aes(y = value, x = Valence, color = Identity)) +
        tidybayes::stat_halfeye(aes(fill = Identity), alpha = 0.7) +
        stat_summary(aes(group = Identity, color = Identity), fun = mean, geom = "line") +
        # geom_vline(data = p_ms_rt1_vlines, aes(xintercept = value, colour = Valence), linetype = "dashed") +
        labs(x = expression("Valence"), 
             y = expression('Posteior of reaction times')) +
        #scale_colour_brewer(palette = "Dark2") +
        #scale_fill_brewer(palette = "Dark2") +
        theme_classic()

df_exp4b_m1_plot_rt_diff <- df_exp4b_m1_plot_rt %>%
        # tidyr::unite(term, c('params', 'Identity', 'Valence')) %>%
        dplyr::ungroup() %>%
        dplyr::select(term, `.chain`, `.iteration`, `.draw`, `value`) %>%
        tidyr::pivot_wider(names_from = c(term), values_from = value) %>%   # long to wide
        dplyr::mutate(
                diff_GN_S_RT_M = M_Self_Good - M_Self_Neutral,
                diff_BN_S_RT_M = M_Self_Bad - M_Self_Neutral,
                diff_GB_S_RT_M = M_Self_Good - M_Self_Bad,
                diff_GN_O_RT_M = M_Other_Good - M_Other_Neutral,
                diff_BN_O_RT_M = M_Other_Bad - M_Other_Neutral,
                diff_GB_O_RT_M = M_Other_Good - M_Other_Bad,
                diff_SO_G_RT_M = M_Self_Good - M_Other_Good,
                diff_SO_N_RT_M = M_Self_Neutral - M_Other_Neutral,
                diff_SO_B_RT_M = M_Self_Bad - M_Other_Bad
                ) %>%
  dplyr::select(`.chain`, `.iteration`, `.draw`,
               diff_GN_S_RT_M:diff_SO_B_RT_M) %>%
  tidyr::pivot_longer(cols = diff_GN_S_RT_M:diff_SO_B_RT_M, names_to = "term_diff", values_to =  "value") %>%  # wide to long
  dplyr::mutate(term_diff = factor(term_diff, levels = c('diff_GN_S_RT_M', 'diff_BN_S_RT_M', 'diff_GB_S_RT_M', 
                                                         'diff_GN_O_RT_M', 'diff_BN_O_RT_M', 'diff_GB_O_RT_M', 
                                                         'diff_SO_G_RT_M', 'diff_SO_N_RT_M', 'diff_SO_B_RT_M')))
df_exp4b_m1_plot_rt_diff %>% 
        dplyr::filter(term_diff == 'diff_SO_G_RT_M') %>%  dplyr::pull(value) %>%
        bayestestR::describe_posterior(., centrality = "mean",
                                       ci = 0.95,
                                       ci_method = 'hdi',
                                       test = c("p_direction", "p_significance"))

df_exp4b_m1_plot_rt_diff %>% 
        dplyr::filter(term_diff == 'diff_SO_N_RT_M') %>%  dplyr::pull(value) %>%
        bayestestR::describe_posterior(., centrality = "mean",
                                       ci = 0.95,
                                       ci_method = 'hdi',
                                       test = c("p_direction", "p_significance"))

df_exp4b_m1_plot_rt_diff %>% 
        dplyr::filter(term_diff == 'diff_SO_B_RT_M') %>%  dplyr::pull(value) %>%
        bayestestR::describe_posterior(., centrality = "mean",
                                       ci = 0.95,
                                       ci_method = 'hdi',
                                       test = c("p_direction", "p_significance"))

p_exp4b_rt_diff_val <- df_exp4b_m1_plot_rt_diff %>%
        dplyr::filter(str_detect(term_diff, '_S_RT_M|_O_RT_M')) %>%
        dplyr::mutate(Identity = dplyr::case_when(grepl("_S", term_diff) ~ "Self",
                                                  grepl("_O", term_diff) ~"Other"),
                      Identity = factor(Identity, levels = c("Self", "Other"))) %>%
        dplyr::mutate(term_diff = stringr::str_sub(.$term_diff, end = -8)) %>%
        dplyr::mutate(term_diff = dplyr::case_when(grepl("_GB", term_diff) ~ "Good vs. Bad",
                                                   grepl("_GN", term_diff) ~"Good vs. Neutral",
                                                   grepl("_BN", term_diff) ~ "Bad vs. Neutral"),
                      term_diff = factor(term_diff, levels = c("Good vs. Bad", "Good vs. Neutral", "Bad vs. Neutral"))) %>%
        # dplyr::filter((value >= -1.5) & (value <= 1.5)) %>%
        dplyr::rename(conditions = term_diff) %>%
        ggplot2::ggplot(aes(x = value, y = fct_rev(conditions), fill = after_stat(x < 0))) +
        tidybayes::stat_halfeye() +
        geom_vline(xintercept = 0, linetype = "dashed") +
        scale_fill_manual(values = c('skyblue', 'gray80'),
                    breaks = c(TRUE, FALSE),
                    name = "Effect" , labels = c("Yes", "No")) + 
        # scale_fill_manual(values = c('gray80', 'skyblue')) +
        labs(x = expression("Valence effect on RTs "),
             y = expression("Contrasts")) + 
        facet_wrap( ~ Identity, nrow = 1)

p_exp4b_rt_diff_id <- df_exp4b_m1_plot_rt_diff %>%
        dplyr::filter(str_detect(term_diff, '_SO_')) %>%
        dplyr::mutate(term_diff = dplyr::case_when(grepl("_B", term_diff) ~ "Bad",
                                                   grepl("_N", term_diff) ~"Neutral",
                                                   grepl("_G", term_diff) ~ "Good"),
                      term_diff = factor(term_diff, levels = c("Good", "Neutral", "Bad"))) %>%
        # dplyr::filter(!str_detect(term_diff, '_GB_')) %>%
        # tidyr::unite(term_diff, c('Identity', 'term_diff')) %>%
        # dplyr::filter((value >= -1.5) & (value <= 1.5)) %>%
        dplyr::rename(conditions = term_diff) %>%
        ggplot2::ggplot(aes(x = value, fill = after_stat(x < 0))) + # , y = fct_rev(conditions)
        tidybayes::stat_halfeye() +
        geom_vline(xintercept = 0, linetype = "dashed") +
        scale_fill_manual(values = c('skyblue', 'gray80'),
                    breaks = c(TRUE, FALSE),
                    name = "Effect" , labels = c("Yes", "No")) + 
        # scale_fill_manual(values = c('skyblue')) +   # note: only one value here, used blue here
        labs(x = expression("Self-referential effect on RTs "),
             y = expression("Contrasts (Self vs. Other)"))+ 
        facet_wrap( ~ conditions, nrow = 1)

```

```{r plot-exp4b-BGLM, fig.cap="exp4a: Results of Bayesian GLM analysis.",  fig.height=9, fig.width=12, warning=FALSE}
library(patchwork)
p3 <- (p_exp4b_rt1 + exp4b_sdt_p ) + plot_layout(nrow = 1, guides = "collect") 
# p2 <- p_exp4b_rt_diff_val + p_exp4b_dprime1_diff_val + plot_layout(nrow = 1, byrow = FALSE, guides = "collect") 
p4 <- (p_exp4b_rt_diff_id + p_exp4b_dprime1_diff_id) + plot_layout(nrow = 1, byrow = FALSE, guides = "collect") 
```

```{r plot-exp4-all, fig.cap="exp4: Results of Bayesian GLM analysis.",  fig.height=9, fig.width=15, warning=FALSE}
library(patchwork)

design <- "
  1234
  5678
"
p_exp4a_rt1 + exp4a_sdt_p + p_exp4b_rt1 + exp4b_sdt_p + p_exp4a_rt_diff_val + p_exp4a_dprime1_diff_val + p_exp4b_rt_diff_id + p_exp4b_dprime1_diff_id  + plot_layout(design = design, guides = "collect")

# ((p1 +plot_layout(guides = "collect")) + p3 + plot_layout(guides = "collect")) + plot_layout(ncol = 3, widths = c(1, 1, 4), guides = 'keep')
# 
# (((p_exp4a_rt1 + exp4a_sdt_p + plot_layout(guides = "collect", nrow = 1)) + 
#                 (p_exp4b_rt1 + exp4b_sdt_p + plot_layout(guides = "collect", nrow = 1)) + plot_layout(nrow = 1)) + 
#         ((p_exp4a_rt_diff_val + p_exp4a_dprime1_diff_val + plot_layout(guides = "collect", nrow = 1)) 
#          + (p_exp4b_rt_diff_id + p_exp4b_dprime1_diff_id + plot_layout(guides = "collect", nrow = 1)) + plot_layout(nrow = 1))) + 
#         plot_layout(design = design, guides = "keep") +  plot_annotation(tag_levels = 'A')  

```


In experiment 4b, moral character was the task-relevant factor, and we found that there were main effect of moral character: shapes associated with good character were performed better than other-related conditions, on both *d'* and reaction times.

Most importantly, we found evidence that task-irrelevant self-referential process also played an role. For shapes associated with good person, the *d* prime was greater when shapes had an "self" inside than with "other" inside ($mean_{diff}$ = 0.14, 95% credible intervals [-0.02, 0.31], BF = 12.07, p = 0.92), but this effect did not happen when the target shape where associated with "neutral" ($mean_{diff}$ = 0.04, 95% CI [-.11, .18]) or "bad" person ($mean_{diff}$ = -.05, 95% CI[-.18, .09]). 

The same trend appeared for the RT data. For shapes associated with good person, with a "self" inside the shape reduced the reaction times as compared with when a "other" inside the shape ($mean_{diff}$ = -55 ms, 95%CI[-75, -35]), but this effect did not occur when the shapes were associated neutral ($mean_{diff}$ = 10, 95% CI [1, 20]) or bad ($mean_{diff}$ = 5, 95%CI [-16, 27]) person. See Figure \@ref(fig:plot-exp4-all).

# Discussion
We human inevitably view other people and ourselves in a moral lens [citation is needed]. Yes how this moral lens will change our information processes is unknown. Across nine experiments, we studied the processing of moral character using a social associative learning task, we examined the effect of moral character on a matching task and explored the mechanisms underlying the effect. We found robust evidence that good character are prioritized in the matching task, regardless of the label used for moral characters or the way stimuli are presented. We documented that this positivity effect was driven by a self-referential processing: prioritization only occur when moral characters are self-referential but not other-referential. The prioritization effect occur when self and good character are combined, whether task-relevant or not. When good character were other-referential, even implicitly, the information process might be slowed down. Together, our findings highlight the importance of the self-referential in perceiving positive moral character. These findings contributed to a growing literature on the social nature of perception [@xiao_perceiving_2016; @freeman_chapter_2020] by supporting the idea that people can prioritized not just physically salient, or affective stimuli, but also socially salient stimuli, i.e., instantly acquired moral information.

First, we examined the perceptual process of moral character to understand how moral information are processed. Prior research has demonstrated that bad moral behavior is stronger in impression formation [citation] and bad moral character are attended quicker than neutral moral character []. The empirical studies on the moral character often focus on self-reported  data rather than behavioral response. In this paper, we examined the perceptual processes of moral character. In doing so, we shifted the focus from consequences of information process of moral character to the information process itself, thus broaden the scope of the existing research. 

Second, perceptual processing is the upstream of our information that can help us understand priority of different information. We thus contributed to the research on moral character by demonstrating that information related to good character in general, and good moral self in specific, is prioritized. Specifically, we found that instantly learned moral character information can change the information process of neutral, non-social information. Presumably this prioritization occurs because good moral character and moral self is central to one's social life. Research has found that moral self is essential for one's identity and people has stronger self-enhancement effect in moral domain than in other social domain. This positivity effect is opposite to negativity effect in impression formation, suggesting that impression formation and perceptual-matching may involved different information process mechanisms. This positivity effect, though surprising at first, is well supported by previous studies. Positivity effect had been found in associative learning [], lexical decision-making [], and IAT []. A common feature of these paradigms is that decision-making occurs at relative later stage of the information processing in perception, instead of early sensory processing stage. In the current paradigm, participants made a matching judgment, which was only possible after participants formed a perception of both the shape and the label and retrieve the association between them. ample evidence supported the idea that positive stimuli have advantage at the later stage of perception [@pool_attentional_2016]. The task used in the current study may explain why the result are different from previous studies such as @anderson_visual_2011 and @eiserbeck_visual_2020, where the early processing stage were targeted by attention blink paradigm. 

The absence of negativiity effect may also caused by the fact that the bad character here is an abstract concept that may not bring concrete threatening to the participants, therefore it is not as strong as previous studies used emotional stimuli that has higher arousal. Besides, recent study found that when the moral violation is not life-threatening, the impression of bad character is volatile in the social context [].

Third, knowing that good character and moral-self is prioritized is not sufficient; we need to know why this prioritization occurs. Our results indicate that the good character prioritization is driven by spontaneous self-referential processing. Also, these results revealed that either a general-self based social categorization or moral self as anchor view alone can explain the results. Instead, we proposed that moral-self based social categorization can better account for the results, especially the results where either identity or moral character information were task-irrelevant. These results echo prior research on moral-self view, suggesting that moral-self as true self is not only at self-report level but also at perceptual level. Further, our results showed that we not only regard moral self as the true-self, but also seek to categorize information based on moral-self: when good-other creates an ambiguous situation, the responses was slowed down in perceptual processing. 

Fourth, we find that behavioral data and self-reported data doesn't congruent. When asked to rate the distance between self and good person, the distance is similar to the distance between self and neutral person. However, the distance between self and bad person is the longest, even longer than the distance between good and bad. These results might be caused by the social desirability effect that often occurs in self-reporting. However, we didn't not find strong evidence for the correlation between behavioral results and the self-reported person distance. 

[Memory or perception.] One would argue that the effect here may represent a memory effect instead of perpetual effect *per se*. (1) how to define perception is debated, while some researchers included memory components in perception, others do not. Here, we are more on the broader view of perception. (2), the memory effect view predict that the effect will be eliminated after participants became familiar with the association. We did supplementary analysis where we divided the whole experiment into three different stage: early, middle, and later, and then compared the results pattern of early and later stages. These results revealed null effect of training. These additional analysis suggested that memory effect may exist, but in a sense that they reflected a long-term, stable pattern of different valenced moral character, instead of a short-term, associative learning induced effect.

[free association from small world of words]


# References
```{r create_r-references, echo=FALSE,results='hide'}
#r_refs(file = "r-references.bib"))
```

\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

<div id = "refs"></div>
\endgroup
