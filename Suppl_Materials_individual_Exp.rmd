---
title             : "Supplementary Materials for Perpecptual Salience of Positive Self"
shorttitle        : "Supplementary Materials"

author: 
  - name          : "Chuan-Peng Hu"
    affiliation   : "1,2"
    corresponding : yes    # Define only one corresponding author
    address       : "Langenbeckstr. 1, Neuroimaging Center, University Medical Center Mainz, 55131 Mainz, Germany"
    email         : "hcp4715@gmail.com"
  - name          : "Kaiping Peng"
    affiliation   : "1"
  - name          : "Jie Sui"
    affiliation   : "1,3"

affiliation:
  - id            : "1"
    institution   : "Tsinghua University, 100084 Beijing, China"
  - id            : "2"
    institution   : "Leibniz Institute for Resilience Research, 55131 Mainz, Germany"
  - id            : "3"
    institution   : "University of Aberdeen, Aberdeen, Scotland"
    
authornote: |
  Chuan-Peng Hu, Department of Psychology, Tsinghua University, 100084 Beijing, China; Germany Resilience Center, 55131 Mainz, Germany.
  Kaiping Peng, Department of Psychology, Tsinghua University, 100084 Beijing, China.
  Jie Sui, Department of Psychology, the University of Bath, Bath, UK.

  Authors contriubtion: CPH, JS, & KP design the study, CPH collected the data, CPH analyzed the data and drafted the manuscript. KP & JS supported this project.

wordcount         : "X"

bibliography      :  
  - r-references.bib
  - endnote.bib

floatsintext      : no
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : yes
mask              : no
draft             : no

documentclass     : "apa6"
classoption       : "man"
output            : 
  papaja::apa6_pdf:
    latex_engine  : xelatex
---

```{r setup, include=FALSE}
#rm(list = ls())

#output: pdf_document
#knitr::opts_chunk$set(echo = TRUE)
source('Initial.r')
curDir = here::here() #dirname(rstudioapi::getActiveDocumentContext()$path)
#curDir = '.'#dirname(rstudioapi::getSourceEditorContext()$path)
figDir = here::here('figures')
# Install the stable development verions from GitHub
if(!"papaja" %in% rownames(installed.packages())) devtools::install_github("crsh/papaja")

library(brms)

# using afex and emmeans to do the ANOVA and emmeans for post-hoc comparison
afex_options(emmeans_model = "multivariate")
options(tinytex.verbose = F) # debug the tex
knitr::opts_chunk$set(message = FALSE)

set.seed(42)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed)

CommonColnames_d  <- c("ExpID", "Site", "Subject", "Age", "Sex", 'Domain', "Identity", "Valence", "dprime")
CommonColnames_rt <- c("ExpID", "Site", "Subject", "Age", "Sex", 'Domain', "Matchness", "Identity", "Valence", "RT")

load("AllData.RData")

```


Instead of using the mean of reaction or the Frequentist way to calculate the sensitivity under signal detection theory, We analyzed our data using Hierarchical Bayesian Drift Diffusion Model (HDDM). This was done for a few reasons: first, either mean or median of RTs are representative to the RT distribution, which is usually highly skewed; second, sequential sampling models have a concrete assumption about the generative process of RTs and accurate, provide stronger framework for testing hypothesis. Also, these models had been widely used in two alternative forced choice (TAFC) task, including perceptual matching task [van_zandt_comparison_2000].

Using HDDM to extract the dependent variable allow us to infer the perceptual process, at least better than we can infer when using mean or median-based GLM. Previous studies have showed that each parameter of the DDM is influence by different way. The initial bias is largely influenced by the proportion of each type of trial, the boundary is influenced by the instruction about the accuracy, while the drift rate is mainly related to relative perceptual salience or easiness of the perceptual decision-making.

Before analyzing the real data, we did parameter recovery to test the sanity of the model.

First, we simulated the data using the `hddm.generate.gen_rand_data` in HDDM model. To emulate the previous study on the perceptual matching task (same-faster-different-slow) and self-tagging task (manipulated effect only occur at the matched trials), we simulated six conditions. For the mismatching trials, we ....; For the matching trials, we simulated three levels, we varied drift rate ($v$) at three level: $1.5$, $2.5$, and $3.5$, while kept the other parameters fixed ($a = 1$, $t=0.4$, $z=0.5$).

# Experiment 1a

## Methods
### Participants
`r df1a.T.basic$N` college students (`r df1a.T.basic$Nf` female, age = `r df1a.T.basic$Age_mean` $\pm$ `r df1a.T.basic$Age_sd` years) participated. `r df1a.T.basic$N_thu` of them were recruited from Tsinghua University community in 2014; `r df1a.T.basic$N_wzu` were recruited from Wenzhou University in 2017. All participants were right-handed except one, and all had normal or corrected-to-normal vision. Informed consent was obtained from all participants prior to the experiment according to procedures approved by the local ethics committees. `r nrow(df1a.excld.sub)` participant’s data were excluded from analysis because nearly random level of accuracy, leaving `r df1a.v.basic$N` participants (`r df1a.v.basic$Nf` female, age = `r df1a.v.basic$Age_mean` $\pm$ `r df1a.v.basic$Age_sd` years).

### Stimuli and Tasks
Three geometric shapes were used in this experiment: triangle, square, and circle. These shapes were paired with three labels (bad person, good person or neutral person). The pairs were counterbalanced across participants. 

### Procedure
As we describe in general method part, this experiment had two phases. First, there was a learning stage. Participants were asked to learn the relationship between geometric shapes (triangle, square, and circle) and different person (bad person, a good person, or a neutral person). For example, a participant was told, “bad person is a circle; good person is a triangle; and a neutral person is represented by a square.” After participant remember the associations (usually in a few minutes), participants started a practicing phase of matching task which has the exact task as in the experimental task. 
In the experimental task, participants judged whether shape–label pairs, which were subsequently presented, were correct. Each trial started with the presentation of a central fixation cross for 500 ms. Subsequently, a pairing of a shape and label (good person, bad person, and neutral person) was presented for 100 ms. The pair presented could confirm to the verbal instruction for each pairing given in the training stage, or it could be a recombination of a shape with a different label, with the shape–label pairings being generated at random. The next frame showed a blank for 1100ms. Participants were expected to judge whether the shape was correctly assigned to the person by pressing one of the two response buttons as quickly and accurately as possible within this timeframe (to encourage immediate responding). Feedback (correct or incorrect) was given on the screen for 500 ms at the end of each trial, if no response detected, “too slow” was presented to remind participants to accelerate. Participants were informed of their overall accuracy at the end of each block. The practice phase finished and the experimental task began after the overall performance of accuracy during practice phase achieved 60%. 
For pariticpants from the Tsinghua community, they completed 6 experimental blocks of 60 trials. Thus, there were 60 trials in each condition (bad-person matched, bad-person nonmatching, good-person matched, good-person nonmatching, neutral-person matched, and neutral-person nonmatching). For the participants from Wenzhou Univeristy, they finished 6 blocks of 120 trials, therefore, 120 trials for each condition.

### Data analysis
As we describe in the general method section.

## Results

```{r 'ex1a-dprime-rt', fig.cap="RT and *d* prime of Experiment 1a.", fig.height=6, fig.width=10, warning=FALSE}
rtdata <- df1a.v.rt_m %>% dplyr::filter(Matchness == "Match") %>% dplyr::rename(RT = RT_m)
Mplots(expName = 'exp1a', df1a.v.dprime_l, rtdata)

#plotData <- dplyr::full_join(rtdata, df1a.v.dprime_l, by = c('Site','Subject','Age','Sex','Valence'))

#p <- ggplot(plotData, aes(x = RT, y = dprime, color = Valence)) + geom_point()
  
#ggExtra::ggMarginal(p, groupColour = TRUE, groupFill = TRUE)

```

### d prime
Figure \@ref(fig:ex1a-dprime-rt) shows *d* prime and reaction times during the perceptual matching task. We conducted a single factor (valence: good, neutral, bad) repeated measure ANOVA. 
```{r 1a_dprime, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
df1a.sdt <- df1a.v %>%
  dplyr::filter(!is.na(RESP)) %>% # filter trials without response
  dplyr::mutate(ismatch = ifelse(Matchness == 'Match', 1, 0),
                saymatch = ifelse((Matchness == 'Match' & ACC == 1) | 
                                    (Matchness == 'Mismatch' & ACC == 0), 1, 0),
                ismatch_num = ifelse(Matchness == 'Match', 0.5, -0.5))

# fit a two-level hierarchical model for SDT, didn't specify the prior
exp1a_std_m1 <- brms::brm(saymatch ~ 0 + Valence + Valence:ismatch_num + 
                         (0 + Valence + Valence:ismatch_num | Subject),
                       family = bernoulli(link="probit"),
                       data = df1a.sdt,
                       #control = list(adapt_delta = .95),
                       cores = parallel::detectCores(),
                       file = here::here("glmmModels/exp1a_std_m1_EffectCode"))
summary(exp1a_std_m1)

plot(hypothesis(exp1a_std_m1,
                "ValenceGood:ismatch_num > ValenceNeutral:ismatch_num"))

plot(hypothesis(exp1a_std_m1,
                "ValenceGood:ismatch_num > ValenceBad:ismatch_num"))

  # anova for d prime with 2*2 design
df1a_dprime_anova <- afex::aov_ez('Subject','dprime',df1a.v.dprime_l, within = c('Valence'))
df1a_dprime_anova_apa <- df1a_dprime_anova %>% papaja::apa_print.afex_aov()

posthoc_1a_d <- emmeans::emmeans(df1a_dprime_anova, "Valence") # compare each valence for both self and other condition
#pairs(posthoc_1a_d)
```
```{r results='asis', echo = F, eval=F}
#knitr::kable(nice(df4b_dprime_anova), caption = "ANOVA of d prime")
papaja::apa_table(df1a_dprime_anova_apa$table
  , caption = "Repeated measure ANOVA of *d* prime from Experiment 1a"
  , note = "*d* prime was calculated in a signal detection way.")

```

We found the effect of Valence (`r df1a_dprime_anova_apa$full$Valence`). The post-hoc comparison with multiple comparison correction revealed that the shapes associated with Good-person (2.11, SE = 0.14) has greater *d* prime than shapes associated with Bad-person (1.75, SE = 0.14), *t*(50) = 3.304, *p* = 0.0049. The Good-person condition was also greater than the Netural-person condition (1.95, SE = 0.16), but didn't reach statical significant, *t*(50) = 1.54, *p* = 0.28. Neither the Neutral-person conditiona is significantly greater than the Bad-person conidition, *t*(50) = 2.109, *p* = .098.

### Reaction time
```{r 1a_RT, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
df1a_RT_anova <- afex::aov_ez('Subject','RT_m',df1a.v.rt_m, within = c('Matchness','Valence')) # using afex's function

df1a_RT_anova_apa <- df1a_RT_anova %>% papaja::apa_print.afex_aov()

df1a.v.rt_m1 <- df1a.v %>%
  dplyr::filter(ACC == 1 & Matchness == "Match") %>%
  dplyr::group_by(Site,Subject,Matchness, Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup() %>%
  dplyr::mutate(Valence = factor(Valence, levels = c("Good","Neutral","Bad")))

df1a_RT_anova_m <- afex::aov_ez('Subject','RT_m',df1a.v.rt_m1, within = c('Valence'))
df1a_RT_anova_m_apa <- df1a_RT_anova_m %>% papaja::apa_print.afex_aov()

df1a.v.rt_m2 <- df1a.v %>%
  dplyr::filter(ACC == 1 & Matchness == "Mismatch") %>%
  dplyr::group_by(Site,Subject,Matchness, Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup()

df1a_RT_anova_nm <- afex::aov_ez('Subject','RT_m',df1a.v.rt_m2, within = c('Valence'))
df1a_RT_anova_nm_apa <- df1a_RT_anova_nm %>% papaja::apa_print.afex_aov()

posthoc_1a_rt <- emmeans::emmeans(df1a_RT_anova_m, "Valence") # compare each valence for both self and other condition
# pairs(posthoc_1a_rt)

```
We conducted 2 (Matchness: Match v. Mismatch) by 3 (Valence: good, neutral, bad) repeated measure ANOVA. We found the main effect of Matchness (`r df1a_RT_anova_apa$full$Matchness`), main effect of valence (`r df1a_RT_anova_apa$full$Valence`), and intercation between Matchness and Valence (`r df1a_RT_anova_apa$full$Matchness_Valence`).

We then carried out two separate ANOVA for Match and Mismatched trials. For matched trials, we found the effect of valence `r df1a_RT_anova_m$full$Valence`. We further examined the effect of valence for both self and other for mached trials. We found that shapes associated with Good Person (684 ms, SE = 11.5) responded faster than Neutral (709 ms, SE = 11.5), *t*(50) = -2.265, *p* = 0.0702) and Bad Person (728 ms, SE = 11.7), *t*(50) = -4.41, *p* = 0.0002), and the Neutral condition was faster than the Bad condition, *t*(50) = -2.495, *p* = 0.0415). For non-matched trials, there was no significant effect of Valence (`r df1a_RT_anova_nm$full$Valence`).

# Experiment 1b
In this study, we aimed at excluding the potential confouding factor of the familarity of words we used in experiment 1a, by matching the familiarity of the words.

## Method

```{r loadingData_1b,echo=FALSE,results='hide', eval = FALSE}
# data collected in Tsinghua U
df1b_1 <- read.csv(file.path('.', 'exp1b', 'rawdata_behav_exp1b_2014.csv'), header = TRUE,
                   sep = ",", stringsAsFactors=FALSE, na.strings=c("","NA")) %>%
        dplyr::mutate(Site = "THU", Subject = Subject + 1100)

# data collected in Wenzhou U
df1b_2 <- read.csv(file.path('.', 'exp1b', 'rawdata_behav_exp1b_201705.csv'), header = TRUE,
                   sep = ",",stringsAsFactors=FALSE,na.strings=c("","NA")) %>%
        dplyr::mutate(Site = "WZU")

# combine data and clean
df1b   <- rbind(df1b_1,df1b_2) %>%
        dplyr::rename(ACC = Target.ACC,           # rename columns
                      RT  = Target.RT,
                      CRESP = Target.CRESP,
                      BlockNo = BlockList.Sample,
                      TrialNo = SubTrial,
                      RESP = Target.RESP,
                      Matchness = YesNoResp,
                      Valence = Shape) %>%
        dplyr::mutate(Valence = ifelse(Valence == "Normal", "Neutral", Valence),   # recode values
                      Matchness = ifelse(Matchness == "Yes", "Match", "Mismatch"),
                      Age = ifelse(Age == 0, NA, Age),
                      #Subject = factor(Subject),
                      #ExpID = 'Exp_1b',
                      Identity = NA,
                      #Domain = "Morality",
                      Site = factor(Site)) %>% # if the min age is 0, that age is missing
        #dplyr::select(CommonColnames)%>%
        dplyr::arrange(Subject)

rm(df1b_1,df1b_2)

df1b.T.basic     <- df1b %>%
  dplyr::select(Site, Subject, Age, Sex) %>%
  dplyr::distinct(Subject, .keep_all = TRUE) %>%
  dplyr::summarise(N = length(Subject),
                   N_thu = length(Site[Site == "THU"]),
                   N_wzu = length(Site[Site == "WZU"]),
                   Nf = length(Sex[Sex == "female"]),
                   Nm = length(Sex[Sex == "male"]),
                   Age_mean = round(mean(Age,na.rm=TRUE),2),
                   Age_sd = round(sd(Age,na.rm=TRUE),2))

# number of participant who didn't finished the experiment
nQuit <- length(unique(df1b$Subject[is.na(df1b$BlockNo)])) - length(unique(df1b$Subject[!is.na(df1b$BlockNo)]))

# participants should be excluded
df1b.excld.sub <-  df1b %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::group_by(Subject) %>%
#  dplyr::mutate(ACC = ifelse(RT <= 200, 0, ACC)) %>%  # set less than 200 ms response as wrong
  dplyr::summarise(N = length(ACC),                   # caculate the overall accuracy for each subject
                   N_crrct = sum(ACC),
                   ACC = sum(ACC)/length(ACC)) %>%
  dplyr::filter(ACC < 0.6) %>%                        # exlucde the participants with less than 60% overall accuracy
  dplyr::select(Subject)

# The rate of excluded trials in valid data
df1b.invalid_trial_rate   <- df1b %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::filter(!(Subject %in% df1b.excld.sub$Subject)) %>%   # exclude the invalid subjects
  dplyr::summarize(rate = length(RT[RT <= 200 & ACC == 1])/length(RT))

df1b.v   <- df1b %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::filter(!(Subject %in% df1b.excld.sub$Subject)) %>%   # exclude the invalid subjects
  dplyr::filter(!(RT <= 200 & ACC == 1))                      # exclude < 200 trials

df1b.v.basic     <- df1b.v %>%
  dplyr::select(Site, Subject, Age, Sex) %>%
  dplyr::distinct(Subject, .keep_all = TRUE) %>%
  dplyr::summarise(N = length(Subject),
                   N_thu = length(Site[Site == "THU"]),
                   N_wzu = length(Site[Site == "WZU"]),
                   Nf = length(Sex[Sex == "female"]),
                   Nm = length(Sex[Sex == "male"]),
                   Age_mean = round(mean(Age,na.rm=TRUE),2),
                   Age_sd = round(sd(Age,na.rm=TRUE),2))

# calculate d prime
df1b.v.dprime_l <- df1b.v %>%
  dplyr::mutate(sdt = mosaic::derivedFactor("hit" = (ACC ==1 & Matchness == "Match"),     # code as hit
                                    "CR" = (ACC ==1  & Matchness == "Mismatch"),  # code as correct reject
                                    "miss" = (ACC == 0 & Matchness == "Match"),   # code as miss
                                    "FA" = (ACC == 0 & Matchness == "Mismatch"),  # code as false alarm
                                    .method ="first",  .default = NA)) %>% 
  dplyr::group_by(Site, Subject, Age, Sex, Valence, sdt) %>%
  dplyr::summarise(N = length(sdt)) %>%                                      # calculate the counts for each 
  dplyr::ungroup() %>%
  tidyr::spread(key = sdt, value = N,fill = 0) %>%                           # long-to-wide format
  dplyr::mutate(hitR = hit/(hit + miss),                                     # hit rate
                FAR  = FA/(FA+CR)) %>%                                       # fa rate
  dplyr::mutate(hitR = ifelse(hitR == 1, 1 - 1/(2*(hit + miss)), hitR),      # if hit rate is 1, standardize it
                FAR  = ifelse(FAR == 0, 1/(2*(hit + miss)), FAR)) %>%        # if FA rate is 0, standardize it
  dplyr::mutate(dprime = qnorm(hitR) - qnorm(FAR)) %>%
  dplyr::select(Site, Subject, Age, Sex, Valence, dprime) %>%                # select relevant columns
  dplyr::mutate(Valence = factor(Valence, levels = c("Good","Neutral","Bad")))

# calculate the mean RT of each condition for each participants for ANOVA
df1b.v.rt_m <- df1b.v %>%
  dplyr::filter(ACC == 1) %>%
  dplyr::group_by(Site, Subject, Age, Sex, Matchness, Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup()

### prepare for the later meta-analysis
df1b.meta.d <- df1b.v.dprime_l %>% 
  dplyr::mutate(Identity = NA,
                ExpID = 'Exp1b',
                Domain = "Morality") %>%        # add domain as morality, to be comparable with experiment 5.
  dplyr::select(CommonColnames_d)

df1b.meta.rt <- df1b.v.rt_m %>% 
  dplyr::rename(RT = RT_m) %>%
  dplyr::mutate(Identity = NA,
                ExpID = 'Exp1b',
                Domain = "Morality") %>%        # add domain as morality, to be comparable with experiment 5.
  dplyr::select(CommonColnames_rt)

```

### Participants
`r df1b.T.basic$N` college students (`r df1b.T.basic$Nf` female, age = `r df1b.T.basic$Age_mean` $\pm$ `r df1b.T.basic$Age_sd` years) participated. `r df1b.T.basic$N_thu` of them were recruited from Tsinghua University community in 2014; `r df1b.T.basic$N_wzu` were recruited from Wenzhou University in 2017. All participants were right-handed except one, and all had normal or corrected-to-normal vision. Informed consent was obtained from all participants prior to the experiment according to procedures approved by the local ethics committees. `r nrow(df1b.excld.sub)` participant’s data were excluded from analysis because nearly random level of accuracy, leaving `r df1b.v.basic$N` participants (`r df1b.v.basic$Nf` female, age = `r df1b.v.basic$Age_mean` $\pm$ `r df1b.v.basic$Age_sd` years).

### Stimuli and Tasks
Three geometric shapes (triangle, square, and circle, with 3.7º × 3.7º of visual angle) were presented above a white fixation cross subtending 0.8º × 0.8º of visual angle at the center of the screen. The three shapes were randomly assigned to three labels with different moral valence: a morally bad person (“恶人”, ERen), a morally good person (“善人”, ShanRen) or a morally neutral person (“常人”, ChangRen). The order of the associations between shapes and labels was counterbalanced across participants.
Three labels used in this experiment is selected based on the rating results from an independent survey, in which participants rated the familiarity, frequency, and concreteness of eight different words online. Of the eight words, three of them are morally positive (HaoRen, ShanRen, Junzi), two of them are morally neutral (ChangRen, FanRen), and three of them are morally negative (HuaiRen, ERen, LiuMang). An independent sample consist of 35 participants (22 females, age 20.6 ± 3.11) were recruited to rate these words. Based on the ratings (see supplementary materials Figure S1), we selected ShanRen, ChangRen, and ERen to represent morally positve, neutral, and negative person. 

### Procedure
For participants from both Tsinghua community and Wenzhou community, the procedure in the current study was exactly same as in experiment 1a. For participants in Tsinghua community, they finished a survey suite include personal distance, objective and subjective SES, belief in just world (Wu et al., 2011), disgust senstivity scale (谭永红 et al., 2007), trait justice (Wu et al., 2014), and cognitive reflection test (Frederick, 2005). For participants from Wenzhou community, they finished exactly the same questionnaires as the participants from Wenzhou University in experiment 1a.

## Data Analysis
Data was analyzed as in experiment 1a. 

## Results

```{r 'ex1b-dprime-rt', fig.cap="RT and *d* prime of Experiment 1b.", fig.height=6, fig.width=10, warning=FALSE}
rtdata <- df1b.v.rt_m %>% dplyr::filter(Matchness == "Match") %>% dplyr::rename(RT = RT_m)

Mplots(expName = 'exp1b', df1b.v.dprime_l,rtdata)
```

Figure \@ref(fig:ex1b-dprime-rt) shows *d* prime and reaction times of experiment 1b. 

### *d* prime

```{r 1b_dprime, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
# anova for d prime
df1b_dprime_anova <- afex::aov_ez('Subject','dprime',df1b.v.dprime_l, within = c('Valence'))
df1b_dprime_anova_apa <- df1b_dprime_anova %>% papaja::apa_print.afex_aov()

posthoc_1b_d <- emmeans::emmeans(df1b_dprime_anova, "Valence") # compare each valence for both self and other condition
#pairs(posthoc_1b_d)
```
Repeated measures ANOVA revealed main effect of valence, `r df1b_dprime_anova_apa$full$Valence`. Paired t test showed that the Good-Person condition (1.87 $\pm$ 0.102) was with greater *d* prime than Netural condition (1.44 $\pm$ 0.101, *t*(51) = 5.945, *p* < 0.001). We also found that the Bad-Person condition (1.67 $\pm$ 0.11) has also greater *d* prime than neutral condition , *t*(51) = 3.132, *p* = 0.008). There Good-person condition was also slightly greater than the bad conidition, *t*(51) = 2.265, *p* = 0.0701.

### Reaction time

```{r 1b_RT, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
df1b_RT_anova <- afex::aov_ez('Subject','RT_m',df1b.v.rt_m, within = c('Matchness','Valence'))
df1b_RT_anova_apa <- df1b_RT_anova %>% papaja::apa_print.afex_aov()

df1b.v.rt_m1 <- df1b.v %>%
  dplyr::filter(ACC == 1 & Matchness == "Match") %>%
  dplyr::group_by(Site,Subject,Matchness, Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup() %>%
  dplyr::mutate(Valence = factor(Valence, levels = c("Good","Neutral","Bad")))

df1b.v.rt_m %>%
  dplyr::group_by(Matchness, Valence) %>%
  dplyr::summarise(mean = mean(RT_m),
                   sd = sd(RT_m))

df1b_RT_anova_m <- afex::aov_ez('Subject','RT_m', df1b.v.rt_m1,     # using afex's function 
                                  within = c('Valence'))
df1b_RT_anova_m_apa <- df1b_RT_anova_m %>% papaja::apa_print.afex_aov()

df1b.v.rt_m2 <- df1b.v %>%
  dplyr::filter(ACC == 1 & Matchness == "Mismatch") %>%
  dplyr::group_by(Site,Subject,Matchness, Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup()

df1b_RT_anova_nm <- afex::aov_ez('Subject','RT_m',df1b.v.rt_m2,     # using afex's function 
                                  within = c('Valence'))
df1b_RT_anova_nm_apa <- df1b_RT_anova_nm %>% papaja::apa_print.afex_aov()
posthoc_1b_rt <- emmeans::emmeans(df1b_RT_anova_m, "Valence") # compare each valence for both self and other condition
# pairs(posthoc_1b_rt)
```
We found intercation between Matchness and Valence (`r df1b_RT_anova_apa$full$Matchness_Valence`) and then analyzed the matched trials and mismatched trials separately, as in experiment 1a. For matched trials, we found the effect of valence `r df1b_RT_anova_m_apa$full$Valence`. Post-hoc *t*-tests revealed that shapes associated with Good Person (684 $\pm$ 8.77) were responded faster than Neutral-Person (740 $\pm$ 9.84), (*t*(51) = -8.167, *p* < 0.001) and Bad Person (728 $\pm$ 9.15), *t*(51) = -5.724, *p* < 0.0001). While there was no significant differences between Neutral and Bad-Person condition (*t*(51) = 1.686, *p* = 0.221). For non-matched trials, there was no significant effect of Valence (`r df1b_RT_anova_nm_apa$full$Valence`).

## Discussion
These results confirmed the facilitation effect of positive moral valence on the perceptual matching task. This pattern of results mimic prior results demonstrating self-bias effect on perceptual matching (Sui et al., 2012) and in line with previous studies that indirect learning of other’s moral reputation do have influence on our subsequence behavior (Fouragnan et al., 2013). 


# Experiment 1c
In this study, we further control the valence of words using in our experiment. Instead of using label with moral valence, we used valence-neutral names in China. Participant first learn behaviors of the different person, then, they associate the names and shapes. And then they perform a name-shape matching task.

## Method

```{r loadingData_1c,echo=FALSE,results='hide', eval = FALSE}
# data collected in Tsinghua U
df1c <- read.csv(file.path('.', 'exp1c', 'rawdata_behav_exp1c_2014.csv'), header = TRUE,
                   sep = ",", stringsAsFactors=FALSE, na.strings=c("","NA")) %>%
  dplyr::rename(Subject = 1) %>%
  dplyr::select(Subject, Age, Handedness,Sex,TrialList1.Sample,BlockList.Sample,
                 Shape,YesNoResp,CorrectAnswer,                         # select necessary columns
                 Target1.ACC,Target1.RESP, Target1.RT) %>%
  dplyr::rename(BlockNo = BlockList.Sample,
                TrialNo = TrialList1.Sample,
                ACC = Target1.ACC,                         # rename columns
                CRESP = CorrectAnswer,
                RT = Target1.RT, RESP =Target1.RESP,
                Matchness = YesNoResp, Valence = Shape) %>%
  dplyr::mutate(Valence = ifelse(Valence == "Normal", "Neutral", Valence),    # change value
                Valence = factor(Valence, levels=c("Good", "Neutral","Bad")),
                Matchness = ifelse(Matchness == "Yes", "Match", "Mismatch"),
                Matchness = factor(Matchness, levels=c("Match", "Mismatch"))) %>%
  dplyr::mutate(Site = "THU",
                #Identity = NA,
                #ExpID = "Exp1c",
                #Domain = "Morality",
                Subject = Subject + 1200) %>%    # change subject ID to 12XX
  #dplyr::select(CommonColnames) %>%
  dplyr::arrange(Subject)
#length(unique(df1c$Subject))

# distinguish between practice and formal data
df1c.subj_P <- df1c %>%                      # subjet for practice
  dplyr::filter(is.na(BlockNo)) %>%
  dplyr::distinct(Subject)

df1c.subj_T <- df1c %>%                       # subjects in formal exp
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::distinct(Subject)

# number of participant who didn't finished the experiment
nQuit <- length(df1c.subj_P) - length(df1c.subj_T)

df1c.T.basic     <- df1c %>%
  dplyr::select(Site, Subject, Age, Sex) %>%
  dplyr::distinct(Subject, .keep_all = TRUE) %>%
  dplyr::summarise(N = length(Subject),
                   N_thu = length(Site[Site == "THU"]),
                   N_wzu = length(Site[Site == "WZU"]),
                   Nf = length(Sex[Sex == "female"]),
                   Nm = length(Sex[Sex == "male"]),
                   Age_mean = round(mean(Age,na.rm=TRUE),2),
                   Age_sd = round(sd(Age,na.rm=TRUE),2))

# participants should be excluded
df1c.excld.sub <-  df1c %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::group_by(Subject) %>%
  #dplyr::mutate(ACC = ifelse(RT <= 200, 0, ACC)) %>%  # set less than 200 ms response as wrong
  dplyr::summarise(N = length(ACC),                   # caculate the overall accuracy for each subject
                   N_crrct = sum(ACC),
                   ACC = sum(ACC)/length(ACC)) %>%
  dplyr::filter(ACC < 0.6) %>%                        # exlucde the participants with less than 60% overall accuracy
  dplyr::select(Subject)

# The rate of excluded trials in valid data
df1c.invalid_trial_rate   <- df1c %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::filter(!(Subject %in% df1c.excld.sub$Subject)) %>%   # exclude the invalid subjects
  dplyr::summarize(rate = length(RT[RT <= 200 & ACC == 1])/length(RT))

df1c.v   <- df1c %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::filter(!(Subject %in% df1c.excld.sub$Subject)) %>%   # exclude the invalid subjects
  dplyr::filter(!(RT <= 200 & ACC == 1))                      # exclude < 200 trials

df1c.v.basic     <- df1c.v %>%
  dplyr::select(Site, Subject, Age, Sex) %>%
  dplyr::distinct(Subject, .keep_all = TRUE) %>%
  dplyr::summarise(N = length(Subject),
                   N_thu = length(Site[Site == "THU"]),
                   N_wzu = length(Site[Site == "WZU"]),
                   Nf = length(Sex[Sex == "female"]),
                   Nm = length(Sex[Sex == "male"]),
                   Age_mean = round(mean(Age,na.rm=TRUE),2),
                   Age_sd = round(sd(Age,na.rm=TRUE),2))

# calculate d prime
df1c.v.dprime_l <- df1c.v %>%
  dplyr::mutate(sdt = mosaic::derivedFactor("hit" = (ACC ==1 & Matchness == "Match"),     # code as hit
                                    "CR" = (ACC ==1  & Matchness == "Mismatch"),  # code as correct reject
                                    "miss" = (ACC == 0 & Matchness == "Match"),   # code as miss
                                    "FA" = (ACC == 0 & Matchness == "Mismatch"),  # code as false alarm
                                    .method ="first",  .default = NA)) %>% 
  dplyr::group_by(Site, Subject, Age, Sex, Valence, sdt) %>%
  dplyr::summarise(N = length(sdt)) %>%                                      # calculate the counts for each 
  dplyr::ungroup() %>%
  tidyr::spread(key = sdt, value = N,fill = 0) %>%                           # long-to-wide format
  dplyr::mutate(hitR = hit/(hit + miss),                                     # hit rate
                FAR  = FA/(FA+CR)) %>%                                       # fa rate
  dplyr::mutate(hitR = ifelse(hitR == 1, 1 - 1/(2*(hit + miss)), hitR),      # if hit rate is 1, standardize it
                FAR  = ifelse(FAR == 0, 1/(2*(hit + miss)), FAR)) %>%        # if FA rate is 0, standardize it
  dplyr::mutate(dprime = qnorm(hitR) - qnorm(FAR)) %>%
  dplyr::select(Site, Subject, Age, Sex, Valence, dprime) %>%                # select relevant columns
  dplyr::mutate(Valence = factor(Valence, levels = c("Good","Neutral","Bad")))

# calculate mean RT for anova
df1c.v.rt_m <- df1c.v %>%
  dplyr::filter(ACC == 1) %>%
  dplyr::group_by(Site, Subject, Age, Sex, Matchness, Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup()

### prepare for the later meta-analysis
df1c.meta.d <- df1c.v.dprime_l %>% 
  dplyr::mutate(Identity = NA,
                ExpID = 'Exp1c',
                Domain = "Morality") %>%        # add domain as morality, to be comparable with experiment 5.
  dplyr::select(CommonColnames_d)

df1c.meta.rt <- df1c.v.rt_m %>% 
  dplyr::rename(RT = RT_m) %>%
  dplyr::mutate(Identity = NA,
                ExpID = 'Exp1c',
                Domain = "Morality") %>%        # add domain as morality, to be comparable with experiment 5.
  dplyr::select(CommonColnames_rt)
```
### Participants
`r df1c.T.basic$N` college students (`r df1c.T.basic$Nf` female, age = `r df1c.T.basic$Age_mean` $\pm$ `r df1c.T.basic$Age_sd` years) participated. All of them were recruited from Tsinghua University community in 2014. Informed consent was obtained from all participants prior to the experiment according to procedures approved by the local ethics committees. No participant was excluded because they overall accuracy were above 0.6.

### Stimuli and Tasks
Three geometric shapes (triangle, square, and circle, with 3.7º × 3.7º of visual angle) were presented above a white fixation cross subtending 0.8º × 0.8º of visual angle at the center of the screen. The three most common names were chosen, which are neutral in moral valence before the manipulation.
Three names (Zhang, Wang, Li) were first paired with three paragraphs of behavioral description. Each description includes one sentence of biographic infomration and four sentences that describing the moral behavioral under that name. To assess the that these three descriptions represented good, neutral, and bad valence, we collected the ratings of three person on six dimensions: morality, likability, trustworthiness, dominance, competence, and aggressiviess, from an independent sample (n = 34, 18 female, age = 19.6 ± 2.05). The rating results showed that the person with morally good behavioral description has higher score on morality (M = 3.59, SD = 0.66) than neutral (M = 0.88, SD = 1.1), *t*(33) = 12.94, *p* < .001, and bad conditions (M = -3.4, SD = 1.1), *t*(33) = 30.78, *p* < .001. Neutral condition was also significant higher than bad conditions $t(33) = 13.9$, $p < .001$ (See supplementary materials).

### Procedure
After arriving the lab, participants were informed to complete two experimental tasks, first a social memory task to remember three person and their behaviors, after tested for their memory, they will finish a perceptual matching task. 
In the social memory task, the descriptions of three person were presented without time limitation. Participant self-paced to memorized the behaviors of each person. After they memorizing, a recognition task was used to test their memory effect. Each participant was required to have over 95% accuracy before preceding to matching task.
The perceptual learning task was followed, three names were randomly paired with geometric shapes. Participants were required to learn the association and perform a practicing task before they start the formal experimental blocks. They kept practicing util they reached 70% accuracy. Then, they would start the perceptual matching task as in experiment 1a. They finished 6 blocks of perceptual matching trials, each have 120 trials. 

## Data Analysis
Data was analyzed as in experiment 1a. 

## Results

```{r 'ex1c-dprime-rt', fig.cap="RT and *d* prime of Experiment 1c.", fig.height=6, fig.width=10, warning=FALSE}
rtdata <- df1c.v.rt_m %>% dplyr::filter(Matchness == "Match") %>% dplyr::rename(RT = RT_m)

Mplots(expName = 'exp1c', df1c.v.dprime_l,rtdata)

```


```{r 1c_rt_dprime, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
# anova for d prime
df1c_dprime_anova <- afex::aov_ez('Subject','dprime',df1c.v.dprime_l,  # using afex's function 
                                  within = c('Valence'))

df1c_dprime_anova_apa <- df1c_dprime_anova %>% papaja::apa_print.afex_aov()

posthoc_1c_d <- emmeans::emmeans(df1c_dprime_anova, "Valence") # compare each valence for both self and other condition
#pairs(posthoc_1c_d)

df1c_RT_anova <- afex::aov_ez('Subject','RT_m',df1c.v.rt_m,     # using afex's function 
                                  within = c('Matchness','Valence'))
df1c_RT_anova_apa <- df1c_RT_anova %>% papaja::apa_print.afex_aov()

```

Figure \@ref(fig:ex1c-dprime-rt) shows *d* prime and reaction times of experiment 1c. We conducted same analysis as in Experiment 1a. Our analysis didn't should effect of valence on *d* prime, `r df1c_dprime_anova_apa$full$Valence`. Neither the effect of valence on RT (`r df1c_RT_anova_apa$full$Valence`) or interaction between valence and matchness on RT (`r df1c_RT_anova_apa$full$Matchness_Valence`).

## Discussion
Experiment 1c was conducted in a old way, i.e., we peeked the data when we collected around 20 participants, and decided to stop because the non-signficant results. (move this experiment to supplementary?) 

# Experiment 2: Sequential presenting
Experiment 2 was conducted for two purpose: (1) to further confirm the facilitation effect of positive moral associations; (2) to test the effect of expectation of occurrence of each pair. In this experiment, after participant learned the assocation between labels and shapes, they were presented a label first and then a shape, they then asked to judge whether the shape matched the label or not (see  (Sui, Sun, Peng, & Humphreys, 2014). Previous studies showed that when the labels presented before the shapes, participants formed expectations about the shape, and therefore a top-down process were introduced into the perceptual matching processing. If the facilitation effect of postive moral valence we found in experiment 1 was mainly drive by top-down processes, this sequential presenting paradigm may eliminate or attenuate this effect; if, however, the facilitation effect ocured because of button-up processes, then, similar facilitation effect will appear even with sequential presenting paradigm.

## Method

```{r loadingData_2,echo=FALSE,results='hide', eval = FALSE}
# data collected in Tsinghua U
df2 <- read.csv(file.path('.', 'exp2', 'rawdata_behav_exp2.csv'), header = TRUE,
                   sep = ",", stringsAsFactors=FALSE, na.strings=c("","NA")) %>%
  dplyr::rename(ACC = Target.ACC,           # rename columns
                RT  = Target.RT,
                CRESP = Target.CRESP,
                BlockNo = BlockList.Sample,
                TrialNo = SubTrial,
                RESP = Target.RESP,
                Matchness = YesNoResp,
                Valence = Shape) %>%
  dplyr::mutate(Valence = ifelse(Valence == "Normal", "Neutral", Valence),       # recode values
                Matchness = ifelse(Matchness == "Yes", "Match", "Mismatch"),
                Age = ifelse(Age == 0, NA, Age),
                Site = "THU",
                #ExpID = 'exp2',
                #Identity = NA,
                #Domain = "Morality",
                Subject = ifelse(Subject < 40, Subject + 1000, Subject + 2000))  # recode subject ID, identify those particiant from exp1a
  #dplyr::select(CommonColnames)

df2.T.basic     <- df2 %>%
  dplyr::select(Site, Subject, Age, Sex) %>%
  dplyr::distinct(Subject, .keep_all = TRUE) %>%
  dplyr::summarise(N = length(Subject),
                   N_thu = length(Site[Site == "THU"]),
                   N_wzu = length(Site[Site == "WZU"]),
                   Nf = length(Sex[Sex == "female"]),
                   Nm = length(Sex[Sex == "male"]),
                   Age_mean = round(mean(Age,na.rm=TRUE),2),
                   Age_sd = round(sd(Age,na.rm=TRUE),2))
  
# number of participant who practiced but not in the formal experiment
nQuit <- length(unique(df2$Subject[is.na(df2$BlockNo)])) - length(unique(df2$Subject[!is.na(df2$BlockNo)]))

# participants should be excluded
df2.excld.sub <-  df2 %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::group_by(Subject) %>%
  #dplyr::mutate(ACC = ifelse(RT <= 200, 0, ACC)) %>%  # set less than 200 ms response as wrong
  dplyr::summarise(N = length(ACC),                   # caculate the overall accuracy for each subject
                   N_crrct = sum(ACC),
                   ACC = sum(ACC)/length(ACC)) %>%
  dplyr::filter(ACC < 0.6) %>%                        # exlucde the participants with less than 60% overall accuracy
  dplyr::select(Subject)

# The rate of excluded trials in valid data
df2.invalid_trial_rate   <- df2 %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::filter(!(Subject %in% df2.excld.sub$Subject)) %>%   # exclude the invalid subjects
  dplyr::summarize(rate = length(RT[RT <= 200 & ACC == 1])/length(RT))

df2.v   <- df2 %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::filter(!(Subject %in% df2.excld.sub$Subject)) %>%   # exclude the invalid subjects
  dplyr::filter(!(RT <= 200 & ACC == 1))                      # exclude < 200 trials

df2.v.basic     <- df2.v %>%
  dplyr::select(Site, Subject, Age, Sex) %>%
  dplyr::distinct(Subject, .keep_all = TRUE) %>%
  dplyr::summarise(N = length(Subject),
                   N_thu = length(Site[Site == "THU"]),
                   N_wzu = length(Site[Site == "WZU"]),
                   Nf = length(Sex[Sex == "female"]),
                   Nm = length(Sex[Sex == "male"]),
                   Age_mean = round(mean(Age,na.rm=TRUE),2),
                   Age_sd = round(sd(Age,na.rm=TRUE),2))

# calculate d prime
df2.v.dprime_l <- df2.v %>%
  dplyr::mutate(sdt = mosaic::derivedFactor("hit" = (ACC ==1 & Matchness == "Match"),     # code as hit
                                    "CR" = (ACC ==1  & Matchness == "Mismatch"),  # code as correct reject
                                    "miss" = (ACC == 0 & Matchness == "Match"),   # code as miss
                                    "FA" = (ACC == 0 & Matchness == "Mismatch"),  # code as false alarm
                                    .method ="first",  .default = NA)) %>% 
  dplyr::group_by(Site, Subject, Age, Sex, Valence, sdt) %>%
  dplyr::summarise(N = length(sdt)) %>%                                      # calculate the counts for each 
  dplyr::ungroup() %>%
  tidyr::spread(key = sdt, value = N,fill = 0) %>%                           # long-to-wide format
  dplyr::mutate(hitR = hit/(hit + miss),                                     # hit rate
                FAR  = FA/(FA+CR)) %>%                                       # fa rate
  dplyr::mutate(hitR = ifelse(hitR == 1, 1 - 1/(2*(hit + miss)), hitR),      # if hit rate is 1, standardize it
                FAR  = ifelse(FAR == 0, 1/(2*(hit + miss)), FAR)) %>%        # if FA rate is 0, standardize it
  dplyr::mutate(dprime = qnorm(hitR) - qnorm(FAR)) %>%
  dplyr::select(Site, Subject, Age, Sex, Valence, dprime) %>%                # select relevant columns
  dplyr::mutate(Valence = factor(Valence, levels = c("Good","Neutral","Bad")))

# calculated means RT for ANOVA
df2.v.rt_m <- df2.v %>%
  dplyr::filter(ACC == 1) %>%
  dplyr::group_by(Site, Subject, Age, Sex, Matchness, Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup()

### prepare for the later meta-analysis
df2.meta.d <- df2.v.dprime_l %>% 
  dplyr::mutate(Identity = NA,
                ExpID = 'Exp2',
                Domain = "Morality") %>%        # add domain as morality, to be comparable with experiment 5.
  dplyr::select(CommonColnames_d)

df2.meta.rt <- df2.v.rt_m %>% 
  dplyr::rename(RT = RT_m) %>%
  dplyr::mutate(Identity = NA,
                ExpID = 'Exp2',
                Domain = "Morality") %>%        # add domain as morality, to be comparable with experiment 5.
  dplyr::select(CommonColnames_rt)

```

### Participants

`r df2.T.basic$N` participants (`r df2.T.basic$Nf` female, age = `r df2.T.basic$Age_mean` $\pm$ `r df2.T.basic$Age_sd`) were recruited. 24 of them had participated in Experiment 1a (9 male, mean age = 21.9, s.d. = 2.9), and the time gap between these experiment 1a and experiment 2 is at least six weeks. The results of `r nrow(df2.excld.sub)` participants were excluded from analysis because of less than 60% overall accuracy, remains `r df2.v.basic$N` participants (`r df2.v.basic$Nf` female, age = `r df2.v.basic$Age_mean` $\pm$ `r df2.v.basic$Age_sd`).

### Procedure
In Experiment 2, the sequential presenting makes the matching task much easier than experiment 1. To avoid ceiling effect on behavioral data, we did a few pilot experiments to get optimal parameters, i.e., the conditions under which participant have similar accuracy as in Experiment 1 (around 70 ~ 80% accuracy). 
In the final procedure, the label (good person, bad person, or neutral person) was presented for 50 ms and then masked by a scrambled image for 200 ms. A geometric shape followed the scrambled mask for 50 ms in a noisy background (which was produced by first decomposing a square with ¾ gray area and ¼ white area to small squares with a size of 2 × 2 pixels and then re-combine these small pieces randomly), instead of pure gray background in Experiment 1. After that, a blank screen was presented 1100 ms, during which participants should press a button to indicate the label and the shape match the original association or not. Feedback was given, as in study 1. The next trial then started after 700 ~ 1100 ms blank. Other aspects of study 2 were identical to study 1.

### Analysis
Data was analyzed as in study 1a. 

## Results

```{r 'ex2-dprime-rt', fig.cap="RT and *d* prime of Experiment 2.", fig.height=6, fig.width=10, warning=FALSE}
rtdata <- df2.v.rt_m %>% dplyr::filter(Matchness == "Match") %>% dplyr::rename(RT = RT_m)

Mplots(expName = 'exp2', df2.v.dprime_l,rtdata)

```

Figure \@ref(fig:ex2-dprime-rt) shows *d* prime and reaction times of experiment 2. Less than 0.2% correct trials with less than 200ms reaction times were exlucded. 

### *d* prime.

```{r 2_dprime, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
# anova for d prime
df2_dprime_anova <- afex::aov_ez('Subject','dprime',df2.v.dprime_l, within = c('Valence'))
df2_dprime_anova_apa <- df2_dprime_anova %>% papaja::apa_print.afex_aov()

posthoc_2_d <- emmeans::emmeans(df2_dprime_anova, "Valence") # compare each valence for both self and other condition
#pairs(posthoc_2_d)
```
There was evidence for the main effect of valence, `r df2_dprime_anova_apa$full$Valence`. Paired t test showed that the Good-Person condition (2.79 $\pm$ 0.17) was with greater *d* prime than Netural condition (2.21 $\pm$ 0.16, *t*(33) = 4.723, *p* = 0.001) and Bad-person condition (2.41 $\pm$ 0.14), *t*(33) = 4.067, *p* = 0.008). There was no-significant difference between Neutral-person and Bad-person conidition, *t*(33) = -1,802, *p* = 0.185.

### Reaction time
The results of reaction times of matchness trials showed similiar pattern as the *d* prime data.

```{r 2_RT, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
df2_RT_anova <- afex::aov_ez('Subject','RT_m',df2.v.rt_m, within = c('Matchness','Valence'))
df2_RT_anova_apa <- df2_RT_anova %>% papaja::apa_print.afex_aov()

# match trials
df2.v.rt_m1 <- df2.v %>%
  dplyr::filter(ACC == 1 & Matchness == "Match") %>%
  dplyr::group_by(Site,Subject,Matchness, Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup() %>%
  dplyr::mutate(Valence = factor(Valence, levels = c("Good","Neutral","Bad")))

df2_RT_anova_m <- afex::aov_ez('Subject','RT_m',df2.v.rt_m1,     # using afex's function 
                                  within = c('Valence'))
df2_RT_anova_m_apa <- df2_RT_anova_m %>% papaja::apa_print.afex_aov()

posthoc_2_rt <- emmeans::emmeans(df2_RT_anova_m, "Valence") # compare each valence for both self and other condition
# pairs(posthoc_2_rt)

# Mismatch trials
df2.v.rt_m2 <- df2.v %>%
  dplyr::filter(ACC == 1 & Matchness == "Mismatch") %>%
  dplyr::group_by(Site,Subject,Matchness, Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup()

df2_RT_anova_nm <- afex::aov_ez('Subject','RT_m',df2.v.rt_m2,     # using afex's function 
                                  within = c('Valence'))
df2_RT_anova_nm_apa <- df2_RT_anova_nm %>% papaja::apa_print.afex_aov()

```
We found intercation between Matchness and Valence (`r df2_RT_anova_apa$full$Matchness_Valence`) and then analyzed the matched trials and mismatched trials separately, as in experiment 1a. For matched trials, we found the effect of valence `r df2_RT_anova_m_apa$full$Valence`. Post-hoc *t*-tests revealed that shapes associated with Good Person (548 $\pm$ 9.4) were responded faster than Neutral-Person (582 $\pm$ 10.9), (*t*(33) = -3.95, *p* = 0.0011) and Bad Person (582 $\pm$ 10.2), *t*(33) = -3.9, *p* = 0.0013). While there was no significant differences between Neutral and Bad-Person condition (*t*(33) = -0.01, *p* = 0.999).  For non-matched trials, there was no significant effect of Valence (`r df2_RT_anova_nm_apa$full$Valence`).

## Discussion
In this experiment, we repeated the results pattern that the positive moral valenced stimuli has an advantage over the neutral or the negative valenced association. Moreover, with a croass task analysis, we didn’t found evidence that the experiment task interacted with moral valence, suggesting that the effect might not be effect by experiment task. 
These findings suggested that the facilitation effect of positive moral valence is robust and not affected by task. This robust effect detected by the associative learning is unexpected. 

# Experiment 3a
To examine the modulation effect of positive valence was an intrinsic, self-referential process, we designed study 3. In this study, moral valence was assigned to both self and a stranger. We hypothesized that the modulation effect of moral valence will be stronger for the self than for a stranger.

## Method
```{r loadingData_3a,echo=FALSE,results='hide', , eval = FALSE}
# data collected in Tsinghua U
df3a <- read.csv(file.path('.', 'exp3a', 'rawdata_behav_exp3a_2014.csv'), header = TRUE,
                   sep = ",", stringsAsFactors=FALSE, na.strings=c("","NA")) %>%
  dplyr::mutate() %>%
  dplyr::rename(ACC = Target.ACC,           # rename columns
                RT  = Target.RT,
                CRESP = Target.CRESP,
                BlockNo = BlockList.Sample,
                TrialNo = SubTrial,
                RESP = Target.RESP,
                Matchness = YesNoResp,
                Valence = morality,
                Identity = self) %>%
  # in this experiment we need to get the value of valence and identity from shape
  dplyr::mutate(Valence = derivedFactor("Neutral" = (Shape == "Normalself" | Shape == 'Normalother'), 
                                        "Good" = (Shape == "Goodself" | Shape == 'Goodother'), 
                                        "Bad" = (Shape == "Badself" | Shape == 'Badother'), 
                                        .method ="first", .default = NA),
                Identity  = derivedFactor("Self" = (Shape == "Normalself" | Shape == 'Goodself' | Shape == 'Badself'), 
                                        "Other" = (Shape == "Normalother" | Shape == 'Goodother' | Shape == 'Badother'), 
                                        .method ="first", .default = NA),
                Matchness = ifelse(Matchness == "Yes", "Match", "Mismatch"),
                Age = ifelse(Age == 0, NA, Age),
                Site = "THU",
                #ExpID = "Exp3a",
                #Domain = "Morality",
                Subject = Subject + 3000) #%>%                                        # re-code the subject id
  #dplyr::select(CommonColnames)

df3a.T.basic     <- df3a %>%
  dplyr::select(Site, Subject, Age, Sex) %>%
  dplyr::distinct(Subject, .keep_all = TRUE) %>%
  dplyr::summarise(N = length(Subject),
                   N_thu = length(Site[Site == "THU"]),
                   N_wzu = length(Site[Site == "WZU"]),
                   Nf = length(Sex[Sex == "female"]),
                   Nm = length(Sex[Sex == "male"]),
                   Age_mean = round(mean(Age,na.rm=TRUE),2),
                   Age_sd = round(sd(Age,na.rm=TRUE),2))
  
# number of participant who practiced but not in the formal experiment
nQuit <- length(unique(df3a$Subject[is.na(df3a$BlockNo)])) - length(unique(df3a$Subject[!is.na(df3a$BlockNo)]))

# participants should be excluded
df3a.excld.sub <-  df3a %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::group_by(Subject) %>%
  #dplyr::mutate(ACC = ifelse(RT <= 200, 0, ACC)) %>%  # set less than 200 ms response as wrong
  #dplyr::filter(!(ACC == 1 & RT <= 200)) %>%
  dplyr::summarise(N = length(ACC),                   # caculate the overall accuracy for each subject
                   N_crrct = sum(ACC),
                   ACC = sum(ACC)/length(ACC)) %>%
  dplyr::filter(ACC < 0.6) %>%                        # exlucde the participants with less than 60% overall accuracy
  dplyr::select(Subject)

# The rate of excluded trials in valid data
df3a.invalid_trial_rate   <- df3a %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::filter(!(Subject %in% df3a.excld.sub$Subject)) %>%   # exclude the invalid subjects
  dplyr::summarize(rate = length(RT[RT <= 200 & ACC == 1])/length(RT)) %>%
  dplyr::pull()

df3a.v   <- df3a %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::filter(!(Subject %in% df3a.excld.sub$Subject)) %>%   # exclude the invalid subjects
  dplyr::filter(!(RT <= 200 & ACC == 1))                      # exclude < 200 trials

df3a.v.basic     <- df3a.v %>%
  dplyr::select(Site, Subject, Age, Sex) %>%
  dplyr::distinct(Subject, .keep_all = TRUE) %>%
  dplyr::summarise(N = length(Subject),
                   N_thu = length(Site[Site == "THU"]),
                   N_wzu = length(Site[Site == "WZU"]),
                   Nf = length(Sex[Sex == "female"]),
                   Nm = length(Sex[Sex == "male"]),
                   Age_mean = round(mean(Age,na.rm=TRUE),2),
                   Age_sd = round(sd(Age,na.rm=TRUE),2))

# calculate d prime
df3a.v.dprime_l <- df3a.v %>%
  dplyr::mutate(sdt = mosaic::derivedFactor("hit" = (ACC ==1 & Matchness == "Match"), # code as hit
                                    "CR" = (ACC ==1  & Matchness == "Mismatch"),      # correct reject
                                    "miss" = (ACC == 0 & Matchness == "Match"),       # miss
                                    "FA" = (ACC == 0 & Matchness == "Mismatch"),      # false alarm
                                    .method ="first",  .default = NA)) %>% 
  dplyr::group_by(Site, Subject, Age, Sex, Valence,Identity, sdt) %>%
  dplyr::summarise(N = length(sdt)) %>%                                    # calculate the counts for each 
  dplyr::ungroup() %>%
  tidyr::spread(key = sdt, value = N,fill = 0) %>%                          # long-to-wide format
  dplyr::mutate(hitR = hit/(hit + miss),                                    # hit rate
                FAR  = FA/(FA+CR)) %>%                                      # fa rate
  dplyr::mutate(hitR = ifelse(hitR == 1, 1 - 1/(2*(hit + miss)), hitR),     # if hit rate is 1, standardize it
                FAR  = ifelse(FAR == 0, 1/(2*(hit + miss)), FAR)) %>%       # if FA rate is 0, standardize it
  dplyr::mutate(dprime = qnorm(hitR) - qnorm(FAR)) %>%
  dplyr::select(Site, Subject, Age, Sex, Valence, Identity, dprime) %>%     # select relevant columns
  dplyr::mutate(Valence = factor(Valence, levels = c("Good","Neutral","Bad")),
                Identity = factor(Identity, levels = c('Self', 'Other')))

# calculate the mean RT for each condition of each participant
df3a.v.rt_m <- df3a.v %>%
  dplyr::filter(ACC == 1) %>%
  dplyr::group_by(Site,Subject, Age, Sex, Matchness, Identity, Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup()

### prepare for the later meta-analysis
df3a.meta.d <- df3a.v.dprime_l %>% 
  dplyr::mutate(ExpID = 'Exp3a',
                Domain = "Morality") %>%        # add domain as morality, to be comparable with experiment 5.
  dplyr::select(CommonColnames_d)

df3a.meta.rt <- df3a.v.rt_m %>% 
  dplyr::rename(RT = RT_m) %>%
  dplyr::mutate(ExpID = 'Exp3a',
                Domain = "Morality") %>%        # add domain as morality, to be comparable with experiment 5.
  dplyr::select(CommonColnames_rt)
```

### Participants
`r df3a.T.basic$N` college students (`r df3a.T.basic$Nf` female, age = `r df3a.T.basic$Age_mean` $\pm$ `r df3a.T.basic$Age_sd`) participated in experiment 3a. All of them were right-handed, and all had normal or correted-to-normal vision. Informed consent was obtained from all participants prior to the experiment according to procedures approved by a local ethics committee. One female and one male student did not finish the experiment, and `r nrow(df3a.excld.sub)` participants' data were excluded from analysis because less than 60% overall accuracy, remains `r df3a.v.basic$N` participants (`r df3a.v.basic$Nf` female, age = `r df3a.v.basic$Age_mean` $\pm$ `r df3a.v.basic$Age_sd`).

### Design
Study 3a combined moral valence with self-relevance, hence the experiment has a   2 × 3 × 2 within-subject design. The first variable was self-relevance, include two levels: self-relevance vs. stranger-relevance; the second variable was moral valence, include good, neutral and bad; the third variable was the matching between shape and label: match vs. mismatch.

### Stimuli
The stimuli used in study 3a share the same parameters with experiment 1 & 2. 6 shapes were included (triangle, square, circle, trapezoid, diamond, regular pentagon), as well as 6 labels (good self, neutral self, bad self, good person, bad person, neutral person). To match the concreteness of the label, we asked participant to chosen an unfamiliar name of their own gender to be the stranger.

### Procedure
After being fully explained and signed the informed consent, participants were instructed to chose a name that can represent a stranger with same gender as the participant themselves, from a common Chinese name pool. Before experiment, the experimenter explained the meaning of each label to participants. For example, the “good self” mean the morally good side of themselves, them could imagine the moment when they do something’s morally applauded, “bad self” means the morally bad side of themselves, they could also imagine the moment when they doing something morally wrong, and “neutral self” means the aspect of self that doesn’t related to morality, they could imagine the moment when they doing something irrelevant to morality. In the same sense, the “good other”, “bad other”, and “neutral other” means the three different aspects of the stranger, whose name was chosen before the experiment. Then, the experiment proceeded as study 1a. Each participant finished 6 blocks, each have 120 trials. The sequence of trials was pseudo-randomized so that there are 10 matched trials for each condition and 10 non-matched trials for each condition (good self, neutral sef, bad self, good other, neutral other, bad other) for each block.

### Data Analysis
Data analysis followed strategies described in the general method section. Reaction times and *d* prime data were analyzed as in study 1 and study 2, except that one more within-subject variable (i.e., self-relevance) was included in the repeated measures ANOVA. 


## Results

```{r 'ex3a-dprime-rt', fig.cap="RT and *d* prime of Experiment 3a.", fig.height=6, fig.width=10, warning=FALSE}
rtdata <- df3a.v.rt_m %>% dplyr::filter(Matchness == "Match") %>% dplyr::rename(RT = RT_m)

Mplots(expName = 'exp3a', df3a.v.dprime_l,rtdata)

```

Figure \@ref(fig:ex3a-dprime-rt) shows *d* prime and reaction times of experiment 3a. Less than 5% correct trials with less than 200ms reaction times were exlucded.

### *d* prime

```{r 3a_dprime, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
# anova for d prime
df3a_dprime_anova <- afex::aov_ez('Subject','dprime',df3a.v.dprime_l, within = c('Identity','Valence'))
df3a_dprime_anova_apa <- df3a_dprime_anova %>% papaja::apa_print.afex_aov()

posthoc_3a_d <- emmeans::emmeans(df3a_dprime_anova, "Valence") # compare each valence for both self and other condition
#pairs(posthoc_3a_d)

df3a_dprime_s_anova <- df3a.v.dprime_l %>%
  dplyr::filter(Identity == 'Self') %>%
  afex::aov_ez('Subject','dprime', ., within = c('Valence'))
df3a_dprime_s_anova_apa <- df3a_dprime_s_anova %>% papaja::apa_print.afex_aov()
posthoc_3a_d_s <- emmeans::emmeans(df3a_dprime_s_anova, "Valence")
pairs(posthoc_3a_d_s)

df3a_dprime_o_anova <- df3a.v.dprime_l %>%
  dplyr::filter(Identity == 'Other') %>%
  afex::aov_ez('Subject','dprime', ., within = c('Valence'))
df3a_dprime_o_anova_apa <- df3a_dprime_o_anova %>% papaja::apa_print.afex_aov()
posthoc_3a_d_o <- emmeans::emmeans(df3a_dprime_s_anova, "Valence")
pairs(posthoc_3a_d_o)

```
There was evidence for the main effect of valence, `r df3a_dprime_anova_apa$full$Valence`, and main effect of self-relevance, `r df3a_dprime_anova_apa$full$Identity`, as well as the interaction, `r df3a_dprime_anova_apa$full$Identity_Valence`. 

We then conducted separated ANOVA for self-referential and other-referential trials. The valence effect was shown for the self-referential conditions, `r df3a_dprime_s_anova_apa$full$Valence`. Post-hoc test revealed that the Good-Self condition (1.97 $\pm$ 0.14) was with greater *d* prime than Netural condition (1.41 $\pm$ 0.12, *t*(34) = 4.505, *p* = 0.0002), and Bad-self condition (1.43 $\pm$ 0.102),  *t*(34) = 3.856, *p* = 0.0014. There was difference between neutral and bad conidition, *t*(34) = -0.238, *p* = 0.9694. However, no effect of valence was found for the other-referential condition `r df3a_dprime_o_anova_apa$full$Valence`.

### Reaction time

```{r 3a_RT, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
df3a_RT_anova <- afex::aov_ez('Subject','RT_m',df3a.v.rt_m,     # using afex's function 
                                  within = c('Matchness','Identity','Valence'))
df3a_RT_anova_apa <- df3a_RT_anova %>% papaja::apa_print.afex_aov()
```
We found intercation between Matchness and Valence (`r df3a_RT_anova_apa$full$Matchness_Valence`) and then analyzed the matched trials and mismatched trials separately, as in previous experiments.

```{r 3a_RT_match, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
# match trials
df3a_RT_anova_m <- df3a.v.rt_m %>%
  dplyr::filter(Matchness == "Match") %>%
  afex::aov_ez('Subject','RT_m',., within = c('Identity','Valence'))

df3a_RT_anova_m_apa <- df3a_RT_anova_m %>% papaja::apa_print.afex_aov()

#posthoc_3a_rt <- emmeans::emmeans(df3a_RT_anova_m, c('Identity',"Valence")) # compare each valence for both self and other condition
# pairs(posthoc_3a_rt)

df3a_RT_anova_m_s <- df3a.v.rt_m %>%
  dplyr::filter(Matchness == "Match" & Identity == "Self") %>%
  afex::aov_ez('Subject','RT_m',., within = c('Valence'))

df3a_RT_anova_m_s_apa <- df3a_RT_anova_m_s %>% papaja::apa_print.afex_aov()

posthoc_3a_rt_m_s <- emmeans::emmeans(df3a_RT_anova_m_s, 'Valence')
pairs(posthoc_3a_rt_m_s)

df3a_RT_anova_m_o <- df3a.v.rt_m %>%
  dplyr::filter(Matchness == "Match" & Identity == "Other") %>%
  afex::aov_ez('Subject','RT_m',., within = c('Valence'))

df3a_RT_anova_m_o_apa <- df3a_RT_anova_m_o %>% papaja::apa_print.afex_aov()


# Mismatch trials
df3a_RT_anova_nm <- df3a.v.rt_m %>%
  dplyr::filter(Matchness == "Mismatch") %>%
  afex::aov_ez('Subject','RT_m', ., within = c('Identity','Valence'))

df3a_RT_anova_nm_apa <- df3a_RT_anova_nm %>% papaja::apa_print.afex_aov()
```
For the matched trials, we found that the interaction between identity and valence, `r df3a_RT_anova_m_apa$full$Identity_Valence`, as well as the main effect of valence `r df3a_RT_anova_m_apa$full$Valence`, but not the effect of identity `r df3a_RT_anova_m_apa$full$Identity`. As for the *d* prime, we separated analyzed the self-referential and other-referential trials. For the Self-referential trials, we found the main effect of valence, `r df3a_RT_anova_m_s_apa$full$Valence`; for the other-referential trials, the effect of valence is weaker, `r df3a_RT_anova_m_o_apa$full$Valence`. We then focused on the self conditions: the good-self condition (713 $\pm$ 12) is faster than neutral- (776 $\pm$ 11.8), *t*(34) = -7.396, *p* < .0001 , and bad-self (772 $\pm$ 10.1) conditions,  *t*(34) = -5.66, *p* < .0001. But there is not difference between neutral- and bad-self conditions, *t*(34) = 0.481, *p* = 0.881.

For the mismatched trials, we didn't found any strong effect: identity, `r df3a_RT_anova_nm_apa$full$Identity`, valence `r df3a_RT_anova_nm_apa$full$Valence`, or interaction between the two `r df3a_RT_anova_nm_apa$full$Identity_Valence`.

# Experiment 3b
In study 3a, participants had to remember 6 pairs of association, which cause high cogitive load during the whole exepriment. To eliminate the influence of cognitive load, we conducted study 3b, in which participant learn three aspect of self and stranger seperately in to consecutive task. We hypothesize that we will replicate the pattern of study 3a, i.e., the effect of moral valence only occurs for self-relevant conditions.

## Method
```{r loadingData_3b,echo=FALSE,results='hide', eval = FALSE}
# data collected in Tsinghua U
df3b <- read.csv(file.path('.','exp3b', 'rawdata_behav_exp3b_2017.csv'), header = TRUE,
                   sep = ",", stringsAsFactors=FALSE, na.strings=c("","NA")) %>%
  dplyr::mutate() %>%
  dplyr::rename(ACC = Target.ACC,           # rename columns
                RT  = Target.RT,
                CRESP = CorrectAnswer,
                #BlockNo = BlockList.Sample,
                #TrialNo = SubTrial,
                RESP = Target.RESP,
                Matchness = YesNoResp) %>%
                #Valence = morality,
                #Identity = self
  # in this experiment we need to get the value of valence and identity from shape
  dplyr::mutate(Valence = derivedFactor("Neutral" = (Shape == "Neutralself" | Shape == 'NeutralOther'), 
                                        "Good" = (Shape == "Goodself" | Shape == 'GoodOther'), 
                                        "Bad" = (Shape == "Badself" | Shape == 'BadOther'), 
                                        .method ="first", .default = NA),
                Identity  = ifelse(Identity == "Self" | Identity == 'self', "Self", "Other"),
                Matchness = ifelse(Matchness == "Yes", "Match", "Mismatch"),
                Age = ifelse(Age == 0, NA, Age),  # if the min age is 0, that age is missing
                BlockNo = dplyr::coalesce(otherBlocklList.Sample, selfBlockList.Sample),
                TrialNo = dplyr::coalesce(OtherTrialist.Sample, selfTrialList.Sample, otherProcTrialList.Sample, selfPracTrialList.Sample),
                Site = "WZU") 
#                Subject = factor(Subject))

df3b.T.basic     <- df3b %>%
  dplyr::select(Site, Subject, Age, Sex) %>%
  dplyr::distinct(Subject, .keep_all = TRUE) %>%
  dplyr::summarise(N = length(Subject),
                   N_thu = length(Site[Site == "THU"]),
                   N_wzu = length(Site[Site == "WZU"]),
                   Nf = length(Sex[Sex == "female"]),
                   Nm = length(Sex[Sex == "male"]),
                   Age_mean = round(mean(Age,na.rm=TRUE),2),
                   Age_sd = round(sd(Age,na.rm=TRUE),2))
  
# participants should be excluded
df3b.excld.sub <-  df3b %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::group_by(Subject) %>%
  #dplyr::mutate(ACC = ifelse(RT <= 200, 0, ACC)) %>%  # set less than 200 ms response as wrong
  #dplyr::filter(!(ACC == 1 & RT <= 200)) %>%
  dplyr::summarise(N = length(ACC),                   # caculate the overall accuracy for each subject
                   N_crrct = sum(ACC),
                   ACC = sum(ACC)/length(ACC)) %>%
  dplyr::filter(ACC < 0.6) %>%                        # exlucde the participants with less than 60% overall accuracy
  dplyr::select(Subject)

df3b.excld.sub2 <- df3b.excld.sub
df3b.excld.sub2[5,1] <- 31003 # the participant whose hit rate is zero under one condition.

# The rate of excluded trials in valid data
df3b.invalid_trial_rate   <- df3b %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::filter(!(Subject %in% df3b.excld.sub2$Subject)) %>%   # exclude the invalid subjects
  dplyr::summarize(rate = length(RT[RT <= 200 & ACC == 1])/length(RT)) %>%
  dplyr::pull()

df3b.v   <- df3b %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::filter(!(Subject %in% df3b.excld.sub2$Subject)) %>%   # exclude the invalid subjects
  dplyr::filter(!(RT <= 200 & ACC == 1))                      # exclude < 200 trials

df3b.v.basic     <- df3b.v %>%
  dplyr::select(Site, Subject, Age, Sex) %>%
  dplyr::distinct(Subject, .keep_all = TRUE) %>%
  dplyr::summarise(N = length(Subject),
                   N_thu = length(Site[Site == "THU"]),
                   N_wzu = length(Site[Site == "WZU"]),
                   Nf = length(Sex[Sex == "female"]),
                   Nm = length(Sex[Sex == "male"]),
                   Age_mean = round(mean(Age,na.rm=TRUE),2),
                   Age_sd = round(sd(Age,na.rm=TRUE),2))

# calculate d prime
df3b.v.dprime_l <- df3b.v %>%
  dplyr::mutate(sdt = mosaic::derivedFactor("hit" = (ACC ==1 & Matchness == "Match"), # code as hit
                                    "CR" = (ACC ==1  & Matchness == "Mismatch"),      # correct reject
                                    "miss" = (ACC == 0 & Matchness == "Match"),       # miss
                                    "FA" = (ACC == 0 & Matchness == "Mismatch"),      # false alarm
                                    .method ="first",  .default = NA)) %>% 
  dplyr::group_by(Site, Subject, Age, Sex, Valence,Identity, sdt) %>%
  dplyr::summarise(N = length(sdt)) %>%                                    # calculate the counts for each 
  dplyr::ungroup() %>%
  tidyr::spread(key = sdt, value = N,fill = 0) %>%                          # long-to-wide format
  dplyr::mutate(hitR = hit/(hit + miss),                                    # hit rate
                FAR  = FA/(FA+CR)) %>%                                      # fa rate
  dplyr::mutate(hitR = ifelse(hitR == 1, 1 - 1/(2*(hit + miss)), hitR),     # if hit rate is 1, standardize it
                FAR  = ifelse(FAR == 0, 1/(2*(hit + miss)), FAR)) %>%       # if FA rate is 0, standardize it
  dplyr::mutate(dprime = qnorm(hitR) - qnorm(FAR)) %>%
  dplyr::select(Site, Subject, Age, Sex, Valence, Identity, dprime) %>%   # select relevant columns
  dplyr::mutate(Valence = factor(Valence, levels = c("Good","Neutral","Bad")),
                Identity = factor(Identity, levels = c('Self', 'Other')))

# calculate mean RT for each condition of each participant
df3b.v.rt_m <- df3b.v %>%
  dplyr::filter(ACC == 1) %>%
  dplyr::group_by(Site, Subject, Age, Sex, Matchness, Identity, Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup()

### prepare for the later meta-analysis
df3b.meta.d <- df3b.v.dprime_l %>% 
  dplyr::mutate(ExpID = 'Exp3b',
                Domain = "Morality") %>%        # add domain as morality, to be comparable with experiment 5.
  dplyr::select(CommonColnames_d)

df3b.meta.rt <- df3b.v.rt_m %>% 
  dplyr::rename(RT = RT_m) %>%
  dplyr::mutate(ExpID = 'Exp3b',
                Domain = "Morality") %>%        # add domain as morality, to be comparable with experiment 5.
  dplyr::select(CommonColnames_rt)
```

### Participants
Study 3b were finished in 2017, at that time we have calculated that the effect size (Cohen’s d) of good-person (or good-self) vs. bad-person (or bad-other) was between 0.47 ~ 0.53, based on study 1a, 1b, 2, 3a, 4a, and 4b. Based on this effect size, we estimated that 54 participants would allow we to detect the effec size of Cohen’s = 0.5 with 95% power and alpha = 0.05, using G*power 3.192 (Faul, Erdfelder, Buchner, & Lang, 2009; Faul, Erdfelder, Lang, & Buchner, 2007). Therefore, we planned to stop after we arrived this number. During the data collected at Wenzhou University, `r df3b.T.basic$N` participants (`r df3b.T.basic$Nf` females; 19 to 25 years of age, age = `r df3b.T.basic$Age_mean` $\pm$ `r df3b.T.basic$Age_sd`) came to the testing room and we tested all of them during a single day. All participants were right-handed, and all had normalneutral or corrected-to-normal vision. Informed consent was obtained from all participants prior to the experiment according to procedures approved by a local ethics committee. `r nrow(df3b.excld.sub)` participants’ data were excluded from analysis because their over all accuracy was lower than 60%, 1 more participant waw excluded because of zero hit rate for one condition, leaving `r df3b.v.basic$N` participants (`r df3b.v.basic$Nf`  females; 19 to 25 years old, age = `r df3b.v.basic$Age_mean` $\pm$ `r df3b.v.basic$Age_sd`). 


### Design
Study 3b has the same experimental design as 3a, with a 2× 3× 2 within-subject design. The first variable was self-relevance, include two levels: self-relevant vs. stranger-relevant; the second variable was moral valence, include good, neutral and bad; the third variable was the matching between shape and label: match vs. mismatch.
 Stimuli.	The stimuli used in study 3b share the same parameters with experiment 3a. 6 shapes were included (triangle, square, circle, trapezoid, diamond, regular pentagon), as well as 6 labels, but the labels changed to “good self”, “neutral self”, “bad self”, “good him/her”, bad him/her”, “neutral him/her”, the stranger’s label is consistent with participants’ gender. Same as study 3a, we asked participant to chosen an unfamiliar name of their own gender to be the stranger before showing them the relationship. Note, because of implementing error, the personal distance data didn’t collect for this experiment.
 
### Procedure
In this experiment, participants finished two matching tasks, i.e., self-matching task, and other-matching task. In the self-matching task, participants first associate the three aspects of self to three different shapes, and then perform the matching task. In the other-matching task, participants first associate the three aspects of the stranger to three different shapes, and then perform the matching task. The order of self-task and other-task are counter-balanced among participants.
Different from experiment 3a, after presenting the stimuli pair for 100ms, participant has 1900 ms to response, and they were feedbacked with both accuracy and reaction time.
As in study 3a, before each task, the intruction showed the meaning of each label to participants. The self-matching task and other-matching task were randomized between participants. Each participant finished 6 blocks, each have 120 trials.

### Data Analysis
Data analysis is the same as study 3a.

## Results

```{r 'ex3b-dprime-rt', fig.cap="RT and *d* prime of Experiment 3b.", fig.height=6, fig.width=10, warning=FALSE}
rtdata <- df3b.v.rt_m %>% dplyr::filter(Matchness == "Match") %>% dplyr::rename(RT = RT_m)

Mplots(expName = 'exp3b', df3b.v.dprime_l,rtdata)

```

Figure \@ref(fig:ex3b-dprime-rt) shows *d* prime and reaction times of experiment 3b. Less than 5% correct trials with less than 200ms reaction times were exlucded.

### *d* prime

```{r 3b_dprime, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
# anova for d prime
df3b_dprime_anova <- afex::aov_ez('Subject','dprime',df3b.v.dprime_l, within = c('Identity','Valence'))
df3b_dprime_anova_apa <- df3b_dprime_anova %>% papaja::apa_print.afex_aov()

# calculate d prime for self condition
df3b_dprime_anova_s <- df3b.v.dprime_l %>%
  dplyr::filter(Identity == "Self") %>%
  afex::aov_ez('Subject','dprime', ., within = c('Valence'))

df3b_dprime_anova_s_apa <- df3b_dprime_anova_s %>% papaja::apa_print.afex_aov()

df3b_dprime_anova_o <- df3b.v.dprime_l %>%
  dplyr::filter(Identity == "Other") %>%
  afex::aov_ez('Subject','dprime', ., within = c('Valence'))

df3b_dprime_anova_o_apa <- df3b_dprime_anova_o %>% papaja::apa_print.afex_aov()
#df3b_dprime_anova_o_apa$full$Valence

posthoc_3b_d_s <- emmeans::emmeans(df3b_dprime_anova_s, "Valence")  # main effect
pairs(posthoc_3b_d_s)

posthoc_3b_d_o <- emmeans::emmeans(df3b_dprime_anova_o, "Valence")  # main effect
pairs(posthoc_3b_d_o)
```
There was evidence for the main effect of valence, `r df3b_dprime_anova_apa$full$Valence`, and main effect of self-relevance, `r df3b_dprime_anova_apa$full$Identity`, as well as the intercation, `r df3b_dprime_anova_apa$full$Identity_Valence`. Therefore we conducted repeated measure ANOVA for self and other conditions separately. We found the valence effect for self-referential condition (`r df3b_dprime_anova_s_apa$full$Valence`) and other-referential condition (`r df3b_dprime_anova_o_apa$full$Valence`). Post-hoc comparison for the self-referential conditions revealed that *d*’ was larger for good self (2.23 $\pm$ 0.1087) than for bad self (1.66 $\pm$ 0.098), *t*(55) = 6.11, *p* < 0.0001, Cohen’s *d* = 0.817, 95% CI [0.511 1.117] , BF10 = 8.43, and neutral self (1.91 $\pm$ 0.088), *t*(55) = 3.03, *p* = 0.0104, Cohen’s *d*  = 0.404, 95%CI [0.13 0.675] , BF10 = 1.33e+5. There was also higher d’ for neutral-self condition than bad-self conditions, *t*(55) = 3.02, *p* = 0.0106, Cohen’s *d*  = 0.403, 95% CI [0.129 0.674], BF10 = 8.22. For other-referential conditions, good-other (2.03 $\pm$ 0.12) was smaller than neutral-other (2.28 $\pm$ 0.133), *t*(55) = -2.262, *p* = 0.0699, but not the bad-other condition (2.19 $\pm$ 0.122), *t*(55) = -1.559, *p* = 0.272. Neither evidence for the neutral and bad-other condition *t*(55) = 1.11, *p* = 0.51.

```{r 3b_dprime_id, echo=FALSE, results='hide', warning=FALSE, message=FALSE}

posthoc_3b_d_2 <- emmeans::emmeans(df3b_dprime_anova, "Identity", by = "Valence")  # main effect

pairs(posthoc_3b_d_2)
```

We also tested the effect of personal association by comparing *d’* values for difference moral valence level. The results showed that the bad-self association condition was responded worse than the bad-other association condition, *t*(55) = -4.1, *p* < 0.001, Cohen’s *d*  = -0.548, 95% CI [-0.827 -0.265], BF10 = 167.  The neutral-self was also worse than the neutral-other, *t*(55) = -3.15, *p* = 0.0026 , Cohen’s *d*  = -0.422, 95% CI [-0.693 -0.146], BF10 = 11.7. While the good-self association condition and good-stranger conditions are not differ from each other, *t*(55) = 1.394, *p* = 0.169, Cohen’s *d* = 0.186, 95% CI[-0.079 0.449], BF10 = 0.364.

### Reaction time

```{r 3b_RT, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
df3b_RT_anova <- afex::aov_ez('Subject','RT_m',df3b.v.rt_m, within = c('Matchness','Identity','Valence'))
df3b_RT_anova_apa <- df3b_RT_anova %>% papaja::apa_print.afex_aov()
```
The results of reaction times of matchness trials showed similar pattern as the *d* prime data. We found three-way intercation between matchness, and valence (`r df3b_RT_anova_apa$full$Matchness_Valence`) and then analyzed the matched trials and mismatched trials separately, as in previous experiments.

```{r 3b_RT_match, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
df3b.v.rt_m %>% 
  dplyr::group_by(Matchness, Identity, Valence) %>%
  dplyr::summarise(rt_mean = mean(RT_m),
                   rt_sd = sd(RT_m))

# match trials
df3b_RT_anova_m <- df3b.v.rt_m %>%
  dplyr::filter(Matchness == "Match") %>%
  afex::aov_ez('Subject','RT_m', ., within = c('Identity','Valence'))
df3b_RT_anova_m_apa <- df3b_RT_anova_m %>% papaja::apa_print.afex_aov()

posthoc_3b_rt <- emmeans::emmeans(df3b_RT_anova_m, c('Identity',"Valence")) # compare each valence for both self and other condition
# pairs(posthoc_3b_rt)

df3b.v.rt_m1_s_anova <- df3b.v.rt_m %>%
  dplyr::filter(Matchness == "Match" & Identity == "Self") %>%
  afex::aov_ez('Subject','RT_m', ., within = c('Valence'))
df3b.v.rt_m1_s_anova_apa <- df3b.v.rt_m1_s_anova %>% papaja::apa_print.afex_aov()

df3b.v.rt_m1_o_anova <- df3b.v.rt_m %>%
  dplyr::filter(Matchness == "Match" & Identity == "Other") %>%
  afex::aov_ez('Subject','RT_m', ., within = c('Valence'))
df3b.v.rt_m1_o_anova_apa <- df3b.v.rt_m1_o_anova %>% papaja::apa_print.afex_aov()

# Mismatch trials
df3b_RT_anova_nm <- df3b.v.rt_m %>%
  dplyr::filter(Matchness == "Mismatch") %>%
  afex::aov_ez('Subject','RT_m', ., within = c('Identity','Valence'))
df3b_RT_anova_nm_apa <- df3b_RT_anova_nm %>% papaja::apa_print.afex_aov()

df3b_RT_anova_nm_s <- df3b.v.rt_m %>%
  dplyr::filter(Matchness == "Mismatch" & Identity == "Self") %>%
  afex::aov_ez('Subject','RT_m', ., within = c('Valence'))
df3b_RT_anova_nm_s_apa <- df3b_RT_anova_nm_s %>% papaja::apa_print.afex_aov()

df3b_RT_anova_nm_o <- df3b.v.rt_m %>%
  dplyr::filter(Matchness == "Mismatch" & Identity == "Other") %>%
  afex::aov_ez('Subject','RT_m', ., within = c('Valence'))
df3b_RT_anova_nm_o_apa <- df3b_RT_anova_nm_o %>% papaja::apa_print.afex_aov()

posthoc_3b_rt_nm_o <- emmeans::emmeans(df3b_RT_anova_nm_o, 'Valence')
pairs(posthoc_3b_rt_nm_o)
```
For the matched trials, we found that interaction between of valence and identity, `r df3b_RT_anova_m_apa$full$Identity_Valence`, BF10 = 1.17. Then, the matched trials were analyzed for the self-relevance and other-relevance pairs separately. The results showed a significant effect of moral valence for the self condition, `r df3b.v.rt_m1_s_anova_apa$full$Valence`, BF10 = 4.54e+6. Paired *t*-tests showed that responses to the good-self association (817 ± 119) were faster than to bad-self associations (915 ± 132), *t*(55) = -8.78, *p* < 0.001, Cohen’s *d* = -1.173, 95% CI [-1.511 -0.828], BF10 = 1.84e+9, and to neutral-self association (880 ± 116), *t*(55) = 3.748, *p* < 0.0001, Cohen’s *d* = -0.501, 95% CI [-0.777 -0.221], BF10 = 58.7. The neutral-self was faster than the bad-self associations, *t*(55) = -2.41, *p* = 0.019 , Cohen’s *d* = -0.321, 95% CI [-0.589 -0.051], BF10 = 2.03. 

The effect of moral valence was also significant for the other-relevance conditions, `r df3b.v.rt_m1_o_anova_apa$full$Valence`, BF10 = 8.55. the good-other condition (734 ± 158) didn’t differ from neutral-other condition (735 ±160), t(55) = -0.07, p = 0.946, Cohen’s *d* = -0.009, 95% CI [-0.271 -0.293], BF10 = 0.15, but faster than the bad other condition (776 ± 173), *t*(55) = -3.14, *p* = 0.0027, Cohen’s *d* = -0.419, 95% CI [-0.691 -0.144], BF10 = 11.3. The neutral-other condition also faster than the bad-other condition, *t*(55) = -3.232, *p* = 0.0021, Cohen’s *d* = -0.432, 95% CI [-0.704 -0.156], BF10 = 14.3. 

We also analyzed the effect of self-relevance on the different moral valence levels. The results showed that for all three different valence levels, there the self condition was responded slower than other condition: good-self  vs. good-stranger, *t*(55) = 4.29, *p* < 0.001, Cohen’s *d* = 0.573, 95% CI [0.288 0.854], BF10 = 297.2; neutral-self  vs. neutral -stranger, *t*(55) = 7.17, *p* < 0.001, Cohen’s *d* = 0.958, 95% CI [0.638 1.272]), BF10 = 5.77e+6; bad-self vs. bad-other, *t*(55) = 6.03, *p* < 0.001, Cohen’s *d* = 0.806, 95% CI [0.5 1.11], BF10 = 100208.03.

For the mismacthed trials, we also found interaction between of valence and identity, `r df3b_RT_anova_nm_apa$full$Identity_Valence`. Further analysis showed that there was effect of valence for other-referential trials (`r df3b_RT_anova_nm_o_apa$full$Valence`) but not for the self-referential trials (`r df3b_RT_anova_nm_s_apa$full$Valence`). Post-hoc comparison revealed that bad-other trials (857 $\pm$ 20.9) were responded faster than good (967 $\pm$ 25.1), *t* = -9.625, *p* < 0.0001, and neutral (876 $\pm$ 21.4) trials, *t* = -2.263, *p* = 0.697, good-other conditions were also slower than neutral-other, *t* = -8.016, *p* < 0.0001

## Discussion
In experiment 3b, we separated the self-referential and other-referential tasks into different blocks so that participants had lower cognitive load when finish the task. We replicated the pattern from experiment 3a that the valence effect is stronger when the stimuli were self-referential. Contrast to experiment 3a, however, we found that the self-referential condition is out-performed by other-referential conditions. This pattern suggest that the self-referential enhanced the valence effect, and the advantage to self might be relative instead of absolute.

# Experiment 4a
In study 1-3 participants made explicit judgements about moral associations. In Experiment 4, we examined whether the interaction between moral valence and identity occur even when one of the variable was irrelevent to the task. In experiment 4a, participants learnt associations between shapes and self/other labels, then made perceptual match judgements only about the self or other conditions labels and shapes (cf. Sui et al., 2012). However, we presented labels of different moral valence in the shapes, which means that the moral valence factor become task irrelevant. If the binding between moral good and self is intrinsic and automatic, then we will observe that facilitating effect of moral good for self conditions, but not for other conditions.

In study 4b, we changed the role of valence and identity in task. In this experiment, participants learn the association between moral valence and the made perceptual match judgements to associations between different moral valence and shapes as in study 1-3. Different from experiment 1 ~ 3, we made put the labels of "self/other" in the shapes so that identity served as an task irrelevant variable. As in experiment 4a, we also hypothesized that the instrinc binding between morally good and self will enhance the performance of good self condition, even identity is irrelevant to the task.

```{r loadingData_4a,echo=FALSE,results='hide', eval = FALSE}
df4a_1 <- read.csv(file.path(".", "exp4a", "rawdata_behav_exp4a_2015.csv"), 
                   header = TRUE, sep = ",",stringsAsFactors=FALSE,na.strings=c("","NA")) %>%
  dplyr::rename(Morality = morality,
                Identity = self) %>%
  dplyr::mutate(Site = "THU") %>%
  dplyr::mutate(Subject = Subject + 4100)  

df4a_2 <- read.csv(file.path(".", "exp4a", "rawdata_behav_exp4a_2017.csv"),header = TRUE, sep = ",",stringsAsFactors=FALSE,na.strings=c("","NA")) %>%
  dplyr::mutate(Site = "WZU")

df4a <- rbind(df4a_1,df4a_2) %>%
  dplyr::rename(ACC = Target.ACC,           # rename columns
                RT  = Target.RT,
                CRESP = Target.CRESP,
                BlockNo = BlockList.Sample,
                TrialNo = SubTrial,
                RESP = Target.RESP,
                Matchness = YesNoResp,
                Valence = Morality) %>%
  dplyr::mutate(Valence  = ifelse(Valence == "Normal", "Neutral", Valence),
                Identity = ifelse(Identity == "self" | Identity == "Self", "Self", "Other"),
                Matchness = ifelse(Matchness == "Yes", "Match", "Mismatch"),
                Age = ifelse(Age == 0, NA, Age))
                #Subject = factor(Subject))

rm(df4a_1,df4a_2) # remove the temporary variables.

df4a.T.basic     <- df4a %>%
  dplyr::select(Site, Subject, Age, Sex) %>%
  dplyr::distinct(Subject, .keep_all = TRUE) %>%
  dplyr::summarise(N = length(Subject),
                   N_thu = length(Site[Site == "THU"]),
                   N_wzu = length(Site[Site == "WZU"]),
                   Nf = length(Sex[Sex == "female"]),
                   Nm = length(Sex[Sex == "male"]),
                   Age_mean = round(mean(Age,na.rm=TRUE),2),
                   Age_sd = round(sd(Age,na.rm=TRUE),2))
  
# number of participant who practiced but not in the formal experiment
nQuit <- length(unique(df4a$Subject[is.na(df4a$BlockNo)])) - length(unique(df4a$Subject[!is.na(df4a$BlockNo)]))

# participants should be excluded
df4a.excld.sub <-  df4a %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::group_by(Subject) %>%
  #dplyr::mutate(ACC = ifelse(RT <= 200, 0, ACC)) %>%  # set less than 200 ms response as wrong
  #dplyr::filter(!(ACC == 1 & RT <= 200)) %>%
  dplyr::summarise(N = length(ACC),                   # caculate the overall accuracy for each subject
                   N_crrct = sum(ACC),
                   ACC = sum(ACC)/length(ACC)) %>%
  dplyr::filter(ACC < 0.6) %>%                        # exlucde the participants with less than 60% overall accuracy
  dplyr::select(Subject)

# The rate of excluded trials in valid data
df4a.invalid_trial_rate   <- df4a %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::filter(!(Subject %in% df4a.excld.sub$Subject)) %>%   # exclude the invalid subjects
  dplyr::summarize(rate = length(RT[RT <= 200 & ACC == 1])/length(RT)) %>%
  dplyr::pull()

df4a.v   <- df4a %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::filter(!(Subject %in% df4a.excld.sub$Subject)) %>%   # exclude the invalid subjects
  dplyr::filter(!(RT <= 200 & ACC == 1))                      # exclude < 200 trials

df4a.v.basic     <- df4a.v %>%
  dplyr::select(Site, Subject, Age, Sex) %>%
  dplyr::distinct(Subject, .keep_all = TRUE) %>%
  dplyr::summarise(N = length(Subject),
                   N_thu = length(Site[Site == "THU"]),
                   N_wzu = length(Site[Site == "WZU"]),
                   Nf = length(Sex[Sex == "female"]),
                   Nm = length(Sex[Sex == "male"]),
                   Age_mean = round(mean(Age,na.rm=TRUE),2),
                   Age_sd = round(sd(Age,na.rm=TRUE),2))

# calculating the dprime 
df4a.v.dprime_l <- df4a.v %>%
  dplyr::mutate(sdt = mosaic::derivedFactor("hit" = (ACC ==1 & Matchness == "Match"), # code as hit
                                    "CR" = (ACC ==1  & Matchness == "Mismatch"),      # correct reject
                                    "miss" = (ACC == 0 & Matchness == "Match"),       # miss
                                    "FA" = (ACC == 0 & Matchness == "Mismatch"),      # false alarm
                                    .method ="first",  .default = NA)) %>% 
  dplyr::group_by(Site, Subject, Age, Sex, Valence,Identity, sdt) %>%
  dplyr::summarise(N = length(sdt)) %>%                                    # calculate the counts for each 
  dplyr::ungroup() %>%
  tidyr::spread(key = sdt, value = N,fill = 0) %>%                          # long-to-wide format
  dplyr::mutate(hitR = hit/(hit + miss),                                    # hit rate
                FAR  = FA/(FA+CR)) %>%                                      # fa rate
  dplyr::mutate(hitR = ifelse(hitR == 1, 1 - 1/(2*(hit + miss)), hitR),     # if hit rate is 1, standardize it
                FAR  = ifelse(FAR == 0, 1/(2*(hit + miss)), FAR)) %>%       # if FA rate is 0, standardize it
  dplyr::mutate(dprime = qnorm(hitR) - qnorm(FAR)) %>%
  dplyr::select(Site, Subject, Age, Sex, Valence, Identity, dprime) %>%   # select relevant columns
  dplyr::mutate(Valence = factor(Valence, levels = c("Good","Neutral","Bad")),
                Identity = factor(Identity, levels = c('Self', 'Other')))

df4a.v.rt_m <- df4a.v %>%
  dplyr::filter(ACC == 1) %>%
  dplyr::group_by(Site,Subject, Age, Sex, Matchness, Identity, Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup()

### prepare for the later meta-analysis
df4a.meta.d <- df4a.v.dprime_l %>% 
  dplyr::mutate(ExpID = 'Exp4a',
                Domain = "Morality") %>%        # add domain as morality, to be comparable with experiment 5.
  dplyr::select(CommonColnames_d)

df4a.meta.rt <- df4a.v.rt_m %>% 
  dplyr::rename(RT = RT_m) %>%
  dplyr::mutate(ExpID = 'Exp4a',
                Domain = "Morality") %>%        # add domain as morality, to be comparable with experiment 5.
  dplyr::select(CommonColnames_rt)

```
## Methods
### Participants
`r df4a.T.basic$N` participants (`r df4a.T.basic$Nf` female, age = `r df4a.T.basic$Age_mean` $\pm$ `r df4a.T.basic$Age_sd`) participated the current study, `r df4a.T.basic$N_thu` of them were from Tsinghua Universtiy in 2015, `r df4a.T.basic$N_wzu` were from Wenzhou University parpticipated in 2017. All participants were right-handed, and all had normalneutral or corrected-to-normalneutral vision. Informed consent was obtained from all participants prior to the experiment according to procedures approved by a local ethics committee. The data from `r nrow(df4a.excld.sub)` participants from Wenzhou site were excluded from analysis because their accuracy was close to chance (< 0.6). The results for the remaining `r df4a.v.basic$N` participants (`r df4a.v.basic$Nf` female, age = `r df4a.v.basic$Age_mean` $\pm$ `r df4a.v.basic$Age_sd`) were analyzed and reported.

### Experimental design
As in Experiment 3, a 2× 3× 2 within-subject design was used. The first variable was self-relevance (self and stranger associations); the second variable was moral valence (good, normalneutral and bad associations); the third variable was the matching between shape and label (matching vs. non-match for the personal association). 
However, in this the task, participants only learn the association between two geometric shapes and two labels (self and other), i.e., only self-relevance were related to the task. The moral valence manipulation was achieved by embeding the personal label of the labels in the geometric shapes, see below. For simplicity, the trials where shapes where paired with self and with a word of “good person” inside were shorted as good-self condition, similarly, the trials where shapes paired with the self and with a word of “bad person” inside were shorted as bad-self condition. Hence, we also have six conditions: good-self, neutral-self, bad-self, good-other, neutral-other, and bad-other.

### Stimuli
2 shapes were included (circle, square) and each appeared above a central fixation cross with the personal label appearing below.  However, the shapes were not empty but with a two-Chinese-character word in the middle, the word was one of three labels with different moral valence: “good person”, “bad person” and “neutral person”. Before the experiment, participants learned the self/other association, and were informed to only response to the association between shapes’ configure and the labels below the fixation, but ignore the words within shapes. Besides the behavioral experiments, participants from Tsinghua community also finished questionnaires as Experiments 3, and participants from Wenzhou community finished a series of questionnaire as the other experiment finished in Wenzhou.

### Procedure
The procedure was similar to Experiment 1. There were 6 blocks of trial, each with 120 trials for 2017 data. Due to procedure error, the data collected in 2015 in Tsinghua community only have 60 trials for each block, i.e., 30 trials per condition. 

### Data analysis
The data were analyzed in the same way as in experiment 3a and 3b.


## Results

```{r 'ex4a-dprime-rt', fig.cap="RT and *d* prime of Experiment 4a.", fig.height=6, fig.width=10, warning=FALSE}

rtdata <- df4a.v.rt_m %>% dplyr::filter(Matchness == "Match") %>% dplyr::rename(RT = RT_m)

Mplots(expName = 'exp4a', df4a.v.dprime_l,rtdata)

```

Figure \@ref(fig:ex4a-dprime-rt) shows *d* prime and reaction times of experiment 4a.

### *d* prime.

```{r analyzing for d prime_4a, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
# anova for d prime with 2*2 design
df4a_dprime_anova <- afex::aov_ez('Subject','dprime',df4a.v.dprime_l, within = c('Identity','Valence'))
df4a_dprime_anova_apa <- df4a_dprime_anova %>% papaja::apa_print.afex_aov()

df4a_dprime_s_anova <- df4a.v.dprime_l %>%
  dplyr::filter(Identity == "Self")%>%
  afex::aov_ez('Subject','dprime', ., within = c('Valence'))
df4a_dprime_s_anova_apa <- df4a_dprime_s_anova %>% papaja::apa_print.afex_aov()

posthoc_4a_d_s <- emmeans::emmeans(df4a_dprime_s_anova, "Valence")
pairs(posthoc_4a_d_s)

df4a_dprime_o_anova <- df4a.v.dprime_l %>%
  dplyr::filter(Identity == "Other")%>%
  afex::aov_ez('Subject','dprime', ., within = c('Valence'))
df4a_dprime_o_anova_apa <- df4a_dprime_o_anova %>% papaja::apa_print.afex_aov()

posthoc_4a_d_m1 <- emmeans::emmeans(df4a_dprime_anova, "Valence", by = "Identity") # compare each valence for both self and other condition
#pairs(posthoc_4a_d_m1)
# summary(as.glht(pairs(m2)), test=adjusted("free"))
posthoc_4a_d_m2 <- emmeans(df4a_dprime_anova, "Identity", by = "Valence") # compare self vs. other for each valence condition
#pairs(posthoc_4a_d_m2)

```
We conducted 2 (Idenity: self v. other) by 3 (morlaity: good, neutral, bad) repeated measures ANOVA. The effect of identity (`r df4a_dprime_anova_apa$full$Identity`), also the interaction between identity and valence, (`r df4a_dprime_anova_apa$full$Identity_Valence`). But not the effect of valence was not found, `r df4a_dprime_anova_apa$full$Valence`. We further examined the effect of valence for both self and other. For the self-referential trials,  there was a weak effect of valence `r df4a_dprime_s_anova_apa$full$Valence`. Post-hoc analysis showed that good self condition (2.55 $\pm$ 0.111) is slightly higher than bad self condition (2.38 $\pm$ 0.105) , *t*(58) = 2.339, *p* = .0583. But there was no differences between good-self and neutral self (2.45 $\pm$ 0.101), *t*(58) = 1.575, *p* = .264, neither between neutral-self and bad-self, *t*(58) = 0.966, *p* = .601. As for the other-referential conditions, the result didn't show effect of valence `r df4a_dprime_o_anova_apa$full$Valence`.

### Reaction times

```{r analyzing for RT_4a, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
df4a_RT_anova <- afex::aov_ez('Subject','RT_m',df4a.v.rt_m, within = c('Matchness','Identity','Valence'))
df4a_RT_anova_apa <- df4a_RT_anova %>% papaja::apa_print.afex_aov()

# match trials
df4a_RT_anova_m <- df4a.v.rt_m %>%
  dplyr::filter(Matchness == "Match") %>%
  afex::aov_ez('Subject','RT_m', ., within = c('Identity','Valence'))
df4a_RT_anova_m_apa <- df4a_RT_anova_m %>% papaja::apa_print.afex_aov()

posthoc_4a_rt <- emmeans::emmeans(df4a_RT_anova_m, c('Identity',"Valence")) # compare each valence for both self and other condition
# pairs(posthoc_4a_rt)

# match trials: self condition
df4a_RT_anova_m_s <- df4a.v.rt_m %>%
  dplyr::filter(Matchness == "Match" & Identity == "Self") %>%
  afex::aov_ez('Subject','RT_m', ., within = c('Valence'))
df4a_RT_anova_m_s_apa <- df4a_RT_anova_m_s %>% papaja::apa_print.afex_aov()

posthoc_4a_rt_s <- emmeans::emmeans(df4a_RT_anova_m_s, c("Valence")) # compare each valence for both self and other condition
pairs(posthoc_4a_rt_s)

# match trials: other condition
df4a_RT_anova_m_o <- df4a.v.rt_m %>%
  dplyr::filter(Matchness == "Match" & Identity == "Other") %>%
  afex::aov_ez('Subject','RT_m', ., within = c('Valence'))
df4a_RT_anova_m_o_apa <- df4a_RT_anova_m_o %>% papaja::apa_print.afex_aov()

# Mismatch trials
df4a_RT_anova_nm <- df4a.v.rt_m %>%
  dplyr::filter(Matchness == "Mismatch") %>%
  afex::aov_ez('Subject','RT_m', ., within = c('Identity','Valence'))
df4a_RT_anova_nm_apa <- df4a_RT_anova_nm %>% papaja::apa_print.afex_aov()
```
We conducted 2 (Matchness: match v. mismatch) by 2 (Idenity: self v. other) by 3 (morlaity: good, neutral, bad) repeated measure ANOVA. There was a main effect of Matchness (`r df4a_RT_anova_apa$full$Matchness`) and intercation between Matchness and Identity(`r df4a_RT_anova_apa$full$Matchness_Identity`)

We carried out two separate ANOVA for both matched and mismatched trials. The results showed that for matched trials, there was an interaction between valence and identity, `r df4a_RT_anova_m_apa$full$Identity_Valence`. However, there is no main effect of valence (`r df4a_RT_anova_m_apa$full$Valence`). We futher broke down the interaction by analyzing the data for self and other pairs separately. There was a significant effect of moral valence for self-stimuli, `r df4a_RT_anova_m_s_apa$full$Valence`, BF10 = 11.16. Paired *t*-tests showed that good-self condition (654 ± 67) were faster relative to bad-self condition (665 ± 64.6), *t*(58) = -3.47, *p* = 0.0028, Cohen’s *d* = -0.451 CI [-0.718 -0.182], BF10 = 27.0, and  over neutral-self condition (664 ± 64), *t*(58) = -2.78, *p* = 0.013, Cohen’s  *d* = -0.362, 95% CI [-0.624 -0.097], BF10 = 4.63. The neutral-self and bad-self conditionsdid not differ, *t*(58) = -0.44, *p* = 0.89, Cohen’s *d* = 0.0499, CI [-0.305 0.206], BF10 = 0.153. For the stranger condition, the results showed that there was no difference among these conditions, `r df4a_RT_anova_m_o_apa$full$Valence`, BF10 = 0.077.

For non-matched trials, there was no significant effect. Morality (`r df4a_RT_anova_nm_apa$full$Identity`), Identity(`r df4a_RT_anova_nm_apa$full$Valence`), interaction (`r df4a_RT_anova_nm_apa$full$Identity_Valence`).



```{r results='asis', echo = F, eval=FALSE}
#knitr::kable(nice(df4b_dprime_anova), caption = "ANOVA of d prime")
#apa_table(df4a_RT_anova_m_apa$table
#  , caption = "A really beautiful ANOVA table."
#  , note = "Note that the column names contain beautiful mathematical copy: This is because the table has variable labels."
#)
```

# Experiment 4b

## Method

```{r loadingData_4b,echo=FALSE,results='hide', eval = FALSE}
df4b_1 <- read.csv(file.path(".", "exp4b", "rawdata_behav_exp4b_2015.csv"), 
                             header = TRUE, sep = ",",stringsAsFactors=FALSE,na.strings=c("","NA")) %>%
  dplyr::rename(Morality = morality) %>%
  dplyr::mutate(Site = "THU")

df4b_2 <- read.csv(file.path(".", "exp4b", "rawdata_behav_exp4b_2017.csv"), 
                             header = TRUE, sep = ",",stringsAsFactors=FALSE,na.strings=c("","NA")) %>%
  dplyr::rename(Morality = morality) %>%
  dplyr::mutate(Site = "WZU")

df4b <- rbind(df4b_1,df4b_2) %>%
  dplyr::rename(ACC = Target.ACC,           # rename columns
                RT  = Target.RT,
                CRESP = Target.CRESP,
                BlockNo = BlockList.Sample,
                TrialNo = SubTrial,
                RESP = Target.RESP,
                Matchness = YesNoResp,
                Valence = Morality) %>%
  dplyr::mutate(Valence  = ifelse(Valence == "Ord", "Neutral", Valence),
                Identity = ifelse(Identity == "self" | Identity == "Self", "Self", "Other"),
                Matchness = ifelse(Matchness == "Yes", "Match", "Mismatch"),
                Age = ifelse(Age == 0, NA, Age))                             # if the min age is 0, that age is missing
                #ExpID = 'Exp4b', Domain = "Morality") %>%
#  dplyr::select(CommonColnames)

rm(df4b_1,df4b_2) # remove the temporary variables.

df4b.T.basic     <- df4b %>%
  dplyr::select(Site, Subject, Age, Sex) %>%
  dplyr::distinct(Subject, .keep_all = TRUE) %>%
  dplyr::summarise(N = length(Subject),
                   N_thu = length(Site[Site == "THU"]),
                   N_wzu = length(Site[Site == "WZU"]),
                   Nf = length(Sex[Sex == "female"]),
                   Nm = length(Sex[Sex == "male"]),
                   Age_mean = round(mean(Age,na.rm=TRUE),2),
                   Age_sd = round(sd(Age,na.rm=TRUE),2))
  
# number of participant who practiced but not in the formal experiment
nQuit <- length(unique(df4b$Subject[is.na(df4b$BlockNo)])) - length(unique(df4b$Subject[!is.na(df4b$BlockNo)]))

# participants should be excluded
df4b.excld.sub <-  df4b %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::group_by(Subject) %>%
  #dplyr::mutate(ACC = ifelse(RT <= 200, 0, ACC)) %>%  # set less than 200 ms response as wrong
  dplyr::summarise(N = length(ACC),                   # caculate the overall accuracy for each subject
                   N_crrct = sum(ACC),
                   ACC = sum(ACC)/length(ACC)) %>%
  dplyr::filter(ACC < 0.6) %>%                        # exlucde the participants with less than 60% overall accuracy
  dplyr::select(Subject)

# The rate of excluded trials in valid data
df4b.invalid_trial_rate   <- df4b %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::filter(!(Subject %in% df4b.excld.sub$Subject)) %>%   # exclude the invalid subjects
  dplyr::summarize(rate = length(RT[RT <= 200 & ACC == 1])/length(RT)) %>%
  dplyr::pull()

df4b.v   <- df4b %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::filter(!(Subject %in% df4b.excld.sub$Subject)) %>%   # exclude the invalid subjects
  dplyr::filter(!(RT <= 200 & ACC == 1))                      # exclude < 200 trials

df4b.v.basic     <- df4b.v %>%
  dplyr::select(Site, Subject, Age, Sex) %>%
  dplyr::distinct(Subject, .keep_all = TRUE) %>%
  dplyr::summarise(N = length(Subject),
                   N_thu = length(Site[Site == "THU"]),
                   N_wzu = length(Site[Site == "WZU"]),
                   Nf = length(Sex[Sex == "female"]),
                   Nm = length(Sex[Sex == "male"]),
                   Age_mean = round(mean(Age,na.rm=TRUE),2),
                   Age_sd = round(sd(Age,na.rm=TRUE),2))

# calculating the dprime 
df4b.v.dprime_l <- df4b.v %>%
  dplyr::mutate(sdt = mosaic::derivedFactor("hit" = (ACC ==1 & Matchness == "Match"), # code as hit
                                    "CR" = (ACC ==1  & Matchness == "Mismatch"),      # correct reject
                                    "miss" = (ACC == 0 & Matchness == "Match"),       # miss
                                    "FA" = (ACC == 0 & Matchness == "Mismatch"),      # false alarm
                                    .method ="first",  .default = NA)) %>% 
  dplyr::group_by(Site, Subject, Age, Sex, Valence,Identity, sdt) %>%
  dplyr::summarise(N = length(sdt)) %>%                                    # calculate the counts for each 
  dplyr::ungroup() %>%
  tidyr::spread(key = sdt, value = N,fill = 0) %>%                          # long-to-wide format
  dplyr::mutate(hitR = hit/(hit + miss),                                    # hit rate
                FAR  = FA/(FA+CR)) %>%                                      # fa rate
  dplyr::mutate(hitR = ifelse(hitR == 1, 1 - 1/(2*(hit + miss)), hitR),     # if hit rate is 1, standardize it
                FAR  = ifelse(FAR == 0, 1/(2*(hit + miss)), FAR)) %>%       # if FA rate is 0, standardize it
  dplyr::mutate(dprime = qnorm(hitR) - qnorm(FAR)) %>%
  dplyr::select(Site, Subject, Age, Sex, Valence, Identity, dprime) %>%   # select relevant columns
  dplyr::mutate(Valence = factor(Valence, levels = c("Good","Neutral","Bad")),
                Identity = factor(Identity, levels = c('Self', 'Other')))

df4b.v.rt_m <- df4b.v %>%
  dplyr::filter(ACC == 1) %>%
  dplyr::group_by(Site,Subject, Age, Sex, Matchness, Identity, Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup()

### prepare for the later meta-analysis
df4b.meta.d <- df4b.v.dprime_l %>% 
  dplyr::mutate(ExpID = 'Exp4b',
                Domain = "Morality") %>%        # add domain as morality, to be comparable with experiment 5.
  dplyr::select(CommonColnames_d)

df4b.meta.rt <- df4b.v.rt_m %>% 
  dplyr::rename(RT = RT_m) %>%
  dplyr::mutate(ExpID = 'Exp4b',
                Domain = "Morality") %>%        # add domain as morality, to be comparable with experiment 5.
  dplyr::select(CommonColnames_rt)

```
### Participants
`r df4b.T.basic$N` college students (`r df4b.T.basic$Nf` female, age = `r df4b.T.basic$Age_mean` $\pm$ `r df4b.T.basic$Age_sd`) participated the current study, `r df4b.T.basic$N_thu` of them were from Tsinghua Universtiy in 2015 `r df4b.T.basic$N_wzu` were from Wenzhou University parpticipated in 2017. All participants were right-handed, and all had normalneutral or corrected-to-normalneutral vision. Informed consent was obtained from all participants prior to the experiment according to procedures approved by a local ethics committee. The data from `r nrow(df4b.excld.sub)` participants were excluded from analysis because their accuracy was close to chance (< 0.6). The results for the remaining `r df4b.v.basic$N` participants (`r df4b.v.basic$Nf` female, age = `r df4b.v.basic$Age_mean` $\pm$ `r df4b.v.basic$Age_sd`) were analyzed and reported.

### Experimental design
The experimental design of this experiment is same as experiment 4a:  a 3× 2 × 2 within-subject design with moral valence (good, normalneutral and bad associations), self-relatedness (self vs. other), and matchness between shape and label (match vs. mismatch for the personal association) as within-subject variables. However, in the current task, the participants learned the associations between three shapes and three labels with different moral valence: good-person, neutral-person, and bad-person. While the word “self” or “other” were presented in the shapes (see below).

### Stimuli
In this task, 3 shapes were included (circle, square, and trapezoid) and were presented above a central fixation cross, as in previous experiments.  Similar to experiment 4a, the shapes were not empty but with a two-Chinese-character word in the middle corresponding to the labels “self” and “other”. Before the experiment, we informed participants only response to the relationship between shapes’shapes configure and the labels below the fixation, ignoring the wordswithin each shape. Besides the behavioral experiments, participants also finished questionnaires as Experiments 1-3.

### Procedure
The procedure was similar to Experiment 4 a. Both samples of participants finished 6 blocks of trial, each with 120 trials.

### Data analysis
The data were analyzed as in experiment 4a.

## Results

```{r 'ex4b-dprime-rt', fig.cap="RT and *d* prime of Experiment 4b.", fig.height=6, fig.width=10, warning=FALSE}
rtdata <- df4b.v.rt_m %>% dplyr::filter(Matchness == "Match") %>% dplyr::rename(RT = RT_m)

Mplots(expName = 'exp4b', df4a.v.dprime_l,rtdata)
```

Figure \@ref(fig:ex4b-dprime-rt) shows *d* prime and reaction times of experiment 4b.

### *d* prime
```{r analyzing for d prime_e4b, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
# anova for d prime with 2*2 design
df4b_dprime_anova <- afex::aov_ez('Subject','dprime',df4b.v.dprime_l, within = c('Identity','Valence'))
df4b_dprime_anova_apa <- df4b_dprime_anova %>% papaja::apa_print.afex_aov()
#df4b_dprime_anova <- apa_print(df4b_dprime_anova)
```
We conducted 2 (Idenity: self v. other) by 3 (morlaity: good, neutral, bad) repeated measure ANOVA. The results revealed no effect of valence (`r df4b_dprime_anova_apa$full$Valence`), or identity, `r df4b_dprime_anova_apa$full$Identity`, or their interactions, `r df4b_dprime_anova_apa$full$Identity_Valence`.

### Reaction times
We conducted 2 (Matchness: match v. mismatch) by 2 (Idenity: self v. other) by 3 (morlaity: good, neutral, bad) repeated measure ANOVA:
```{r analyzing for RT_4b, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
df4b_RT_anova <- afex::aov_ez('Subject','RT_m',df4b.v.rt_m,     # using afex's function 
                                  within = c('Matchness','Identity','Valence'))
df4b_RT_anova_apa <- df4b_RT_anova %>% papaja::apa_print.afex_aov()
```
There was a main effect of Matchness (`r df4b_RT_anova_apa$full$Matchness`), main effect of valence (`r df4b_RT_anova_apa$full$Valence`),  intercation between Matchness and Valence(`r df4b_RT_anova_apa$full$Matchness_Valence`), and three way interaction (`r df4b_RT_anova_apa$full$Matchness_Identity_Valence`).

```{r analyzing for RT_4b_match, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
# match trials
df4b.v.rt_m1 <- df4b.v %>%
  dplyr::filter(ACC == 1 & Matchness == "Match") %>%
  dplyr::group_by(Site, Subject, Matchness, Identity, Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup() %>%
  dplyr::mutate(Valence = factor(Valence, levels = c("Good","Neutral","Bad")),
                Identity = factor(Identity, levels = c('Self', 'Other')))

df4b_RT_anova_m <- afex::aov_ez('Subject','RT_m',df4b.v.rt_m1,     # using afex's function 
                                  within = c('Identity','Valence'))
df4b_RT_anova_m_apa <- df4b_RT_anova_m %>% papaja::apa_print.afex_aov()

posthoc_4b_rt <- emmeans::emmeans(df4b_RT_anova_m, 'Identity', by = "Valence") # compare each valence for both self and other condition
# pairs(posthoc_4b_rt)

# Mismatch trials
df4b.v.rt_m2 <- df4b.v %>%
  dplyr::filter(ACC == 1 & Matchness == "Mismatch") %>%
  dplyr::group_by(Site,Subject,Matchness, Identity, Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup()

df4b_RT_anova_nm <- afex::aov_ez('Subject','RT_m',df4b.v.rt_m2,     # using afex's function 
                                  within = c('Identity','Valence'))
df4b_RT_anova_nm_apa <- df4b_RT_anova_nm %>% papaja::apa_print.afex_aov()

# match trials: self condition
df4b.v.rt_m1_s <- df4b.v %>%
  dplyr::filter(ACC == 1 & Matchness == "Match" & Identity == "Self") %>%
  dplyr::group_by(Site, Subject, Matchness, Identity, Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup() %>%
  dplyr::mutate(Valence = factor(Valence, levels = c("Good","Neutral","Bad")))

df4b_RT_anova_m_s <- afex::aov_ez('Subject','RT_m',df4b.v.rt_m1_s,     # using afex's function 
                                  within = c('Valence'))
df4b_RT_anova_m_s_apa <- df4b_RT_anova_m_s %>% papaja::apa_print.afex_aov()

posthoc_4b_rt_s <- emmeans::emmeans(df4b_RT_anova_m_s, c("Valence")) # compare each valence for both self and other condition
# pairs(posthoc_4b_rt_s)

# match trials: other condition
df4b.v.rt_m1_o <- df4b.v %>%
  dplyr::filter(ACC == 1 & Matchness == "Match" & Identity == "Other") %>%
  dplyr::group_by(Site, Subject, Matchness, Identity, Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup() %>%
  dplyr::mutate(Valence = factor(Valence, levels = c("Good","Neutral","Bad")))

df4b_RT_anova_m_o <- afex::aov_ez('Subject','RT_m',df4b.v.rt_m1_o,     # using afex's function 
                                  within = c('Valence'))
df4b_RT_anova_m_o_apa <- df4b_RT_anova_m_o %>% papaja::apa_print.afex_aov()

posthoc_4b_rt_o <- emmeans::emmeans(df4b_RT_anova_m_o, c("Valence")) # compare each valence for both self and other condition
# pairs(posthoc_4b_rt_o)
```
We futher broke down the interaction by analyzing the data for self and other pairs separately. There was a significant effect of moral valence for self-stimuli, `r df4b_RT_anova_m_s_apa$full$Valence`, BF10 = 11.16. Paired *t* tests showed that good-self association (680 ± 9.79) were faster than bad-self associations (721  ± 8.97), *t*(44) = -4.22, *p* < .001, Cohen’s *d* = -0.629 CI [-0.947 -0.306], BF10 = 200, and  neutral-self association (713 $\pm$ 8.19), *t*(44) = -4.67, *p* < 0.001, Cohen’s *d* = -0.696, 95% CI [-1.019 -0.367], BF10 = 745.3. The neutral-self and bad-self associations did not differ, *t*(44) = -1.04, *p* = .31, Cohen’s *d* = -0.155, 95%CI [-0.448 0.14], BF10 = 0.267. RTs in good-self condition were facilitated but without performance being impaired for bad-self associations (relative to the normal neutral self)(see Figure 5). 
For other-association condition, the main effect of moral valence was  also significant, `r df4b_RT_anova_m_o_apa$full$Valence`, BF10 = 21. The RT for good-other association condition (688 ± 66.9) is faster than the bad-other association condition (718 ± 49.7), t(44) = -3.353, p = 0.0017, Cohen’s d = -0.4999, 95%CI [-0.8075 -0.1872], BF10 = 18.84. The RT for good-other condition is slightly faster than neutral-other condition (704 ± 57.1), but the evidence is not strong, t (44) = -2.21, p = 0.0324, Cohen’s d = -0.3294, 95%CI [-6278 -0.0275], BF10 = 1.454. While there is is no strong evidence about the differences between bad-other vs. neutral-other conditions, t(44) = -1.8267, p = 0.0745, Cohen’s d = -0.2723, 95%CI [-0.5685 0.0268], BF10 = 0.743.

We also comparied the reaction times for self- and other- association in different valence condition. we found that Good-self condition is faster than good-other condition, *t*(44) = -2.165, *p* = 0.0358; neutral self is slower than neutral-other condition, *t*(44) = 3.064, *p* = 0.0037. Bad-self and bad-other did not show difference, *t*(44) = 0.623, *p* = 0.5363.

For non-matched trials, there was no significant effect. Identity (`r df4b_RT_anova_nm_apa$full$Identity`), interaction (`r df4b_RT_anova_nm_apa$full$Identity_Valence`). But here are effect of Valence (`r df4b_RT_anova_nm_apa$full$Valence`)

## Discussion
In experiment 4, we manipulated the task so that the moral valence (experiment 4a) or the self-relatedness (experiment 4b) become irrelevant to the task. We found robust effects of the tasks: when the self-relatedness is task related, the results showed a strong effect of self-relatedness; in contrast, when moral valence become task related the main effect of moral valence was strong. However, the task irrelevant stimuli in the shape also had influence on the performance. The good self conditions (the shape associated the self and with a “good person” within the shape) performed better than bad self conditions even when the self was the only task relevant stimuli. Also, good-self showed advantage over good-other when valence is the only task relevant variable while idenity was not. Together, these results suggest that moral valence and self-referential can still couple together and facilitated the perceptual decision making even one feature of them is implicit.

# Experiment 5: Generalization of positive effect
So far, we have considered the modulation effect of morality and found that the positive moral valence could enhance the perception. However, we still not sure whether this effect was moral specific or reflecting a more general mechanism of effect of positive valence. To test the specificity of morality, we conducted experiment 5, in which three more categories of stimuli were used (people of different attractiveness, scene of diffenent attractivness, and emotional words with different valence). In this study, participants finished 4 session of association task, each with different categories of stimuli.

## Method

```{r loadingData_5,echo=FALSE,results='hide', eval = FALSE}
df5 <- read.csv(file.path(".", "exp5_specificity", "rawdata_behav_5_specificity_2016.csv"),
                header = TRUE, sep = ",",
                stringsAsFactors=FALSE, na.strings=c("","NA")) %>%
  dplyr::rename(BlockListM.Sample = BlockListMoral.Sample, 
                Matchness = YesNoResp, CRESP = CorrectAnswer) %>%                            # rename the columns
  dplyr::mutate(Matchness = ifelse(Matchness == "Yes", "Match", "Mismatch"),
                taskType = derivedFactor("Emotion"  = (Label == "sad" | Label == "happy" | Label == "neutral"),
                                         "Morality" = (Label == "bad" | Label == "good" | Label == "ordinary"),
                                         "Person"   = (Label == "uglyP" | Label == "beautyP" | Label == "normalP"),
                                         "Scene"    = (Label == "uglyS" | Label == "beautyS" | Label == "normalS"), 
                                         .method ="first", .default = NA),
                Valence = derivedFactor("Good"= (Label ==  "good" | Label == "happy" | Label == "beautyP"  | Label == "beautyS"),
                                         "Bad" = (Label == "bad"  | Label == "sad"   | Label == "uglyP"    | Label == "uglyS"),
                                         "Neutral" = (Label == "ordinary" | Label == "neutral" | Label == "normalP" | Label == "normalS"),
                                         .method ="first", .default = NA)) %>%
  tidyr::replace_na(list(PracListE="",    PracListM="",    PracListP="",    PracListS="")) %>%          # replace NA with "" for later unite
                         #BlockListE.Sample="", BlockListM.Sample="", BlockListP.Sample="", BlockListS.Sample="",
                         #TrialListE.Sample="", TrialListM.Sample="", TrialListP.Sample="", TrialListS.Sample="",
                         #TargetE.ACC="",  TargetM.ACC="",  TargetP.ACC="",  TargetS.ACC="",
                         #TargetE.RESP="", TargetM.RESP="", TargetP.RESP="", TargetS.RESP="",
                         #TargetE.RT="",   TargetM.RT="",   TargetP.RT="",   TargetS.RT="")) %>%
  tidyr::unite("PracList", PracListE,PracListM,PracListP,PracListS, sep = "")  %>%                # unite all praclist
  #tidyr::unite("BlockNo", BlockListE.Sample,BlockListM.Sample,BlockListP.Sample,BlockListS.Sample, sep = "") %>% # unite all blocklist
  #tidyr::unite("TrialNo", TrialListE.Sample,TrialListM.Sample,TrialListP.Sample,TrialListS.Sample, sep = "") %>% # unite all blocklist
 # tidyr::unite("ACC", TargetE.ACC,  TargetM.ACC,  TargetP.ACC,  TargetS.ACC, sep = "") %>%        # unite all ACC
  #tidyr::unite("RESP", TargetE.RESP,  TargetM.RESP,  TargetP.RESP,  TargetS.RESP, sep = "") %>%   # unite all RESP
  #tidyr::unite("RT", TargetE.RT,  TargetM.RT,  TargetP.RT,  TargetS.RT, sep = "") %>%             # unite all RT
  dplyr::mutate(Site = "THU", 
                ExpID = "Exp5",
                RESP = dplyr::coalesce(TargetE.RESP,  TargetM.RESP,  TargetP.RESP,  TargetS.RESP),
                ACC = dplyr::coalesce(TargetE.ACC,  TargetM.ACC,  TargetP.ACC,  TargetS.ACC), 
                RT = dplyr::coalesce(TargetE.RT,  TargetM.RT,  TargetP.RT,  TargetS.RT),
                BlockNo = dplyr::coalesce(BlockListE.Sample,BlockListM.Sample,BlockListP.Sample,BlockListS.Sample),
                TrialNo = dplyr::coalesce(TrialListE.Sample,TrialListM.Sample,TrialListP.Sample,TrialListS.Sample)) %>% 
                #BlockNo = as.numeric(BlockNo),
                #TrialNo = as.numeric(TrialNo)) %>% 
  dplyr::mutate_if(is_character, list(~na_if(.,""))) %>%    # blank to NA
  dplyr::select(-c(TargetE.RESP,  TargetM.RESP, TargetP.RESP,  TargetS.RESP,
                  TargetE.ACC,  TargetM.ACC,  TargetP.ACC,  TargetS.ACC,
                  TargetE.RT,  TargetM.RT,  TargetP.RT,  TargetS.RT,
                  BlockListE.Sample,BlockListM.Sample,BlockListP.Sample,BlockListS.Sample,
                  TrialListE.Sample,TrialListM.Sample,TrialListP.Sample,TrialListS.Sample))

df5.T.basic     <- df5 %>%
  dplyr::select(Site, Subject, Age, Sex) %>%
  dplyr::distinct(Subject, .keep_all = TRUE) %>%
  dplyr::summarise(N = length(Subject),
                   N_thu = length(Site[Site == "THU"]),
                   N_wzu = length(Site[Site == "WZU"]),
                   Nf = length(Sex[Sex == "female"]),
                   Nm = length(Sex[Sex == "male"]),
                   Age_mean = round(mean(Age,na.rm=TRUE),2),
                   Age_sd = round(sd(Age,na.rm=TRUE),2))
  
# find the participants who practiced but not finish experiment
subjPrac <- df5 %>% dplyr::filter(is.na(df5$BlockNo)) %>% dplyr::distinct(Subject)
subjFinish <- df5 %>% dplyr::filter(!is.na(df5$BlockNo)) %>% dplyr::distinct(Subject)
subjQuit <- subjPrac$Subject[which(!subjPrac$Subject %in% subjFinish$Subject)] 

# participants should be excluded
df5.excld.sub <-  df5 %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::group_by(Subject) %>%
  dplyr::summarise(N = length(ACC),                   # caculate the overall accuracy for each subject
                   N_crrct = sum(ACC),
                   ACC = sum(ACC)/length(ACC)) %>%
  dplyr::filter(ACC < 0.6) %>%                        # exlucde the participants with less than 60% overall accuracy
  dplyr::select(Subject)

# The rate of excluded trials in valid data
df5.invalid_trial_rate   <- df5 %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::filter(!(Subject %in% subjQuit)) %>%                 # exclude the invalid subjects
  dplyr::filter(!(Subject %in% df5.excld.sub$Subject)) %>%    # exclude the invalid subjects
  dplyr::summarize(rate = length(RT[RT <= 200 & ACC == 1])/length(RT)) %>%
  dplyr::pull()

df5.v   <- df5 %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::filter(!(Subject %in% subjQuit)) %>%                 # exclude the invalid subjects
  dplyr::filter(!(Subject %in% df5.excld.sub$Subject)) %>%   # exclude the invalid subjects
  dplyr::filter(!(RT <= 200 & ACC == 1)) %>%                      # exclude < 200 trials
  dplyr::arrange(Subject)

df5.v.basic     <- df5.v %>%
  dplyr::select(Site, Subject, Age, Sex) %>%
  dplyr::distinct(Subject, .keep_all = TRUE) %>%
  dplyr::summarise(N = length(Subject),
                   N_thu = length(Site[Site == "THU"]),
                   N_wzu = length(Site[Site == "WZU"]),
                   Nf = length(Sex[Sex == "female"]),
                   Nm = length(Sex[Sex == "male"]),
                   Age_mean = round(mean(Age,na.rm=TRUE),2),
                   Age_sd = round(sd(Age,na.rm=TRUE),2))

# calculating the dprime 
df5.v.dprime_l <- df5.v %>%
  dplyr::mutate(sdt = mosaic::derivedFactor("hit" = (ACC ==1 & Matchness == "Match"), # code as hit
                                    "CR" = (ACC ==1  & Matchness == "Mismatch"),      # correct reject
                                    "miss" = (ACC == 0 & Matchness == "Match"),       # miss
                                    "FA" = (ACC == 0 & Matchness == "Mismatch"),      # false alarm
                                    .method ="first",  .default = NA)) %>% 
  dplyr::group_by(Site, taskType, Subject, Age, Sex, Valence,sdt) %>%
  dplyr::summarise(N = length(sdt)) %>%                                    # calculate the counts for each 
  dplyr::ungroup() %>%
  tidyr::spread(key = sdt, value = N,fill = 0) %>%                          # long-to-wide format
  dplyr::mutate(hitR = hit/(hit + miss),                                    # hit rate
                FAR  = FA/(FA+CR)) %>%                                      # fa rate
  dplyr::mutate(hitR = ifelse(hitR == 1, 1 - 1/(2*(hit + miss)), hitR),     # if hit rate is 1, standardize it
                FAR  = ifelse(FAR == 0, 1/(2*(hit + miss)), FAR)) %>%       # if FA rate is 0, standardize it
  dplyr::mutate(dprime = qnorm(hitR) - qnorm(FAR)) %>%
  dplyr::select(Site, Subject, Age, Sex, taskType,Valence, dprime) %>%   # select relevant columns
  dplyr::mutate(Valence = factor(Valence, levels = c("Good","Neutral","Bad")),
                taskType = factor(taskType, levels = c('Morality', 'Emotion',"Person", "Scene")))
# anova for RT with 2*2 design
df5.v.rt_m <- df5.v %>%
  dplyr::filter(ACC == 1) %>%
  dplyr::group_by(Site,Subject, Age, Sex, Matchness,taskType,Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup() %>%
  dplyr::mutate(Valence = factor(Valence, levels = c("Good","Neutral","Bad")),
                taskType = factor(taskType, levels = c('Morality', 'Emotion',"Person", "Scene")))

### prepare for the later meta-analysis
df5.meta.d <- df5.v.dprime_l %>% 
  dplyr::rename(Domain = taskType) %>%
  dplyr::mutate(ExpID = 'Exp5',
                Identity = NA) %>%        # add domain as morality, to be comparable with experiment 5.
  dplyr::select(CommonColnames_d)

df5.meta.rt <- df5.v.rt_m %>% 
  dplyr::rename(Domain = taskType,
                RT = RT_m) %>%
  dplyr::mutate(ExpID = 'Exp5',
                Identity = NA) %>%        # add domain as morality, to be comparable with experiment 5.
  dplyr::select(CommonColnames_rt)
```

### Participants
`r df5.T.basic$N` participant recruited from Tsinghua University university community (`r df5.T.basic$Nf` females; age = `r df5.T.basic$Age_mean` $\pm$ `r df5.T.basic$Age_sd`). All participants were right-handed, and all had normal or corrected-to-normal vision. Informed consent was obtained from all participants prior to the experiment according to procedures approved by the local ethics committee. The data from 5 participants were excluded from analysis, `r length(df5.nQuit)` participant didn’t finished the experiment, and the other `r nrow(df5.excld.sub)` were exclued because of the overall accuracy was less than 60%. The results for the remaining `r df5.v.basic$N` subjects (`r df5.v.basic$Nf` female, age = `r df5.v.basic$Age_mean` $\pm$ `r df5.v.basic$Age_sd`) were included in data analyses.

### Experimental design
A 4 × 3 × 2 within-subject design was used. The first independent variable was stimuli categories (morality, atttractiveness of people, attractiveness of scene, and emotional words); the second independent variables is valence (positive, neutral and negative); the third variable was the matching between shape and label (match vs. mismatch for the association). The task was to learn  the association between each geometric shape and the self/other label.

### Stimuli
4 sets of shapes were included (three circle, three rectangle, three kind of triangle, and three kinds of  quadrangle), each set of shape were paired with one category of label, counter-balanced across subjects. Besides the behavioral experiments, participants also finished questionnaires XXXXXXXX.

### Procedure
Participants finish 4 session of experiment, and each include one experiment as in experiment 1. And the order of each category was randomnized for each participants. Each session started with a practice, and proceed to formal experiment when reached over 60% accuracy. Each session included 6 blocks of trial, each with 120 trials. 

## Results

```{r 'ex5-dprime-rt', fig.cap="RT and *d* prime of Experiment 5.", fig.height=6, fig.width=15, warning=FALSE}

P.dprime <- ggplot(df5.v.dprime_l,aes(x = taskType, y = dprime, fill = Valence)) +
                geom_flat_violin(aes(fill = Valence),position = position_nudge(x = 0.1, y = 0),
                                 adjust = 1.5, trim = FALSE, alpha = 0.5,color = NA) +
                geom_dotplot(aes(x = taskType, y = dprime, color = Valence), 
                             binaxis='y', binwidth = 0.01, stackdir='center', dotsize= 5.5,
                             position = position_dodge(0.2)) +
                geom_boxplot(aes(x = taskType,  y = dprime, fill = Valence), 
                             outlier.shape = NA, alpha = 0.5, width = 0.1,  color = 'black',
                             position = position_dodge(0.2)) + 
                scale_color_brewer(palette = "Dark2") +
                scale_fill_brewer(palette = "Dark2") +
                ylab(expression(paste(italic("d"), " prime"))) +
               # scale_x_discrete(breaks = c(1,2),labels = c("Good","Bad")) +
                scale_y_continuous(expand = c(0, 0), limits = c(-1,5)) +
                apatheme
          
          
P.rt <- ggplot(df5.v.rt_m,aes(x = taskType , y = RT_m, fill = Valence))+
      geom_flat_violin(aes(fill = Valence),position = position_nudge(x = 0.1, y = 0),
                       adjust = 1.5, trim = FALSE, alpha = 0.5,color = NA) +
      #geom_point(aes(x = as.numeric(Morality)-0.15,y = RT, color = Identity), 
      #           position = position_jitter(width = 0.02),size = 1, shape = 20)+
      geom_dotplot(aes(x = taskType,y = RT_m, color = Valence), 
                   binaxis='y', binwidth = 0.8, stackdir='center', dotsize= 8,
                   position = position_dodge(0.2)) + 
      geom_boxplot(aes(x = taskType,  y = RT_m,fill = Valence),outlier.shape = NA,
                   alpha = 0.5, width = 0.1,  color = "black",
                   position = position_dodge(0.2))+ 
      scale_color_brewer(palette = "Dark2")+
      scale_fill_brewer(palette = "Dark2")+
      ylab("Reaction Times")+
      #scale_x_discrete(breaks = c(1,2),labels = c("Good","Bad")) +
      scale_y_continuous(expand = c(0, 0),limits = c(300,1000))+
      apatheme
multiplot(P.rt,P.dprime,cols = 2)

```

Figure \@ref(fig:ex5-dprime-rt) shows *d* prime and reaction times of experiment 5.

### *d* prime
```{r analyzing for d prime_e5, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
# anova for d prime with 2*2 design
df5_dprime_anova <- afex::aov_ez('Subject','dprime',df5.v.dprime_l,  # using afex's function 
                                  within = c('taskType','Valence'))
df5_dprime_anova_apa <- df5_dprime_anova %>% papaja::apa_print.afex_aov()
#df4b_dprime_anova <- apa_print(df4b_dprime_anova)
```


```{r analyzing for d prime_e5_tasks, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
# calculating the dprime 
df5.v.dprime_M_anova <- df5.v.dprime_l %>%
  dplyr::filter(taskType == "Morality") %>%
  afex::aov_ez('Subject','dprime', ., within = c('Valence'))
df5_dprime_M_anova_apa <- df5.v.dprime_M_anova %>% papaja::apa_print.afex_aov()
post_hoc_5_d_m <- emmeans::emmeans(df5.v.dprime_M_anova,'Valence')
pairs(post_hoc_5_d_m)

df5.v.dprime_E_anova <- df5.v.dprime_l %>%
  dplyr::filter(taskType == "Emotion") %>%
  afex::aov_ez('Subject','dprime', ., within = c('Valence'))
df5_dprime_E_anova_apa <- df5.v.dprime_E_anova %>% papaja::apa_print.afex_aov()
post_hoc_5_d_e <- emmeans::emmeans(df5.v.dprime_E_anova,'Valence')
pairs(post_hoc_5_d_e)

df5.v.dprime_P_anova <- df5.v.dprime_l %>%
  dplyr::filter(taskType == "Person") %>%
  afex::aov_ez('Subject','dprime', ., within = c('Valence'))
df5_dprime_P_anova_apa <- df5.v.dprime_P_anova %>% papaja::apa_print.afex_aov()
post_hoc_5_d_p <- emmeans::emmeans(df5.v.dprime_P_anova,'Valence')
pairs(post_hoc_5_d_p)


df5.v.dprime_S_anova <- df5.v.dprime_l %>%
  dplyr::filter(taskType == "Scene") %>%
  afex::aov_ez('Subject','dprime', ., within = c('Valence'))
df5_dprime_S_anova_apa <- df5.v.dprime_S_anova %>% papaja::apa_print.afex_aov()

post_hoc_5_d_s <- emmeans::emmeans(df5.v.dprime_S_anova,'Valence')
pairs(post_hoc_5_d_s)

```

We conducted 4 (task type: morality, emotion, person, scene) by 3 (morlaity: good, neutral, bad) repeated measure ANOVA. The results revealed no effect of task type (`r df5_dprime_anova_apa$full$taskType`), but revealed effect of valence, `r df5_dprime_anova_apa$full$Valence`, and their interactions, `r df5_dprime_anova_apa$full$taskType_Valence`. 

We then conducted ANOVA separately for four different tasks. For the morality task, the valence effect `r df5_dprime_M_anova_apa$full$Valence`.

For emotion conditions, we found that main effect of valence `r df5_dprime_E_anova_apa$full$Valence`. Post-hoc comparison showed that good (2.13, s.e. = 0.161) was not different from neutral condition (2.10, se = 0.125), *t*(37) = 0.163, *p* = 0.9854, but both are higher than  than bad condition (1.79, se = 0.148) (neutral > bad, *t*(37) = 3.588, *p* = 0.0027; good > bad, *t*(37) = 2.62, *p* = 0.0332).

For the person appearance, the main effect of valence is significant, `r df5_dprime_P_anova_apa$full$Valence`. Post-hoc analysis found that good condition (2.4, se = 0.167) was higher than both neutral (1.71, se = 0.175, *t*(37) = 5.482, *p* < .0001) and bad (1.70, se = 0.182, *t*(37) = 6.365, *p* < .0001), but neutral and bad condition are not different (*t*(37) = 0.197, *p* =0.9788).

For scene appearance, the main effect of valence is significnat `r df5_dprime_S_anova_apa$full$Valence`. Post-hoc analysis revealed the same pattern as in person task: good condition (2.23, se = 0.156) is higher than both neutral (1.57, se = 0.178, *t*(37) =4.683, *p* = 0.0001) and bad (1.77, se = 0.148, *t*(37) = 3.414, *p* = 0.0044), but neutral and bad conditions are not different (*t*(37) = -1.893, *p* = 0.1549)


### Reaction time

As in previous experiment, we focused our analysis on the matched trials. We conducted 4 (task type: morality, emotion, beauty of person, beauty of scene) by 3 (Valence: good, neutral, bad) repeated measure ANOVA for matched trials only.
```{r 5_RT, echo=FALSE, results='hide', warning=FALSE, message=FALSE}

df5_RT_anova <- afex::aov_ez('Subject','RT_m',df5.v.rt_m, within = c("Matchness",'taskType','Valence')) # using afex's function

df5_RT_anova_apa <- df5_RT_anova %>% papaja::apa_print.afex_aov()

df5.v.rt_anova_m <- df5.v.rt_m %>%
  dplyr::filter(Matchness == "Match") %>%
  afex::aov_ez('Subject','RT_m', ., within = c('taskType','Valence'))
df5.v.rt_anova_m_apa <- df5.v.rt_anova_m %>% papaja::apa_print.afex_aov()
posthoc_5_rt_m <- emmeans::emmeans(df5.v.rt_anova_m, 'Valence', by = 'taskType')
pairs(posthoc_5_rt_m)

df5.v.rt_anova_m_M <- df5.v.rt_m %>%
  dplyr::filter(Matchness == "Match" & taskType == "Morality") %>%     # task = morality
  afex::aov_ez('Subject','RT_m', ., within = c('Valence'))
df5.v.rt_anova_m_M_apa <- df5.v.rt_anova_m_M %>% papaja::apa_print.afex_aov()

df5.v.rt_anova_m_E <- df5.v.rt_m %>%
  dplyr::filter(Matchness == "Match" & taskType == "Emotion") %>%     # task = emotion
  afex::aov_ez('Subject','RT_m', ., within = c('Valence'))
df5.v.rt_anova_m_E_apa <- df5.v.rt_anova_m_E %>% papaja::apa_print.afex_aov()

df5.v.rt_anova_m_P <- df5.v.rt_m %>%
  dplyr::filter(Matchness == "Match" & taskType == "Person") %>%     # task = person
  afex::aov_ez('Subject','RT_m', ., within = c('Valence'))
df5.v.rt_anova_m_P_apa <- df5.v.rt_anova_m_P %>% papaja::apa_print.afex_aov()

df5.v.rt_anova_m_S <- df5.v.rt_m %>%
  dplyr::filter(Matchness == "Match" & taskType == "Scene") %>%     # task = scene
  afex::aov_ez('Subject','RT_m', ., within = c('Valence'))
df5.v.rt_anova_m_S_apa <- df5.v.rt_anova_m_S %>% papaja::apa_print.afex_aov()

df5.v.rt_anova_nm <- df5.v.rt_m %>%
  dplyr::filter(Matchness == "Mismatch") %>%
  afex::aov_ez('Subject','RT_m', ., within = c('taskType','Valence'))

df5.v.rt_anova_nm_M <- df5.v.rt_m %>%
  dplyr::filter(Matchness == "Mismatch" & taskType == "Morality") %>%     # task = morality
  afex::aov_ez('Subject','RT_m', ., within = c('Valence'))

df5.v.rt_anova_nm_E <- df5.v.rt_m %>%
  dplyr::filter(Matchness == "Mismatch" & taskType == "Emotion") %>%     # task = emotion
  afex::aov_ez('Subject','RT_m', ., within = c('Valence'))

df5.v.rt_anova_nm_P <- df5.v.rt_m %>%
  dplyr::filter(Matchness == "Mismatch" & taskType == "Person") %>%     # task = person
  afex::aov_ez('Subject','RT_m', ., within = c('Valence'))
posthoc_5_rt_nm_P <- emmeans::emmeans(df5.v.rt_anova_nm_P, 'Valence')
pairs(posthoc_5_rt_nm_P)

df5.v.rt_anova_nm_S <- df5.v.rt_m %>%
  dplyr::filter(Matchness == "Mismatch" & taskType == "Scene") %>%     # task = scene
  afex::aov_ez('Subject','RT_m', ., within = c('Valence'))
posthoc_5_rt_nm_S <- emmeans::emmeans(df5.v.rt_anova_nm_S, 'Valence')
pairs(posthoc_5_rt_nm_S)
```
We din't found the main effect of task type (`r df5.v.rt_anova_m_apa$full$taskType`), but the main effect of valence (`r df5.v.rt_anova_m_apa$full$Valence`), and intercation between Matchness and Valence (`r df5.v.rt_anova_m_apa$full$taskType_Valence`). We then analyze the effect of valence for each task type. We found that for all four task, the valence effect was significant: morality (`r df5.v.rt_anova_m_M_apa$full$Valence`), emotion (`r df5.v.rt_anova_m_E_apa$full$Valence`), person (`r df5.v.rt_anova_m_P_apa$full$Valence`), scene (`r df5.v.rt_anova_m_S_apa$full$Valence`). Post-hoc analyses revealed that for emotion task, the good condition is reacted faster than bad condition (*t*(37) = 3.475, *p* = 0.0037) but not neutral conditions are not different ((*t*(37) = -0.77, *p* = 0.7236)). The bad condiiton is longer than the neutral (*t*(37) = 5.09, *p* < 0.0001). The pattern is different for morality, person, and scence tasks, which showed that good is faster than both neutral ((*ts*(37) = [-7.289 -2.4], *ps* < 0.0548)) and bad (*ts*(37) = [-7.232 -3.817], *ps* < 0.0014).

## Discussion
Morality is not specific but reflected an general positive effect. However, this positive effect might not same as the emotion effect.

# Experiment 6a: EEG study 1
Experiment 6a was conducted to study the neural correlates of the positive prioritization effect. The behavioral paradigm is same as experiment 2. 

## Method
```{r loadingData_6a,echo=FALSE,results='hide', eval = FALSE}
df6a <- read.csv(file.path(".", "exp6a_erp1", "rawdata_erp_exp6a_2014.csv"), 
                 header = TRUE, sep = ",",
                 stringsAsFactors=FALSE,na.strings=c("","NA")) %>%
  dplyr::filter(!is.na(BlockList.Sample)) %>%                                                   # select only form exp
  dplyr::rename(BlockNo = BlockList.Sample,
                TrialNo = SubTrial,
                Matchness = YesNoResp, 
                Valence = Shape,
                ACC = Target.ACC, 
                CRESP = Target.CRESP,                   # rename the columns
                RESP = Target.RESP, RT = Target.RT) %>%    #
  dplyr::mutate(Valence = ifelse(Valence == "Normal", "Neutral", Valence),                   # re-code the data
                Matchness = ifelse(Matchness == "Yes", "Match", "Mismatch"),
                Age = ifelse(Age == 0, NA, Age)) %>%
  dplyr::mutate(Site = "THU",
                #ExpID = "Exp6a",        # add experiment id
                #Domain = "Morality",    # add domain as morality (to be comparable with experiment 5)
                #Identity = NA,
                Subject = Subject + 6100) # here started with 61XX instead of 60XX, which is the id for anther project.

#df6a_meta <- df6a %>% dplyr::select(CommonColnames)
# show the number of trials for each condition
# df6a_trials <- df6a %>%
#   dplyr::group_by(Subject, Matchness, Valence) %>%
#   dplyr::summarise(N_trial = length(TrialNo)) %>%
#   dplyr::ungroup()

df6a.T.basic     <- df6a %>%
  dplyr::select(Site, Subject, Age, Sex) %>%
  dplyr::distinct(Subject, .keep_all = TRUE) %>%
  dplyr::summarise(N = length(Subject),
                   N_thu = length(Site[Site == "THU"]),
                   N_wzu = length(Site[Site == "WZU"]),
                   Nf = length(Sex[Sex == "female"]),
                   Nm = length(Sex[Sex == "male"]),
                   Age_mean = round(mean(Age,na.rm=TRUE),2),
                   Age_sd = round(sd(Age,na.rm=TRUE),2))
  
# participants should be excluded
df6a.excld.sub <-  df6a %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::group_by(Subject) %>%
  #dplyr::mutate(ACC = ifelse(RT <= 200, 0, ACC)) %>%  # set less than 200 ms response as wrong
  dplyr::summarise(N = length(ACC),                   # caculate the overall accuracy for each subject
                   N_crrct = sum(ACC),
                   ACC = sum(ACC)/length(ACC)) %>%
  dplyr::filter(ACC < 0.6) %>%                        # exlucde the participants with less than 60% overall accuracy
  dplyr::select(Subject)

# The rate of excluded trials in valid data
df6a.invalid_trial_rate   <- df6a %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::filter(!(Subject %in% df6a.excld.sub$Subject)) %>%   # exclude the invalid subjects
  dplyr::summarize(rate = length(RT[RT <= 200 & ACC == 1])/length(RT)) %>%
  dplyr::pull()

df6a.v   <- df6a %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::filter(!(Subject %in% df6a.excld.sub$Subject)) %>%   # exclude the invalid subjects
  dplyr::filter(!(RT <= 200 & ACC == 1))                      # exclude < 200 trials

df6a.v.basic     <- df6a.v %>%
  dplyr::select(Site, Subject, Age, Sex) %>%
  dplyr::distinct(Subject, .keep_all = TRUE) %>%
  dplyr::summarise(N = length(Subject),
                   N_thu = length(Site[Site == "THU"]),
                   N_wzu = length(Site[Site == "WZU"]),
                   Nf = length(Sex[Sex == "female"]),
                   Nm = length(Sex[Sex == "male"]),
                   Age_mean = round(mean(Age,na.rm=TRUE),2),
                   Age_sd = round(sd(Age,na.rm=TRUE),2))

# calculating the dprime 
df6a.v.dprime_l <- df6a.v %>%
  dplyr::mutate(sdt = mosaic::derivedFactor("hit" = (ACC ==1 & Matchness == "Match"), # code as hit
                                    "CR" = (ACC ==1  & Matchness == "Mismatch"),      # correct reject
                                    "miss" = (ACC == 0 & Matchness == "Match"),       # miss
                                    "FA" = (ACC == 0 & Matchness == "Mismatch"),      # false alarm
                                    .method ="first",  .default = NA)) %>% 
  dplyr::group_by(Site, Subject, Age, Sex, Valence, sdt) %>%
  dplyr::summarise(N = length(sdt)) %>%                                    # calculate the counts for each 
  dplyr::ungroup() %>%
  tidyr::spread(key = sdt, value = N,fill = 0) %>%                          # long-to-wide format
  dplyr::mutate(hitR = hit/(hit + miss),                                    # hit rate
                FAR  = FA/(FA+CR)) %>%                                      # fa rate
  dplyr::mutate(hitR = ifelse(hitR == 1, 1 - 1/(2*(hit + miss)), hitR),     # if hit rate is 1, standardize it
                FAR  = ifelse(FAR == 0, 1/(2*(hit + miss)), FAR)) %>%       # if FA rate is 0, standardize it
  dplyr::mutate(dprime = qnorm(hitR) - qnorm(FAR)) %>%
  dplyr::select(Site, Subject, Age, Sex, Valence, dprime) %>%   # select relevant columns
  dplyr::mutate(Valence = factor(Valence, levels = c("Good","Neutral","Bad")))

# Mean RT for each condition of each participant.
df6a.v.rt_m <- df6a.v %>%
  dplyr::filter(ACC == 1) %>%
  dplyr::group_by(Site,Subject, Age, Sex, Matchness, Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup()

### prepare for the later meta-analysis
df6a.meta.d <- df6a.v.dprime_l %>% 
  dplyr::mutate(ExpID = 'Exp6a',
                Domain = "Morality",
                Identity = NA) %>%        # add domain as morality, to be comparable with experiment 5.
  dplyr::select(CommonColnames_d)

df6a.meta.rt <- df6a.v.rt_m %>% 
  dplyr::rename(RT = RT_m) %>%
  dplyr::mutate(ExpID = 'Exp6a',
                Domain = "Morality",
                Identity = NA) %>%        # add domain as morality, to be comparable with experiment 5.
  dplyr::select(CommonColnames_rt)

```

### Participants
`r df6a.T.basic$N` college students (`r df6a.T.basic$Nf` female, age = `r df6a.T.basic$Age_mean` $\pm$ `r df6a.T.basic$Age_sd`) participated the current study, all of them were from Tsinghua Universtiy in 2014. Informed consent was obtained from all participants prior to the experiment according to procedures approved by a local ethics committee. No participant was excluded from behavioral analysis.

### Experimental design
The experimental design of this experiment is same as experiment 2:  a 3 × 2 within-subject design with moral valence (good, neutral and bad associations) and matchness between shape and label (match vs. mismatch for the personal association) as within-subject variables. 

### Stimuli
Three geometric shapes (triangle, square and circle, each 4.6º × 4.6º of visual angle) were presented at the center of screen for 50 ms after 500ms of fixation (0.8º × 0.8º of visual angle). The association of the three shapes to bad person (“坏人, HuaiRen”), good person (“好人, HaoRen”) or ordinary  person (“常人, ChangRen”) was counterbalanced across participants. The words bad person, good person or ordinary  person (3.6º × 1.6º) was also displayed at the center fo the screen. Participants had to judge whether the pairings of label and shape matched (e.g., Does the circle represent a bad person?). The experiment was run on a PC using E-prime software (version 2.0). These stimuli were displayed on a 22-in CRT monitor (1024×768 at 100Hz).
We used backward masking to avoid over-processing of the moral words, in which a scrabmled picture were presented for 900 ms after the label. Also, to avoid the celling effect on accruacy, shapes were presented on a noisy background based on our pilot studies. The noisy images were made by scrambling a picutre of 3/4gray and ¼ white at resoluation of 2 × 2 pixel. 

### Procedure
The procedure was similar to Experiment 2. Participants finished 9 blocks of trial, each with 120 trials. In total, participants finished 180 trials for each combination of condition.

As in experiment 2 (Sui, He, & Humphreys, 2012), subjects first learned the associations between labels and shapes and then completed a shape-label matching task (e.g., good person-triangle). In each trial of the matching task, a fixation were first presented for 500 ms, followed by a 50 ms label; then, a scramled picture presented 900 ms. After the backward mask, the shape were presented on a noisy background for 50ms. Participant have to response in 1000ms after the presentation of the shape, and finnally, a feedback screen was presented for 500 ms (see figure 1). The inter-trial interval (ITI) were randomly varied at the range of 1000 ~ 1400 ms. 

All the stimuli were presented on a gray background (RGB: 127, 127, 127). E-primed 2.0 was used to present stimuli and collect behavioral results. Data were collected and analyzed when accuracy performance in total reached 60%. 

## Results

```{r 'ex6a-dprime-rt', fig.cap="RT and *d* prime of Experiment 6a.", fig.height=6, fig.width=15, warning=FALSE}
rtdata <- df6a.v.rt_m %>% dplyr::filter(Matchness == "Match") %>% dplyr::rename(RT = RT_m)

Mplots(expName = 'exp6a', df6a.v.dprime_l,rtdata)

```

Only the behavioral results were reported here. Figure \@ref(fig:ex6a-dprime-rt) shows *d* prime and reaction times of experiment 6a.

### *d* prime
```{r analyzing for d prime_e6a, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
# anova for d prime with 2*2 design
df6a_dprime_anova <- afex::aov_ez('Subject','dprime',df6a.v.dprime_l,  # using afex's function 
                                  within = c('Valence'))
df6a_dprime_anova_apa <- df6a_dprime_anova %>% papaja::apa_print.afex_aov()

posthoc_6a_d <- lsmeans::lsmeans(df6a_dprime_anova, specs = 'Valence')
graphics::pairs(posthoc_6a_d)
# plot(posthoc_5a_d, comparisons = TRUE)
```
We conducted repeated measures ANOVA, with moral valence as independent variable. The results revealed the main effect of valence (`r df6a_dprime_anova_apa$full$Valence`). Post-hoc anlaysis revealed that shapes link with Good person (mean = 3.13, SE = 0.109) is greater than Neutral condition (mean = 2.88, SE = 0.14),*t* = 2.916, *df* = 24, *p* = 0.02, p-value adjusted by Tukey method, but the *d* prime between Good and bad (mean = 3.03, SE = 0.142) (*t* = 1.512, *df* = 24, *p* = 0.3034, p-value adjusted by Tukey method), bad and neutral (*t* = 1.599, *df* = 24, *p* = 0.2655, p-value adjusted by Tukey method) were not siginificant.

### Analaysis of reaction time.
The results of reaction times of matchness trials showed similiar pattern as the *d* prime data.
```{r 6a_RT, echo=FALSE, results='hide', warning=FALSE, message=FALSE}

df6a_RT_anova <- afex::aov_ez('Subject','RT_m',df6a.v.rt_m,     # using afex's function 
                                  within = c('Matchness','Valence'))
df6a_RT_anova_apa <- df6a_RT_anova %>% papaja::apa_print.afex_aov()

# match trials
df6a.v.rt_m1 <- df6a.v %>%
  dplyr::filter(ACC == 1 & Matchness == "Match") %>%
  dplyr::group_by(Site,Subject,Matchness, Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup() %>%
  dplyr::mutate(Valence = factor(Valence, levels = c("Good","Neutral","Bad")))

df6a_RT_anova_m <- afex::aov_ez('Subject','RT_m',df6a.v.rt_m1,     # using afex's function 
                                  within = c('Valence'))
df6a_RT_anova_m_apa <- df6a_RT_anova_m %>% papaja::apa_print.afex_aov()

posthoc_6a_rt <- emmeans::emmeans(df6a_RT_anova_m, "Valence") # compare each valence for both self and other condition
# pairs(posthoc_6a_rt)

# Mismatch trials
df6a.v.rt_m2 <- df6a.v %>%
  dplyr::filter(ACC == 1 & Matchness == "Mismatch") %>%
  dplyr::group_by(Site,Subject,Matchness, Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup()

df6a_RT_anova_nm <- afex::aov_ez('Subject','RT_m', df6a.v.rt_m2,     # using afex's function 
                                  within = c('Valence'))
df6a_RT_anova_nm_apa <- df6a_RT_anova_nm %>% papaja::apa_print.afex_aov()

```

We found intercation between Matchness and Valence (`r df6a_RT_anova_apa$full$Matchness_Valence`) and then analyzed the matched trials and mismatched trials separately, as in experiment 2. For matched trials, we found the effect of valence `r df6a_RT_anova_m_apa$full$Valence`. For non-matched trials, there was no significant effect of Valence (`r df6a_RT_anova_nm_apa$full$Valence`). Post-hoc *t*-tests revealed that shapes associated with Good Person (mean = 550, SE = 13.8) were responded faster than Neutral-Person (501, SE = 14.7), (*t*(24) = -5.171, *p* = 0.0001) and Bad Person (523, SE = 16.3), *t*(24) = -8.137, *p* < 0.0001)., and Neutral is faster than Bad-Person condition (*t*(32) = -3.282, *p* = 0.0085).


# Experiment 6b: EEG study 2
Experiment 6b was conducted to study the neural correlates of the prioritization effect of positive self, i.e., the neural underlying of the behavioral effect found int experiment 3a. However, as in experiment 5a, the procedure of this experiment was modified to adopted to ERP experiment. 

## Method
```{r loadingData_6b,echo=FALSE,results='hide', eval = FALSE}
df6b_d1 <- read.csv(file.path(".", "exp6b_erp2", "rawdata_erp_exp6b_d1_2016.csv"), 
                    header = TRUE, sep = ",",
                    stringsAsFactors=FALSE,na.strings=c("","NA")) %>%
  dplyr::filter(!is.na(BlockList.Sample)) %>%                                                   # select only form exp
  dplyr::rename(BlockNo = BlockList.Sample,
                TrialNo = SubTrial,
                Matchness = YesNoResp,
                Identity = identity,
                Valence = morality,
                ACC = Target.ACC, 
                CRESP = Target.CRESP,                   # rename the columns
                RESP = Target.RESP, RT = Target.RT) %>%    #
  dplyr::mutate(Identity = ifelse(Identity == "self" | Identity == 'Self', "Self", 'Other'),                   # re-code the data
                Valence = derivedFactor("Bad" = (Valence == "bad"), 
                                        "Good" = (Valence == "good"), 
                                        "Neutral" = (Valence == "normal"), 
                                        .method ="first", .default = NA),
                Matchness = ifelse(Matchness == "Yes", "Match", "Mismatch"),
                Age = ifelse(Age == 0, NA, Age)) %>%
  dplyr::mutate(Site = "THU")

#df6b_meta <- df6b_d1 %>%
#  dplyr::mutate(ExpID = "Exp6b",
#                Domain = "Morality") %>%
#  dplyr::select(CommonColnames)

df6b_d2 <- read.csv(file.path(".", "exp6b_erp2", "rawdata_erp_exp6b_d2_2016.csv"), 
                    header = TRUE, sep = ",",
                    stringsAsFactors=FALSE,na.strings=c("","NA")) %>%
  dplyr::filter(!is.na(BlockList.Sample)) %>%                                                   # select only form exp
  dplyr::rename(BlockNo = BlockList.Sample,
                TrialNo = SubTrial,
                Matchness = YesNoResp,
                Identity = identity,
                Valence = morality,
                ACC = Target.ACC, 
                CRESP = Target.CRESP,                   # rename the columns
                RESP = Target.RESP, RT = Target.RT) %>%    #
  dplyr::mutate(Identity = ifelse(Identity == "self" | Identity == 'Self', "Self", 'Other'),                   # re-code the data
                Valence = derivedFactor("Bad" = (Valence == "bad"), 
                                        "Good" = (Valence == "good"), 
                                        "Neutral" = (Valence == "normal"), 
                                        .method ="first", .default = NA),
                Matchness = ifelse(Matchness == "Yes", "Match", "Mismatch"),
                Age = ifelse(Age == 0, NA, Age)) %>%
  dplyr::mutate(Site = "THU")


df6b_d1.T.basic     <- df6b_d1 %>%
  dplyr::select(Site, Subject, Age, Sex) %>%
  dplyr::distinct(Subject, .keep_all = TRUE) %>%
  dplyr::summarise(N = length(Subject),
                   N_thu = length(Site[Site == "THU"]),
                   N_wzu = length(Site[Site == "WZU"]),
                   Nf = length(Sex[Sex == "female"]),
                   Nm = length(Sex[Sex == "male"]),
                   Age_mean = round(mean(Age,na.rm=TRUE),2),
                   Age_sd = round(sd(Age,na.rm=TRUE),2))

df6b_d2.T.basic     <- df6b_d2 %>%
  dplyr::select(Site, Subject, Age, Sex) %>%
  dplyr::distinct(Subject, .keep_all = TRUE) %>%
  dplyr::summarise(N = length(Subject),
                   N_thu = length(Site[Site == "THU"]),
                   N_wzu = length(Site[Site == "WZU"]),
                   Nf = length(Sex[Sex == "female"]),
                   Nm = length(Sex[Sex == "male"]),
                   Age_mean = round(mean(Age,na.rm=TRUE),2),
                   Age_sd = round(sd(Age,na.rm=TRUE),2))
  
# participants should be excluded
df6b_d1.excld.sub <-  df6b_d1 %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::group_by(Subject) %>%
  #dplyr::mutate(ACC = ifelse(RT <= 200, 0, ACC)) %>%  # set less than 200 ms response as wrong
  dplyr::summarise(N = length(ACC),                   # caculate the overall accuracy for each subject
                   N_crrct = sum(ACC),
                   ACC = sum(ACC)/length(ACC)) %>%
  dplyr::filter(ACC < 0.6) %>%                        # exlucde the participants with less than 60% overall accuracy
  dplyr::select(Subject)

# The rate of excluded trials in valid data
df6b_d1.invalid_trial_rate   <- df6b_d1 %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::filter(!(Subject %in% df6b_d1.excld.sub$Subject)) %>%   # exclude the invalid subjects
  dplyr::summarize(rate = length(RT[RT <= 200 & ACC == 1])/length(RT)) %>%
  dplyr::pull()

df6b_d1.v   <- df6b_d1 %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::filter(!(Subject %in% df6b_d1.excld.sub$Subject)) %>%   # exclude the invalid subjects
  dplyr::filter(!(RT <= 200 & ACC == 1))                      # exclude < 200 trials

df6b_d1.v.basic     <- df6b_d1.v %>%
  dplyr::select(Site, Subject, Age, Sex) %>%
  dplyr::distinct(Subject, .keep_all = TRUE) %>%
  dplyr::summarise(N = length(Subject),
                   N_thu = length(Site[Site == "THU"]),
                   N_wzu = length(Site[Site == "WZU"]),
                   Nf = length(Sex[Sex == "female"]),
                   Nm = length(Sex[Sex == "male"]),
                   Age_mean = round(mean(Age,na.rm=TRUE),2),
                   Age_sd = round(sd(Age,na.rm=TRUE),2))

df6b_d2.excld.sub <-  df6b_d2 %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::group_by(Subject) %>%
  #dplyr::mutate(ACC = ifelse(RT <= 200, 0, ACC)) %>%  # set less than 200 ms response as wrong
  dplyr::summarise(N = length(ACC),                   # caculate the overall accuracy for each subject
                   N_crrct = sum(ACC),
                   ACC = sum(ACC)/length(ACC)) %>%
  dplyr::filter(ACC < 0.6) %>%                        # exlucde the participants with less than 60% overall accuracy
  dplyr::select(Subject)


df6b_d2.v   <- df6b_d2 %>%
  dplyr::filter(!is.na(BlockNo)) %>%
  dplyr::filter(!(Subject %in% df6b_d2.excld.sub$Subject)) %>%   # exclude the invalid subjects
  dplyr::filter(!(RT <= 200 & ACC == 1))                      # exclude < 200 trials

df6b_d2.v.basic     <- df6b_d2.v %>%
  dplyr::select(Site, Subject, Age, Sex) %>%
  dplyr::distinct(Subject, .keep_all = TRUE) %>%
  dplyr::summarise(N = length(Subject),
                   N_thu = length(Site[Site == "THU"]),
                   N_wzu = length(Site[Site == "WZU"]),
                   Nf = length(Sex[Sex == "female"]),
                   Nm = length(Sex[Sex == "male"]),
                   Age_mean = round(mean(Age,na.rm=TRUE),2),
                   Age_sd = round(sd(Age,na.rm=TRUE),2))

# calculate d prime
df6b_d1.v.dprime_l <- df6b_d1.v %>%
  dplyr::mutate(sdt = mosaic::derivedFactor("hit" = (ACC ==1 & Matchness == "Match"), # code as hit
                                    "CR" = (ACC ==1  & Matchness == "Mismatch"),      # correct reject
                                    "miss" = (ACC == 0 & Matchness == "Match"),       # miss
                                    "FA" = (ACC == 0 & Matchness == "Mismatch"),      # false alarm
                                    .method ="first",  .default = NA)) %>% 
  dplyr::group_by(Site, Subject, Age, Sex, Valence,Identity, sdt) %>%
  dplyr::summarise(N = length(sdt)) %>%                                     # calculate the counts for each 
  dplyr::ungroup() %>%
  tidyr::spread(key = sdt, value = N,fill = 0) %>%                          # long-to-wide format
  dplyr::mutate(hitR = hit/(hit + miss),                                    # hit rate
                FAR  = FA/(FA+CR)) %>%                                      # fa rate
  dplyr::mutate(hitR = ifelse(hitR == 1, 1 - 1/(2*(hit + miss)), hitR),     # if hit rate is 1, standardize it
                FAR  = ifelse(FAR == 0, 1/(2*(hit + miss)), FAR)) %>%       # if FA rate is 0, standardize it
  dplyr::mutate(dprime = qnorm(hitR) - qnorm(FAR)) %>%
  dplyr::select(Site, Subject, Age, Sex, Valence, Identity, dprime) %>%     # select relevant columns
  dplyr::mutate(Valence = factor(Valence, levels = c("Good","Neutral","Bad")),
                Identity = factor(Identity, levels = c('Self', 'Other')))

#  prepare the mean RT for each participant
df6b_d1.v.rt_m <- df6b_d1.v %>%
  dplyr::filter(ACC == 1) %>%
  dplyr::group_by(Site,Subject, Age, Sex, Matchness, Identity, Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup()

### prepare for the later meta-analysis
df6b.meta.d <- df6b_d1.v.dprime_l %>% 
  dplyr::mutate(ExpID = 'Exp6b',
                Domain = "Morality") %>%        # add domain as morality, to be comparable with experiment 5.
  dplyr::select(CommonColnames_d)

df6b.meta.rt <- df6b_d1.v.rt_m %>% 
  dplyr::rename(RT = RT_m) %>%
  dplyr::mutate(ExpID = 'Exp6b',
                Domain = "Morality") %>%        # add domain as morality, to be comparable with experiment 5.
  dplyr::select(CommonColnames_rt)

```

### Participants
`r df6b_d1.T.basic$N` college students (`r df6b_d1.T.basic$Nf` female, age = `r df6b_d1.T.basic$Age_mean` $\pm$ `r df6b_d1.T.basic$Age_sd`) participated the current study, all of them were recruited from Tsinghua Universtiy in 2016. Informed consent was obtained from all participants prior to the experiment according to procedures approved by a local ethics committee. For day 1's data, `r nrow(df6b_d1.excld.sub)` participant was excluded from the current analysis because of lower than 60% overall accuracy, remaining `r df6b_d1.v.basic$N` participants (`r df6b_d1.v.basic$Nf` female, age = `r df6b_d1.v.basic$Age_mean` $\pm$ `r df6b_d1.v.basic$Age_sd`). For day 2's data, one participant dropped out, leaving 22 participants  (`r df6b_d2.v.basic$Nf` female, age = `r df6b_d2.v.basic$Age_mean` $\pm$ `r df6b_d2.v.basic$Age_sd`), all of them has overall accuracy higher than 60%.

### Experimental design
The experimental design of this experiment is same as experiment 3:  a 2 × 3 × 2 within-subject design with self-relevance (self-relevant vs. other-relevant), moral valence (good, neutral, and bad) and matchness between shape and label (match vs. mismatch) as within-subject variables. 

### Stimuli
As in experiment 3a, 6 shapes were included (triangle, square, circle, trapezoid, diamond, regular pentagon), as well as 6 labels (good self, neutral self, bad self, good person, bad person, neutral person). To match the concreteness of the label, we asked participant to chosen an unfamiliar name of their own gender to be the stranger.

### Procedure
The procedure was similar to Experiment 2 and 6a. Subjects first learned the associations between labels and shapes and then completed a shape-label matching task. In each trial of the matching task, a fixation were first presented for 500 ms, followed by a 50 ms label; then, a scramled picture presented 900 ms. After the backward mask, the shape were presented on a noisy background for 50ms. Participant have to response in 1000ms after the presentation of the shape, and finnally, a feedback screen was presented for 500 ms (see figure 1). The inter-trial interval (ITI) were randomly varied at the range of 1000 ~ 1400 ms. 

All the stimuli were presented on a gray background (RGB: 127, 127, 127). E-primed 2.0 was used to present stimuli and collect behavioral results. Data were collected and analyzed when accuracy performance in total reached 60%. 

Because learning 6 associations was more difficult than 3 associations and participant might have low accuracy (see experiment 3a), the current study had extended to a two-day paradigm to maximizing the accurate trials that can be used in EEG data. At the first day, participants learnt the associations and finished 9 blocks of the matching task, each had 120 trials, without EEG recording. That is, each condition has 90 trials.

Participants came back to lab at the second day and finish the same task again, with EEG recorded. Before the EEG experiment, each participant finished a practice session again, if their accuracy is equal or higher than 85%, they start the experiment (one participant used lower threshold 75%). Each participant finished 18 blocks, each has 90 trials. One participant finished additional 6 blocks because of high error rate at the beginning, another two participant finished addition 3 blocks because of the technique failure in recording the EEG data. To increase the number of trials that can be used for EEG data analysis, matched trials has twice number as mismatched trials, therefore, for matched trials each participants finished 180 trials for each condition, for mismatched trials, each conditions has 90 trials.

## Results

```{r 'ex6b-d1-dprime-rt', fig.cap="RT and *d* prime of Experiment 6a.", fig.height=6, fig.width=15, warning=FALSE}

rtdata <- df6b_d1.v.rt_m %>% dplyr::filter(Matchness == "Match") %>% dplyr::rename(RT = RT_m)

Mplots(expName = 'exp6b_d1', df6b_d1.v.dprime_l,rtdata)

```

Only the behavioral results were reported here.
```{r 6b_dprime_d1, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
# anova for d prime
df6b_d1_dprime_anova <- afex::aov_ez('Subject','dprime',df6b_d1.v.dprime_l,  # using afex's function 
                                  within = c('Identity','Valence'))
df6b_d1_dprime_anova_apa <- df6b_d1_dprime_anova %>% papaja::apa_print.afex_aov()

# anova for self condition
df6b_d1_dprime_s_anova <- df6b_d1.v.dprime_l %>%
  dplyr::filter(Identity == "Self") %>%
  afex::aov_ez('Subject','dprime',., within = c('Valence'))

df6b_d1_dprime_s_anova_apa <- df6b_d1_dprime_s_anova %>% papaja::apa_print.afex_aov()

posthoc_6b_d1_s_d <- emmeans::emmeans(df6b_d1_dprime_s_anova, "Valence") # compare each valence for both self and other condition
#pairs(posthoc_6b_d1_s_d)

# anova for Other condition
df6b_d1_dprime_o_anova <- df6b_d1.v.dprime_l %>%
  dplyr::filter(Identity == "Other") %>%
  afex::aov_ez('Subject','dprime',., within = c('Valence'))

df6b_d1_dprime_o_anova_apa <- df6b_d1_dprime_o_anova %>% papaja::apa_print.afex_aov()
```
### Day one

Figure \@ref(fig:ex6b-d1-dprime-rt) shows *d* prime and reaction times from day 1 of the experiment 6b. 

#### *d* prime
There was evidence for the interaction between identity and valence, `r df6b_d1_dprime_anova_apa$full$Identity_Valence`. We further split the self- and other-relevant trials. For the self trials, there was significant effect of valence, `r df6b_d1_dprime_s_anova_apa$full$Valence`. Post-hoc comparison showed that the good-self condition (2.71, SE = 0.199) is better than both neutral-self (1.98, SE = 0.151), *t*(21) = 5.984, *p* < 0.001, and bad-self condition (2.07, SE = 0.154), *t*(21) = 6.555, *p* < 0.001. But there was no significant difference between bad-self and neutral-self, *t*(21) = -1.059, *p* = 0.549. For other trials, there was no significant effect of valuence, `r df6b_d1_dprime_o_anova_apa$full$Valence`.

```{r 6b_RT, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
df6b_d1_RT_anova <- afex::aov_ez('Subject','RT_m',df6b_d1.v.rt_m,     # using afex's function 
                                  within = c('Matchness','Identity','Valence'))
df6b_d1_RT_anova_apa <- df6b_d1_RT_anova %>% papaja::apa_print.afex_aov()

# Day 1: match trials
df6b_d1_RT_anova_m <- df6b_d1.v %>%
  dplyr::filter(ACC == 1 & Matchness == "Match") %>%
  dplyr::group_by(Site, Subject, Matchness, Identity, Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup() %>%
  dplyr::mutate(Valence = factor(Valence, levels = c("Good","Neutral","Bad")),
                Identity = factor(Identity, levels = c('Self', 'Other'))) %>%
  afex::aov_ez('Subject','RT_m', ., within = c('Identity','Valence'))
df6b_d1_RT_anova_m_apa <- df6b_d1_RT_anova_m %>% papaja::apa_print.afex_aov()

### For matched, self trials
df6b_d1_RT_anova_m_s <- df6b_d1.v %>%
  dplyr::filter(ACC == 1 & Matchness == "Match" & Identity == "Self") %>%
  dplyr::group_by(Site, Subject, Matchness, Identity, Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup() %>%
  dplyr::mutate(Valence = factor(Valence, levels = c("Good","Neutral","Bad"))) %>%
  afex::aov_ez('Subject','RT_m', ., within = c('Valence'))

df6b_d1_RT_anova_m_s_apa <- df6b_d1_RT_anova_m_s %>% papaja::apa_print.afex_aov()

posthoc_6b_d1_rt_s <- emmeans::emmeans(df6b_d1_RT_anova_m_s, 'Valence') # compare each valence for both self and other condition
# pairs(posthoc_6b_d1_rt_s)

### For matched, other trials
df6b_d1_RT_anova_m_o <- df6b_d1.v %>%
  dplyr::filter(ACC == 1 & Matchness == "Match" & Identity == "Other") %>%
  dplyr::group_by(Site, Subject, Matchness, Identity, Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup() %>%
  dplyr::mutate(Valence = factor(Valence, levels = c("Good","Neutral","Bad"))) %>%
  afex::aov_ez('Subject','RT_m', ., within = c('Valence'))
df6b_d1_RT_anova_m_o_apa <- df6b_d1_RT_anova_m_o %>% papaja::apa_print.afex_aov()

# Day1: Mismatch trials
df6b_d1_RT_anova_nm <- df6b_d1.v %>%
  dplyr::filter(ACC == 1 & Matchness == "Mismatch") %>%
  dplyr::group_by(Site,Subject,Matchness, Identity, Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup() %>%
  afex::aov_ez('Subject','RT_m', ., within = c('Identity','Valence'))
df6b_d1_RT_anova_nm_apa <- df6b_d1_RT_anova_nm %>% papaja::apa_print.afex_aov()
```

#### RT
For the matched trials, there was interaction between identity and valence, `r df6b_d1_RT_anova_m_apa$full$Identity_Valence`. We split the self-relevant and other relevant trials separately. For the self condition, the valence effect is significant, `r df6b_d1_RT_anova_m_s_apa$full$Valence`. The Self-good (484, SE = 13.2) is faster than self-neutral (543, SE = 16.7) , *t* = -4.521, *p* = 0.0005, *df* = 21 and self-bad condition (535, SE = 18.4),  *t* = -4.489, *p* = 0.0006, *df* = 21. but not significant different between neutral and bad condition, *t* = 0.689, *p* = 0.772, *df* = 21. For other condition, there was no effect of valence, `r df6b_d1_RT_anova_m_o_apa$full$Valence`. 


```{r 'ex6b-d2-dprime-rt', fig.cap="RT and *d* prime of Experiment 6b.", fig.height=6, fig.width=15, warning=FALSE}
# calculate d prime
df6b_d2.v.dprime_l <- df6b_d2.v %>%
  dplyr::mutate(sdt = mosaic::derivedFactor("hit" = (ACC ==1 & Matchness == "Match"), # code as hit
                                    "CR" = (ACC ==1  & Matchness == "Mismatch"),      # correct reject
                                    "miss" = (ACC == 0 & Matchness == "Match"),       # miss
                                    "FA" = (ACC == 0 & Matchness == "Mismatch"),      # false alarm
                                    .method ="first",  .default = NA)) %>% 
  dplyr::group_by(Site, Subject, Age, Sex, Valence,Identity, sdt) %>%
  dplyr::summarise(N = length(sdt)) %>%                                    # calculate the counts for each 
  dplyr::ungroup() %>%
  tidyr::spread(key = sdt, value = N,fill = 0) %>%                          # long-to-wide format
  dplyr::mutate(hitR = hit/(hit + miss),                                    # hit rate
                FAR  = FA/(FA+CR)) %>%                                      # fa rate
  dplyr::mutate(hitR = ifelse(hitR == 1, 1 - 1/(2*(hit + miss)), hitR),     # if hit rate is 1, standardize it
                FAR  = ifelse(FAR == 0, 1/(2*(hit + miss)), FAR)) %>%       # if FA rate is 0, standardize it
  dplyr::mutate(dprime = qnorm(hitR) - qnorm(FAR)) %>%
  dplyr::select(Site, Subject, Age, Sex, Valence, Identity, dprime) %>%     # select relevant columns
  dplyr::mutate(Valence = factor(Valence, levels = c("Good","Neutral","Bad")),
                Identity = factor(Identity, levels = c('Self', 'Other')))

# Day2: match trials
df6b_d2.v.rt_m1 <- df6b_d2.v %>%
  dplyr::filter(ACC == 1 & Matchness == "Match") %>%
  dplyr::group_by(Site, Subject, Matchness, Identity, Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup() %>%
  dplyr::mutate(Valence = factor(Valence, levels = c("Good","Neutral","Bad")),
                Identity = factor(Identity, levels = c('Self', 'Other')))

rtdata <- df6b_d2.v.rt_m1 %>% dplyr::filter(Matchness == "Match") %>% dplyr::rename(RT = RT_m)

Mplots(expName = 'exp6b_d2', df6b_d2.v.dprime_l,rtdata)

```

### Day two

Figure \@ref(fig:ex6b-d2-dprime-rt) shows *d* prime and reaction times from day 2 of the experiment 6b. 


```{r 5b_dprime_d2, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
df6b_d2_dprime_anova <- afex::aov_ez('Subject','dprime',df6b_d2.v.dprime_l,  # using afex's function 
                                  within = c('Identity','Valence'))
df6b_d2_dprime_anova_apa <- df6b_d2_dprime_anova %>% papaja::apa_print.afex_aov()
#posthoc_5b_d2_d <- emmeans::emmeans(df6b_d1_dprime_anova, "Valence") # compare each valence for both self and other condition
#pairs(posthoc_5b_d2_d)

# anova for self condition
df6b_d2_dprime_s_anova <- df6b_d2.v.dprime_l %>%
  dplyr::filter(Identity == "Self") %>%
  afex::aov_ez('Subject','dprime',., within = c('Valence'))

df6b_d2_dprime_s_anova_apa <- df6b_d2_dprime_s_anova %>% papaja::apa_print.afex_aov()

posthoc_5b_d2_s_d <- emmeans::emmeans(df6b_d2_dprime_s_anova, "Valence") # compare each valence for both self and other condition
#pairs(posthoc_5b_d2_s_d)

# anova for Other condition
df6b_d2_dprime_o_anova <- df6b_d2.v.dprime_l %>%
  dplyr::filter(Identity == "Other") %>%
  afex::aov_ez('Subject','dprime',., within = c('Valence'))

df6b_d2_dprime_o_anova_apa <- df6b_d2_dprime_o_anova %>% papaja::apa_print.afex_aov()

```
#### *d* prime
There was evidence for the interaction between identity and valence, `r df6b_d2_dprime_anova_apa$full$Identity_Valence`.  We further split the self- and other-relevant trials. For the self trials, there was significant effect of valence, `r df6b_d2_dprime_s_anova_apa$full$Valence`. Post-hoc comparison showed that the good-self condition (2.71, SE = 0.214) is better than both neutral-self (2.43, SE = 0.175), *t*(21) = 2.98, *p* = 0.0189, and bad-self condition (2.43, SE = 0.199), *t*(21) = 3.93, *p* = 0.0021. But there was no significant difference between bad-self and neutral-self, *t*(21) = -0.097, *p* = 0.995. For other trials, there was no significant effect of valuence, `r df6b_d2_dprime_o_anova_apa$full$Valence`.

```{r 5b_d2_RT_match, echo=FALSE, results='hide', warning=FALSE, message=FALSE}

df6b_d2.v.rt_m <- df6b_d2.v %>%
  dplyr::filter(ACC == 1) %>%
  dplyr::group_by(Site,Subject,Matchness, Identity, Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup()

df6b_d2_RT_anova <- afex::aov_ez('Subject','RT_m',df6b_d2.v.rt_m,     # using afex's function 
                                  within = c('Matchness','Identity','Valence'))
df6b_d2_RT_anova_apa <- df6b_d2_RT_anova %>% papaja::apa_print.afex_aov()


df6b_d2_RT_anova_m <- afex::aov_ez('Subject','RT_m',df6b_d2.v.rt_m1,     # using afex's function 
                                  within = c('Identity','Valence'))
df6b_d2_RT_anova_m_apa <- df6b_d2_RT_anova_m %>% papaja::apa_print.afex_aov()

posthoc_5b_d2_rt <- emmeans::emmeans(df6b_d2_RT_anova_m, c('Identity',"Valence")) # compare each valence for both self and other condition
# pairs(posthoc_5b_d2_rt)

df6b_d2_RT_anova_m_s <- df6b_d2.v %>%
  dplyr::filter(ACC == 1 & Matchness == "Match" & Identity == "Self") %>%
  dplyr::group_by(Site, Subject, Matchness, Identity, Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup() %>%
  dplyr::mutate(Valence = factor(Valence, levels = c("Good","Neutral","Bad"))) %>%
  afex::aov_ez('Subject','RT_m', ., within = c('Valence'))

df6b_d2_RT_anova_m_s_apa <- df6b_d2_RT_anova_m_s %>% papaja::apa_print.afex_aov()

posthoc_5b_d2_rt_s <- emmeans::emmeans(df6b_d2_RT_anova_m_s, 'Valence') # compare each valence for both self and other condition
# pairs(posthoc_5b_d2_rt_s)

### For matched, other trials
df6b_d2_RT_anova_m_o <- df6b_d2.v %>%
  dplyr::filter(ACC == 1 & Matchness == "Match" & Identity == "Other") %>%
  dplyr::group_by(Site, Subject, Matchness, Identity, Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup() %>%
  dplyr::mutate(Valence = factor(Valence, levels = c("Good","Neutral","Bad"))) %>%
  afex::aov_ez('Subject','RT_m', ., within = c('Valence'))

df6b_d2_RT_anova_m_o_apa <- df6b_d2_RT_anova_m_o %>% papaja::apa_print.afex_aov()

# Day2: Mismatch trials
df6b_d2_RT_anova_nm <- df6b_d2.v %>%
  dplyr::filter(ACC == 1 & Matchness == "Mismatch") %>%
  dplyr::group_by(Site,Subject,Matchness, Identity, Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup() %>%
  afex::aov_ez('Subject','RT_m', ., within = c('Identity','Valence'))
df6b_d2_RT_anova_nm_apa <- df6b_d2_RT_anova_nm %>% papaja::apa_print.afex_aov()
```

#### RT
For the matched trials, the interaction between identity and valence, `r df6b_d2_RT_anova_m_apa$full$Identity_Valence`. As in previous studies, we splited the self- and other-relevant trials. For the self condition, the valence effect is significant, `r df6b_d2_RT_anova_m_s_apa$full$Valence`. The Self-good (480, SE = 16.9) is faster than self-neutral (504, SE = 17.3) , *t* = -2.289, *p* = 0.0795, *df* = 21 and self-bad condition (508, SE = 17.9),  *t* = -4.342, *p* = 0.0008, *df* = 21. but not significant different between neutral and bad condition, *t* = -0.503, *p* = 0.871, *df* = 21. For other condition, there was no effect of valence, `r df6b_d2_RT_anova_m_o_apa$full$Valence`. 

\newpage

# References
```{r create_r-references}
papaja::r_refs(file = "r-references.bib")
```

\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

<div id = "refs"></div>
\endgroup
