## Experiment 1a 
### Methods
#### Participants
`r df1a.T.basic$N` college students (`r df1a.T.basic$Nf` female, age = `r df1a.T.basic$Age_mean` $\pm$ `r df1a.T.basic$Age_sd` years) participated. `r df1a.T.basic$N_thu` of them were recruited from Tsinghua University community in 2014; `r df1a.T.basic$N_wzu` were recruited from Wenzhou University in 2017. All participants were right-handed except one, and all had normal or corrected-to-normal vision. Informed consent was obtained from all participants prior to the experiment according to procedures approved by the local ethics committees. `r nrow(df1a.excld.sub)` participant’s data were excluded from analysis because nearly random level of accuracy, leaving `r df1a.v.basic$N` participants (`r df1a.v.basic$Nf` female, age = `r df1a.v.basic$Age_mean` $\pm$ `r df1a.v.basic$Age_sd` years).

#### Stimuli and Tasks
Three geometric shapes were used in this experiment: triangle, square, and circle. These shapes were paired with three labels (bad person, good person or neutral person). The pairs were counterbalanced across participants. 

#### Procedure
This experiment had two phases. First, there was a brief learning stage. Participants were asked to learn the relationship between geometric shapes (triangle, square, and circle) and different concepts of moral character (bad person, a good person, or a neutral person). For example, a participant was told, “bad person is a circle; good person is a triangle; and a neutral person is a square.” After participant remembered the associations (usually in a few minutes), participants started a practicing phase of matching task which has the exact task as in the experimental task. 

In the experimental task, participants judged whether shape–label pairs, which were subsequently presented, were correct (i.e., the same as they learned). Each trial started with the presentation of a central fixation cross for 500 ms. Subsequently, a pairing of a shape and label (good person, bad person, and neutral person) was presented for 100 ms. The pair presented could confirm to the verbal instruction for each pairing given in the training stage, or it could be a recombination of a shape with a different label, with the shape–label pairings being generated at random. The next frame showed a blank for 1100ms. Participants were expected to judge whether the shape was correctly assigned to the person by pressing one of the two response buttons as quickly and accurately as possible within this timeframe (to encourage immediate responding). Feedback (correct or incorrect) was given on the screen for 500 ms at the end of each trial, if no response detected, “too slow” was presented to remind participants to accelerate. Participants were informed of their overall accuracy at the end of each block. The practice phase finished and the experimental task began after the overall performance of accuracy during practice phase achieved 60%. 

For participants from the Tsinghua community, they completed 6 experimental blocks of 60 trials. Thus, there were 60 trials in each condition (bad-person match, bad-person nonmatch, good-person match, good-person nonmatch, neutral-person match, and neutral-person nonmatch). For the participants from Wenzhou University, they finished 6 blocks of 120 trials, therefore, 120 trials for each condition.

#### Data analysis
As described in general methods section, this experiment used three approaches to analyze the behavioral data: Classical NHST, Bayesian Hierarchical Generalized Linear Model, and Hierarchical drift diffusion model. 
 <!-- Shall I write more about HDDM here, or just refer the interested reader to the paper? -->

### Results

```{r 'ex1a-dprime-rt', fig.cap="RT and *d* prime of Experiment 1a.", fig.height=4.5, fig.width=9, warning=FALSE}
p_1a_d_rt <- Val_plot_NHST(df.rt = df1a.v.rt_m, df.d = df1a.v.dprime_l)
```

#### Classic NHST
##### *d* prime
Figure \@ref(fig:ex1a-dprime-rt) shows *d*' and reaction times during the perceptual matching task. We conducted a single factor (valence: good, neutral, bad) repeated measure ANOVA. 

```{r 1a_dprime_NHST, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
# anova for d prime with 2*2 design
df1a_dprime_anova <- afex::aov_ez('Subject','dprime',df1a.v.dprime_l, within = c('Valence'))
df1a_dprime_anova_apa <- df1a_dprime_anova %>% papaja::apa_print.afex_aov()

posthoc_1a_d <- emmeans::emmeans(df1a_dprime_anova, "Valence") # compare each valence for both self and other condition
#pairs(posthoc_1a_d)
```

```{r results='asis', echo = F, eval=F}
# knitr::kable(nice(df4b_dprime_anova), caption = "ANOVA of d prime")
papaja::apa_table(df1a_dprime_anova_apa$table
  , caption = "Repeated measure ANOVA of *d* prime from Experiment 1a"
  , note = "*d* prime was calculated in a signal detection way.")

```

We found the effect of Valence (`r df1a_dprime_anova_apa$full$Valence`). The post-hoc comparison with multiple comparison correction revealed that the shapes associated with Good-person (2.11, SE = 0.14) has greater *d* prime than shapes associated with Bad-person (1.75, SE = 0.14), *t*(50) = 3.304, *p* = 0.0049. The Good-person condition was also greater than the Neutral-person condition (1.95, SE = 0.16), but didn't reach statistical significant, *t*(50) = 1.54, *p* = 0.28. Neither the Neutral-person condition is significantly greater than the Bad-person condition, *t*(50) = 2.109, *p* = .098.

##### Reaction times
```{r 1a_RT_NHST, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
df1a_RT_anova <- afex::aov_ez('Subject','RT_m',df1a.v.rt_m, within = c('Matchness','Valence')) # using afex's function

df1a_RT_anova_apa <- df1a_RT_anova %>% papaja::apa_print.afex_aov()

df1a.v.rt_m1 <- df1a.v %>%
  dplyr::filter(ACC == 1 & Matchness == "Match") %>%
  dplyr::group_by(Site,Subject,Matchness, Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup() %>%
  dplyr::mutate(Valence = factor(Valence, levels = c("Good","Neutral","Bad")))

df1a_RT_anova_m <- afex::aov_ez('Subject','RT_m',df1a.v.rt_m1, within = c('Valence'))
df1a_RT_anova_m_apa <- df1a_RT_anova_m %>% papaja::apa_print.afex_aov()

df1a.v.rt_m2 <- df1a.v %>%
  dplyr::filter(ACC == 1 & Matchness == "Mismatch") %>%
  dplyr::group_by(Site,Subject,Matchness, Valence) %>%
  dplyr::summarise(RT_m = mean(RT),
                   Ntrial = length(RT)) %>%
  dplyr::ungroup()

df1a_RT_anova_nm <- afex::aov_ez('Subject','RT_m',df1a.v.rt_m2, within = c('Valence'))
df1a_RT_anova_nm_apa <- df1a_RT_anova_nm %>% papaja::apa_print.afex_aov()

posthoc_1a_rt <- emmeans::emmeans(df1a_RT_anova_m, "Valence") # compare each valence for both self and other condition
# pairs(posthoc_1a_rt)
```
We conducted 2 (Matchness: match v. nonmatch) by 3 (Valence: good, neutral, bad) repeated measure ANOVA. We found the main effect of Matchness (`r df1a_RT_anova_apa$full$Matchness`), main effect of valence (`r df1a_RT_anova_apa$full$Valence`), and interaction between Matchness and Valence (`r df1a_RT_anova_apa$full$Matchness_Valence`).

We then carried out two separate ANOVA for Match and Mismatched trials. For matched trials, we found the effect of valence `r df1a_RT_anova_m$full$Valence`. We further examined the effect of valence for both self and other for matched trials. We found that shapes associated with Good Person (684 ms, SE = 11.5) responded faster than Neutral (709 ms, SE = 11.5), *t*(50) = -2.265, *p* = 0.0702) and Bad Person (728 ms, SE = 11.7), *t*(50) = -4.41, *p* = 0.0002), and the Neutral condition was faster than the Bad condition, *t*(50) = -2.495, *p* = 0.0415). For non-matched trials, there was no significant effect of Valence (`r df1a_RT_anova_nm$full$Valence`).

#### Bayesian hierarchical GLM
##### d prime
```{r 1a_dprime_BGLM, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
exp1a_sdt_m1 <- fun_sdt_val('1a')

summary(exp1a_sdt_m1)    # check summary
# pp_check(exp1a_sdt_m1)  # posterior predictive check

hypothesis(exp1a_sdt_m1, "ValenceGood:ismatch > ValenceNeutral:ismatch")  # 0.97
hypothesis(exp1a_sdt_m1, "ValenceGood:ismatch > ValenceBad:ismatch")      # 1
hypothesis(exp1a_sdt_m1, "ValenceNeutral:ismatch > ValenceBad:ismatch")   # 0.91
hypothesis(exp1a_sdt_m1, "ValenceGood > ValenceNeutral")  # 0.82
hypothesis(exp1a_sdt_m1, "ValenceGood > ValenceBad")      # .95
hypothesis(exp1a_sdt_m1, "ValenceNeutral > ValenceBad")   # 0.81

# exp1a_sdt_p <- fun_plot_sdt_val(exp1a_sdt_m1)
exp1a_sdt_p <- exp1a_sdt_m1 %>%
  emmeans::emmeans( ~ ismatch | Valence) %>%
  tidybayes::gather_emmeans_draws() %>%
  dplyr::mutate(ismatch = ifelse(ismatch == 0, 'criterion', 'd prime'),
                ismatch = factor(ismatch, levels = c('d prime', 'criterion')),
                Valence = factor(Valence, levels = c('Good', 'Neutral',  'Bad'))) %>%
  ggplot2::ggplot(aes(x = Valence, y = .value)) +
  tidybayes::stat_halfeye() + # position=position_dodge(width = 0.1)
  stat_summary(aes(group = NA), fun.y = mean, geom = "line") +
  facet_grid(cols = vars(ismatch), scales = "free_y") +
  theme_classic()
```
We fitted a Bayesian hierarchical GLM for signal detection theory. The results showed that when the shapes were tagged with labels with different moral valence, the sensitivity ($d'$) and criteria ($c$) were both influenced. For the $d'$, we found that the shapes associated with good person (2.46, 95% CI[2.21 2.72]) is greater than shapes tagged with moral bad (2.07, 95% CI[1.83 2.32]), $P_{PosteriorComparison} = 1$. Shape tagged with morally good person is also greater than shapes tagged with neutral person (2.23, 95% CI[1.95 2.49]), $P_{PosteriorComparison} = 0.97$. Also, the shapes tagged with neutral person is greater than shapes tagged with morally bad person, $P_{PosteriorComparison} = 0.92$. 

Interesting, we also found the criteria for three conditions also differ, the shapes tagged with good person has the highest criteria (-1.01, [-1.14 -0.88]), followed by shapes tagged with neutral person(-1.06, [-1.21 -0.92]), and then the shapes tagged with bad person(-1.11, [-1.25 -0.97]). However, pair-wise comparison showed that only showed strong evidence for the difference between good and bad conditions.

##### Reaction times
```{r 1a_rt_BGLM, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
# fit a three-level hierarchical model for RT, didn't specify the prior
exp1a_rt_m1 <- fun_rt_val('1a')
#plot(exp1a_rt_m1, "b_")
summary(exp1a_rt_m1)  # n
# pp_check(exp1a_rt_m1)

# Population-Level Effects: 
#                    Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
# Intercept              -0.30      0.02    -0.33    -0.26 1.02      288      642  # baseline: mismatch:neutral = -.3
# ValenceBad              0.00      0.01    -0.01     0.01 1.00     3611     3116  # mismatch:neutral + mismatch:bad  = -.3
# ValenceGood             0.00      0.01    -0.01     0.01 1.00     2749     2691  # mismatch:neutral + mismatch:Good = -.3
# ismatch                -0.07      0.01    -0.09    -0.06 1.00     2203     2371  # mismatch:neutral + ismatch = (-0.30) + (-0.07) = -0.37
# ValenceBad:ismatch      0.02      0.01     0.00     0.05 1.00     2451     2495  # mismatch:neutral + ismatch + match:bad  = (-0.30) + (-0.07) + 0.02 = -0.35
# ValenceGood:ismatch    -0.04      0.02    -0.07    -0.01 1.00     1911     2326  # mismatch:neutral + ismatch + match:good = (-0.30) + (-0.07) +-0.04 = -0.41

hypothesis(exp1a_rt_m1, "ismatch < 0")  # Effect of matchness: Match < mis-match, p = 1
hypothesis(exp1a_rt_m1, "ValenceGood:ismatch < 0")  # Match good < Match Neutral, p = 0.99
hypothesis(exp1a_rt_m1, "ValenceBad:ismatch > 0")   # Match Bad > Match Neutral, p = 0.99
hypothesis(exp1a_rt_m1, "(ValenceGood:ismatch - ValenceBad:ismatch) < 0")   # Match Good < Match Bad, p = 1

#exp1a_rt_p <- fun_plot_rt_val(exp1a_rt_m1)
exp1a_rt_p <- exp1a_rt_m1 %>%
  emmeans::emmeans( ~ ismatch | Valence) %>%
  tidybayes::gather_emmeans_draws() %>%
  dplyr::mutate(ismatch = ifelse(ismatch == 0, 'nonmatch', 'match'),
              Valence = factor(Valence, levels = c('Good', 'Neutral',  'Bad'))) %>%
  dplyr::rename(log_RT = .value) %>%
  dplyr::mutate(`Reaction times (ms)` = exp(log_RT)*1000) %>%
  ggplot2::ggplot(aes(x = Valence, y = `Reaction times (ms)`)) +
  tidybayes::stat_halfeye() +
  ggplot2::stat_summary(aes(group = NA), fun.y = mean, geom = "line") +
  facet_grid(~ ismatch) +
  theme_classic()
```

```{r plot-exp1a-BGLM, fig.cap="Exp1a: Results of Bayesian GLM analysis.", fig.height=4.5, fig.width=9, warning=FALSE}
#library(patchwork)
#exp1a_rt_p + exp1a_sdt_p + plot_annotation(tag_levels = 'A')  + plot_layout(nrow = 1, byrow = FALSE)
```

We fitted a Bayesian hierarchical GLM for RTs, with a log-normal distribution as the link function. We used the posterior distribution of the regression coefficient to make statistical inferences. As in previous studies, the matched conditions are much faster than the mismatched trials ($P_{PosteriorComparison} = 1$). We focused on matched trials only, and compared different conditions: Good is faster than the neutral, $P_{PosteriorComparison} = .99$, it was also faster than the Bad condition, $P_{PosteriorComparison} = 1$. And the neutral condition is faster than the bad condition, $P_{PosteriorComparison} = .99$. However, the mismatched trials are largely overlapped. See Figure \@ref(fig:plot-exp1a-BGLM).

#### HDDM

```{r plot-exp1a-HDDM, fig.cap="Exp1a: Results of HDDM.",  fig.height=4.5, fig.width=9, warning=FALSE}
df1a.hddm.group.trace <- read_csv(here::here('HDDM','df1a_group_traces.csv'))

params_p <- df1a.hddm.group.trace %>%
  dplyr::mutate(sample = 1:nrow(.)) %>%
  dplyr::select(chain, sample, contains('Match') | contains('Mismatch')) %>%
  tidyr::pivot_longer(.,`a(Match.Bad)`:`t(Mismatch.Neutral)`, names_to = 'conditions', values_to = 'value') %>%
  tidyr::separate(., conditions, into = c('v1', 'valence'), sep= '[.]') %>%       # split into two part
  tidyr::separate(., v1, into = c('param', 'matchness'), sep = '[(]') %>%         # further split the first half into two part
  dplyr::mutate(valence = stringr::str_sub(.$valence, start = 1, end = -2)) %>%   # remove the last two elements ') ' from the strings
  dplyr::arrange(., param) %>%
  tidyr::pivot_wider(., id_cols = c('chain', 'sample', 'matchness', 'valence'), names_from = 'param', values_from = 'value')

p_1a_hddm <- params_p %>% 
  dplyr::mutate(valence = factor(valence, levels = c("Good", "Neutral", "Bad")),
                matchness = ifelse(matchness == 'Mismatch', 'Nonmatch', matchness)) %>%
  ggplot2::ggplot(., aes(x = v, y = a, group = valence, color = valence)) +
  geom_point() + 
  scale_colour_brewer(palette = "Dark2") +
  scale_fill_brewer(palette = "Dark2") +
  facet_grid(~ matchness) +
  ylab(expression(paste("Boundary separation ",italic("a"), sep = ' '))) +
  xlab(expression(paste("Drift rate ",italic("v"), sep = ' '))) +
  theme_bw()+
    theme(panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          panel.background = element_blank(),
          panel.border = element_blank(),
          text=element_text(family='Times'),
          legend.title=element_blank(),
          legend.text = element_text(size =8),
          plot.title = element_text(lineheight=.8, face="bold", size = 9, margin=margin(0,0,10,0)),
          axis.text = element_text (size = 8, color = 'black'),
          axis.title = element_text (size = 8),
          #axis.title.x = element_blank(),
          #axis.title.y = element_blank(),
          axis.line.x = element_line(color='black', size = 1),    # increase the size of font
          axis.line.y = element_line(color='black', size = 1),    # increase the size of font
          strip.text = element_text (size = 8, color = 'black'), # size of text in strips, face = "bold"
          panel.spacing = unit(3, "lines")
    ) 
```

We fitted our data with HDDM, using the response-coding [See also, @Hu_2020_GoodSelf]. We estimated separate drift rate ($v$), non-decision time ($T_{0}$), and boundary separation ($a$) for each condition. We found that the shapes tagged with good person has higher drift rate and higher boundary separation than shapes tagged with both neutral and bad person. Also, the shapes tagged with neutral person has a higher drift rate than shapes tagged with bad person, but not for the boundary separation. Finally, we found that shapes tagged with bad person had longer non-decision time (see Figure \@ref(fig:plot-exp1a-HDDM)).


