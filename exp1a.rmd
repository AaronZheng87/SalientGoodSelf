## Experiment 1a 
### Methods
#### Participants
`r df1a.T.basic$N` college students (`r df1a.T.basic$Nf` female, age = `r df1a.T.basic$Age_mean` $\pm$ `r df1a.T.basic$Age_sd` years) participated. `r df1a.T.basic$N_thu` of them were recruited from Tsinghua University community in 2014; `r df1a.T.basic$N_wzu` were recruited from Wenzhou University in 2017. All participants were right-handed except one, and all had normal or corrected-to-normal vision. Informed consent was obtained from all participants prior to the experiment according to procedures approved by the local ethics committees. `r nrow(df1a.excld.sub)` participant’s data were excluded from analysis because nearly random level of accuracy, leaving `r df1a.v.basic$N` participants (`r df1a.v.basic$Nf` female, age = `r df1a.v.basic$Age_mean` $\pm$ `r df1a.v.basic$Age_sd` years).

#### Stimuli and Tasks
Three geometric shapes were used in this experiment: triangle, square, and circle. These shapes were paired with three labels (bad person, good person or neutral person). The pairs were counterbalanced across participants. 

#### Procedure
This experiment had two phases. First, there was a brief learning stage. Participants were asked to learn the relationship between geometric shapes (triangle, square, and circle) and different concepts of moral character (bad person, a good person, or a neutral person). For example, a participant was told, “bad person is a circle; good person is a triangle; and a neutral person is a square.” After participants remembered the associations (usually in a few minutes), they started a practicing phase of matching task which had the exact task as in the experimental task. 

In the experimental task, participants judged whether shape–label pairs, which were subsequently presented, were correct (i.e., the same as they learned). Each trial started with the presentation of a central fixation cross for 500 ms. Subsequently, a pairing of a shape and label (good person, bad person, and neutral person) was presented for 100 ms. The pair presented could confirm to the verbal instruction for each pairing given in the training stage, or it could be a recombination of a shape with a different label, with the shape–label pairings being generated at random. The next frame showed a blank for 1100ms. Participants were expected to judge whether the shape was correctly assigned to the person by pressing one of the two response buttons as quickly and accurately as possible within this timeframe (to encourage immediate responding). Feedback (correct or incorrect) was given on the screen for 500 ms at the end of each trial, if no response detected, “too slow” was presented to remind participants to accelerate. Participants were informed of their overall accuracy at the end of each block. The practice phase finished and the experimental task began after the overall performance of accuracy during practice phase achieved 60%. 

For participants from the Tsinghua community, they completed 6 experimental blocks of 60 trials. Thus, there were 60 trials in each condition (bad-person match, bad-person nonmatch, good-person match, good-person nonmatch, neutral-person match, and neutral-person nonmatch). For the participants from Wenzhou University, they finished 6 blocks of 120 trials, therefore, 120 trials for each condition.

#### Data analysis
As described in general methods section, we used Bayesian Bayesian Hierarchical Generalized Linear Model for hypothesis testing and Hierarchical drift diffusion model. We also included the classic NHST results in the online supplementary results. 
 <!-- Shall I write more about HDDM here, or just refer the interested reader to the paper? -->

### Results
#### Hypothesis testing

```{r 'ex1a-dprime-rt', fig.cap="RT and *d* prime of Experiment 1a.", fig.height=6, fig.width=10, warning=FALSE}
p_1a_d_rt <- Val_plot_NHST(df.rt = df1a.v.rt_m, df.d = df1a.v.dprime_l)
```

<!-- Here I briefly checked the pattern of accuracy -->
```{r}
df.plot <- df1a.v %>%
        dplyr::group_by(Subject, Matchness, Valence) %>%
        dplyr::summarise(mean_acc = mean(ACC)) %>%
        dplyr::ungroup() %>%
        dplyr::group_by(Matchness, Valence) %>%
        dplyr::summarise(grand_mean_acc = mean(mean_acc))
    #dplyr::filter(Matchness == 'Match') %>%  # select matching data for plotting only.
    #dplyr::rename(RT = RT_m) %>%
    #dplyr::full_join(., df.d) %>%  
    #tidyr::pivot_longer(., cols = c(RT, dprime), 
    #                    names_to = 'DVs', 
    #                    values_to = "value") %>% # to longer format
    dplyr::mutate(Valence =factor(Valence, levels = c('Good','Neutral', 'Bad')),
                  DVs = factor(DVs, levels = c('RT', 'dprime')),
                  # create an extra column for ploting the individual data cross different conditions.
                  Conds = mosaic::derivedFactor("1" = (Valence == 'Good'), 
                                                "2" = (Valence == 'Neutral'),
                                                "3" = (Valence == 'Bad'),
                                                method ="first", .default = NA),
                  Conds = as.numeric(as.character(Conds)),
    ) 
```

##### d prime
```{r 1a_dprime_BGLM, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
exp1a_sdt_m1 <- fun_sdt_val('1a')

summary(exp1a_sdt_m1)    # check summary

# brms::pp_check(exp1a_sdt_m1) # posterior predictive check
# bayesplot::pp_check(exp1a_sdt_m1)

hypothesis(exp1a_sdt_m1, "ValenceGood:ismatch > ValenceNeutral:ismatch")  # 0.97
hypothesis(exp1a_sdt_m1, "ValenceGood:ismatch > ValenceBad:ismatch")      # 1
hypothesis(exp1a_sdt_m1, "ValenceNeutral:ismatch > ValenceBad:ismatch")   # 0.91
hypothesis(exp1a_sdt_m1, "ValenceGood > ValenceNeutral")  # 0.82
hypothesis(exp1a_sdt_m1, "ValenceGood > ValenceBad")      # .95
hypothesis(exp1a_sdt_m1, "ValenceNeutral > ValenceBad")   # 0.81

## Get the predicted responses?
## pp <- predict(exp1a_sdt_m1)

# plot d prime
exp1a_sdt_p <- exp1a_sdt_m1 %>%
  emmeans::emmeans( ~ ismatch | Valence) %>%
  tidybayes::gather_emmeans_draws() %>%
  dplyr::mutate(ismatch = ifelse(ismatch == 0, 'criterion', 'd prime'),
                ismatch = factor(ismatch, levels = c('d prime', 'criterion')),
                Valence = factor(Valence, levels = c('Good', 'Neutral',  'Bad'))) %>%
  dplyr::filter(ismatch == 'd prime') %>%
  dplyr::mutate(DV = 'd prime') %>%
  ggplot2::ggplot(aes(x = Valence, y = .value)) +
  tidybayes::stat_halfeye() + # position=position_dodge(width = 0.1)
  stat_summary(aes(group = NA), fun.y = mean, geom = "line") +
  ylab(expression(paste("Sensitivity ",italic("d'"), sep = ' '))) +
  #facet_grid(cols = vars(ismatch), scales = "free_y") +
  theme_classic() + 
  theme(axis.title.x = element_blank())

## plot d prime and c as scatter points?
# exp1a_sdt_p %>%  tidyr::pivot_wider(., id_cols = c('.draw', 'Valence'), names_from = 'ismatch', values_from = '.value')  %>%
#   ggplot2::ggplot(., aes(x = `d prime`, y = criterion, group = Valence, color = Valence)) +
#   geom_point() + 
#   scale_colour_brewer(palette = "Dark2") +
#   scale_fill_brewer(palette = "Dark2") +
#   #facet_grid(~ matchness) +
#   ylab(expression(paste("Criterion ",italic("c"), sep = ' '))) +
#   xlab(expression(paste("Sensitivity ",italic("d'"), sep = ' '))) +
#   theme_bw() +
#     theme(panel.grid.major = element_blank(),
#           panel.grid.minor = element_blank(),
#           panel.background = element_blank(),
#           panel.border = element_blank(),
#           text=element_text(family='Times'),
#           legend.title=element_blank(),
#           legend.text = element_text(size =8),
#           plot.title = element_text(lineheight=.8, face="bold", size = 9, margin=margin(0,0,10,0)),
#           axis.text = element_text (size = 8, color = 'black'),
#           axis.title = element_text (size = 8),
#           #axis.title.x = element_blank(),
#           #axis.title.y = element_blank(),
#           axis.line.x = element_line(color='black', size = 1),    # increase the size of font
#           axis.line.y = element_line(color='black', size = 1),    # increase the size of font
#           strip.text = element_text (size = 8, color = 'black'), # size of text in strips, face = "bold"
#           panel.spacing = unit(3, "lines")
#     ) 
```
We fitted a Bayesian hierarchical GLM for signal detection theory. The results showed that when the shapes were tagged with labels with different moral character, the sensitivity ($d'$) and criteria ($c$) were both influenced. For the $d'$, we found that the shapes associated with good person (2.46, 95% CI[2.21 2.72]) is greater than shapes tagged with moral bad (2.07, 95% CI[1.83 2.32]), $P_{PosteriorComparison} = 1$. Shape tagged with morally good person is also greater than shapes tagged with neutral person (2.23, 95% CI[1.95 2.49]), $P_{PosteriorComparison} = 0.97$. Also, the shapes tagged with neutral person is greater than shapes tagged with morally bad person, $P_{PosteriorComparison} = 0.92$. 

Interesting, we also found the criteria for three conditions also differ, the shapes tagged with good person has the highest criteria (-1.01, [-1.14 -0.88]), followed by shapes tagged with neutral person(-1.06, [-1.21 -0.92]), and then the shapes tagged with bad person(-1.11, [-1.25 -0.97]). However, pair-wise comparison showed that only showed strong evidence for the difference between good and bad conditions.

##### Reaction times
```{r 1a_rt_BGLM, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
exp1a_rt_m1 <- fun_rt_val('1a')

#plot(exp1a_rt_m1, "b_")
summary(exp1a_rt_m1)  # n
# pp_check(exp1a_rt_m1)

# Population-Level Effects: 
#                    Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
# Intercept              -0.30      0.02    -0.33    -0.26 1.02      288      642  # baseline: mismatch:neutral = -.3
# ValenceBad              0.00      0.01    -0.01     0.01 1.00     3611     3116  # mismatch:neutral + mismatch:bad  = -.3
# ValenceGood             0.00      0.01    -0.01     0.01 1.00     2749     2691  # mismatch:neutral + mismatch:Good = -.3
# ismatch                -0.07      0.01    -0.09    -0.06 1.00     2203     2371  # mismatch:neutral + ismatch = (-0.30) + (-0.07) = -0.37
# ValenceBad:ismatch      0.02      0.01     0.00     0.05 1.00     2451     2495  # mismatch:neutral + ismatch + match:bad  = (-0.30) + (-0.07) + 0.02 = -0.35
# ValenceGood:ismatch    -0.04      0.02    -0.07    -0.01 1.00     1911     2326  # mismatch:neutral + ismatch + match:good = (-0.30) + (-0.07) +-0.04 = -0.41

hypothesis(exp1a_rt_m1, "ismatch < 0")  # Effect of matchness: Match < nonmatch, p = 1
hypothesis(exp1a_rt_m1, "ValenceGood:ismatch < 0")  # Match good < Match Neutral, p = 0.99
hypothesis(exp1a_rt_m1, "ValenceBad:ismatch > 0")   # Match Bad > Match Neutral, p = 0.99
hypothesis(exp1a_rt_m1, "(ValenceGood:ismatch - ValenceBad:ismatch) < 0")   # Match Good < Match Bad, p = 1

## Get the predicted responses?
# pp <- predict(exp1a_rt_m1)

# plot matching
exp1a_rt_p <- exp1a_rt_m1 %>%
  emmeans::emmeans( ~ ismatch | Valence) %>%
  tidybayes::gather_emmeans_draws() %>%
  dplyr::mutate(ismatch = ifelse(ismatch == 0, 'nonmatch', 'match'),
              Valence = factor(Valence, levels = c('Good', 'Neutral',  'Bad'))) %>%
  dplyr::filter(ismatch == 'match') %>%  # only plot the match trials
  dplyr::rename(log_RT = .value) %>%
  dplyr::mutate(`Reaction times (ms)` = exp(log_RT)*1000) %>%
  ggplot2::ggplot(aes(x = Valence, y = `Reaction times (ms)`)) +
  tidybayes::stat_halfeye() +
  ggplot2::stat_summary(aes(group = NA), fun.y = mean, geom = "line") +
  #facet_grid(~ ismatch) +
  theme_classic() + 
  theme(axis.title.x = element_blank())

# exp1a_p <- exp1a_rt_p %>%
#   rbind(exp1a_sdt_p) %>%
#   dplyr::mutate(DV=factor(DV, levels = c('Reaction times (ms)', 'd prime'))) %>%
#   ggplot2::ggplot(aes(x = Valence, y = `.value`)) +
#   tidybayes::stat_halfeye() +
#   ggplot2::stat_summary(aes(group = NA), fun.y = mean, geom = "line") +
#   facet_wrap( ~ DV, scales = "free_y", nrow = 1) +
#   # facet_grid(cols = vars(label), scales = "free_y") +
#   theme_classic() + 
#   theme(axis.title.x = element_blank())
```

```{r plot-exp1a-BGLM, fig.cap="Exp1a: Results of Bayesian GLM analysis.", fig.height=4.5, fig.width=9, warning=FALSE}
#library(patchwork)
#exp1a_rt_p + exp1a_sdt_p + plot_annotation(tag_levels = 'A')  + plot_layout(nrow = 1, byrow = FALSE)
```

We fitted a Bayesian hierarchical GLM for RTs, with a log-normal distribution as the link function. We used the posterior distribution of the regression coefficient to make statistical inferences. As in previous studies, the matched conditions are much faster than the mismatched trials ($P_{PosteriorComparison} = 1$). We focused on matched trials only, and compared different conditions: Good is faster than the neutral, $P_{PosteriorComparison} = .99$, it was also faster than the Bad condition, $P_{PosteriorComparison} = 1$. And the neutral condition is faster than the bad condition, $P_{PosteriorComparison} = .99$. However, the mismatched trials are largely overlapped. See Figure \@ref(fig:plot-exp1a-BGLM).

#### HDDM

```{r plot-exp1a-HDDM, fig.cap="Exp1a: Results of HDDM.",  fig.height=4.5, fig.width=9, warning=FALSE}
df1a.hddm.group.trace <- read_csv(here::here('HDDM','df1a_group_traces.csv'))

params_p <- df1a.hddm.group.trace %>%
  dplyr::mutate(sample = 1:nrow(.)) %>%
  dplyr::select(chain, sample, contains('Match') | contains('Mismatch')) %>%
  tidyr::pivot_longer(.,`a(Match.Bad)`:`t(Mismatch.Neutral)`, names_to = 'conditions', values_to = 'value') %>%
  tidyr::separate(., conditions, into = c('v1', 'valence'), sep= '[.]') %>%       # split into two part
  tidyr::separate(., v1, into = c('param', 'matchness'), sep = '[(]') %>%         # further split the first half into two part
  dplyr::mutate(valence = stringr::str_sub(.$valence, start = 1, end = -2)) %>%   # remove the last two elements ') ' from the strings
  dplyr::arrange(., param) %>%
  tidyr::pivot_wider(., id_cols = c('chain', 'sample', 'matchness', 'valence'), names_from = 'param', values_from = 'value')

p_1a_hddm <- params_p %>% 
  dplyr::mutate(valence = factor(valence, levels = c("Good", "Neutral", "Bad")),
                matchness = ifelse(matchness == 'Mismatch', 'Nonmatch', matchness)) %>%
  dplyr::filter(matchness == 'Match') %>%
  ggplot2::ggplot(., aes(x = v, y = a, group = valence, color = valence)) +
  geom_point() + 
  scale_colour_brewer(palette = "Dark2") +
  scale_fill_brewer(palette = "Dark2") +
  # facet_grid(~ matchness) +
  ylab(expression(paste("Boundary separation ",italic("a"), sep = ' '))) +
  xlab(expression(paste("Drift rate ",italic("v"), sep = ' '))) +
  theme_bw()+
    theme(panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          panel.background = element_blank(),
          panel.border = element_blank(),
          text=element_text(family='Times'),
          legend.title=element_blank(),
          legend.text = element_text(size =8),
          legend.position="bottom",
          plot.title = element_text(lineheight=.8, face="bold", size = 9, margin=margin(0,0,10,0)),
          axis.text = element_text (size = 8, color = 'black'),
          axis.title = element_text (size = 8),
          #axis.title.x = element_blank(),
          #axis.title.y = element_blank(),
          axis.line.x = element_line(color='black', size = 1),    # increase the size of font
          axis.line.y = element_line(color='black', size = 1),    # increase the size of font
          strip.text = element_text (size = 8, color = 'black'), # size of text in strips, face = "bold"
          panel.spacing = unit(3, "lines")
    ) 
```

We fitted our data with HDDM, using the response-coding [See also, @Hu_2020_GoodSelf]. We estimated separate drift rate ($v$), non-decision time ($T_{0}$), and boundary separation ($a$) for each condition. We found that the shapes tagged with good person has higher drift rate and higher boundary separation than shapes tagged with both neutral and bad person. Also, the shapes tagged with neutral person has a higher drift rate than shapes tagged with bad person, but not for the boundary separation. Finally, we found that shapes tagged with bad person had longer non-decision time (see Figure \@ref(fig:plot-exp1a-HDDM)).


